#+TITLE: LuneScript のマクロ展開
#+DATE: 2023-09-25
# -*- coding:utf-8 -*-
#+LAYOUT: post
#+TAGS: LuneScript
#+AUTHOR: ifritJP
#+OPTIONS: ^:{}
#+STARTUP: nofold

しばらく停止していた「LuneScript のセルフホストビルド時間 1 秒切り活動」を再開。

CPU を買い替えれば、ほぼ間違いなく 1 秒切れそうだがそれは最終手段なので、
その前になんとか 1 秒切りを達成したい。

* 現状確認

そんな訳で、まずはどの処理にどれだけ時間がかかっているか？を確認する。

go の pprof は便利だが、現状は pprof の Graph, Flame Graph を見ても
どの処理も満遍なく時間がかかっているようにしか見えないため、
改善個所を見けるのが困難だ。

そこで、以前から仕込んでおいた自前のログを元に、ボトルネックがあるかどうかの確認を進める。

ただ、ログだとイマイチ相関関係が掴み難いので、可視化することにした。
この可視化には、PLANTUML のタイミング図生成機能を利用する。
PLANTUML を利用するため、ログを解析し、
可視化に必要な情報をピックアップして PLANTUML の書式に変換するスクリプトを組んだ。


LuneScript は、多くの goroutine が同時に動作する。
goroutine 数はビルド対象に依存して変わるが、
現状のセルフホストビルドの場合は 265 個の goroutine が起動している。

なので、全ての goroutine の処理状況をそのまま可視化しても、
そこから有益な情報を得るのは難しいだろう。

そこで、まずは可視化前のログの情報からどこに一番時間がかかっていそうかを調べると、
AST 生成処理に掛っていそうだと分った。
LuneScript の内部構造的にも、 AST 生成処理が一番重そうなのはあっていそうだ。

ということで、ログから AST 生成処理に着目してグラフ化する。

この AST 生成処理グラフを見ると、明らかに想定外な結果になっていることが分った。
ただ、これは単にログが足らないだけだったので、ログを追加してグラフを補完していった。

そして、補完したフラフの中から次のモノを抽出した。

[[../bottle_neck.svg]]

これは、あるソースの AST 解析の時間経過と、
その経過時間の時に解析しているソースコードの行番号の相関を表わす図である。
多くの場合、経過時間と行番号は 1 次関数的な関係に近くなるはずだが、
このグラフでは、
破線で区切った最初と最後と途中の 3 つの領域で明らかに傾向が異なる。
というか、最初と最後は同じ傾向だが、途中の領域が他と比べて明らかに時間がかかっている。

そこで、この解析対象のソースコードの内容(800行〜2400行辺り)を確認すると、
マクロを多用していることが分った。
さらに、このソースコードだけに絞って pprof を確認すると、
マクロ展開部に多くの時間がかかっていることが確認できた。

以上のことから、このマクロ展開処理を改善するのが、
LuneScript のセフルホストビルドの速度改善につながると判断した。

* マクロ展開処理

マクロ展開処理に想定外の時間がかかっていることが分ったが、
では LuneScript のマクロ展開とは具体的に何をやっているのかを説明する。
しかし、マクロ展開を説明するには、
その前に AST 解析処理の説明をする必要があるので、まずはそちらの概要から説明する。

LuneScript では、次のフローで AST 解析を行なっている。

- Tokenizer で対象のソースコードから Token を切り出す
- Token を Syntax に当て嵌め AST の Node を生成していく
- Node がマクロ展開だった場合、
  そのマクロ定義を展開し、展開した内容を元に Token 切り出しから Node 生成を行なう。  

この「マクロ定義を展開し、展開した内容を元に Token 切り出しから Node 生成を行なう」のに、
想定以上の時間がかかってしまっているのが現状だ。

ただ、ここで一つ疑問が浮ぶ。それは、「マクロ定義を展開し、展開した内容を元に Token 切り出しから Node 生成を行なう」
の処理の内、後半の「展開した内容を元に Token 切り出しから Node 生成を行なう」は、
通常の AST 解析処理とほとんど変わらない処理のはずである。

であるのに、先ほどのグラフを見ると、
他のマクロを利用していない個所と比べると異様なまでに時間が掛ってしまっている。

ということは、前半の「マクロ定義を展開」の部分に時間がかかっている、と考えられる。


この「マクロ定義を展開」が何をやっているのかを説明するには、
Tokenizer の処理をもう少し深掘りする必要がある。

Tokenizer は、
解析対象のコードを LuneScript で定義している Token 毎に切り出すのが責務である。

なお、 Tokenizer は次の =getToken()= と =pushback()= の API を持つ。

- =getToken()= は、コードから切り出した Token を順次返す API である。
- =pushback()= は、 取得した Token を一時的に Tokenizer に戻す API である。
  =pushback()= で戻した Token は、次の =getToken()= コール時に取得される。

例えば、次のようなコードの場合、

#+BEGIN_SRC lns
macro _hoge() {
  print( "aaa" );
}
_hoge();
#+END_SRC

=getToken()= を実行すると次の Token が順次取得できる。

: 'macro', '_hoge', '(', ')', '{', 'print', '(', '"aaa"', ')', ';', '}', '_hoge', '(', ')', ';"

この取得した Token を元に、
LuneScript の Syntax に当て嵌めて AST の Node を生成していく。

- AST 解析処理は、上記の Token ='macro'= を読み込んだ時点でマクロの定義を認識する。
- そして、Token ='}'= を読み込んだ時点でマクロ定義処理が終了する。
- さらに、次の Token ='_hoge', '(', ')'= から、 =_hoge= マクロ展開を認識し、
  =_hoge= マクロに定義されている次の 5 つの Token が =pushback= される。

: 'print', '(', '"aaa", ')', ';"

- この =pushback= されたトークンが、通常の AST 解析によって処理される。



このように、「マクロ定義を展開」は、
そのマクロに定義されている Token を =pushback= することで、実現している。


大抵、マクロ展開はそのマクロ展開を指定するために必要なコード量よりも、
展開されるコード量の方が多くなる。
よって、マクロを多用すると書いてあるコード量よりも時間が掛るのは、
ある意味で当然とも言える。

しかし、それだけで上記のグラフに現れるほど重くなるのか？というと疑問である。

そこで、次のグラフを用意した。

[[../node_graph.svg]]

これは先ほどのグラフに、経過時間に対する Node 数との相関を表わすグラフを追加している。

これを見ると、先ほどのグラフと同じ傾向であることが読み取れる。
つまり、マクロ展開されたコードによって処理する Node は増えるが、
その増えた Node 数よりも処理時間が増えていることが分かる。

以上から、「マクロ定義を展開」処理を改善する方向で考える。


* マクロ展開トークンのキャッシュ

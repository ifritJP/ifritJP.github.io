{"categories":[],"posts":[{"content":"  皆さんはキーボードのキーを入れ替えてますか？ キー入れ替えのメジャーな用途は、 Ctrl キーと Cap Lock キーの入れ替えでしょう。  そのような人は、 「OS のキー入れ替え設定」するのが新しい PC セットアップ時の手順の一つに なっている人も少なくないでしょう。  しかし、「OS のキー入れ替え設定」が常に出来るとは限りません。 例えば、共有 PC を使うケースや、 そもそも OS がキー入れ替えをサポートしていないケースなど。  そのような時に使うことを想定して作ったのが、Hardware Keyboard Remapper です。 Hardware Keyboard Remapper とは   今回作成した Hardware Keyboard Remapper は、 接続されているキーボードのキー入力を、 別のキー入力に変換して出力するプログラムで、 Raspberry pi zero w (以降 pi0w と略記)上で動作します。 構成   Hardware Keyboard Remapper は、以下の構成になります。 Bluetooth keyboard ===(Bluetooth)==\u0026gt; Raspberry pi zero w ===(USB)==\u0026gt; PC   pi0w と Bluetooth keyboard を予めペアリングしておき、 その pi0w を HID Keyboard として を PC に接続します。 そして、 BT keyboard のキー入力を pi0w 内で 任意の HID keyboard コードに変換して PC に通知することで、 OS に依存しないキーの置き換えを実現しています。  なお、半導体不足の影響か、現在 pi0w の入手性が著しく悪くなっています。 そのうち raspberry pi zero 2 w が発売されるとは思いますが、 それも日本で入手できるのは暫く先になりそうです。  しかし、ソフトウェアエンジニアなら、 使っていない pi0w の 1 台や 2 台程度、家に転がっていると思うので、 問題ないでしょう。  ちなみに、 M5stack を使って同じようなものを作ろうと取り組んでいる最中ではあります。 ただし、そちらは PC へのキー入力が USB ではなく、 BT になりそうです。 使用方法   残念ながら「アプリを実行すれば使える」という程お手軽なモノではありません。  ここでは、raspberry pi をセットアップした経験があることを前提に、 使用方法をします。  まず、簡単に手順をまとめると以下になります。    pi0w と BT keyboard をペアリング    pi0w の USB Gadget を有効化    github から hw-key-remapper を clone    pi0w の USB Gadget の HID キーボードを登録    Key をカスタマイズ pi0w と BT keyboard をペアリング     ペアリングは次の手順で行ないます。    BT keyboard をペアリング開始状態にする    以下を pi0w で実行   $ sudo bluetoothctl [bluetooth]# default-agent [bluetooth]# scan on     暫くすると、キーボードが検出され以下のような出力がされる   [NEW] Device XX:XX:XX:XX:XX:XX hogehogeKeyboard     目的のキーボードであることを確認し、 この XX:XX:XX:XX:XX:XX の情報をもとに以下を実行する   [bluetooth]# pair XX:XX:XX:XX:XX:XX [bluetooth]# trust XX:XX:XX:XX:XX:XX [bluetooth]# connect XX:XX:XX:XX:XX:XX [bluetooth]# exit   以上の設定を行なっておけば、次回からは自動でペアリングされます。  なお、ここで重要なのは trust しておくことです。 trust しておかないと、 再接続する時にまた操作が必要になります。 github から hw-key-remapper を clone   pi0w で以下を実行します。  ※ 事前に golang 1.15 以降をインストールしておきます。 git clone --depth 1 https://github.com/ifritJP/hw-key-remapper.git cd hw-key-remapper go build  pi0w の USB Gadget を有効化   pi0w の /boot/config.txt に以下を追加します。 [all] dtoverlay=dwc2   pi0w の /etc/modules に以下を追加します。 dwc2  注意   pi0w の RNDIS 通信を有効にしている場合、 以下を /boot/cmdline.txt に追加していると思います。 modules-load=dwc2,g_ether   この指定は外してください。 これを設定していると、 pi0w を HID キーボード化できません。  後のステップで、別の方法で RNDIS を有効化します。  なお、 以下の作業は RNDIS 経由の ssh ではなく、 WiFi 経由の ssh か、あるいは pi0w のコンソールで直接作業してください。  また、RNDIS 経由の ssh で作業していた場合は、 一旦 raspberry pi を再起動してください。 pi0w の USB Gadget で HID キーボードを登録   clone した hw-key-remapper のディレクトリに移動し、 pi0w で以下を実行します。 sudo bash usb_gadget/rndis_hid.sh   これで、 pi0w が RNDIS と HID の複合デバイスとして構築されます。  以下のコマンドで、 hid デバイスと NIC に usb が pi0w 上に認識されていることが確認できます。 ls /dev/hid* ip a   なお、 sudo bash usb_gadget/rndis_hid.sh を手動で実行するのは面倒なので、 /etc/rc.local に以下を追加します。 bash フルパスusb_gadget/rndis_hid.sh   rc.local ではなく、サービスとして追加するのがカッコいいのかもしれないですが、 usb_gadget/rndis_hid.sh は一度 on すると、 動的に off が正常にできないっぽいので、今回はカッコ良さは求めません。  pi0w に接続している PC が windows OS であれば、 この状態でコントロールパネルの「デバイスとプリンター」に、 次の名前のデバイスが登録されているはずです。 Linux USB Gadget/RNDIS+HID   これが RNDIS と HID の複合デバイスになります。  HID はドライバの設定等は不要です。 一方で、RNDIS を利用する場合は、別途ドライバの設定をしてください。 ドライバの更新 → 手動 → 一覧から選択 → ネットワークアダプタ → Microsoft → リモート NDIS 互換デバイス   なお、ここまで設定しておくと、 次回の ppi0w の起動時に「不明なUSBデバイス(デバイス記述子要求の失敗)」として 認識されますが、30秒程度で正常に複合デバイスとして認識されます。 キー変換プログラムを登録   キー変換プログラムは、次のモードを持ちます。    input event デバイス名のリスト出力    input event デバイスから入力されているキー情報出力    input event デバイスから入力されているキー情報を変換して HID キーボードとして出力 デバイス名の取得     まずは、以下を実行し「input event デバイス名のリスト出力」して、 デバイス名をメモっておきます。 sudo ./hw-keyboard-remapper -mode list   なお以下の場合、Keyboard のデバイス名がリストに出力されないので注意してください。    BT Keyboard がペアリングされていない    BT Keyboard が省電力モードに入って接続が切れている    なお、 vc4 がリストされますが、それはキーボードではなく VideoCoreIV チップです。 input event デバイスから入力されているキー情報出力   以下を実行し、キー入力を取得できているか確認します。 $ sudo ./hw-keyboard-remapper -mode scan -kb \u0026#34;XXXXXXXXXXXXXXX\u0026#34;   ここで、 \u0026#34;XXXXXXXXXXXXXXX\u0026#34; には先程メモしたキーボード名を指定します。  キーボードでキーを押すと、そのキー情報が出力されます。 例えば m j と入力すると、以下のような出力がされます。 DEBU[0002] [event] press key 50(0x32) KEY_M -\u0026gt; Keyboard m and M INFO[0002] data [0 0 16 0 0 0 0 0] DEBU[0003] [event] release key 50(0x32) KEY_M -\u0026gt; Keyboard m and M INFO[0003] data [0 0 0 0 0 0 0 0] DEBU[0003] [event] press key 36(0x24) KEY_J -\u0026gt; Keyboard j and J INFO[0003] data [0 0 13 0 0 0 0 0] DEBU[0004] [event] press key 36(0x24) KEY_J -\u0026gt; Keyboard j and J INFO[0004] data [0 0 13 0 0 0 0 0]   ここで、 press key 50(0x32) KEY_M は \u0026#34;m\u0026#34; の押下イベントが発生したことを示し、 50(0x32) は linux 側の \u0026#34;m\u0026#34; のキーコードを示します。 data [0 0 16 0 0 0 0 0] は HID コードの変換結果を示し、 3 バイト目の 16 は、 HID の \u0026#34;m\u0026#34; のコードを示します。  キーのカスタマイズは、この HID コードが重要になります。  この HID コードの詳細は、次の USB の規格書を参照してください。    各キーのコード情報は、以下の資料の 「10 Keyboard/Keypad Page (0x07)」 を参照    https://usb.org/document-library/hid-usage-tables-122      Ctl, Alt 等の modifier キー情報は、以下の資料の「8.3 Report Format for Array Items」を参照    https://www.usb.org/document-library/device-class-definition-hid-111      なお、 linux のキーコードから HID コードへの変換がバグっている可能性は否定できません。 ローカルで修正するか、 issue で報告するか、 pull request してください。 hw-keyboard-remapper の終了   pi0w に ssh でアクセスしている場合、 Ctrl-C すればプログラムは終了します。  しかし、 pi0w のコンソールから実行している場合、 全てのキー入力がこのプログラムに取られて効かないため、 Ctrl-C も無効です。  この状態からプログラムを終了させる場合、 pi0w に接続しているキーボードから以下(qwe を4回)を入力してください。 qweqweqweqwe   これで終了します。  なおこの文字列は、 「偶然のキータイプでは発生せずに、簡単に入力できる文字列」として使用しています。  qweqweqweqwe が「普通に使う文字列だ」というのであれば、 適宜コードを変更してください。 (もしかしたら、 steam でゲームしてたら qwe を使うこともあるのかも？) Key をカスタマイズ   単純に linux のキーコードから HID コードへ変換しても意味はないので、 HID コードを別のキーのコードに置き換えるように設定します。  置き換えは JSON ファイルで指定します。  JSON は次のような形式です。 リポジトリに config.json.sample を同梱しているので、適宜に編集してください。  なお、config.json を読み込ませるには、 -conf オプションで config.json のパスを指定してください。 { \u0026#34;InputKeyboardName\u0026#34;: \u0026#34;XXXXXXXXXXXXXXXXXXX\u0026#34;, \u0026#34;SwitchKeys\u0026#34;: [ { \u0026#34;Src\u0026#34;: 57, \u0026#34;Dst\u0026#34;: 224, \u0026#34;Comment\u0026#34;: \u0026#34;CaspLock -\u0026gt; L-Ctrl\u0026#34; }, { \u0026#34;Src\u0026#34;: 224 , \u0026#34;Dst\u0026#34;: 57, \u0026#34;Comment\u0026#34;: \u0026#34;L-Ctrl -\u0026gt; CaspLock\u0026#34; } ], \u0026#34;ConvKeyMap\u0026#34;: { \u0026#34;0x9\u0026#34;: [ { \u0026#34;modMask\u0026#34;: 1, \u0026#34;modResult\u0026#34;: 1, \u0026#34;Code\u0026#34;: 79, \u0026#34;modXor\u0026#34;: 1, \u0026#34;Comment\u0026#34;: \u0026#34;C-f -\u0026gt; right arrow\u0026#34; } ], \u0026#34;0x5\u0026#34;: [ { \u0026#34;modMask\u0026#34;: 1, \u0026#34;modResult\u0026#34;: 1, \u0026#34;Code\u0026#34;: 80, \u0026#34;modXor\u0026#34;: 1, \u0026#34;Comment\u0026#34;: \u0026#34;C-b -\u0026gt; left arrow\u0026#34; } ], \u0026#34;138\u0026#34;: [ { \u0026#34;modMask\u0026#34;: 34, \u0026#34;modResult\u0026#34;: 2, \u0026#34;Code\u0026#34;: 79, \u0026#34;modXor\u0026#34;: 2, \u0026#34;Comment\u0026#34;: \u0026#34;L-SHIFT-MUHENKAN -\u0026gt; right arrow\u0026#34; }, { \u0026#34;modMask\u0026#34;: 34, \u0026#34;modResult\u0026#34;: 32, \u0026#34;Code\u0026#34;: 80, \u0026#34;modXor\u0026#34;: 32, \u0026#34;Comment\u0026#34;: \u0026#34;L-SHIFT-MUHENKAN -\u0026gt; left arrow\u0026#34; } ] } }   JSON は以下の情報を持ちます。    InputKeyboardName    SwitchKeys    ConvKeyMap InputKeyboardName     接続する BT Keyboard 名を指定します。  コマンドラインに -kb オプション指定がある場合、-kb オプションを優先します。 SwitchKeys   置き換える HID キーコードのペアを指定します。    Src    置き換え元の HID キーコード。 integer。      Dst    置き換え先の HID キーコード。 integer。      Comment    コメントです。変換には関係ありません。      On    この置き換え情報が有効かどうかを示します。 bool。    このキーが存在しないか、 true を指定した場合、有効として扱います。    一時的に off にしたい場合に false を指定することを想定しています。      これは、単純にキーそのものを置き換えます。 例えば、 Ctrl と CapLock の置き換えのような時に利用します。  単純にキーそのものを置き換えるので、 「Shift を押しながら A を押した場合に、他のキーに置き換えたい」と いうような用途には使えません。  その場合は、 ConvKeyMap で指定します。 ConvKeyMap   ConvKeyMap は、 Ctrl や Shift などの modifier キーを押しながら他のキーを押した時の、 キーコード変換方法を定義します。  例えば C-f を押下したら → キーのコードを送る、なんてことも可能です。  ConvKeyMap は、次の要素からなります。 \u0026#34;ConvKeyMap\u0026#34;: { \u0026#34;key1\u0026#34;: [ {info}, ... ], \u0026#34;key2\u0026#34;: [ {info}, ... ], ... }     key    変換元の HID キーコードを文字列で指定します。    例えば f を押下した場合の動作を定義する場合、 \u0026#34;0x9\u0026#34; を指定します。    キーコードの表現は、16進数か 10 進数です。      info    変換条件を次の配列で指定します。    modMask    modifier のマスク値を指定します。      modResult    modifier のマスク結果を指定します。      Code    条件成立時の HID コードを指定します。      modXor    条件成立時の modifier の XOR 値を指定します。      Comment    SwitchKeys と同じです。      On    SwitchKeys と同じです。          ConvKeyMap で指定すると、次の条件が成り立つ時に動作します。 (modMask \u0026amp; modifier) == modResult   例えば Left-Ctrl が押下されていることを条件にするには、 modMask と modResult 両方に 1 を指定します。  以下のサンプルは、 C-f が押下された場合、 → に変換することを示します。 \u0026#34;0x9\u0026#34;: [ { \u0026#34;modMask\u0026#34;: 1, \u0026#34;modResult\u0026#34;: 1, \u0026#34;Code\u0026#34;: 79, \u0026#34;modXor\u0026#34;: 1, \u0026#34;Comment\u0026#34;: \u0026#34;C-f -\u0026gt; right arrow\u0026#34; } ],   ここで、modXor が 1 なので modifier に 1 が xor され、 結果的に出力される modifier の Left-Ctrl ビットが 0 になっていることに注意してください。  Shift キーが押された時のキーの入れ替えも同じように行ないます。  なお、 C-f を → に変換すると、 emacs では C-x C-f が C-x → になってしまうので、変換はオススメしません。 変換プログラムの実行   以下を実行します。 $ sudo ./hw-keyboard-remapper -conf config.json -v   これで config.json で設定した remap が反映され、 pi0w に接続した BT キーボードの入力が、 pi0w と USB 接続している PC に HID キーボードの入力として通知されます。  上記コマンドで動作を確認したら、/etc/rc.local に追加します。 nice -n -5 パス/hw-keyboard-remapper -conf パス/config.json \u0026gt; /del/null \u0026amp;   他のプログラムによってキー入力処理が滞ると、 キーリピートなどの現象に繋りやすくなるため、 nice で 優先度を上げて実行しています。 /etc/issue の編集   前述の通り、このプログラムを実行していると pi0w のコンソール上でキー入力が効かなくなる。 当然ログインも出来ない。  ssh 経由であれば作業できるが、 ssh を接続できないケースがある。 その時に、 qweqweqweqwe を入力すればキーボードが使えるようになるが、 そんな事は絶対に忘れるので、 pi0w の login プロンプトに警告を表示するように設定しておく。  /etc/issue に以下を設定しておくことで、メッセージが表示される。 =====\u0026gt; Keyboard is invalid now. To available the keyboard, enter \u0026#34;qweqweqweqwe\u0026#34;. Raspbian GNU/Linux 11 \\n \\l   なお、/etc/issue を編集する場合、 元のメッセージよりも前に設定せずに後に設定すると、 ssh 接続の鍵認証が出来なくなって、パスワード認証に切り替わってしまいました。 トラブルシューティング   dwc2 モジュールをロードした後、 USB Gadget に登録しないまま pi0w を PC に接続していると、 PC 側の USB 周りが不安定になることがありました。 「不明なUSBデバイス(デバイス記述子要求の失敗)」として認識されたまま、 放置するのが良くないようです。  環境依存かもしれませんが、dwc2 モジュールをロードした後は、 速やかに usb_gadget/rndis_hid.sh を実行してください。 rc.local に usb_gadget/rndis_hid.sh を設定しておけば、問題ありません。  なお、 usb_gadget/rndis_hid.sh は pi0w を RNDIS + HID デバイスにするスクリプトです。  RNDIS が不要で、 HID だけで良いという場合は usb_gadget/rndis_hid.sh の代わりに、 usb_gadget/hid.sh を実行すると HID だけを登録できます。  ただし、これも環境依存かもしれませんが、 usb_gadget/hid.sh 実行時も PC の USB 回りが不安定になりました。  よって usb_gadget/hid.sh は、 RNDIS を使いたくない人で、 かつ PC の USB 周りが不安定になるかどうか確認する人柱になっても良い人以外は オススメしません。 ","id":0,"section":"posts","summary":"皆さんはキーボードのキーを入れ替えてますか？ キー入れ替えのメジャーな用途は、 Ctrl キーと Cap Lock キーの入れ替えでしょう。 そのような人は、 「OS のキー","tags":null,"title":"Hardware Keyboard Remapper(OS に依存しないキーボードのキー入れ替え)を作った","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-01-10-hw-keyboard-remapper/","year":"2022"},{"content":"  4K ディスプレイが欲しくなったので調べものをしている。  液晶ディスプレイを選ぶ際、用途によってさまざまな観点でチェックするだろう。 しかし、誰もが気になるのは 「ドット抜け」 だろう。  そんな訳で、各メーカー毎のドット抜け保証についてまとめてみた。 ドット抜け保証まとめ   国内で購入可能なメジャーメーカーの保証状況を以下に示す。    順位 メーカー 保証内容 リンク     1? EIZO 1点もない (例外あり) リンク   2? ACER 中央に集中して3点以内、又は全面で７点以内 リンク   3? DELL 製品によって異なる。詳細は後述。 リンク   4 IO DATA ドット抜け 0.001% 未満 リンク   5 iiyama 0.001％以下 リンク   6 LG ドット抜け 0.01% 以下 リンク   8 BENQ 修理・交換対象外 リンク   - ASUS ※保証内容を見つけられず –    保証内容 1 位(？) EIZO   ドット抜け(無輝点) は 1 点もない ことが保証される。 ただし、黒点や光り方のムラなどは保証されない。  例えば、 黒点が大量にあっても保証外 ということになる。 なんだかイマイチな気がする。  一応 1 位にはしたが、 微妙なので 「1位(？)」 としている。 保証内容 2 位(？) ACER   次点は、 ACER の「中央に集中して3点以内、又は全面で７点以内」。 7点は多いと思うかもしれないが、 4K であれば 7 点は全体の 0.000085 % 未満なので非常に少ないと言える。 保証内容 3 位(？) DELL   次は DELL。 DELL はモデルによって保証内容が異なる。 一番良いモデルの保証は、 ACER と同レベルあるいは DELL の方が良いが、 そうでないモデルの場合は ACER に劣る。 よって、3 位(？) とする。  保証内容の詳細は、 上記表の ACER のリンクを参照すること。 保証内容 4 位 IO DATA   次は IO DATA で「ドット抜け 0.001% 未満」。  f0.001% というと、かなり少ない様に思うが、 4K だと 82 ドットとなる。 82 ドットは、これまでのメーカーと比べると桁違いに多いことが分かる。 保証内容 5 位 iiyama   次が iiyama で「ドット抜け 0.001% 以下」。  僅差だが、 IO DATA が 0.001% 「未満」なのに対し、 iiyama は 「0.001% 以下」となり、 iiyama は IO DATA の次となる。 保証内容 6 位 LG   次が LG の 「ドット抜け 0.01% 以下」。 これは酷い。 0.01% ということは 4K なら 829 ドットとなる。  いくらなんでも保証のレベルが低過ぎだろ。 大手の液晶パネルメーカーだからって、殿様商売しているんじゃなかろうか？ 保証内容 7 位 BENQ   次は BENQ の「修理・交換対象外」。 BENQ に関しては「ドット抜けは対応しない」と明言している。 とてもじゃないが、怖くて替えない。 保証内容 ランキング保留 ASUS   最後に、 ASUS は保証内容を見つけられなかったので、判断は保留。  ただし、「保証内容を見つけ易いところに掲載していない」ということ自体、印象が悪い。 メーカー内の品質規定   今回の調査は、ユーザクレームに対する保証だが、 メーカー内の品質規定がどうなっているのかは気になるところ。  例えば、出荷時は OK でも、 搬送途中などの衝撃によって異常が発生することは十分に考えられる。 それ以外にも、経年劣化等でドット抜けが発生こともある。  そのようなことを考えると、出荷時のドット欠け検査では、 ある程度のマージンを設けて品質チェックをしていることが考えられる。  その辺りはメーカーの内部機密なので、入手は困難だろう。 まとめ   私の経験上、ディスプレイを使ってきてドット抜けに装具した経験は滅多にない。  『滅多にない』ということは、 逆に言えば「あった」ということでもある。 ディスプレイは常時見て作業するものなので、 そこに欠陥があると集中を妨げる要因にもなる。  4K ディスプレイはかなりお手頃価格で購入できるようになっている。 とはいえ、気軽に買い替えるほどの値段でもない。  最低限の保証を受けられるメーカーを選択するべきだろう。  ただし、現実問題、保証の規定があったとしても、 サポート窓口が反応しない、等の別問題がある可能性はあるので、 その辺りは個人で判断して欲しい。  今回の調査結果を受けて、LG と BENQ, ASUS は候補から外した。 ","id":1,"section":"posts","summary":"4K ディスプレイが欲しくなったので調べものをしている。 液晶ディスプレイを選ぶ際、用途によってさまざまな観点でチェックするだろう。 しかし、誰もが","tags":null,"title":"液晶ディスプレイメーカーのドット抜け保証","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-12-05-display-dots/","year":"2021"},{"content":"  数ヶ月間 LuneScript から離れていますが、生存アピールのためにちょっと触れておきます  今日現在、 LuneScript は言語機能としてエラーハンドリングと大域脱出をサポートしていません。  現在でも、module 機能を利用して 裏技的にエラーハンドリングと大域脱出を使うことは出来なくもないです。 しかし、それはあくまでも裏技で正式機能ではありません。  「何故サポートしていないか？」というと、 エラーハンドリングと大域脱出のベストプラクティスが分からないためです。  なお、「今の LuneScript の言語仕様が全てベストプラクティスなのか？」と問われれば、 残念ながら違います。 しかし、 自分の中で納得した仕様 になっています。  一方で、「エラーハンドリングと大域脱出」に関しては、 イマイチ決めかねています。 エラーは例外か？   『エラー』を、『例外として投げて、投げられた例外を掴まえて処理する』という方法は、 よく使われています。 しかし、 この方法はなにか違う気がしています。  そもそも 『「例外」ってなんだ？』 という疑問が浮びます。  私は、「例外 == 普通は起らないような状態を表わすべきもの」と考えています。 例えば「kill ジグナルの受信」などが例外に該当すると思います。  しかし幾つかの言語では、 「正常系ではない異常系」を「例外」として扱かっているケースがあります。 例えば、「ファイルの書き込みに失敗した状態」が「例外」として扱われていたりします。  これは なにか違う 気がします。  何が違うって、「ファイルの書き込みに失敗した状態」なんていうのは、 良くあるケースです。 良くあるケースが「例外」って何か変じゃない？ と感じるんです。  プログラムっていうのは、エラー処理を含めて完成するものだと私は思います。 つまり、エラー処理って「例外」じゃないですよね？と考えています。  まぁ、ユースケース記述でいうところの「メインフロー、代替フロー、例外フロー」のうち、 「例外フロー」がエラー処理になるから、やっぱり「例外」じゃないか？ というツッコミはあると思います。 ですが、 ちょっとした操作ミス等で発生するエラーと、 普通は発生しないエラーとを「例外」という一つの概念で扱うのは間違っているんじゃないか？ と感じています。  たとえば Java では Error と RuntimeException と その他Exception とで、 これらエラーを区別して管理できるようになっていますが、 exception という 1 つの概念であることには違いありません。  区別できるという点では、Java のエラー種別は私の考えと一致しています。 しかし、 実際に Java でプログラムしているとメンドイなぁ、と思ってしまいます。  「メンドイ」と思ってしまうのは、「何かが違う」ということだと思います。  例えば nil 安全を実現する unwrap 等の処理は一手間かかりますが、 nil 安全によるメリットと、unwrap 等の一手間を天秤にかければ、 メリットの方が大きいと感じることができ、面倒とはそれほど思いません。  もちろん「それほど思わない」というのは「少しは思っている」ということであり、 nil 安全に関しても、もっと手間がかからない方法があるんじゃないか模索しています。  「例外」の良くないところは、 「エラー」と「大域脱出」が一括りに扱われてしまっているところだと思います。  「例外」が「 普通は発生しないエラー 」に限られるのであれば、 「大域脱出」とセットになっているのも理解できますし、合理的だと思います。 例えば、 kill シグナルを受けたら「大域脱出」するのは納得できますよね？  しかし上述した通り、「 ちょっとした操作ミス等で発生するエラー 」も 「例外」として扱う場合は、 「大域脱出」がセットになっているのは影響が大き過ぎると考えます。  「大域脱出」は最終手段であり、文法上も専用に扱わなければなりません。 この「専用の文法」が、「メンドイ」と感じる元になっています。  「 ちょっとした操作ミス等で発生するエラー 」は、 普通に発生する可能性があるものであり、 普通に発生するならば、 特別に扱うことなく普通に処理を書けるべきです。 go のエラーハンドリング   go のエラーハンドリングは error 型のデータを戻り値で返し、 それを処理することでエラーハンドリングしています。  なお、 error 型のデータはあくまでも関数の戻り値であって、大域脱出とは別ものです。  つまり、 go のエラーハンドリングは、特別に扱うことなく普通に処理が書けます。  この error 型によるエラーハンドリングは、 以下の go の特徴によって支えられています。    関数の多値返却    defer    特に defer は go の大きな特徴と言えます。  この仕様をパクって「LuneScript でエラーハンドリングをサポートする」ことも考えましたが、 LuneScript はトランスコンパイラであり、 go の特徴に依存する実現方法は採用すべきでない 、 ということもあって採用を見送っています。  defer がなくても error 型を追加すれば それなりのエラーハンドリングは実現出来ます。 しかし、go のエラーハンドリングは defer があってこそです。  そもそも、error 型を追加するだけなら、 LuneScript の言語仕様として組込まなくても ユーザプログラムレベルで実現できますし。。 LuneScript でのエラーハンドリング   上で例として挙げた go だけでなく、 Rust でも関数戻り値の Option, Result 型でエラーを扱っています。  エラー型を追加し、それを処理することでエラーハンドリングする、 というのは「 特別に扱うことなく普通に処理を書けるべき 」という 私の考えにも合致します。一方で go の defer は便利ですが、 トランスコンパイル先の言語仕様に大きく依存します。  今後対応するかもしれないトランスコンパイル先の言語で、 defer と同等の機能が実現できない、 あるいは実現できてもコストが大きくかかる、ということが容易に想像できます。  現状でも、Lua では簡単には defer を実現できません。  そんな訳で、LuneScript はエラーハンドリングと大域脱出をサポートしていません。  言語仕様に依存せず、且つ、 簡便にエラーハンドリングを記述できる方法を模索中です。  とはいえ、 そう遠くない未来に、 必要に迫られてなんらかの方法を対応しなければならなくなる気はしています。 ","id":2,"section":"posts","summary":"数ヶ月間 LuneScript から離れていますが、生存アピールのためにちょっと触れておきます 今日現在、 LuneScript は言語機能としてエラーハンドリングと大域脱出をサポートし","tags":null,"title":"LuneScript がエラーハンドリングと大域脱出をサポートできていない理由","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-11-14-lunescript-error-handling/","year":"2021"},{"content":"  VirtualBox/VMWare と WSL2 は共存可能です。 しかし、共存させると VirtualBox/VMWare 上の GuestOS にオーバーヘッドがかかります。  今回はオーバーヘッドの概要と、共存と排他の設定切り替え方法のネタです。 VirtualBox と WSL2 共存のオーバーヘッド   以下に VirtualBox と WSL2 の実行時の階層図を示します。   この図は、次の 4 つの状態を表わしています。    (A) 従来の Windows で VirtualBox を動かす状態    (B) Windows で WSL2 を動かす状態    (C) Windows で WSL2 と VirtualBox を動かす状態(異常時)    (D) Windows で WSL2 と VirtualBox を動かす状態(正常時)    (A) は、 WSL サポート前の Windows で VirtualBox を動かしていた状態です。 Windows 上に VirtualBox があり、 その上に GuestOS が動作していました。  (B) は、Windows で WSL2 を動かしている状態です。 WSL2 では、 ハードウェアの上に hypervisor があり、 その上に Windows カーネルと Linux kernel があります。  (C) は、WSL2 と VirtualBox を共存させようとしている状態です。 この場合 VirtualBox に × を付けていますが、 これは VirtualBox が動かないことを示しています。  Windows Kernel が hypervisor 上で動いている場合、 (A) の形態の VirtualBox は動きません。 VirtualBox を動かすには (D) のように 「Windowsハイパーバイザープラットフォーム」 が必要です。  これにより、 (D) の VirtualBox は (A) と比べると オーバーヘッドがあることが分かります。 アプリによってその影響度合いは異なりますが、 私の用途的に 約 100 〜 200% 程度の性能劣化 がありました。  WSL2 に移行し、 VirtualBox はほとんど使用しないようなケースでは、 VirtualBox にオーバーヘッドがあっても問題ありません。 しかし、「VirtualBox も捨て切れない」というケースもあると思います。  WSL2 への移行の過渡期などは特にそうなるでしょう。  そこで、 VirtualBox の 性能を重視した (A) と、 WSL2 との共存可能な (D) を切り替えて使うための方法 を 以下で示します。 VirtualBox/VMWare と WSL2 の共存と、 VirtualBox/VMWare 占有の切り替え方法   (D) の構成と (A) の構成を比べた場合、次の 2 つが異なります。    hypervisor    windows ハイパーバイザープラットフォーム    この 2 つの無効・有効を切り替えることで、 (D) と (A) を切り替えられます。  この 2 つの無効・有効を切り替えるには、 PC の再起動が必要 になります。 再起動が必要なのは、使い勝手に問題があると言わざるを得ないですが、 hypervisor がカーネルよりも下にあることを考えると、 有効・無効に再起動が必要になるのは仕方がないと納得するしかないです。。  なお、この 2 つの無効・有効の切り替え処理には、 さほど時間はかかりません。 これは、せめてもの救いです。 (D) から (A) に切り替える   (D) から (A) に切り替えるには、 管理者権限の power shell で以下を実行してから、 PC を再起動します。 # hypervisor の無効化 C:\\Windows\\System32\\bcdedit.exe /set hypervisorlaunchtype off # windows ハイパーバイザープラットフォームの無効化 Disable-WindowsOptionalFeature -online -featurename HypervisorPlatform -NoRestart   なお、 hypervisor だけ無効化し、 windows ハイパーバイザープラットフォーム が有効な状態だと、 本来は windows ハイパーバイザープラットフォーム を使わなくても VirtualBox は動くはずです。 しかし実際には、windows ハイパーバイザープラットフォームを使って 余計なオーバーヘッドがかかってしまうようです。  よって、2 つとも無効にする必要があります。 (A) から (D) に切り替える   (A) から (D) に切り替えるには、 管理者権限の power shell で以下を実行してから、 PC を再起動します。 # windows ハイパーバイザープラットフォームの有効化 Enable-WindowsOptionalFeature -online -featurename HypervisorPlatform -NoRestart # hypervisor の有効化 C:\\Windows\\System32\\bcdedit.exe /set hypervisorlaunchtype auto  まとめ   WSL や docker のような技術は軽くて便利ではありますが、 VirtualBox のようにハードウェアを仮想化する環境が 必要になるケースは今後もあるでしょう。  そのような時に、オーバーヘッドが気にならない程度に改善されることを期待します。  もしかしたら、 Win11 では既に改善されていたりするんだろうか？ ","id":3,"section":"posts","summary":"VirtualBox/VMWare と WSL2 は共存可能です。 しかし、共存させると VirtualBox/VMWare 上の GuestOS にオーバーヘッドがかかります。 今回はオーバーヘッドの概要と、共存と排他の設定切り替え方法の","tags":null,"title":"WSL2 共存による VirtualBox/VMWare の性能低下と、性能重視時の排他設定方法","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-11-08-wsl2-virtualbox/","year":"2021"},{"content":"  自作ツールで、MS Teams に対して投稿を read/write する方法について書きます。 Teams の管理者権限の許可が必須   「 Teams の管理者権限の許可が必須 」です。  大事なことなので始めに書きます。  自作ツールで、MS Teams に任意に投稿を read/write するには、 「 Teams の管理者権限の許可が必須 」です。  たとえ自分自身のアカウントを使って投稿したくても、 自作ツールから行なうには管理者権限の許可が必須 なんです。 MS Graph API へのアクセス   MS Graph API は、以下のサイトにリファレンスが載っています。  \u0026lt;https://docs.microsoft.com/ja-jp/graph/\u0026gt;  これの Teams の API を叩けばアクセスできます。  当然と言えば当然ですが、MS Graph API で Teams にアクセスするには、 その Teams のアカウント認証が必要です。  そして、アカウント認証するには、Azure から発行した ClientID を使用する必要があります。  なお、 CliendID の発行時に、クライアントの種別を指定します。 その種別には、 そのクライアントを登録したアカウントに属する組織のみにアクセスするクライアントか、 それとも組織を限定せずにアクセス可能なクライアントか、を指定します。  より具体的な説明は以下を参照してください。  リンク  Azure の CliendID 発行が出来るユーザは当然限られています。  個人で作った Azure アカウントなら、 自分が管理者でもあるので自由にクライアントを登録できますが、 誰かから発行された Azure アカウントなら、 その発行者(管理者)によって、制限されている可能性があります。  ここで、クライアント登録が出来ないのであれば、ほとんどの場合そこで終わりです。 token 取得   発行された ClientID を指定して、アカウント認証するのですが、 通常はブラウザのインタフェースを通して認証するのが一般的です。  ブラウザを介さずにアカウント認証する場合は、以下の手順になります。  \u0026lt;https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-auth-code-flow\u0026gt; permission   Graph API は、そのスコープごとにアクセス制御されます。  このアクセス制御に permission を与えることで、 API にアクセスできるようになります。  API に permission を与えるには権限が必要になります。 その権限には、個人アカウントで良いものと、管理者権限が必要なものとがあります。  なお、任意にメッセージを投稿するには、管理者権限による permission が必要です。 Teams への投稿   Teams へ投稿するには以下の API を利用します。  \u0026lt;https://docs.microsoft.com/ja-jp/graph/api/resources/teams-api-overview?view=graph-rest-1.0\u0026gt;  Teams のチームへの投稿は次の概念で管理され、 それぞれがユニークな ID を持っています。    team    Teams 内の各チーム      channel    各チーム内に作られるチャネル      message    チャネル内に投稿された各メッセージ      例えば、あるチーム内の、ある channel に 新規投稿する 場合、 対象チームの ID と、対象 channel の ID を取得し、 それら ID を指定してメッセージを投稿します。  新規投稿ではなく、 あるメッセージに対する reply には、 前述の対象チームの ID と、対象 channel の ID に加え、 対象のメッセージ ID を取得する必要があります。  このメッセージ ID を取得するには、 ChannelMessage.Read.All スコープの permission が必要であり、 その permission を与えるには管理者権限が必要になります。  なお、個人間のチャットはチームのメッセージとは異なります。 Graph Explorer   \u0026lt;https://developer.microsoft.com/en-us/graph/graph-explorer\u0026gt;  MS Graph API をブラウザから試すことができる Web ツール(Graph Explorer)が用意されています。  これを利用することで、 token 取得や permission の設定を簡単に行なえます。  なお、このツール上で token 取得はできますが、 その token は短時間で expire する access token なので、 実際にクライアントを自作する際には、 ClientID の発行が必須になります。 MS Graph API について   MS Graph API は、MS のさまざまなサービスにアクセスできる強力な API です。  ですが、強力であるために、セキュリティはかなり安全方面に振っているように思えます。 さまざまなケースで管理者権限による許可が必要になっています。  なんでもかんでも「管理者権限による許可が必要」というのは、 セキュリティの管理手法として、安直ではないのか？と思わないでもない。 ","id":4,"section":"posts","summary":"自作ツールで、MS Teams に対して投稿を read/write する方法について書きます。 Teams の管理者権限の許可が必須 「 Teams の管理者権限の許可が必須 」です。 大事なことなので","tags":null,"title":"MS Teams client の作り方","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-08-30-teams-client/","year":"2021"},{"content":"  asciidoctor-pdf を利用すると asciidoc を pdf 化できます。  ここでは、 asciidoctor-pdf のセットアップと pdf 化時のレイアウト変更方法について説明します。 asciidoctor-pdf のセットアップ   asciidoctor-pdf が既にインストールされている場合、 日本語フォントのインストール時に conflict することがあるので、 ここでは docker を利用します。  docker を使わなくても、ローカル環境に ruby をインストールし、 Dockerfile の RUN と同等の手順を実行してもインストールできます。 asciidoctor-pdf が conflict した場合は、 asciidoctor-pdf をアンインストールしてから asciidoctor-pdf をインストールしなおしてください。 Dockerfile   asciidoctor-pdf を利用するための Dockerfile は以下になります。 FROM alpine:3.14.0 RUN apk update; RUN apk --no-cache add \\ curl \\ bash \\ ruby # asciidoctor-pdf WORKDIR / RUN gem install asciidoctor RUN gem install --pre asciidoctor-pdf RUN gem install asciidoctor-pdf-cjk-kai_gen_gothic RUN asciidoctor-pdf-cjk-kai_gen_gothic-install RUN cp /usr/lib/ruby/gems/2.7.0/gems/asciidoctor-pdf-cjk-kai_gen_gothic-0.1.1/data/themes/KaiGenGothicJP-theme.yml / CMD [\u0026#34;/bin/bash\u0026#34;]  docker-compose  version: \u0026#39;3\u0026#39; services: 2pdf: build: ./ image: asciidoc2pdf container_name: asciidoc2pdf volumes: - \u0026#34;./:/proj\u0026#34; tty: true  変換   以下を実行して asciidoc から pdf を生成します。 $ docker-compose run 2pdf asciidoctor-pdf -a scripts=cjk -a pdf-theme=KaiGenGothicJP-theme.yml -a pdf-fontsdir=$(dirname $(gem which asciidoctor-pdf-cjk-kai_gen_gothic))/../data/fonts /proj/src.adoc   ここで src.adoc は変換元の asciidoc です。  実行すると src.pdf が生成されます。 pdf のレイアウト変更   asciidoctor-pdf を使って asciidoc から pdf に変換する際、 以下のオプションを指定しています。 -a pdf-theme=KaiGenGothicJP-theme.yml   これは、 PDF 変換に使用する theme を指定しています。  asciidoc には、最低限必要な文書情報だけで構成されているため、 「その文書情報をどのように PDF としてレイアウトするか？」は、 theme で制御します。  theme を変更することで、同じ asciidoc でも様々な形式の pdf に変換することができます。  これは、html と css の関係と似ています。  このような制御になるので、 変換元の asciidoc と、 その時に利用した theme ファイルはセットで保存しておくべきです。  次の公式ドキュメントに、この theme の詳細があるのでそちらを見れば良いですが、 ちょっと取っ掛り難いものがあるので、ここでは簡単に変更方法を説明します。  \u0026lt;https://github.com/asciidoctor/asciidoctor-pdf/blob/main/docs/theming-guide.adoc#alignments\u0026gt; theme.yml の変更   theme.yml は、 拡張子から分かるように YAML 形式になっています。  YAML 形式の詳細についてはここでは説明しませんが、 最低限「インデントに意味がある」ことに注意すれば、 theme.yml の変更程度であれば問題ありません。  まず、 先ほどの docker container から KaiGenGothicJP-theme.yml をローカルにコピーします。 sudo docker-compose run 2pdf cp /KaiGenGothicJP-theme.yml /proj   これをテキストエディタで開くと以下のようになります。  ここで font: , page: は、 theme のカテゴリです。 このカテゴリの下に、さらに別のカテゴリあるいは調整項目があります。 font:catalog:KaiGen Gothic JP:normal:KaiGenGothicJP-Regular.ttfbold:KaiGenGothicJP-Bold.ttfitalic:KaiGenGothicJP-Regular-Italic.ttfbold_italic:KaiGenGothicJP-Bold-Italic.ttfRoboto Mono:normal:RobotoMono-Regular.ttfbold:RobotoMono-Bold.ttfitalic:RobotoMono-Italic.ttfbold_italic:RobotoMono-BoldItalic.ttffallbacks:- KaiGenGothicJPpage:background_color:fffffflayout:portrait   それぞれの調整項目毎に値を設定するだけなので、 既に設定されている項目を変更すること自体は簡単にできます。  どのようなカテゴリ、調整項目があるかは、公式のドキュメントを参照してください。 設定項目のアクセス  base:font_color:333333font_family:KaiGenGothicJPfont_size:10.5line_height_length:15line_height:$base_line_height_length/$base_font_size   上記の line_height: $base_line_height_length / $base_font_size を見ると、 $base_line_height_length が使われています。 これは、 base カテゴリの line_height_length を参照しています。  設定項目にアクセスするには、 以下のように YAML の階層表現を利用する方法と、 base:line_height_length:15   階層名をシンボル名に含める方法があります。 base_line_height_length:15   なお、区切り記号は _ と - を使えます。 Key Prefix   設定項目名は、 Key として管理されています。  例えば base_line_height_length が Key です。  どのような Key があるかは、公式のドキュメントに記載があります。  公式のドキュメントで Key を探す際、 Key Prefix: で検索すると、 目的の Key を見つけ易いです。  現在、以下の Key Prefix (抜粋)があります。    cover    page    numbering    base    quotes    link    literal    heading    heading-h\u0026lt;n\u0026gt;    section    title-page    title-page-logo    title-page-title    title-page-subtitle    title-page-authors    title-page-revision    prose    例えば base_line_height_length は、 Key Prefix が base になります。  base の説明の中に、 line-height-length の説明があります。  なお heading-h\u0026lt;n\u0026gt; は、 heading-h1, heading-h2 などを示します。 ","id":5,"section":"posts","summary":"asciidoctor-pdf を利用すると asciidoc を pdf 化できます。 ここでは、 asciidoctor-pdf のセットアップと pdf 化時のレイアウト変更方法について説明します。 asciidoctor-pdf のセットアップ asciidoctor-pdf が既にインストー","tags":null,"title":"asciidoc の pdf 化","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-07-26-asciidoc-2-pdf/","year":"2021"},{"content":"  先日の記事に書いた org-mode ドキュメントの翻訳ツールを作成したので、 今回はそのツールの使用方法を書きます。 セットアップ   golang がインストールされている環境で、以下を実行してください。 go install -tags gopherlua github.com/ifritJP/trans-orgmode@latest  GCP の設定   GCP アカウントを既に持っていることを前提に説明します。  アカウントが無い場合は、作成してください。 プロジェクトの作成   以下の手順に従って作業します。  \u0026lt;https://cloud.google.com/translate/docs/setup?hl=ja#project\u0026gt;  これにより、以下を行ないます。    プロジェクトを作成    API の有効化    サービスアカウントの設定    環境変数 GOOGLE_APPLICATION_CREDENTIALS の設定    上記 URL に記載の「クライアントライブラリのインストール」は 不要 です。 token ファイルの作成   この翻訳ツールは GCP の認証を行なわないため、 事前に GCP のアクセストークンを取得し、 token ファイルを作成しておく必要があります。  アクセストークンは、以下のコマンドを実行すると stdout に出力されます。 $ gcloud auth application-default print-access-token   これで取得したトークンを、以下の JSON 形式でファイルに記録します。 ファイル名は何でも良いです。 { \u0026#34;token\u0026#34;: \u0026#34;GCPTOKEN\u0026#34; }   上記 JSON の GCPTOKEN をアクセストークンに置き換えてください。  なお、アクセストークンは一定時間で expire するので、 再度取得する必要があります。 実行   このツールのオプションは、以下の通りです。 $ trans-orgmode [-v] [-m mode] [-c jsonpath] input.org   ここで -m は、以下のモードを指定します。    org    指定された .org ファイルを解析し、 解析した結果の .org を stdout に出力します。    これは、 .org ファイルの解析が正常に行なえているかどうかを確認するために利用します。      mkreq    指定された .org ファイルを解析し、翻訳が必要な日本語文字列を抽出し、 GCP REST API の request 形式に変換したものを stdout に出力します。    これは、 REST API の request 形式に正しく変換できているかどうかを確認するために、 利用します。      trans    指定された .org ファイルを翻訳し、その結果を stdout に出力します。    このモードでは、-c オプションの指定が必須です。      github    github の README で .org ファイルを使う場合、 .org の CUSTOM_ID によるドキュメント内リンクが出来ません。 その代わり、 headline のリンクが利用可能なので、 CUSTOM_ID に相当する headline のリンクに置き換えを行ない、 結果を stdout に出力します。    これは上記 GCP の翻訳とは関係なく単独で動作します。      -c は、トークンを記載した JSON ファイルのパスを指定します。 -m に trans を指定した場合に必要です。  -v は、 .org ファイルの解析情報を出力します。 デバッグ用の情報です。 制限     このツールは、org-mode のサブセットをサポートします。    どの機能をサポートするかは、 -m のモード指定で org, あるいは mkreq を実行して、 正常に処理されているかどうかで確認できます。      翻訳対象の文の中で *bold* や /italic/ を利用している場合、 翻訳後の文全体を *bold* あるいは /italic/ で強調処理します。    翻訳対象の文の中で =verb= や ~exp~ を利用せずにアルファベットや () などの記号を 利用していると、翻訳結果に悪影響が出ることがあります。    #+BEGIN_SRC や : 内の日本語は、翻訳しません。   ","id":6,"section":"posts","summary":"先日の記事に書いた org-mode ドキュメントの翻訳ツールを作成したので、 今回はそのツールの使用方法を書きます。 セットアップ golang がインストールされている環境","tags":null,"title":"org-mode ドキュメントの翻訳ツールの使い方","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-07-25-org-traslation-intro/","year":"2021"},{"content":"  私は org-mode を使って LuneScript のリファレンスを作成しています。  日本語のリファレンスを書くのも大変ですが、 それを英訳しようとすると気が遠くなります。  そこで機械翻訳を使う予定ですが、 .org ファイルをそのまま機械翻訳で処理すると、 コードブロックや org-mode の区切り記号まで変換され、 意図した結果を得られません。  そこで今回は、org-mode の機械翻訳をスムーズに行なえるツールを検討します。 構成   今回検討する org-mode 翻訳ツールは、以下の構成とします。    入力    .org ファイル      出力    翻訳後の .org ファイル      処理    .org ファイルの parse    \u0026lt;https://github.com/niklasfasching/go-org\u0026gt;      機械翻訳    GCP の Cloud Translation API    \u0026lt;https://cloud.google.com/translate/docs/basic/translating-text?hl=ja\u0026gt;      全体制御    LuneScript で自作     go-org     .org ファイルの parse には go-org を利用します。  go-org は、go で実装された .org ドキュメントの parser で、 hugo はこれを利用して .org ファイルを read しています。  LuneScript のリファレンスは、 hugo で構築しているので、 hugo で利用されているものと同じ parser を使えば、 問題なく parse 出来ると考えて選択しました。 GCP Cloud Translation API   翻訳には、GCP の Cloud Translation API を利用します。  幾つか機械翻訳サービスがありますが、自分がアカウントを持っていて、 無料で使えるのが GCP なのでこれを選択しています。  GCP の Cloud Translation API も一定量を越えれば有料になりますが、 今回使う程度であれば越えることはないでしょう。  ちなみに、1ヶ月間のリクエスト文字数が 500,000 文字までが無料となります。  \u0026lt;https://cloud.google.com/translate/pricing?hl=ja\u0026gt;  ここで言う 文字数 とは、以下によると  \u0026lt;https://cloud.google.com/translate/pricing?hl=ja#charged-characters\u0026gt;  バイト数ではなく、 日本語なら日本語の 1 つのキャラクタを 1 文字として扱うようです。 例えば多くの日本語は utf-8 で 1 文字 3 バイトですが、 1 文字が何バイトであっても 1 としてカウントされます。  \u0026lt;p\u0026gt;こんにちは\u0026lt;/p\u0026gt; を翻訳対象として API に渡した場合、12 文字として扱われます。 これは、 HTML の \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt; の 7 文字と こんにちは の 5 文字の合計です。  ちなみに、 LuneScript のリファレンスの .org ファイルは約 380KB です。 仮に全て utf-8 の日本語として考えると、約 126,000 文字となります。  実際には、 .org には翻訳対象外のサンプルコードが含まれ、 それを除外したデータを機械翻訳 API で処理させるため、 Cloud Translation API で翻訳する文字数は約 126,000 文字よりも 少なくなることが考えられます。  よって、 500,000 文字の無料枠を越えずに .org 全体に翻訳をかけるテストを数回実行できる計算になります。 開発ステップ   ツールの開発ステップとしては、以下を考えています。    go-org を使って .org ファイルを parse する。    parse した要素から翻訳する/しないを判別する。    翻訳する要素をまとめて翻訳 API で翻訳する。    翻訳した要素と、翻訳していない要素から .org を生成する    もちろん、 go-org, 翻訳 API の使い熟しが前段階にあります。 GCP Cloud Translation API   今回は Translation API の REST の v2 basic を利用します。  REST v2 basic を利用する場合、以下の注意が必要です。    一度に翻訳できる文字列数は、 128 個まで    API の body のサイズは 200KB まで    上記の条件を満さない場合は、エラーとなります。  なお、エラーの場合は課金対象にならないようです。  GCP のライブラリを利用すると、 ライブラリ側がこの制限を満すように制御するため、 制限を意識する必要はありません。 ","id":7,"section":"posts","summary":"私は org-mode を使って LuneScript のリファレンスを作成しています。 日本語のリファレンスを書くのも大変ですが、 それを英訳しようとすると気が遠くなります。 そこで機","tags":null,"title":"org-mode ドキュメントの翻訳ツール検討","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-07-19-org-traslation/","year":"2021"},{"content":"  今回の記事は、 先日検討した LuneScript のクラスのオブジェクトを スタックに割り当てて高速化できるかどうか？の検討結果です。 結果   今回の検討結果は以下の通りです。  「スタック割り当て自体は有効ですが、 スタック割り当てから escape されないように設計しないと効果を得られません。」  なんだか当たり前な検討結果ですが、そうなんだから仕方がない。  では、なぜそのような結果になったかを説明していきます。 検討内容   LuneScript でオブジェクトをスタック割り当てするには、 そのオブジェクトのクラスは次の条件を全て満す必要があります。    全てのメンバが immutable    Super クラスがない    Sub クラスがない    この条件にマッチし、なおかつ生成数の多いクラスは以下になりました。    Positon    トークンの位置情報      Token    Parse したトークン情報      go の pprof 機能の解析によると、 この 2 つの合計は、生成している全オブジェクト数の 5% ほどになります。  このクラスをスタック割り当てに変更してみたところ以下の結果になりました。    Positon をスタック割り当てに変更    トランスコンパイル時間が 1% 程度 改善      Token をスタック割り当てに変更    トランスコンパイル時間が 10% 程度 悪化      この通り、クラスによって結果が異なりました。  先日の記事で書いたように、オブジェクトをスタック割り当てする場合、 そのオブジェクトを最後までスタック割り当てで扱わないと逆に効率が悪くなります。  では、何故スタック割り当てで扱わないケースがあるのかと言うと、 LuneScript には nilable があるからです。  nilable を表現するために、 go の interface{} を利用しています。 そして、スタック割り当てのオブジェクトを interface{} に変換すると、 escape されます。  このようなケースを改善するには、異常値の表現に nilable は使わずに、 特別な値を定義する必要があります。 あるいは Rust の Option 型のような型を用意する必要があります。  また、 List や Map などの collection 型は interface{} として値を保持します。 そして stem 型も interface{} として保持します。 つまり、collection 型, stem 型で管理することが前提の場合、 スタック割り当て化は逆効果です。  ただ、collection 型を使えないのは流石にハードルが高いので、 スタック割り当てのまま collection 型を使えるように改善したいと考えています。  ということで結論は以下になります。  スタック割り当て自体は有効ですが、 スタック割り当てから escape されないように設計しないと効果を得られません。 今後の予定   今の段階(6827a64)で、 セルフホストのトランスコンパイルの内部処理時間は 0.9 秒弱まで短縮できていますが、 time コマンドの計測結果では 1.1 秒前半です。  この原因の一つに、 collection 型で interface{} を利用していることが挙げられるので改善したいところです。 しかし、これを改善するには go 側の slice, map の generics 対応が必要になります。  よって、go 側の slice, map の generics 対応を持ってから、 collection 型の改善が出来るように対応を検討します。  それまでは、 大きな改善は見込めなさそうなので LuneScript の高速化対応を一旦中断します。 ","id":8,"section":"posts","summary":"今回の記事は、 先日検討した LuneScript のクラスのオブジェクトを スタックに割り当てて高速化できるかどうか？の検討結果です。 結果 今回の検討結果は以下の通り","tags":null,"title":"LuneScript のトランスコンパイル高速化 (スタック割り当て)","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-07-02-lunescript-value-assigned-stack/","year":"2021"},{"content":"  先月から続いて、LuneScript のトランスコンパイル高速化作業をしています。 セルフホストのトランスコンパイル時間   今回の時間短縮は以下の通りです。     lua VM 版 go ビルド版 lua/go     改善前 5/6 (6e5661a9) 25.69 sec 5.84 sec 440%   改善後 5/25 (364095ef) 17.42 sec 2.22 sec 785%   改善後2 6/7(52df422b) 17.57 sec 1.82 sec 965%   改善後3 6/29(8898c475) 18.07 sec 1.13 sec 1599%   改善率(改善前/改善後3) 142% 517%      この表は、セルフホスティングしているソースのトランスコンパイル時間の計測結果を 示しています。 lua VM で動作させた lnsc と、go でビルドした lnsc で計測しています。  改善前の 6e5661a9 は、2021/5/6 のバージョンです。 今回の 改善後3 の 8898c475 は、2021/6/29 のバージョンです。  この表の通り、 改善前の Lua と、 今回の改善後3 go のトランスコンパイル時間を比べると (/ 25.69 1.13) 22.734513274336287 == 2273% 改善しています。  あと少しで 1 秒を切れるところまで改善しました。  なおこの時間は、 lns コマンドの処理時間を time コマンドで計測した結果です。 一方で、トランスコンパイラ内部で計測すると、 その処理時間は 約 0.94 秒 となっていて 1 秒を切っています。 つまり、トランスコンパイラの起動・終了処理に 約 0.2 秒程度かかっているようです。 flamegraph   次の図は、セルフホストのトランスコンパイル実行時の flamegraph です。   これを見ると、左端の Go runtime にかなり多くの時間がかかっていることが分かります。 ただ、この時間がパフォーマンスにどの程度影響しているかは分かっていません。  この Go のランタイム処理は、基本的には GC の制御だと思います。  GC 制御にこれだけ時間がかかっているということは、 それだけオブジェクトをヒープに生成しているということでもあります。 つまり、ヒープへのオブジェクト生成を抑制できれば、 GC 制御も軽くなることが考えられます。  現状の LuneScript は、 全てのクラスのオブジェクトをポインタで管理 します。  以下の記事によると、 ポインタで管理するオブジェクトは、 ほとんど全てのケースでヒープに生成される ということです。  \u0026lt;https://hnakamur.github.io/blog/2018/01/30/go-heap-allocations/\u0026gt;  つまり、 LuneScript のクラスオブジェクトは、 ほとんど全てがヒープに生成される ことになります。  これでは Go のランタイム処理が重くなるのも当然 でしょう。  ならば、出来るだけポインタを使用せずにクラスオブジェクトを管理できれば、 ヒープのオブジェクト数が減り、Go のランタイム処理は軽くなるはずです。  ただしここで疑問なのは、 GC 処理が重いのは間違いないとしても、 スタック割り当てにした時に、本当に軽くなるのか？ というところ。  また、LuneScript のデータ構造で、 オブジェクトをスタック割り当てにすることが可能かどうか？ というところです。 スタック割り当てなら早い？   スタック割り当てにして本当に高速化できるのかを確認するため、 簡単な検証用コードを作成しました。  このコードは、 sub1 〜 sub4 をそれぞれ一定回数実行し、 それぞれの実行時間を出力します。  コメントの // escape は、 $ go build -gcflags -m コマンドで escapes to heap と出力された箇所を示します。 package main import \u0026#34;fmt\u0026#34; import \u0026#34;time\u0026#34; import \u0026#34;runtime\u0026#34; type Test struct { val int } var list1 = make( [] Test, 1 ) var list2 = make( [] interface{}, 1 ) func sub1( test Test ) { list1[ 0 ] = test } func sub2( test *Test ) { list2[ 0 ] = test } func sub3( test Test ) { list2[ 0 ] = test // escape } func sub4( test *Test ) { list1[ 0 ] = *test } func profile( name string, callback func() ) { runtime.GC() prev := time.Now() callback() fmt.Printf( \u0026#34;%s: time = %v\\n\u0026#34;, name, time.Now().Sub( prev ).Milliseconds() ) } func main() { maxCount := 100000 * 50000 profile( \u0026#34;sub1\u0026#34;, func() { test := Test{} for count := 0; count \u0026lt; maxCount; count++ { sub1( test ) } }) profile( \u0026#34;sub2\u0026#34;, func() { test := \u0026amp;Test{} // escape  for count := 0; count \u0026lt; maxCount; count++ { sub2( test ) } }) profile( \u0026#34;sub3\u0026#34;, func() { test := Test{} for count := 0; count \u0026lt; maxCount; count++ { sub3( test ) // escape  } }) profile( \u0026#34;sub4\u0026#34;, func() { test := \u0026amp;Test{} for count := 0; count \u0026lt; maxCount; count++ { sub4( test ) } }) }   この処理は、 Test 構造体のオブジェクトを生成し、 スライスの list1 あるいは list2 に格納します。 オブジェクトの生成から格納するまでの間、 値渡しで処理するか、ポインタ渡しで処理するかによって、 実行時間にどのような違いが出るかを計測します。  各関数はそれぞれ以下を実行しています。    sub1    値渡しのまま処理する。      sub2    ポインタ渡しのまま処理し、interface{} に変換する。      sub3    値渡しのデータを、 interface{} に変換して処理する。      sub4    ポインタが示すアドレスから、値をコピーして処理する。      上記プログラムの実行結果は次の通りです。 sub1: time = 1765 sub2: time = 3724 sub3: time = 11300 sub4: time = 3713   これを見ると、以下が分かります。    値渡しをしている sub1 が一番高速に動作している。    ポインタ渡しをしている sub2 は、sub1 の倍以上の時間かかっている。    値渡しのデータを interface{} に変換している sub3 は、 最初からポインタでデータを保持している sub2 の 3 倍時間がかかっている。    ポインタ渡しのデータから値をコピーするだけなら escape されない。 しかし、コピーに時間がかかってしまい、 最初から最後までポインタで持っている sub2 と変わらない。    これにより、 値渡しがポインタ渡しよりも高速に動作する ことが確認できました。  一方で、 sub3 のケースのように 値をスタック割り当てで処理する場合でも、 途中で interface{} に変換すると逆に遅くなる ケースがある。 ということも分かりました。  特に、 sub1 と sub2 の比率と、 sub2 と sub3 の比率を比べると、明らかに後者の方が大きいです。  つまり、 中途半端なスタック割り当ては逆効果になる ということです。 sub1 のつもりでスタック割り当て対応したら、結果は sub3 になってしまう。 そんなことが起きる可能性があります。  これを考えると、 下手にスタック割り当てすると今よりさらに遅くなる 可能性があるということで、 スタック割り当て対応は慎重に 行なわなければなりません。 スタック割り当てを実現する場合   LuneScript でスタック割り当てを実現する場合、以下を検討する必要があります。    lua にトランスコンパイルした時の動作の定義    スタック割り当てと、ヒープ割り当ての syntax 上の表現 lua にトランスコンパイルした時の動作の定義     lua は、ポインタという概念がありません。 というか、全てのクラスオブジェクト(table)は、ポインタで管理されるため、 go のようにヒープ割り当てされているオブジェクトを、 スタック割り当てにすれば速くなる、ということはありません。  特に、スタック型の引数を持つ関数の動作を lua で再現するには、 ヒープ割り当てのオブジェクトを clone することになり、 ヒープ割り当てのオブジェクトが clone した分増え、 パフォーマンスが余計に劣化するだけです。  このパフォーマンス劣化を防ぐには、 go と lua とで出力を変更する必要があります。 具体的には、go に変換する場合はスタック割り当てオブジェクト同士のコピーにし、 lua に変換する場合はヒープオブジェクトのポインタ渡しにします。  しかし、これではそのオブジェクトが mutable であった時に、 go と lua とで論理が異なることになります。  逆に言えば、 オブジェクトが immutable であれば、 go と lua とで同じ論理になることになります。  だとすれば、go でスタック割り当てオブジェクトを使う条件として、 完全 immutable オブジェクト を前提にすることで、 go と lua とで同じ論理を保ちつつ、 go を高速化できる可能性があります。  ここでいう 「完全 immutable オブジェクト」 とは、 「ある時点 T 以降で変更されることがないオブジェクトの T 以降」 を指します。  たとえば以下のような場合、 test は 「完全 immutable オブジェクト」 ではありません。 class Test { let mut val:int {pub,pub}; } fn foo( test:\u0026amp;Test ) { print( test.$val ); } fn bar( test:Test ) { test.set_val( 10 ); } let mut test = new Test(1); foo( test ); // 1 bar( test ); foo( test ); // 10   上記のコードで、 foo() の中では test は immutable ですが、 完全 immutable オブジェクト ではありません。  なぜなら、 bar() によって、 test のメンバが書き換えられるためです。  このように、ある範囲では immutable に見えても、 全体で見ると mutable なオブジェクトは 完全 immutable オブジェクト ではありません。  一方で、例えば以下のようなケースでは、 test は 完全 immutable オブジェクト です。 class Test { let mut val:int {pub,pub}; } fn foo( test:\u0026amp;Test ) { print( test.$val ); } fn bar( test:Test ) { test.set_val( 10 ); } let test; { let mut work = new Test(1); foo( work ); bar( work ); test = work; } foo( test );   なぜなら test の型は \u0026amp;Test であり、 なおかつ test の代入元の work は、既にスコープ外になっていて、 mutable アクセス可能な変数が存在しないためです。  ただ、このようなケースを 完全 immutable オブジェクト として扱うのは困難です。  なぜなら、 mutable 型のシンボルの有無を保証しなければならないためです。  もしも、これを実現するのなら、 Rust のようなアクセス権制御を導入する必要があるでしょう。  Rust のようなアクセス権制御導入は最終手段にしたいので、 ここでは 完全 immutable オブジェクト として扱うために、 そのオブジェクトのクラスに次の制限を設定します。    どのクラスからも継承されていない    全てのメンバが immutable。 あるいは、オブジェクトを生成する時点で immutable として生成する。    上記制限を満す時に限り、そのクラスのオブジェクトを 完全 immutable オブジェクト とします。 スタック割り当てと、ヒープ割り当ての syntax 上の表現   上記検証コードで確認した通り、 スタック割り当てにしても処理が高速化させるとは限りません。  つまり、ヒープ割り当てからスタック割り当てに時間をかけて切り替えて、 実際にパフォーマンスを計測してみたら遅くなっていた、なんていう可能性があります。  よって、あるオブジェクトをヒープ割り当てからスタック割り当て切り替える、 そしてその逆を簡単に切り替えられるようにする必要があります。  このように対応することで、高速化の検討作業を効率化できます。  これを実現するには以下が必要です。    スタック割り当てと、ヒープ割り当ての syntax 上の表現の違いを、 クラス宣言の表現に極力おさめる。    クラス宣言の外の syntax 表現の違いが出る場合は、 機械的な置換が出来る表現にする。    現状の syntax 候補としては、 __absImmut インタフェースを implement したクラスを、 完全 immutable オブジェクトとして扱います。  なお、__absImmut インタフェースを implement したクラスは、以下を制限します。    immutable なメンバーしか持てない。    継承できない。    まずは __absImmut インタフェースの対応をすすめ、 それで効果が出るかどうかを確認する予定です。 ","id":9,"section":"posts","summary":"先月から続いて、LuneScript のトランスコンパイル高速化作業をしています。 セルフホストのトランスコンパイル時間 今回の時間短縮は以下の通","tags":null,"title":"LuneScript のトランスコンパイル高速化 (トランスコンパイル時間を 2273 パーセント改善)","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-06-28-lunescript-build-time-2000/","year":"2021"},{"content":"  LuneScript の高速化のため、マルチスレッド化を行ないました。  今回は、LuneScript のどこをマルチスレッド化したのか、 マルチスレッド化で何故高速化できるのかを説明します。 ビルド時間   今回の時間短縮は以下の通りです。     lua VM 版 go ビルド版 lua/go     改善前 5/6 (6e5661a9) 25.69 sec 5.84 sec 440%   改善後 5/25 (364095ef) 17.42 sec 2.22 sec 785%   改善後2 6/7(52df422b) 17.57 sec 1.82 sec 965%   改善率(改善前/改善後2) 146% 329%      この表は、セルフホスティングしているソースのトランスコンパイル時間の計測結果を 示しています。 lua VM で動作させた lnsc と、go でビルドした lnsc で計測しています。  改善前の 6e5661a9 は、2021/5/6 のバージョンです。 改善後2 の 52df422b は、2021/6/7 のバージョンです。  この表の通り、 改善前の Lua と、改善後 go のトランスコンパイル時間を比べると (/ 25.69 1.82 ) 14.115384615384615 ≒ 1412% 改善しています。  改善後2 の lua と go の比較では 965%、 改善前と改善後2 の go の時間を比べると、 329% 改善しています。  前回からさらに並列度を上げています。 LuneScript の処理フロー   LuneScript は次の処理を行ないます。    .lns ファイルの parse    AST の構築    AST から .lua, .meta の生成    AST から .go の生成    図にすると、以下のようになります。 digraph G { rankdir = LR; subgraph clusterA { style=rounded; label=\u0026#34;thread\u0026#34;; \u0026#34;.lns\u0026#34; [shape=circle; margin=0.2;]; parse [shape=rect; margin=0.2; style=filled; fillcolor=\u0026#34;#44cc44\u0026#34;;]; token [shape=tripleoctagon; margin=0.2;]; create_Ast [shape=rect; margin=0.2; style=filled; fillcolor=\u0026#34;#44cc44\u0026#34;;]; AST [shape=octagon; margin=0.2;]; convLua [shape=rect; margin=0.2; style=filled; fillcolor=\u0026#34;#44cc44\u0026#34;;]; \u0026#34;.lua\u0026#34; [shape=circle; margin=0.2;]; \u0026#34;.meta\u0026#34; [shape=circle; margin=0.2;]; convGo [shape=rect; margin=0.2; style=filled; fillcolor=\u0026#34;#44cc44\u0026#34;;]; \u0026#34;.go\u0026#34; [shape=circle; margin=0.2;]; \u0026#34;.lns\u0026#34; -\u0026gt; parse parse -\u0026gt; token token -\u0026gt; create_Ast create_Ast -\u0026gt; AST AST -\u0026gt; convLua convLua -\u0026gt; \u0026#34;.lua\u0026#34; convLua -\u0026gt; \u0026#34;.meta\u0026#34; AST -\u0026gt; convGo convGo -\u0026gt; \u0026#34;.go\u0026#34; } }    ここで、色が付いているのが処理で、色の無いのが処理の入出力データです。  上記の処理を、各ファイルに対して行ないます。 マルチスレッド化   マルチスレッド化した LuneScript の処理は次です。 digraph G { rankdir = LR; subgraph clusterA { style=\u0026#34;rounded\u0026#34;; label=\u0026#34;thread\u0026#34;; \u0026#34;.lns\u0026#34; [shape=circle; margin=0.2;]; parse [shape=rect; margin=0.2; style=filled; fillcolor=\u0026#34;#44cc44\u0026#34;;]; token [shape=tripleoctagon; margin=0.2;]; } subgraph clusterB { style=\u0026#34;rounded\u0026#34;; label=\u0026#34;thread\u0026#34;; create_Ast [shape=rect; margin=0.2; style=filled; fillcolor=\u0026#34;#44cc44\u0026#34;;]; AST [shape=octagon; margin=0.2;]; } subgraph clusterC { style=\u0026#34;rounded\u0026#34;; label=\u0026#34;thread\u0026#34;; convLua [shape=rect; margin=0.2; style=filled; fillcolor=\u0026#34;#44cc44\u0026#34;;]; \u0026#34;.lua\u0026#34; [shape=circle; margin=0.2;]; \u0026#34;.meta\u0026#34; [shape=circle; margin=0.2;]; } subgraph clusterD { style=\u0026#34;rounded\u0026#34;; label=\u0026#34;thread\u0026#34;; convGo [shape=rect; margin=0.2; style=filled; fillcolor=\u0026#34;#44cc44\u0026#34;;]; \u0026#34;.go\u0026#34; [shape=circle; margin=0.2;]; } \u0026#34;.lns\u0026#34; -\u0026gt; parse parse -\u0026gt; token token -\u0026gt; create_Ast create_Ast -\u0026gt; AST AST -\u0026gt; convLua convLua -\u0026gt; \u0026#34;.lua\u0026#34; convLua -\u0026gt; \u0026#34;.meta\u0026#34; AST -\u0026gt; convGo convGo -\u0026gt; \u0026#34;.go\u0026#34; } }    各処理をスレッド化しています。  このマルチスレッド化により、以下の効果があります。    parse と AST 解析を並列処理できる    convLua と convGo を並列処理できる    複数ファイルを処理する場合は、さらに効果を発揮します。 複数ファイル処理時の効果   シングルスレッドで、複数ファイル(file1.lns, file2.lns, file3.lns) を処理すると、 次のようなイメージで処理されます。     step1 step2 step3 step4 step5 step6 step7 step8 step9     file1.lns parse create_Ast convLua convGo        file2.lns     parse create_Ast convLua convGo    file3.lns         parse     時間軸: →→→→→→→→→→→→  これは LuneScript の処理を示す概念図で、 左から右に処理の step が進んでいることを示します。  一方、マルチスレッド化すると以下になります。     step1 step2 step3 step4 step5     file1.lns parse create_Ast convLua/Go     file2.lns  parse create_Ast convLua/Go    file3.lns   parse create_Ast convLua/Go     シングルスレッドと比較して、かなり処理時間を短縮できていることが分かります。  なお、これはあくまでもイメージなので、 実際には綺麗に step で時間が区切られている訳ではありません。  また、先に処理を開始したファイルが処理終了するよりも前に、 後から処理を開始したファイルの処理が終る場合もあります。 マルチプロセスとの違い   ここまでの説明を読んで、以下を疑問に思っている人もいるでしょう。  「マルチスレッド化ではなく、make で並列ビルド(マルチプロセス処理)すれば良いじゃない？」  それはある意味で正しいですが、ある意味で間違いです。  マルチプロセスと比較すると、マルチスレッド対応は以下の効果があります。    プロセス起動にかかるオーバーヘッドを削減できる    依存関係を効率的に対応できる    ここでいう依存関係とは、 『あるファイル A.lns が別のファイル B.lns をインポートしている』ことを指します。  この場合、 B.lns をビルドする際に、A.lns も解析する必要があります。  そして、A.lns と B.lns を make で並列に処理しようとしても、 その依存関係から B.lns は A.lns の後にビルドされることになります。  つまり依存関係がある場合、シングルスレッドで示した時と同じ動作になります。 マルチスレッド化の場合   ここで、以下を疑問に思っている人もいるでしょう。  「依存関係がある場合は、マルチスレッド化しても同じじゃないのか？」  これもある意味で正しいですが、ある意味で間違いです。  ここで、先ほどのマルチスレッドで A.lns と B.lns を処理するケース見てみます。     step1 step2 step3 step4     A.lns parse create_Ast convLua/Go    B.lns  parse create_Ast convLua/Go     A.lns が B.lns をインポートしていても、 A.lns の処理が終る前に B.lns の解析が出来ています。  これが何故かというと、 step2 の A.lns の create_Ast によって A.lns の解析が終っているため、 step3 で B.lns の create_Ast が可能になります。  もちろん、A.lns の create_Ast に時間がかかれば、 その分 B.lns の create_Ast は待たされて時間が延びます。  しかし、 make などのマルチプロセスに比べれば、 明らかにマルチスレッド化の方が効果があります。 goroutine   セルフホストは 44 ファイル(約44KLine)で構成しています。  今回のマルチスレッド処理は、 golang 版のセルフホストで実現しています。  セルフホストの 44 ファイルをトランスコンパイルする際に 動作する goroutine 数を計測したところ、最大で 160 個が同意動作することが判った。  同時に動かす goroutine 数を制限する機能を実装し、 goroutine 数を少なくした場合どのように動作するのかを調べたところ、 以下の結果が得られた。    goroutine 制限数 ビルド時間 (sec)     141 1.82   130 1.83   126 1.93   121 2.02   103 2.04   52 2.02   25 2.13     同時動作させる goroutine 数を少なくすほど、 ビルド時間が劣化することが確認できる。  ただし、goroutine 数をかなり少なくしても、 2割程度のパフォーマンス劣化で済んでいる。  セルフホストのコードは、芋蔓式の依存関係があるため、 goroutine 数を制限しても大きく代わらないのかもしれない。 最後に   LuneScript の高速化のため、マルチスレッド化を行ないました。  これにより、対応前と対応後とで比較すると倍以上の高速化を達成できました。  なお、マルチスレッド化にはデータ競合との戦いがつきものですが、 LuneScript ではデータ競合を論理的に排除する仕組みを組込みました。  これにより、楽に安全にマルチスレッド化を実現できました。  現状、全てのデータ競合を論理的に排除できる訳ではありませんが、 開発の楽さと安全性のバランスの取れたものになっていると思います。  少なくとも、今回、シングルスレッドだった LuneScript のセルフホストコードを マルチスレッド化するにあたって必要だった変更は、かなり少ない修正量で済みました。  github の Code frequency で変更量を見ると、かなり変更したように見えますが、 これはトランスコンパイルしたコードが変更になっているためです。  少しの .lns の変更で、トランスコンパイル結果が変ってしまう現象については、 今後改善していきます。  LuneScript のマルチスレッド化 syntax については、 後日整理してアップする予定です。 ","id":10,"section":"posts","summary":"LuneScript の高速化のため、マルチスレッド化を行ないました。 今回は、LuneScript のどこをマルチスレッド化したのか、 マルチスレッド化で何故高速化","tags":null,"title":"LuneScript のセルフホストのマルチスレッド化 (トランスコンパイル時間を 1412 パーセント改善)","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-06-04-lunescript-selfhost-para/","year":"2021"},{"content":"  今月上旬に TypeScriptToLua の存在を知ったことで、 「Lua のトランスコンパイラ」という LuneScript の主な 存在意義 がほとんど消えてしまいました。  それによって LuneScript 開発に対するモチベーションが一気に下りましたが、 よくよく考えてみれば、今迄も自分以外の誰かが使っていた訳でもないし、 独自言語開発は元々自分がやりたかったこと でもあるので、 TypeScriptToLua があろうとなかろうと 今迄と然程違いはないんじゃないか、 という結論になりました。  そんな訳で、LuneScript は自分の検討用プログラミング言語として 今後も開発を継続 していく予定です。 特に go との連携機能に注力します。  今迄は自分以外のユーザ環境でも使いやすくなるように 多少なりとも考えていましたが、 Lua のトランスコンパイラに TypeScriptToLua ではなく LuneScript を使おうという人はほとんどいないと思うので、 今後は自分特化になります。 ということで、先月末は LSP の対応を進めようと思っていましたが、 別のことを優先します。  既に LSP 対応をやめて トランスコンパイル時間の高速化に着手し、 従来と比べて 1157 パーセントの改善を実現しています。  高速化の詳細は過去記事を参照。 安全な非同期化処理   今回の高速化の実現手段として、 go へのトランスコンパイラ時に 非同期化処理を安全に実現(コンパイラレベルでデータの競合アクセスを排除)する方法を 実験的に対応しました。  この 「安全な非同期化処理」 は、予想以上に効果を発揮し、 今回の非同期化対応のコード修正を完了して動かした際には、 驚くほどすんなりと何のエラーもなく並列化して動かすことができました。 46KLine (go 変換後は77KLine) のプログラムを非同期化して、 一発でまともに動くのは結構凄いことじゃないでしょうか？(自画自賛)  なお、従来のシングルスレッド処理の非同期化には、 非同期化対応の文法エラーが発生するので、 そのエラーを逐次対応する必要があります。  これには、そこそこ時間が掛りましたが、 非同期処理にありがちな実行時の不具合に悩まされるよりは、 コンパイルエラーの方がよほど効率が良いです。  特に syntax の論理的なエラーなので、コンパイラにバグがない限りは、 非同期処理における危険な箇所を抜け漏れなく解決できる、 というのはとても楽だし安全です。  こういうことを実現できるのが、自分用の独自言語を持つ大きなメリットの一つです。  ちなみに、 LuneScript の非同期処理に関しては、 まだ検討段階であり、 syntax エラー検出にバグもあるので、リファレンスに公開するのは、 もう少し先になります。  非同期処理を使用しないケースでは、基本的には影響のないものになっています。 ","id":11,"section":"posts","summary":"今月上旬に TypeScriptToLua の存在を知ったことで、 「Lua のトランスコンパイラ」という LuneScript の主な 存在意義 がほとんど消えてしまいました。 それによって LuneScript 開発に対す","tags":null,"title":"LuneScript のこれからの予定","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-26-lunescript-plan/","year":"2021"},{"content":"  前回から引き続き LuneScript のトランスコンパイル時間短縮を行なっています。  今回の時間短縮は以下の通りです。     lua go lua/go     改善前(6e5661a9) 25.69 sec 5.84 sec 440%   改善後(364095ef) 17.42 sec 2.22 sec 785%   改善率(改善前/改善後) 147% 263%      この表は、セルフホスティングしているソースのトランスコンパイル時間の計測結果を 示しています。 lua VM で動作させた lnsc と、go でビルドした lnsc で計測しています。  改善前の 6e5661a9 は、5/6 のバージョンです。 改善後の 364095ef は、5/25 のバージョンです。  この表の通り、 改善前の Lua と、改善後 go のトランスコンパイル時間を比べると (/ 25.69 2.22 ) 11.572072072072071 ≒ 1157% 改善しています。  改善後の lua と go の比較では 785%、 改善前と改善後の go の時間を比べると、 263% 改善しています。  今回は以下の高速化を行ないました。    meta 情報処理の高速化    ast から lua, go へ変換する処理の並列化    以降では、今回の高速化方法ついて説明します。 meta 情報処理の高速化   LuneScript は、モジュールをインポートする際、 そのモジュールが何のクラスや関数を公開いているか？を解析します。 この「何のクラスや関数を公開しているか」の情報が meta 情報です。  この meta 情報を解析するには時間がかかるため、 解析した meta 情報は .meta ファイルとして保存します。 そして、 .meta ファイルがある場合は、そのファイルから meta 情報を取得します。  個々の .lns ファイルを一つずつトランスコンパイルする際は、 この .meta から取得するのが高速化として重要です。  一方で、複数の .lns ファイルを一括してトランスコンパイルする際は、 この方法は多くの無駄な処理が含まれます。 meta 情報の処理   .meta ファイルを生成し、 生成したファイルを読み込んで meta 情報を構築するには、 以下の処理が必要です。    .lns ファイルを解析し AST を得る。    AST に含まれる .meta 情報から .meta ファイルを出力する。    .meta ファイルを読み込み meta 情報を構築する。    ちなみに、この .meta ファイルを読み込み meta 情報を構築する処理を、 ここでは import 処理と言います。 2 つのファイルを処理するケース   例えば、 2 つのファイル(a.lns, b.lns: b.lns から a.lns を import している)を 一括でトランスコンパイルする場合は以下になります。    a.lns ファイルを解析し AST_a を得る。    AST_a に含まれる meta_a 情報から a.meta ファイルを出力する。    b.lns ファイルを解析し AST_b を得る。    この解析途中に a.meta を読み込み、 meta_a 情報を構築する。      AST_b に含まれる meta_b 情報から b.meta ファイルを出力する。    ここで、 「この解析途中に a.meta を読み込み、 meta_a 情報を構築する。」 は無駄です。  なぜならば、「meta_a 情報」は AST_a に含まれており、 AST_a はメモリ上に残っているため、 「a.meta を読み込み、 meta_a 情報を構築する」ことなく、 メモリ上の AST_a から meta_a を取得できるからです。 import 処理の変更   以下のように import 処理を変更します。    a.lns ファイルを解析し AST_a を得る。    AST_a に含まれる meta_a 情報から a.meta ファイルを出力する。    b.lns ファイルを解析し AST_b を得る。    この解析途中に AST_a に含まれる meta_a 情報を取得する。      AST_b に含まれる meta_b 情報から b.meta ファイルを出力する。    a.meta を読み込み、 meta_a 情報を構築する。 処理と、 AST_a に含まれる meta_a 情報を取得する。 処理を比較すれば、 圧倒的に後者の方が高速に処理できます。  やっていることは非常に単純ですが、これを実現するのは結構大変でした。。 ast から lua, go へ変換する処理の並列化   トランスコンパイルは、以下の処理行ないます。    .lns ファイルを解析して AST を取得する    AST から .lua, .go を生成する    これを .lns ファイル分実行します。  例えば a.lns, b.lns, c.lns の 3 つのファイルがあった場合、 次の通り処理します。    a.lns ファイルを解析して AST_a を取得する    AST_a から .lua, .go を生成する    b.lns ファイルを解析して AST_b を取得する    AST_b から .lua, .go を生成する    c.lns ファイルを解析して AST_c を取得する    AST_c から .lua, .go を生成する    ここで、 「AST_a から .lua, .go を生成する」 、 「AST_b から .lua, .go を生成する」 、 「AST_c から .lua, .go を生成する」 の処理は、 基本的には独立して処理できます。  つまり、これら処理は並列して実行可能です。  そこで go rutine を利用して、並列化しています。  しかし、 直感的に 並列化可能 と言っても、 実際に安全に並列化ができるかどうかは別の話です。  シングルスレッドでは問題にならないことも、 マルチスレッドにすると問題になることが良くあります。  今回の 並列化処理 を実現するにあたり、 マルチスレッド化を安全に論理的に実現する方法を、 LuneScript に追加しました。 ","id":12,"section":"posts","summary":"前回から引き続き LuneScript のトランスコンパイル時間短縮を行なっています。 今回の時間短縮は以下の通りです。 lua go lua/go 改善前(6e5661a9) 25.69 sec 5.84 sec 440% 改","tags":null,"title":"LuneScript のトランスコンパイル時間を 1157 パーセント改善した件","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-25-lunescript-improved-build-time/","year":"2021"},{"content":"  LuneScript は golang へのトランスコンパイルをサポートしている。  golang 対応の付加機能として、LuneScript には限定的な非同期処理を提供している。  今回は、この「限定」を緩和する方法を検討する。 非同期処理を「限定」する理由   非同期処理を限定する主な理由は、非同期処理を安全に実行するためだ。  では、非同期処理のなにが危険なのかといえば、データアクセスの競合だ。  Rust では、データアクセスの競合が発生しないように、 言語の syntax で論理的に競合を排除する方法を採用している。  LuneScript も、同じように言語の syntax で論理的に排除できるように目指したい。  ただ、 Rust の syntax は、 データアクセスの競合排除と、 メモリアロケーションコントロールを行なう上では非常に有用ではあるが、 プログラミングのコストが高いのも事実だ。  LuneScript の目的は、楽をして安全に開発することなので、 安全性とのトレードオフで、もう少しコストの低い方法で実現したい。 特に LuneScript はメモリアロケーションコントロールは gc に任せているので、 Rust ほどの厳密な syntax は不要なので、その分の簡易化はすべきだ。 非同期処理を安全に実現する方法   非同期処理を安全に実現するには、 あるデータ A に対し、 非同期に mutable なアクセスが行なわれないことが保証できれば良い。  言い換えれば、 immutable なアクセスだけであれば安全である。  LuneScript には、メソッドの mut 宣言による mutable 制御がある。 これは、immutable な型のオブジェクトから、 mut 宣言されたメソッドのコールを禁止するものである。 mut 宣言されたメソッドは、 オブジェクトのメンバーを変更することを宣言するものである。  つまり、非同期処理に渡す引数を immutable 型のオブジェクトに限定し、 どこからもそのオブジェクトの mutable メソッドをコールしないようにすれば、 安全に非同期処理が実現できるように考えられる。 しかし、これを実現するのもそう簡単ではない。  その原因は次にある。    あるオブジェクトを、複数の mutable 型の変数に代入できる    メソッドの mutable 制御だけでは対処できないケースがある   複数の mutable 型の変数に代入できる   LuneScript では、 あるクラスのオブジェクトを、 複数の mutable 型の変数に代入することが出来る。 これにより、あるオブジェクトが意図していない所で mutable 型の変数に代入され、 その変数を通して mut 宣言されたメソッドがコールされ、 非同期処理に影響を及ぼす可能性がある。  これを防止するのがまさに Rust が採用する所有権制御である。 ただ前述しているように、 これはコストが大きいので LuneScript では採用したくない。  これに関しては、制限として割り切る方向で考えている。  ただ、完全に割り切ってユーザに管理を丸投げするのではなく、 なんらかの設計の手助けになる情報を提供するツールを別途検討する。 メソッドの mutable 制御だけでは対処できないケース   メソッドの mut 宣言だけでは、以下のケースにおいて危険である。    allmut なメンバを変更するメソッドは mut 宣言が不要なため、 mut 宣言していなくても、実質的に mutable な動作をするケースがある。    モジュールの公開関数からモジュール内の大域変数の変更が可能であり、 かつ関数には mut 宣言がないため安全かどうかの区別できない    form の実行において、そのフォームが mutable な処理かどうか区別できない。    LuneScript では、これらについて論理的に対応する方法を考える。 非同期処理の実現方法   go へのトランスコンパイル時は非同期処理をサポートするが、 一方 Lua へトランスコンパイル時は非同期処理をサポートしない。  つまり、非同期処理として書いたものを、 同期処理として動かしても矛盾のない書き方をする必要がある。  これに関しては、非同期処理をサポートしない場合は 「非同期処理を開始する API」実行時に、同期処理として実行することで対応する。 非同期処理インタフェースの実装   ここの情報は検討中  非同期処理は、クラスのメソッドを非同期で処理することで実現する。 このクラスは、__Runner インタフェースを実装する必要がある。  また、__Runner インタフェースを実装するクラスは、以下を制限する。    引数は、全て immutable 型のオブジェクトでなければならない。 これにより、そのクラス内から競合する mutable アクセスがないことを保証する。    __init() メソッド    pub メソッド    ただし、引数のオブジェクトのクラスのメンバが全て immutable 型の場合は、 その引数自体は immutable でなくても良い。    引数の型が型パラメータの場合、条件を満しているとして処理する。      メソッドからコールする外部モジュールの関数、メソッドは、次の条件を満さなければならない    大域変数、あるいはクロージャの変数に影響を与えてはならない。    allmut への更新がない。      上記制限は、 __Runner インタフェースを実装するクラスの super クラス、 sub クラスも同様に制限される。  上記制限を満すかどうかを確認するため、以下の制御を追加する。    __async 宣言を追加する。    __async 宣言された関数、メソッドは以下の制限に従う。    mutable 型を格納する大域変数、あるいはクロージャの変数にアクセスしない。    allmut 型のシンボルの参照がない    __noasync な関数をコールしてはならない。        _lune_control に default_async_func を追加する。    default_async_func が宣言されたモジュールの関数は、 デフォルトで __async 宣言が付加される。    __async でない関数は、 __noasync 宣言する必要がある。    メソッドは対象外      _lune_control に control_default_async_all を追加する。    default_async_func が宣言されたモジュールの関数は、 全ての関数、メソッドにおいて、async 宣言がデフォルトで付加される。        __noasync 宣言を追加する。    __async 宣言とは逆の働きをする。    default_async_func が宣言されていないモジュールの関数は、 デフォルトで __noasync が付加される。        _lune_control に default_async_this_class を追加する    クラスの body 先頭に default_async_this_class を宣言することで、 そのクラス内は control_default_async_all と同じ効果が得られる。      _lune_control に default_noasync_this_class を追加する    クラスの body 先頭に default_async_this_class を宣言することで、 そのクラス内は control_default_async_all とは逆に、 デフォルトが __noasync 宣言になる。     ","id":13,"section":"posts","summary":"LuneScript は golang へのトランスコンパイルをサポートしている。 golang 対応の付加機能として、LuneScript には限定的な非同期処理を提供している。 今回は、こ","tags":null,"title":"LuneScript のスレッドにおける mutable 制御","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-16-lunescript-thread-mutable-control/","year":"2021"},{"content":"  LuneScript は golang へのトランスコンパイルをサポートしている。  golang 対応の付加機能として、LuneScript には限定的なスレッド機能を提供している。  「限定的」の大きな理由の一つとして、 golang 向け LuneScript ランタイムのマルチスレッド対応問題がある。 golang 向け LuneScript ランタイム   golang 向け LuneScript ランタイムは、幾つか機能を持っている。 その機能の中には、次のものを含む。    and or 演算子の処理を実現するためのスタック。    lua ランタイム制御。    LuneScript は元々 Lua 向けのトランスコンパイラであり、 Lua はシングルスレッドの言語である。 そのため、 LuneScript の上記ランタイムもシングルスレッドを 想定した構成になっているため、そのままではマルチスレッドで利用できない。  シングルスレッド限定で良ければ、 マルチスレッドを考慮した作りに比べて簡単になるし、その分高速にもなる。 マルチスレッド対応   LuneScript ランタイムをマルチスレッド対応する際には、 次の 2 つの方法が考えられる。    ランタイムの複数インスタンス化    ランタイムの排他制御 ランタイムの複数インスタンス化     スレッド毎にランタイムをインスタンス化して管理する場合、 どのランタイムがどのスレッドのものかを管理する必要がある。  一方で、golang には go-routine の識別 ID がない。 つまり、 「必要な時に識別 ID からランタイムを取得する」 ということが 出来ないことになる。  cgo を利用すれば、 go-routine が動作している pthread ID を取得することは可能だが、 golang のタスクスケジューリングでは、 ある go-routine を実行する pthread が常に固定されている訳ではない。 つまり動的に取得した pthread ID は、 go-routine の ID にはならない。  ということは、 LuneScript ランタイム情報にアクセスするためには、 全ての関数にランタイム情報を渡していく必要がある。 ランタイムの排他制御   ランタイムの複数インスタンス化には、 全ての関数パラメータにランタイム情報の追加が必要になる。 これは、全ての関数でオーバーヘッドが追加になり、 当然プログラム全体がその分遅くなる。  そこで、ランタイムは複数インスタンス化せずに、 アクセスが必要な時だけ排他を掛けるケースを考える。  排他には次のケースがある。    mutex を使う    channel を使う    今回は両方検証する。 パファーマンス   golang の簡単なプログラムで、 複数インスタンス化したケースと、ランタイムの排他制御を実施したケースの パフォーマンスを測ってみた。  なお、実際に複数インスタンス化する訳ではなく、 関数に引数を追加するケースと、 排他制御を追加するケースとで、パフォーマンスを測っている。  結果以下となった。 引数に追加 \u0026lt;\u0026lt;\u0026lt;\u0026lt; mutex \u0026lt;\u0026lt; channel   「引数に追加」が一番負荷が少なく、「channel」が一番負荷が高かった。  ただ「mutex」や「channel」の場合は、 必要な箇所だけに制御を追加すれば良いということを考えると、 「mutex」で対応するのが一番良いのかもしれない。  LuneScript のマルチスレッド対応は、「引数に追加」でいこうと思う。 ","id":14,"section":"posts","summary":"LuneScript は golang へのトランスコンパイルをサポートしている。 golang 対応の付加機能として、LuneScript には限定的なスレッド機能を提供している。 「限定的","tags":null,"title":"Go の関数パフォーマンス","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-15-go-func-performance/","year":"2021"},{"content":"  Language Server Protocol (LSP) の調査メモ。  後でまとめる予定だが、まずは調べた情報を列挙していく。 LSP とは   LSP は、プログラミング開発する上で役立つ様々なサポート機能を定義するプロトコル。  従来は、エディタの開発者や、エディタの拡張機能開発者が プログラミング言語毎に様々なサポート機能の開発を行なっていた。  これにより、同じプログラミング言語でも、エディタごとに異る実装が必要で、 あるエディタでは使える機能が、別のエディタでは使えないなどの問題が発生していた。  この問題を解決するためプログラミング言語のエディタサポートに必要な機能を抽象化し、 プロトコルとして定義することで、 ある言語のサポート機能を実装すれば、 どのエディタでも同じサポート機能を利用できるように開発されているのが、 LSP である。  \u0026lt;https://microsoft.github.io/language-server-protocol/specifications/specification-current\u0026gt; JSON-RPC   LSP は、クライアント・サーバ型のプロトコルであり、 JSON-RCP を利用して通信を行なう。  JSON-RCP は、その名の通り JSON を利用するプロコトルである。  JSON-RCP では、やり取りする JSON のサイズを Context-Length で通知する。 Content-Length: 123\\r\\n \\r\\n { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;id\u0026#34;: 1, \u0026#34;method\u0026#34;: \u0026#34;hoge\u0026#34;, \u0026#34;params\u0026#34;: { ... } }   JSON-RPC は、クライアントからのリクエストをサーバが受け、 そのリクエストの処理結果をサーバが返すが、 http のような同期型の通信ではなく非同期型の通信である。 たとえば、クライアントはサーバからのレスポンスを待たずに複数の リクエストを通知できる。  このため、 JSON-RPC の JSON には、 リクエストを識別するための \u0026#34;id\u0026#34; が付加されていて、 リクエストの id と、それに対応するレスポンスには同じ id が付加される。  リクエストが、どのような処理をサーバに依頼するのかを識別する情報として、 \u0026#34;method\u0026#34; がある。そして、その method の追加情報として \u0026#34;params\u0026#34; を指定する。  これらの内容は、 JSON-RCP を利用する実際のプロトコルで定義される。  なお JSON-RCP は、クライアントからのリクエストとそれのレスポンスだけでなく、 サーバからの通知 (notification)と、 レスポンスを必要としないクライアントからの通知(notification)がある。  これらレスポンスを必要しない通知(notification)には、id が付加されない。  これら通信が、 1 つのセッション上で行なわれる。  このセッションは TCP で行なっても、 stdio で行なっても構わない。 LSP の JSON-RPC   ここでは LSP の JSON-RPC について示す。 LSP 初期化フロー   以下に LSP 初期化フローを示す。    \u0026lt;- はクライアントからのリクエスト    -\u0026gt; はサーバからのレスポンス    \u0026lt;= はクライアントからの通知 (サーバからのレスポンスが不要)   \u0026lt;- initialize -\u0026gt; initialize \u0026lt;= initialized     LSP の初期化は、クライアントからの initialized リクエストで始まる。    サーバは、initialized リクエストを受け初期化を行ない結果を返す。    クライアントはサーバからのレスポンスを受けて、 通信に必要な全ての準備が整ったことを示すため、 initialized を通知する。    initialize method において、 クライアント、サーバそれぞれの能力情報が付加される。  クライアント、サーバそれぞれ、その能力に応じて処理を更新する。  LSP の初期化は必ずこのフローで行ない、 このフローが終了するまで他の通信は行なってはならない。 did   LSP では、編集中のファイルを did という概念で管理する。  プログラミングは基本的にソースコードをストレージに保存し、 その保存したファイルを元にコンパイルなどを行なう。  しかし、プログラミングのサポート機能はコーディング中に実行するのが一般的であり、 コーディング中のコードが常にストレージに保存されているとは限らない。 また、ストレージへの保存は時間がかかるため、 サポート機能の実行のたびにストレージに保存するのは効率が悪い。  そこで、クライアント内でコーディング中のコードを、 ストレージに保存せずにサーバ側と同期管理する必要がある。  それを管理するのが did である。  クライアントは、ユーザがコードを編集すると、 その編集内容をサーバに通知する。 サーバは、その編集内容をサーバ内の did に反映する。 これによって、クライアントで編集中のコードと、 サーバの did 内のコードの整合性が保たれる。  編集内容は、部分更新情報が送られるケースと、 全体更新情報が送られるケースがある。  部分更新情報は、開始・終了位置 (lineno,column) と、 その領域を置き換える文字列情報が送られる。 全体更新情報は、文字列情報だけが送れれ、 did 全体を新しくその文字列に置き換える。  部分更新情報は、通信量が少なくすむため高速に処理できる。 しかし、更新処理を間違えると、クライアントとサーバ間で不整合が発生するため、 更新処理には注意が必要である。  なお、サーバ側が部分更新をサポートするの能力情報を initialize のレスポンスとして返すことができる。  クライアントはその能力情報を見て、 サーバが部分更新をサポートしていない場合は、全体更新で通知を行なう。  つまり、サーバ開発の序盤や、対象のコードサイズが十分小さいケースでは、 部分更新を非サポートとして能力を返すことで、サーバ側の機能をシンプルに出来る。 message   サーバから通知される message には次の 2 つがある。    logMessage    showMessage    logMessage は積極的にはユーザに表示されないメッセージで、 showMessage はユーザに表示されるメッセージ。 主な method   後で調べる。    \u0026#34;initialize\u0026#34;    \u0026#34;initialized\u0026#34;    \u0026#34;exit\u0026#34;    \u0026#34;shutdown\u0026#34;    \u0026#34;client/registerCapability\u0026#34;    \u0026#34;textDocument/completion\u0026#34;    \u0026#34;textDocument/didChange\u0026#34;    \u0026#34;textDocument/didClose\u0026#34;    \u0026#34;textDocument/didOpen\u0026#34;    \u0026#34;textDocument/didSave\u0026#34;    \u0026#34;textDocument/documentHighlight\u0026#34;    \u0026#34;textDocument/documentSymbol\u0026#34;    \u0026#34;textDocument/hover\u0026#34;    \u0026#34;textDocument/publishDiagnostics\u0026#34;    \u0026#34;textDocument/signatureHelp\u0026#34;    \u0026#34;textDocument/willSave\u0026#34;    \u0026#34;window/logMessage\u0026#34;    \u0026#34;window/showMessage\u0026#34;    \u0026#34;workspace/configuration\u0026#34;    \u0026#34;workspace/didChangeConfiguration\u0026#34;    \u0026#34;workspace/didChangeWatchedFiles\u0026#34;    \u0026#34;workspace/didChangeWatchedFiles-0\u0026#34;   ","id":15,"section":"posts","summary":"Language Server Protocol (LSP) の調査メモ。 後でまとめる予定だが、まずは調べた情報を列挙していく。 LSP とは LSP は、プログラミング開発する上で役立つ様々なサポート機能を定","tags":null,"title":"Language Server Protocol (LSP) メモ","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-04-lsp/","year":"2021"},{"content":"  LuneScript は、モジュールを利用する際に import 命令を使用する。  この import 命令は、次の処理を行う。    指定のモジュールの .lns ファイルを解析し、何を定義しているかを調べる    shebang などで起動した場合は、指定のモジュールをロードする    今回は、前者の話をする。 meta 情報   モジュールがどんなクラスや関数や変数を定義しているのかを示す情報を、 LuneScript では meta 情報と呼ぶ。  この meta 情報は、 そのモジュール内で pub (あるいは pro) 宣言されている情報からなる。  これには次の情報を含む。    公開しているシンボル名    公開しているシンボルの型情報    そのモジュールが参照している外部モジュール情報    これらは、 .lns ファイルを解析することで取得できる。  この解析には時間がかかるため、 解析した情報を .meta ファイルとして記録しておき、 .lns ファイルが更新されない場合は .lns ファイルを解析する代わりに、 記録しておいた .meta をロードすることで解析時間を短縮している。  .meta ファイルは lua の table 定義として記録してあり、 lua で .meta ファイルをロードすることで型を構成するために必要な table が読み込まれ、 その table 内の情報を元に LuneScript の型情報を生成する。  一般には、 テキストフォーマットよりもバイナリフォーマットの方が高速に処理できる。  LuneScript の .meta ファイルも、 テキストフォーマットではなくバイナリフォーマットの方が高速に処理できる可能性がある。  しかし、次の理由から .meta ファイルを lua の table 定義として記録している。    LuneScript は元々 Lua VM 上で動作するプログラムだったため、 VM 上でバイナリ操作する api を作成するよりも、 Lua VM のネイティブの load 命令を使用する方が高速に処理できる。    meta ファイルの syntax 変更する場合、 バイナリフォーマットよりもテキストフォーマットの方がやり易い。    不具合があった時に、テキストフォーマットの方が追い易い。   型情報   コード上に宣言した型情報は、 LuneScript トランスコンパイラ内では Ast.TypeInfo クラスで管理される。 Ast.TypeInfo インスタンスは、 1 つの型ごとに 1 つ生成される。  そして、個々の Ast.TypeInfo インスタンスは、 Ast.ProcessInfo クラスで管理される。  Ast.TypeInfo にか、型を識別する ID が付加される。 この ID は、 Ast.ProcessInfo ごとにユニークな値が振られる。  つまり、 1 つの Ast.ProcessInfo 内の Ast.TypeInfo は、 同じ ID を持つ Ast.TypeInfo は存在しないが、 異なる Ast.ProcessInfo においては、 同じ ID を持つ Ast.TypeInfo が存在する可能性がある。  この Ast.ProcessInfo から meta 情報を生成する。 そして import 時には、meta 情報から Ast.ProcessInfo を生成する。 ","id":16,"section":"posts","summary":"LuneScript は、モジュールを利用する際に import 命令を使用する。 この import 命令は、次の処理を行う。 指定のモジュールの .lns ファイルを解析し、何を定義しているかを調べ","tags":null,"title":"LuneScript の import と meta","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-04-lunescript-meta/","year":"2021"},{"content":" Rapberry pi 4 で簡易的な NAS を構築している。  メイン PC の OS が Windows なので、 NAS で使っている HDD を Windows PC と直接接続してアクセスすることを考えて、 NTFS フォーマットの USB HDD を raspi にマウントしていた。  しかし、これだとパフォーマンスが全く出ない(ntfs-3g が重すぎる)。  次回の windows 10 アップデートで、 WSL2 の機能をつかった ext4 マウントがサポートさるようなので、 USB HDD のファイルシステムを NTFS から ext4 に変更することにした。  これによって、NTFS の時は smb 経由で 30MB/sec 程度だったのが、 ext4 では 80MB/sec 程度まで向上した。    FS SMB 転送速度 (MB/sec)     NTFS 約 30MB   ext4 約 80MB     ただ、やはりまだ windows での SATA 接続(170MB程度) と比べると、まだだいぶ遅い。  そこで、 UASP ならもう少し速くなるのではないか？ と思ったので、UASP に対応した USB HDD ケースに入れ替えて試した結果が次の表。    protcol local 書き込み速度 (MB/sec)     USB3.0 約 115MB   UASP 約 119MB     「なんということでしょう。」  UASP を利用することで、 書き込み速度が 4MB も向上した。。。    USB3.0 対応 USB-HDD ケースのアクセス速度計測   pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 12.4745 s, 84.1 MB/s pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 9.12218 s, 115 MB/s pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 9.16875 s, 114 MB/s     UASP 対応 USB-HDD ケースのアクセス速度計測   pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 11.6425 s, 90.1 MB/s pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 8.80392 s, 119 MB/s pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 8.82478 s, 119 MB/s   UASP に入れ替えた結果は、 誤差レベル のパフォーマンス改善だった。  もちろん、 UASP に入れ替え後の SMB 転送速度も誤差レベルだった。  ただ、そもそも SMB 転送速度に関しては、 80MB/sec で既に smbd の CPU 占有率が 100% を越えている状態 なので、 HDD の書き込み速度が改善されたとしても、 smb 経由のパフォーマンスはほとんど改善されないのかもしれない。  raspi は、手軽に NAS を構築できる。 その NAS は、数 GB 程度のファイルのアクセスなら、ストレスなく運用できる。  しかし、大量のファイルコピーするような場合は、 windows などの PC に HDD を SATA で接続して作業するのが得策のようだ。 ","id":17,"section":"posts","summary":"Rapberry pi 4 で簡易的な NAS を構築している。 メイン PC の OS が Windows なので、 NAS で使っている HDD を Windows PC と直接接続してアクセスすることを考えて、 NTFS フォーマットの USB HDD","tags":null,"title":"Rapberry pi 4 で構築する NAS (USB HDD UASP) の性能","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-04-03-raspi-usb-hdd/","year":"2021"},{"content":"  go1.16 から embed が利用可能になりました。  \u0026lt;https://golang.org/pkg/embed/\u0026gt;  embed によって、 プログラムにバイナリデータを埋め込む処理が簡単に行なえるようになります。  LuneScript のコンパイラは、 go でビルドした際に Lua 環境がなくても動作するように、 Lua 用のセルフホストコードをコンパイラ内部に埋め込み、 実行時に埋め込んであるセルフホストコードをロードしています。  以前は、 Lua 用のセルフホストコードを []byte として定義するコードを生成するスクリプトを 自前で実行して、それをビルドしていましたが、 embed を利用することで、その作業が不要になりました。  ここでは、 embed を利用する際に引掛った embed の仕様について説明します。 embed の概要   上記 URL からサンプルを引用します。 import _ \u0026#34;embed\u0026#34; //go:embed hello.txt var s string print(s)   このサンプルは、 hello.txt というファイルに保持されたデータを、 s という string 型の変数で利用できるように設定し、 print(s) で出力するコードです。  重要なのは次です。    embed を import する。    バイナリデータを格納する変数を トップスコープ に var で宣言する    変数 var の直前に //go:embed path のコメントを記載する   変数宣言   バイナリデータを格納する変数を宣言します。 この時、次が重要です。    変数はファイル内の トップスコープ に宣言する    変数の型は次のいずれか    string    []byte    embed.FS      embed.FS は、次の用途で利用します。    埋め込むのがファイルではなくディレクトリの場合    バイナリデータだけでなく、ファイルの更新日時などの情報も必要な場合    上記の条件を満さない場合はビルドエラーします。 変数 var の直前に //go:embed path のコメント   データを格納する変数宣言の直前に //go:embed path のコメントを記載します。  この時、次が重要です。    // と go の間に スペースが入ってはならない    path は go build を実行するディレクトリからの 相対パス    . や .. を含まない。      // と go の間にスペースが入ると、単なるコメントとして扱われ、 変数は NULL 値で初期化されます。 この時なんの warning も出力されません。  path は、 . や .. を含まない相対パスです。 つまり、go build を実行するディレクトリ以降にファイルが存在している必要があります。  この path の仕様は少し不便に感じましたが、 プロジェクトを go get でビルドできるようにするには必要な対応だと思うので、 仕方がないところでしょう。 ","id":18,"section":"posts","summary":"go1.16 から embed が利用可能になりました。 \u0026lt;https://golang.org/pkg/embed/\u0026gt; embed によって、 プログラムにバイナリデータを埋め込む処理が簡単に行なえるようになります。 LuneScript のコンパイラは、 go で","tags":null,"title":"go1.16 の embed によるファイル埋め込み","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-02-28-go-embed/","year":"2021"},{"content":"  raspberry pi でローカルサーバを立ち上げているが、 この sdcard 寿命が気になったので調べてみた。  sdcard はでなく、 hdd や ssd で運用する方法もあるが、 sdcard で運用できる方がランニングコストが良いので、できれば sdcard で運用したい。 sdcard の寿命の見積り   iostat -h で sdcard への書き込み量を調べると、 1日約 1GB の書き込み がある。  この書き込みが sdcard の 何ブロックを書き換えているのか不明 なので、 とりあえず 10 倍の 10GB 相当 のブロックを書き換えたとする。  次に sdcard が SLC か MLC か TLC かだが、 パッケージも何も残っていないので予測でしかないが、 数年前にアキバの最安値のものを買ったはずなので TLC と予想する。  そして 16GB の sdcard なので、TLC ならば 約 16TB の書き込みが可能だとすると、 1 日 10GB の書き換えで 約 4 年間 で寿命を越えることになる。  ほとんどが予想でしかないが、少なくとも 1 年は寿命を気にせずに使用できるだろう。  そんな訳で、このままの構成で1年程度運用してから、 来年あたりに MLC の高耐久モデルの sdcard に入れ替えて運用しようと思う。 そうすれば、10 年程度は運用できるだろう。  もちろん 10 年間も運用するとは思えないので、 今のサーバ構成で MLC の sdcard を使用すれば、 実質的に寿命を気にする必要はないだろう。  もしも 1 年の運用中に sdcard の寿命を越えるようなことがあれば、 sdcard のブロック書き換え数の見積りが想定以上だったか、 ハズれの sdcard を引いたかになる。  ブロック書き換え数の見積りが想定以上なのだとしたら、 sdcard の容量を大きめのサイズにすることで対応できるだろう。  ちなみに現状の sdcard の書き込みサイズ情報は以下の通り。  約 185 GB (+ 129 56) $ sudo dumpe2fs -h /dev/mmcblk0p2 | grep \u0026#34;Lifetime writes\u0026#34; dumpe2fs 1.44.5 (15-Dec-2018) Lifetime writes: 129 GB  $ iostat -h Linux 5.10.4-v8+ (raspberrypi4) 17/02/21 _aarch64_\t(4 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 2.9% 3.8% 1.6% 0.3% 0.0% 91.5% tps kB_read/s kB_wrtn/s kB_read kB_wrtn Device 0.41 3.4k 24.8k 7.7G 56.3G mmcblk0  パフォーマンス計測   寿命を予測する方法として、 定期的(月に一度程度)に SD card への書き込みパフォーマンスを記録することにした。  パフォーマンスは dd コマンドによる 200MB 書き込みの時間とする。  ただし、書き込み時間はかなりばらつく。 特に初回の dd コマンドの書き込みはバッファリングが効くためか異様に早いので、 3回目、4回目を記録する。 2021/04/17  $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 42.9515 s, 4.9 MB/s $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 30.8832 s, 6.8 MB/s   この時点で既にめちゃくちゃ遅い。  今後どれほど変っていくのか興味深い。 2021/05/30  $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 28.4992 s, 7.4 MB/s 4$ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 60.2642 s, 3.5 MB/s  $ iostat -h tps kB_read/s kB_wrtn/s kB_read kB_wrtn Device 0.41 3.1k 36.6k 15.9G 187.0G mmcblk0 $ sudo dumpe2fs -h /dev/mmcblk0p2 | grep \u0026#34;Lifetime writes\u0026#34; Lifetime writes: 261 GB   予想よりもだいぶ多い書き込みが発生している。  次回も書き込み速度がさらに下るようなら、 実験を停止して新しい SD カードに移行した方が良いかもしれない。 2021/07/04  $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 47.6562 s, 4.4 MB/s $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 38.4939 s, 5.4 MB/s  $ iostat -h Linux 5.10.4-v8+ (raspberrypi4) 04/07/21 _aarch64_\t(4 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 2.9% 3.6% 1.5% 0.2% 0.0% 91.7% tps kB_read/s kB_wrtn/s kB_read kB_wrtn Device 0.16 2.5k 2.5k 6.9G 6.7G mmcblk0 0.24 0.1k 32.6k 147.1M 88.2G sdb $ sudo dumpe2fs -h /dev/mmcblk0p2 | grep \u0026#34;Lifetime writes\u0026#34; Lifetime writes: 454 GB  2021/08/01  $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 32.3397 s, 6.5 MB/s $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 34.3965 s, 6.1 MB/s  $ iostat -h Linux 5.10.4-v8+ (raspberrypi4) 01/08/21 _aarch64_\t(4 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 3.0% 3.5% 1.5% 0.2% 0.0% 91.8% tps kB_read/s kB_wrtn/s kB_read kB_wrtn Device 0.16 2.5k 2.3k 12.3G 11.7G mmcblk0 0.24 0.0k 33.3k 236.0M 166.7G sdb  2022/01/02  $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 39.4435 s, 5.3 MB/s $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 46.9338 s, 4.5 MB/s $ iostat -h Linux 5.10.4-v8+ (raspberrypi4) 02/01/22 _aarch64_\t(4 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 3.0% 0.3% 1.2% 0.1% 0.0% 95.3% tps kB_read/s kB_wrtn/s kB_read kB_wrtn Device 0.15 3.0k 2.4k 12.4G 10.2G mmcblk0 0.24 0.0k 32.7k 148.3M 136.2G sdb  ","id":19,"section":"posts","summary":"raspberry pi でローカルサーバを立ち上げているが、 この sdcard 寿命が気になったので調べてみた。 sdcard はでなく、 hdd や ssd で運用する方法もあるが、 sdcard で運用できる方がラ","tags":null,"title":"raspberry pi の sdcard 書き換え回数寿命を考える","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-02-17-rasp-sdcard/","year":"2021"},{"content":"  LuneScript の解説サイトは、 hugo を使用して構築している。 その解説サイトに掲載しているソースコードは、 hugo によって解析されて、色付けに必要な \u0026lt;span class=\u0026#34;\u0026#34;\u0026gt; が付加され、 css で色付けを行なっている。 なお、 ソースコードの解析自体は hugo というよりも、 hugo が chroma の API を呼び出して利用している。  しかし LuneScript は超マイナー言語なので、 chroma の対応言語には当然 LuneScript が入っていない。  これだと LuneScript のサンプルコードのハイライトが付かないため、コードを読み難い。 そこで、LuneScript のハイライト表示に対応するために highlight.js を導入したので、 今回は highlight.js を利用して独自言語の色付けを行なうための方法を簡単に説明する。  ハイライト表示の対応手段として chroma の方を変更するという方法もあるが、 highlight.js の方が hugo を使用していないどの Web サイトでも使えるので汎用的だろう。  ちなみに chroma は、 hugo で静的サイトを構築する際に コンテンツ内のソースコードを解析して、解析結果を反映した html を出力する。 一方で highlight.js は、 Web ブラウザでソースを表示する際に動的にソースコードを解析する。  つまり、 chroma 側で対応した方がブラウザの負担を減らし UX を向上できる。 しかし、サンプル程度の短いソースコード解析であれば、 さほど解析に時間がかかることもないので、気にする必要はないだろう。 highlight.js への独自言語追加   まずは以下を追加する。 \u0026lt;script src=\u0026#34;//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;   なお、 highlight.js の公式サイトには default.min.css のロードの記載もあるが、 独自言語追加には不要である。 highlight.js によるソースコード解析   次の関数を実行して、ソースコードを保持する element を highlight.js で解析する。 hljs.highlightBlock( element );   このとき element の class は、 language-言語識別 として定義しておく。 例えば LuneScript は language-lns としている。  なお、 highlight.js の使用方法として次の関数を実行する方法が紹介されているが、 hljs.initHighlightingOnLoad();   この関数は全ての \u0026lt;pre\u0026gt;\u0026lt;code\u0026gt; element を解析対象としてしまう。  今回は、 LuneScript 以外の言語を hugo で解析済みなので、 全ての \u0026lt;pre\u0026gt;\u0026lt;code\u0026gt; を解析対象にしてしまうと 2 重解析になってしまうため、 hljs.highlightBlock( element ); で解析する element を明示的に指定する。  hljs.highlightBlock( element ); によって highlight.js による解析が行なわれるが、 まだこの状態では highlight.js は独自言語に対応していない。 そこで、highlight.js に独自言語の情報を事前に登録しておく。 highlight.js への独自言語の登録   highlight.js へ独自言語を登録するには次の関数を利用する。 hljs.registerLanguage( langName, langDef )   ここで、 langName は前述の language-言語識別 の 言語識別 部分を指す。 つまり language-lns の場合 \u0026#34;lns\u0026#34; を langName に使用する。 langDef は、次のような関数オブジェクトを指定する。 function( obj ) { return { keywords: \u0026#34;hoge foo bar\u0026#34; }; }    つまり、まとめると以下のようになる。 hljs.registerLanguage( \u0026#34;lns\u0026#34;, function( obj ) { return { keywords: \u0026#34;hoge foo bar\u0026#34; }; });    上記の langDef で定義する関数オブジェクトは、 言語情報を定義するオブジェクトを返す。  このオブジェクトの詳細は次の URL に記載がある。  \u0026lt;https://highlightjs.readthedocs.io/en/latest/mode-reference.html\u0026gt;  以降では、良く使う属性について説明する。 言語情報定義オブジェクト   まず、言語情報定義オブジェクトが何を定義するものかを説明する。  highlight.js は、ソースコード内の文字列を解析し、 「どの文字列」が「何の種別」かを判別する。  このオブジェクトは、「どの文字列」「何の種別」を定義するのが役割である。  たとえば、 C 言語では for, while, if などの文字列の種別は予約語(keyword) であり、 /* */ で括られている文字列の種別はコメント(comment) である。  次のオブジェクトを返すことで、for, while, if を keyword として定義できる。 return { contains: [ { className: \u0026#34;keyword\u0026#34;, keyword: \u0026#34;for while if\u0026#34; } ] };    ここで className は、 for while if が keyword であることを示す。  この定義のよって、 highlight.js は解析対象のソースコード内の for を、次のように変換する。 \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;for\u0026lt;span/\u0026gt;   highlight.js は、上記オブジェクトの className で指定した名前を span element のクラス名として使用する。  この例の場合 className: \u0026#34;keyword\u0026#34; で定義したクラス名は、 \u0026#34;hljs-keyword\u0026#34; となる。 仮に className が \u0026#34;hoge\u0026#34; ならば、 \u0026#34;hljs-hoge\u0026#34; となる。  このように 言語情報オブジェクトで定義した各文字列にクラスが指定されるので、 CSS によって hljs-keyword に色を指定することでソースコードの色付けが可能になる。  なお、 className は任意の文字列を定義可能だが、 もし将来独自言語の対応を highlight.js に pull request したい、 という思いがあるならば、 highlight が既に対応している言語に合せて className を利用するべきだろう。 contains  { contains: [ { className: \u0026#34;keyword\u0026#34;, begin: /hoge|foo|bar/ } ] }    contains は、 sub-mode を配列で指定するためのものである。 sub-mode は JavaScript の object で、 上記の例では { className: \u0026#34;keyword\u0026#34;, begin: /hoge|foo|bar/ } が sub-mode である。 複数の種別を定義する際に利用する。 begin, end   begin は、定義する種別の文字列の開始パターンを定義する。 なお、 end を明示的に指定しない場合、 begin でマッチした文字列だけが、所定の種別になる。  つまり、 { className: \u0026#34;keyword\u0026#34;, begin: /hoge|foo|bar/ } は、 種別 keyword は、文字列 hoge , foo, bar から成ることを定義している。  もしも end に end: /$/ を指定した場合、 hoge, foo, bar のいずれから始まり、その行末までが指定した種別 keyword になる。 ネスト   sub-mode はネストできる。 { contains: [ { className: \u0026#34;keyword\u0026#34;, begin: /abc/, end: /ij/, contains: [ { className: \u0026#34;meta\u0026#34;, begin: /ef/ } ] } ] }    上記は keyword の種別の中に meta を含む定義である。  これは、次のような文字列があった場合、 abc defgh ijk   abc 〜 ij までを \u0026#34;keyword\u0026#34; として扱い、 その中の ef を \u0026#34;meta\u0026#34; として扱う。  この時の HTML 出力は次になる。 \u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;abc d\u0026lt;span class=\u0026#34;hljs-meta\u0026#34;\u0026gt;ef\u0026lt;/span\u0026gt;gh ij\u0026lt;/span\u0026gt;k   ネストすることで、ある種別の中に別の種別を定義することが可能になる。 LuneScript の highlight.js 設定   参考までに、 highlight.js に LuneScript を追加登録するスクリプトを載せておく。 \u0026lt;script src=\u0026#34;https://ifritjp.github.io/documents/js/highlight_lns.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://ifritjp.github.io/documents/css/highlight_lns.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;   LuneScript のソースを保持する element の class は、 language-lns として指定する必要がある。 ","id":20,"section":"posts","summary":"LuneScript の解説サイトは、 hugo を使用して構築している。 その解説サイトに掲載しているソースコードは、 hugo によって解析されて、色付けに必要な \u0026lt;span class=\u0026#34;\u0026#34;\u0026gt; が付加され、","tags":null,"title":"highlight.js で独自言語の色付けを追加","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-02-01-hilightjs/","year":"2021"},{"content":"  WSL2 と virtual BOX が共存できるようになったらしいので、 家の環境に WSL2 を入れてみました。  セットアップ自体は上手くいきましたが、 結果として virtual BOX のパフォーマンス(DISK IO？)は 1,2 割程度落ちたようです。  WSL2 のパフォーマンスが WSL2 無効時の virtual BOX と同等程度なので、 virtual BOX から WSL2 に完全移行できるなら問題ないと思いますが、 WSL2 に完全移行できず、かつ、1,2 割程度のパフォーマンスダウンが許容出来ない場合は、 従来通り WSL2 無効で運用することになると思います。  個人的には、試しに暫く WSL2 で運用し、 問題なければそのまま WSL2 に移行する予定です。  今回の作業でいくつかハマったポイントがあるので、 備忘録として残します。  基本的な WSL2 セットアップに関しては、 ネットにいくつも手順が載っているのでそれを参考にしてもらうとして、 ここでは個人的にハマった点に絞って書きます。 VirtualBox での Guest OS 起動が失敗する   以下の 2 つのポイントがあります。 VirtualBox の プロセッサー設定で、ネステッド VT-x/AMD-V を有効化をチェックしている   WSL2 を有効にすると、 VirtualBox などの既存の仮想化アプリに制限がかかり、 一部機能を利用できなくなります。  その一つに「ネステッド VT-x/AMD-V」があるようです。 「Windows ハイパーバイザー プラットフォーム」を有効化していない   WSL2 を有効にしている環境で VirtualBox などの既存の仮想化アプリを実行するには、 上記機能を有効化する必要があります。  WSL2 が有効な環境では、VirtualBox などの既存の仮想化アプリは、 「Windows ハイパーバイザー プラットフォーム」という機能を経由して、 仮想化制御を行なうようです。  なお、VirtualBox などの既存の仮想化アプリはこの機能を経由するため、 WSL2 無効環境と比べるとパフォーマンスが落ちているような気がします。 wsl コマンドを実行する際の Shell は管理者権限で起動してはならない   WSL2 のセットアップで、ディストリビューションのイメージの一覧を確認する際、 次のコマンドを入力します。 wsl -l   この wsl コマンドを実行する際、Shell を管理者権限で実行していると、 ubuntu をインストールしているのにも関わらず次のように出力されました。 \u0026gt; wsl -l Linux 用 Windows サブシステムには、ディストリビューションがインストールされていません。 ディストリビューションは Microsoft Store にアクセスしてインストールすることができます:   何故このようなことになったかというと、 私は普段 Windows を使用する際、 管理者権限のないアカウントで作業してます。 そして、管理者権限が必要な作業をする時に、 管理者権限で実行したり、管理者アカウントで入って作業しています。  今回も、一般ユーザのアカウントで WSL2 をセットアップしていました。  そして、 Web の作業手順に管理者権限で実行するように書いてあったため、 PowerShell を管理者権限で実行していました。  しかし管理者権限の PowerShell で \u0026#34;wsl -l\u0026#34; を実行すると、 管理者権限のユーザ環境にインストールされている ディストリビューション情報がリストされるため、 一般ユーザのアカウントにインストールしていた ubuntu の情報は出力されない、 ということです。  wsl コマンドの操作に管理者権限は不要です。 というか、管理者権限で実行するとこのような現象が発生するため、 管理者権限は付けずにそのまま実行してください。  WSL2 を使うようなユーザは管理者権限を持つアカウントで作業すると思うので、 こんなことにハマらないでしょうが、 一応気をつけてください。 cygwin xorg で GUI 表示できない   virtual Box で作業する際、 ssh で入ってX11トンネリングした xwindow で作業しています。  WSL2 の場合は、 ssh ではなく直接 DISPLAY を指定して作業する例が紹介されています。  その例に沿って作業すると、xwindow の接続が出来なかったので、 それの対応方法を説明します。 Error: Can\u0026#39;t open display:   最初は次のようなエラーになりました。 $ DISPLAY=xxx.xxx.xxx.xxx:0 xeyes Error: Can\u0026#39;t open display: xxx.xxx.xxx.xxx:0   これは、指定の DISPLAY に接続できないことを示します。  これを解決するには、 cygwin の xserver 起動のショートカットに次のオプションを追加します。 -- -listen tcp   ssh のX11トンネリングの場合、 xserver のサービスを listen しなくても接続できるのですが、 ssh のX11トンネリングではなく直接通信を行なう場合は、 xserver のサービスを listen しておく必要があります。 Authorization required, but no authorization protocol specified   xserver のサービスを listen しても、次のようなエラーになりました。 $ DISPLAY=xxx.xxx.xxx.xxx:0 xeyes Authorization required, but no authorization protocol specified Error: Can\u0026#39;t open display: xxx.xxx.xxx.xxx:0   これは、 xserver に接続するには認証が必要なことを示しています。  これを解決するには、次の手順を行ないます。    windows 側で次を実行   $ xauth list NAME:0 MIT-MAGIC-COOKIE-1 ??????????????????????   ここで出力された MIT-MAGIC-COOKIE-1 ?????????????????????? をコピーしておきます。    クライアント側 (ubuntu)で次を実行   $ xauth add xxx.xxx.xxx.xxx:0 MIT-MAGIC-COOKIE-1 ??????????????????????   これで、 ubuntu から windows の xwindow に表示されます。  なお、 server の auth control を無効化する方法 (startxwin の -auth を与えないように修正する方法)でも対応できますが、 xauth を使っておいた方が無難でしょう。 WSL2 のイメージデータの置き場所   WSL2 のイメージデータは、次の場所で管理されています。 C:\\Users\\?????\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu20.04onWindows_????????\\LocalState   このイメージデータを直接操作することはありませんが、 実体が何処にあるかは意識しておいた方が良いでしょう。  自分の PC 環境は、 C ドライブは m.2 NVMe で、 D ドライブを HDD にしていて、 開発作業は D の HDD で行なっています。  開発作業は docker イメージの作成などによって、 そこそこ書き込み量が多いので、 イメージデータが C ドライブにあるのはあまり望ましくないです。  なので、しばらくこのまま使ってみて、 C への書き込み量が急激に増えるようならイメージデータを D に移すか、 virtual box に戻すかしようと思います。  ちなみ現在 (2020/12/09) の書き込み総サイズは、 1522 GB   スペック上、 200TB までは大丈夫なはず。  なお、既に 1 年ちょっと使っている状態なので、 今のペースだと単純計算で 100 年くらいは大丈夫なはずだったｗｗ WSL2 の RAM   WSL2 は、RAM の使用状況を確認せずに固定サイズを上限としてメモリを使用するようです。  これにより、メモリを多く使用する他のアプリと一緒に WSL2 コンテナを実行すると、 メモリ枯渇が発生します。  これを防ぐには、 %USERPROFILE%\\.wslconfig ファイルを生成し、 以下の内容を設定して WSL2 のメモリ上限を設定します。 [wsl2] memory=6GB swap=0   \u0026lt;https://qiita.com/yoichiwo7/items/e3e13b6fe2f32c4c6120\u0026gt;  以上。 ","id":21,"section":"posts","summary":"WSL2 と virtual BOX が共存できるようになったらしいので、 家の環境に WSL2 を入れてみました。 セットアップ自体は上手くいきましたが、 結果として virtual BOX のパフォーマン","tags":null,"title":"WSL2 と cygwin xorg を使って GUI 表示するまでのハマりどころ","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-12-09-wsl2-xwin/","year":"2020"},{"content":"  LuneScript の CI 環境として github actions を使用している。 この CI のテスト時にビルドした go 版 LuneScript のシングルバイナリを、 google drive にアップロードして公開するように対応した。  \u0026lt;https://drive.google.com/drive/folders/1S5NgeM6qIOIUC0rkBHqnWZcuhmsTqB2w\u0026gt;  今回は、この手順について説明する。 公開方法   基本的には次の手順に従えば出来るが、 Google の UI の一部が変っているので、そこを主に補足していく。  \u0026lt;https://qiita.com/satackey/items/56729c8551aabb2ae7cc\u0026gt; skicka   google drive へのアップロードは skicka を利用する。  skicka は OSS だ。  この skicka を利用するためには、 OAuth2 認証 ClientID と Client Secret が必要になる。  OAuth2 認証は、ウェブサービス間のアクセス権を管理するもので、 今回は skicka が google drive へアクセスするための権利を取得するために OAuth2 が必要になる。 OAuth2 ClientID と Client Secret   前述の通り OAuth2 は、ウェブサービス間のアクセス権を管理する。 ここでは google drive と skicka の間のアクセスが対象となる。 では OAuth2 ClientID が何故必要になるかというと、 アクセス権を求めて来ているのが何者で、どのようなサービスなのか？ということを google とユーザ自身が認識するのに利用するためだ。  世の中には google drive にアクセスするサービスが大量にあるが、 それらは全て個々の ID が割り振られている。  そして Client Secret は、 ClientID を使用しているサービスが、 本当にその ClientID の所有者かどうかを判断するために利用する鍵のようなものだ。  ClientID と Client Secret によって、 なりすましによる サービスへの不正アクセスを防止している。 (なりすましの防止というか、 誰がアクセスしようとしているのか？を確認する手段を提供している) skicka に ClientID と Client Secret が必要な理由   ClientID は、そのサービスが何者なのかを識別するためのものなので、 サービス提供者と ClientID の保有者は同じなのが普通である。  しかし、 skicka はオープンソースのツールであり、 もちろん作者は私ではない。 それなのに skicka を利用するために私が ClientID, Secret を用意する必要がある。  それは何故か？  少し話が逸れるが、 twitter クライアントアプリには公式アプリ意外にも様々なアプリがある。 あれらのアプリを利用する際にアカウントの認証は行なうが、 ユーザは ClientID, Secret を用意しなくて良い。  この違いは何かというと、 skicka はツールそのものを提供しているのに対し、 twitter クライアントアプリはサービスを提供している。  別の言い方をすると、 *skicka は使用者自らがサービス提供者* になり、 *twitter クライアントアプリは、 アプリ開発者がサービス提供者* になる。  この違いを認識していないと、 これ以降の作業に問題が生じた時に対処が難しくなるのと、 セキュリティの考え方にも影響してくるので、注意が必要だ。 ClientID / Client Secret 取得方法   取得方法は次の URL の手順に従う。  \u0026lt;https://qiita.com/satackey/items/34c7fc5bf77bd2f5c633\u0026gt;  ただし次の点に注意する。    アプリケーションのタイプを選択する箇所があるが、 この時「テレビと入力機能が限られているデバイス」を選択する。    この選択を間違えると、 OAuth2 認証が失敗する。 トークン取得方法   上記 URL の手順に従うとトークン取得まで行なえる。  しかし、次の点に注意が必要である。  認証を通す前に、次の画面で設定が必要になる。   2箇所をマークしてあるが、それぞれ次の意味である。    アプリを公開    デフォルトでは、サービスがテスト状態になっている。    テスト状態では、事前に登録したアカウントだけが認証が通るようになっている。    つまり、事前にアカウントを登録しておかないと、 上記 URL の手順の OAuth2 認証が通らない。    逆に言えば、事前にアカウントを登録すれば、サービス設定を公開に変更する必要はない。    skicka は個人で使うので、サービスを公開してもリスクしかない。 よって、ここはテスト状態のままにする。      ADD USERS    前述した通り、テスト状態では事前にアカウントを登録しておかないと OAuth2 認証が通らない。    ここでは、そのアカウントの登録を行なう。    アカウント情報は、許可するアカウントのメールアドレスをセットする。    なお、 Client ID を発行したアカウントと、 OAuth2 認証を許可するアカウントが別でも良い。      上記の通り事前にアカウントを登録しておくことで、 OAuth2 認証が通る。  なおこの設定で OAuth2 を通すと警告ページが表示されるが、 これはサービスがテスト設定の状態なための警告なので、 そのまま進めて問題ない。  以上 ","id":22,"section":"posts","summary":"LuneScript の CI 環境として github actions を使用している。 この CI のテスト時にビルドした go 版 LuneScript のシングルバイナリを、 google drive にアップロードして公開するように対応した。 \u0026lt;https://drive.google.com/drive/folders/1S5NgeM6qIOIUC0rkBHqnWZcuhmsTqB2w\u0026gt;","tags":null,"title":"github actions でビルドしたモジュールを google drive にアップロード","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-12-05-lns-release/","year":"2020"},{"content":"  LuneScript 向けの別ツールを作ろうと思い、 LuneScript の go 向けランタイムを単独モジュールとして分割して管理すべく 奮闘した際の備忘録。 go のモジュール   go は、 github に公開されているモジュールを取得して使用できる。  では、自作モジュールを github に公開して使用するにはどうすれば良いか？  ここでは、その方法について順を追って説明する。 go のモジュール管理のおさらい   go にはモジュール管理機能が内包されており、 基本的には次の手順でコマンドを実行するだけで、 使用している依存モジュールを管理できる。 $ go mod init $ go mod tidy   依存モジュール情報は go.mod に記録される。 自作モジュールを github へ公開する   モジュールを github へ公開しないと始まらないので、 まずは github に公開する。  この時ディレクトリ構成は何でも良い。  最も重要な点は、次の 1 点。  タグを付ける  このタグは v0.0.0 (数値はモジュールのバージョン)で付ける。  これがないと、 意図したリビジョンのモジュールを go が取ってきてくれない。  タグは必須ではない。  タグはバージョン管理する際に必要だが、 タグがなくても go でモジュールを利用できる。  go mod init した際に、 プログラムで import しているモジュール情報を収集し、 そのモジュールの最新のタグを拾ってきて go.mod に記録している。  このときに依存モジュールの git に一つもタグがないと、 依存モジュールの初回コミットが利用される。 一つでもタグがある場合は、そのタグが利用される。  go のバージョンアップで go mod init , go mod tidy の動きが変っている。  go 1.16 では、以下の動作になる。    go mod init    go のコードは解析せず、 module 名と go のバージョンだけ記載した go.mod を作成する。      go mod tidy    go のコードを解析し、 import しているモジュール情報を取得し go.mod に反映する。    このとき、 import しているモジュールにタグが付いていれば、 最新タグのモジュールを取得する。    タグ付けした後に更新があったとしても、 それにタグが無ければその更新は無視される。      import しているモジュールにタグが付いていなければ、最新のコミットを取得する    go.mod に、既にモジュール情報、バージョン情報が記載されていれば、 その情報は更新しない。    バージョン情報にブランチ名を書いていると、そのブランチの最新コミットを取得する    これは、モジュールにタグが付いている場合でも、最新コミットを取得する。       自作モジュールの更新   自作モジュールを更新した場合、 git への push はもちろんのこと、 タグを付けなければならない。  前述した通り、go の依存モジュール管理は、あくまでもタグで制御しているため、 その修正を有効にするにはタグ付けが必須である。  自作モジュールを更新した場合、git への push するだけで良い。  なお、ローカルで試す際は git への push せずに確認できる。 go.mod の更新   モジュールを使用している側の go.mod は、 import しているモジュールと、そのバージョン(タグ)を紐付けて管理している。  一度 go.mod にバージョン情報が記録されると、 go mod tidy を実行しても依存モジュールのバージョンが自動で更新されることはない。  使用する依存モジュールのバージョンを更新するには、 go.mod で指定されているバージョンを書き換える必要がある。  最新に変更するだけなら、バージョン情報にブランチ名を書けば良い。 たいていは master を指定するだけでよい。  環境変数の GOPATH 以下にソースを置いていれば、基本的にはこれだけで良い。  環境変数の GOPATH 以下にソースを置いていない場合は、 幾つかの対応が必要となる。  なお、 go module を利用するのであれば、 GOPATH 以下にソースを置くのが結局は間違いのない方法になる。  ただし、GOPATH 以下にソースを置くとディレクトリが深くなってしまうので、 それを嫌うのであれば、ソースを管理するディレクトリは別に作成し、 GOPATH 以下にはシンボリックリンクを作成することで回避できる。 但し、シンボリックリンクでは正常に動作しない可能性も考えられるので、 その辺りは自己責任で。 replace   以上のように、 依存モジュールはバージョン情報で管理されている。  これは、依存モジュールの再現性を担保するには必要な機能である。 一方でバージョン毎に管理するのが面倒なこともある。  replace 機能は、 require しているモジュールを他の場所から取得できるように置き換える機能である。  たとえば、 github.com/ifritJP/lnssqlite3 のモジュールを ../ のローカルディレクトリから取得したい場合は、 次のように書く。 require github.com/ifritJP/lnssqlite3 v0.0.0 replace github.com/ifritJP/lnssqlite3 =\u0026gt; ../   これにより github.com/ifritJP/lnssqlite3 は、 どのバージョンに限らずに ../ ディレクトリのものを利用する。 ブランチ名   前述の通り go.mod は依存モジュールをバージョンと紐付けて管理している。 module hoge go 1.14 require github.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e require github.com/ifritJP/LuneScript v1.1.12-0.20201216131727-df4ec0979d4d   ここで、次のようにバージョンの代わりにブランチ名を指定し、 go mod tidy することで、そのブランチの最新を取得できる。 module hoge go 1.14 require github.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e require github.com/ifritJP/LuneScript master   ただし、go mod tidy すると、 上記の master の部分が v1.1.12-0.20201216131727-df4ec0979d4d のように 最新のバージョンに置き変わるので、 依存ライブラリを再度更新した場合、 go.mod を master に書き直す必要がある。 外部ライブラリを利用している場合   LuneScript は、外部ラリブラリとして lua を利用している。  go は cgo を使うことで C 言語のライブラリを利用できるが、 cgo では外部ライブラリの include パスやリンクオプションを .go のソースファイル内にコメントとして指定する必要がある。  外部ライブラリのパスは環境によって異なるため、 全ての環境に合せて include パスやリンクオプションを指定しておくことは出来ない。  そこで pkg-config を利用する。  cgo で pkg-config を利用するには、次のように指定する。 // #cgo pkg-config: package1 package2 package3   LuneScript では、次のように指定している。 // #include \u0026lt;string.h\u0026gt; // #include \u0026lt;stdlib.h\u0026gt; // #cgo pkg-config: lua-5.3 // #include \u0026lt;lauxlib.h\u0026gt; // #include \u0026lt;lualib.h\u0026gt; import \u0026#34;C\u0026#34;  ","id":23,"section":"posts","summary":"LuneScript 向けの別ツールを作ろうと思い、 LuneScript の go 向けランタイムを単独モジュールとして分割して管理すべく 奮闘した際の備忘録。 go のモジュール go は、 github に公開","tags":null,"title":"go の自作モジュールを github で公開して import するまで","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-11-28-golang-module/","year":"2020"},{"content":"  前回から引き続き LuneScript のトランスコンパイル時間短縮を行なっています。  今回の時間短縮は以下の通りです。    改善前(lua) 改善後(go) 参考 (lua batch) 参考 (luajit)     20.65 sec 4.32 sec 21.90 sec 21.56 sec     この表の通り、 (/ 20.65 4.32) 4.780092592592592 ≒ 478% 改善しています。  以降では、今回の LuneScript 性能向上の実現方法について説明します。 一括処理   従来は、複数ある .lns ファイルを一つずつ処理するために、 LuneScript をファイル数分実行していました。  今回は、複数ある .lns ファイル全てを 一回の LuneScript の起動で処理するように対応しました。  これによって、次の効果が得られていると思います。    データがメモリ上にキャッシュされ、一部の解析が不要になった    複数回の起動終了処理に掛る時間が、 1 度だけになった    ある意味で当たり前といえば当たり前の結果ですが、 これを実現するには、最低限リエントラントにする必要があり、 意外なところに落とし穴があったりするものです。  まぁ今回は事前に準備をしておいたので、 解析処理の繰り返し制御部分を追加しただけで動いたのですが。  上の表を見ると分かりますが、 同じ一括処理を Lua 版 LuneScript で実行すると 逆に遅くなるという結果になりました。  なお、今回の対応後の goprof の結果を見ると、 import 処理が思った以上に短縮されていないことが分かりました。  この原因は、 トランスコンパイルするファイルが異なる場合、 以前別のファイルで import した型も再度登録処理しているため、 想像以上に時間がかかっているようです。  これは、型の ID がファイル毎にシーケンシャルになっていることを前提に処理しているため、 必要な処理です。 この import 処理を高速化するには、 「型の ID がファイル毎にシーケンシャルになっている」ことを期待しないで 処理できるように対応する必要があります。  これはちょっと面倒そうです。  ただこれを改善すると、更に 1 秒近く改善できそうなので対応する価値はあります。  気が向いたら対応しようと思います。  なお今回の一括処理対応では、指定されたファイルをシーケンシャルに処理します。 個々のファイルのトランスコンパイル処理を並列化していません。  LuneScript のセルフホスティングのソースでは、 ほとんどのファイルが片方向リストの様に import しているため、 並列に処理することが出来ません。 前のファイルを処理しないと、次のファイルが処理できない状態です。  よって、並列化されないことはほとんどパフォーマンスに影響しません。 しかし、プロジェクトによっては並列化の影響が大きいこともあります。  その場合は、今回の一括処理すると遅くなる可能性があります。 使用方法   LuneScript のトランスコンパイル対象ファイル指定のオプションに @- を指定し、 トランスコンパイル対象のファイルパスを一行毎 stdin に入力するだけです。  なお、一点注意があります。  一括処理している際の –depends オプションは、 ディレクトリ指定として扱います。  つまり従来のファイル毎の LuneScript では、 –depends オプションは、 Make 用依存ファイルの出力先ファイルパスでしたが、 一括処理時の –depends オプションは依存ファイルの出力先ディレクトリパスになります。 そして、実際に出力さられるファイルは、その出力先ディレクトリパスに トランスコンパイル対象のファイルパスの .lns を .d に変換したファイルとなります。 ","id":24,"section":"posts","summary":"前回から引き続き LuneScript のトランスコンパイル時間短縮を行なっています。 今回の時間短縮は以下の通りです。 改善前(lua) 改善後(go) 参考 (lua batch) 参考 (luajit)","tags":null,"title":"LuneScript のトランスコンパイル時間を 478 パーセント改善した件","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-11-08-lunescript-speed-up-batch/","year":"2020"},{"content":"  LuneScript は Lua 向けのトランスコンパイラで、 LuneScript 自体も Lua 上で動作しています。  また、LuneScript は LuneScript 自体の処理を、 LuneScript で開発する所謂セルフホスティングを採用しています。  そのセルフホスティングしているコード規模は、右肩上がりで増大しています。   上記グラフは少し以前のもので、現在は 50Kline を突破しています。  コード規模が増えて一番気になるのは、やはりコンパイル時間です。  特に LuneScript は Lua で動作するため、 一般的なネイティブのコンパイラよりも遅くなります。  一年以上前から速度向上のための取り組みは行なっていましたが、 今回ようやく速度向上版を安定して運用できるレベルまで到達しました。  そして速度向上の結果、従来と比較して 425% 改善しました。  (2020/11/8) 更新  そして速度向上の結果、従来と比較して 387% 改善しました。  以下は、セルフホストしている LuneScript コードをトランスコンパイルする際に掛る時間を、 改善前と後とで測定した結果です。    改善前(lua) 改善後(go) 参考 (luajit)     20.67 sec 4.86 sec 21.56 sec     この表の通り、 (/ 20.67 4.86) 4.253086419753086 ≒ 425% 改善しています。  以降では、今回の LuneScript 性能向上の実現方法について説明します。 セルフホスティング   前述の通り LuneScript は次の特徴があります。    LuneScript 自体 Lua で動作する    一般的に Lua はネイティブと比べて遅い    この特徴から、 Lua ではなく、ネイティブで動く LuneScript コンパイラを作成するのが、 性能向上のための最も確実性の高い手段だと考えられます。  ネイティブで動くプログラムを組むには、 当然ネイティブに対応したコンパイラが必要になります。  当然ながら、 LuneScript のコードに対応したコンパイラは LuneScript 以外にありません。  また、 Lua のコードに対応したコンパイラもありません。 Lua には、JIT コンパイラに対応した LuaJIT がありますが、 上記の表の通り LuaJIT では LuneScript の速度向上は実現できませんでした。  ではどうすれば LuneScript をネイティブで動かせるか？  次の方法が考えられます。    ネイティブのコンパイルに対応した別の言語で LuneScript を開発する    セルフホストしている LuneScript コードを、ネイティブコードにコンパイルできるように LuneScript を拡張する    上記の 1) は、 LuneScript の特徴であるセルフホスティングを止めるということです。 しかし、セルフホスティングは LuneScript にとって非常に重要な特徴です。 セルフホスティングが重要な理由はいくつかありますが、 品質を担保するという意味での重要性については、以下を参照してください。  \u0026lt;https://ifritjp.github.io/documents/lunescript/test/\u0026gt;  よって、 1) は却下し 2) で対応しています。 ネイティブコードにコンパイルする方法   「ネイティブコードにコンパイル」するには、次の方法があります。    LuneScript から、直接ネイティブコードへのコンパイル機能を LuneScript に拡張する    LuneScript から、別のコンパイラの言語に変換する機能を LuneScript に追加し、 別の言語に変換したソースをそのコンパイラでビルドする    上記 (a) は、独自にコンパイラを作ることになるので、 非常に柔軟に開発することが出来るメリットがあります。 その一方で、多くのことを自分でやらなければならないというデメリットがあります。  上記 (b) は、変換する言語仕様に制限されるというデメリットがありますが、 多くのことを変換先のコンパイラに任せられるというメリットがあります。  (b) はトランスコンパイラそのものであり、 LuneScript との相性が良いと判断し、 (b) を採用しました。  なお、変換先は go を選択しています。  これは、ちょうど go を勉強したいと思っていたタイミングとマッチしていたのと、 静的型付け言語の割には比較的緩く書けるので、 変換先の言語にちょうど良いと考えたためです。  「比較的緩く書ける」のが何故良いのかと言えば、 例えば Rust のように非常に厳格な言語だと、 その言語仕様に併せこむのが困難で、 LuneScript からの変換ができなくなる可能性が高いためです。 LuneScript と Go の言語仕様の差異   LuneScript は、イマドキの言語の多くの仕様を取り込んでいるため、 何気に言語仕様が大きくなっています。  それら言語仕様を、変換先の言語で実現できるかどうかが課題です。 変換先の言語の制約によって、 LuneScript の言語仕様が実現できないことも考えられます。  今回の go への変換については、実現不可能な言語仕様はありませんでした。  ただし、現時点では LuneScript の言語仕様の全てを、 Go 版の LuneScript で実現できているか？ というと、実はそうではなく、 LuneScript をセルフホスティングするために必要な言語仕様に限定しています。  セルフホスティングに必要ない言語仕様については、今後対応していきます。  なお、以下の LuneScript の言語仕様については、 Go 言語の文法には直接ないものなので、 変換処理時にいろいろと制御を入れて実現している仕様の一部です。    クラス継承    多値返却 (go にも多値返却があるが、 LuneScript とは大きく仕様が異なる)    generics    ファイル内スコープ    nil 安全    and or 演算子    Lua 言語との連携    別の言い方をすれば、 go 言語では直接的にはサポートされていないこれらの機能も、 コードの書き方次第で go 言語上で実現できるということ です。 LuneScript の言語仕様への影響   今回の go 言語へのトランスコンパイル対応で、 LuneScript の言語仕様を一部修正しています。  できるだけ従来の仕様に影響がないように対応しましたが、 どうしても吸収できない部分があったため修正しています。  具体的な差分ついては、 LuneScript のサイトの方で後日解説します。  \u0026lt;https://ifritjp.github.io/documents/lunescript/\u0026gt; go 版 LuneScript の利用方法   go 版 LuneScript の利用方法についても、後日 LuneScript のサイトで解説します。  以上。 ","id":25,"section":"posts","summary":"LuneScript は Lua 向けのトランスコンパイラで、 LuneScript 自体も Lua 上で動作しています。 また、LuneScript は LuneScript 自体の処理を、 LuneScript で開発する所謂セルフホスティン","tags":null,"title":"LuneScript のトランスコンパイル時間を 425 パーセント改善した件","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-11-01-lunescript-speed-up/","year":"2020"},{"content":" これまでの LuneScript のコード規模の推移を調べてみた。   これは単純に LuneScript をセルフホストしている .lns ファイルの行数をトータルした結果。 よって、コメントや空行等も入っている。  2020年前半はさぼってたけど、それ以外はコンスタントに成長している感じ。  参考までに、このグラフを作った gnuplot スクリプト。 1列目に YYYY-MM-DD の日付データ、2列目に行数データの dump.csv からデータをロードして、 codesize.svg を出力する。 file=\u0026#39;dump\u0026#39; se g se xdata time se timefmt \u0026#34;%Y-%m-%d\u0026#34; se datafile separator \u0026#34;,\u0026#34; se format x \u0026#34;%Y/%m\u0026#34; se title \u0026#39;Code Size of LuneScript\u0026#39; set xtics rotate by -45 se terminal svg se output \u0026#39;codesize.svg\u0026#39; p file u 1:2 w l title \u0026#34;lineNo\u0026#34; #pause -1  ","id":26,"section":"posts","summary":"これまでの LuneScript のコード規模の推移を調べてみた。 これは単純に LuneScript をセルフホストしている .lns ファイルの行数をトータルした結果。 よって、コメントや空行等","tags":null,"title":"LuneScript のコード規模の推移を調べた","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-10-01-lunescript-codesize/","year":"2020"},{"content":"  emacs で snippet を管理するパッケージに yasnippet がある。  yasnippet はメジャーモード毎に snippet を登録しておき、 編集中のメジャーモードに合せて snippet を呼び出すことができる。  yasnippet に snippet を登録するには、 変数 yas-snippet-dirs で指定しているディレクトリ内に メジャーモード名のディレクトリを作成し、 そのメジャーモード名のディレクトリ内に snippet 情報を記述したファイルを置く。  これにより、 yasnippet のロード時、あるいは M-x yas-reload-all 実行時に、 snippet が yasnippet に登録される。  ここで問題がある。  説明した通り、yasnippet に snippet を登録するには、 メジャーモード名のディレクトリを作成する必要があるが、 emacs のメジャーモード名は / 等を含むことが出来る。 つまり、そのようなメジャーモードのディレクトリを作成することが出来ないので、 snippet を登録することが出来ない。  今回は、/ 等のファイル名に使用できない文字を含むメジャーモードの snippet を 登録する方法について示す。 登録方法   登録方法を説明する前に、 yasnippet の snippet 呼び出し処理について簡単に説明する。    yasnippet は snippet を展開する際、現在のメジャーモードを確認し、 各メジャーモードに登録されている snippet を取得する。    この時、現在のメジャーモードだけでなく、 変数 yas–extra-modes に指定されている モードに登録されている snippet についても取得する。    上記の通り yas–extra-modes に指定されているモードも snippet の検索対象になるので、 今回は yas–extra-modes を利用して対応する。  snippet を登録したいモードを mode_A とする。  次のように処理することで、この mode_A で利用する snippet を登録できる。    mode_A の代替となるモードを作成する。    このモードを mode_B とする。      通常の手順で mode_B に snippet を登録する。    mode_A の hook に、次の処理を行なう関数を登録する。    yas–extra-modes をバッファローカル変数に設定し、その値に \u0026#39;(mode_B) をセットする。      以上により、 メジャーモード mode_A が有効になったバッファの バッファローカル変数 yas–extra-modes に mode_B が登録される。 これで、mode_A 内で yasnippet の snippet を呼び出すと mode_B の snippet が検索対象になる。  上記の方法は、mode_A の snippet を直接登録する方法ではなく、 mode_A と mode_B を紐付けて mode_A の snippet に mode_B の snippet を含めることで、 目的を実現している。  mode_A の snippet を直接登録するには、 yasnippet のコードを修正する以外には方法が無さそうなので、 今回はこのような対応にしている。 ","id":27,"section":"posts","summary":"emacs で snippet を管理するパッケージに yasnippet がある。 yasnippet はメジャーモード毎に snippet を登録しておき、 編集中のメジャーモードに合せて snippet を呼び出すことができる。 yasnippet に snippet","tags":null,"title":"emacs yasnippet の snippet を対応させるモード名に / 等のファイル名に使用できない文字がある場合","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-08-19-emacs-yasnippet/","year":"2020"},{"content":"  LuneScript の開発を続けて約 2 年経過。  2年間ずっと開発し続けているわけではないけど、 かなりの時間を LuneScript の開発にあてている。  そんな訳で、今回は LuneScript の開発工数を概算してみる。  もちろん、作業時間の記録なんて面倒なことはしていないので、 あくまで概算である。 開発作業   LuneScript に限ったことではないが、 github で個人開発する際は、 だいたい次のように開発を進めている。    作業項目(TODOリスト)を doc/todo.org にリストアップする    TODOリストを順次潰していく    作業した日は、出来るだけ commit, push する。    commit する条件は、テストをパスすること。    作業項目の対応の途中でも、キリの良いところで commit, push する。      そんな訳で、「commit した日 + C == 作業した日」が成りたつ。  ここで C は、「作業したが commit していない日」である。 これの多くは、修正内容の規模が大きくて、 1 日ではテストをパスできずに commit できない日である。  このようなケースは、頻度が少ないので概算から除外する。 概算   LuneScript の commit ログは 397 個. $ git log --oneline | wc -l 397   commit の日付けから、同じ日に commit したものは除外し、 異なる日が何個あるかを計算すると、 286 個。 $ git log --pretty=%aI | sed \u0026#39;s/T.*//g\u0026#39; | uniq | wc -l 286   つまり、286 日以上は LuneScript の作業を行なっている。  1 日の作業時間は、日によってバラバラだが、 平均すれば 2 時間以上は間違いなく作業している。 これを計算すれば、 (* 2 286) 572   よって、 572 時間 は最低限 LuneScript にかけている計算になる。  8 時間労働で考えると、 (/ 572 8.0) 71.5 日。4 ヶ月弱の工数。  会社で働けば 100 万円は稼げる。  これは、1 日の平均作業時間を 2 時間として計算した結果であって、 実際にはもっと作業している感覚がある。 あくまで最低限の概算だ。  個人的には、LuneScript は少なくとも 100 万以上の価値がある。 ","id":28,"section":"posts","summary":"LuneScript の開発を続けて約 2 年経過。 2年間ずっと開発し続けているわけではないけど、 かなりの時間を LuneScript の開発にあてている。 そんな訳で、今回は LuneScript の開発工数","tags":null,"title":"LuneScript の開発工数","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-08-01-lunescript-man-hour/","year":"2020"},{"content":" GCP から「Go 1.11 は使えなくなるから Go 1.13 にして」という通知があったので、 忘れないうちに Go 1.13 にして deploy をしたら、次のエラーが出た。 ERROR: (gcloud.functions.deploy) OperationError: code=13, message=Build failed: go mod: -require=xxxxxx/hoge/foo@v0.0.0: invalid path: malformed module path \u0026#34;xxxxxx/hoge/foo\u0026#34;: missing dot in first path element; Error ID: 3182a79f   どうやら、モジュールの先頭ディレクトリは FQDN の形式しないと NG になったようだ。 いままでは . を含まない適当な名前にしてたんだが、 「xxxxxx/hoge/foo の xxxxxx に . が含まれてない == FQDN ではない」、 ということで NG っぽい。 xxxxxx を github pages の自分の FQDN にして deploy したら上手くいった。  ちなみに、ローカルの Go build では FQDN ではなくても問題なかった。 deploy の時だけ問題になるようだ。  どうせなら、ローカルの Go build でもエラーになれば良いのに。 ","id":29,"section":"posts","summary":"GCP から「Go 1.11 は使えなくなるから Go 1.13 にして」という通知があったので、 忘れないうちに Go 1.13 にして deploy をしたら、次のエラーが出た。 ERROR: (gcloud.functions.deploy) OperationError: code=13, message=Build failed: go mod: -require=xxxxxx/hoge/foo@v0.0.0:","tags":null,"title":"Google Cloud Functions の deploy で 'missing dot in first path element; Error ID: 3182a79f' エラー","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-07-18-gcp-function-deploy/","year":"2020"},{"content":" 先日、 Google 翻訳で lunescript が固有名詞として認識された可能性について ネタにしたが、 どうやら本当に lunescript が固有名詞として認識されたのではないかと思われる。  というのも、 google の検索バーに lunesc まで入力すると、   上のように lunescript が候補に挙げられる。  google の単語として登録されたからといって、 LuneScript の認知度が上った訳でもないが、何となく嬉しい。  なお、 lunescript を検索した際の関連ワードは次の通り。   ちゃんと lua を認識している。  念のため、次の状態で確認しているんで、 Google 検索が自分の環境にカスタマイズされているのではないと思われる。    Cookie をクリア    海外 proxy を使ってアクセスする IP を変更    Google には login していない   ","id":30,"section":"posts","summary":"先日、 Google 翻訳で lunescript が固有名詞として認識された可能性について ネタにしたが、 どうやら本当に lunescript が固有名詞として認識されたのではないかと思われる。 とい","tags":null,"title":"LuneScript の Google 検索ワード","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-07-15-lunescript-search/","year":"2020"},{"content":" イマドキは少数派だと思うが、 PC に ubuntu と windows のデュアルブートを設定している。  さらに面倒なことに、 windows は BitLocker で暗号化 \u0026amp; PIN 認証を設定している。  そして、この状態で ubuntu を apt upgrade したら、 何故か windows ブート時の BitLocker の PIN 認証が失敗するようになった。  PIN を間違えているはずはないのだが、何度やっても PIN 認証が通らない。  しかたがないので、 BitLocker の回復キーを入力したところ問題なく起動した。  そういえば ubuntu の apt upgrade 実行時、grub の更新が掛った。 その際、設定をどうするか聞いてきたので、 設定を変更しないように選択したのだが何か問題があったようだ。  なお、回復キーを使って起動した後、 再度 PIN を設定することで、問題なく PIN 認証が通るようになった。  PIN を忘れてなくても、回復キーが必要になることがあるんだな。 ","id":31,"section":"posts","summary":"イマドキは少数派だと思うが、 PC に ubuntu と windows のデュアルブートを設定している。 さらに面倒なことに、 windows は BitLocker で暗号化 \u0026amp; PIN 認証を設定している。 そして、この","tags":null,"title":"デュアルブートの ubuntu を upgrade したら windows の BitLocker が PIN の認証失敗するようになった","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-07-10-bitlocker/","year":"2020"},{"content":"  Go の勉強を兼て「これ」を Go で作っていたんだが、その時感じた Go の特徴をまとめておく。  Go は気軽に書けるのに、非常に高い実行パフォーマンスを出せる使い勝手の良い言語だと思う。  また、パッケージマネージャを言語自身に内蔵しているため、 拡張パッケージが揃っていて、今後さらにパッケージが充実して使える言語になるだろう。  こんな様なことは、もう誰もが書いていることだと思うので、 以降では、もう少し違った角度で Go について考えたことをまとめておく。 Go はエンジニアを信用している言語   「エンジニアを信用している」 とはどういう事かというと、 Go を使うエンジニアはつまらない間違いをしない高レベルな技術を持っていることを 前提にしている、ということだ。  この根拠は、Go の次の言語仕様から来ている。    nil 安全がない    構造体のコンストラクタがない    アクセス制限が公開と package 内限定しかない    Generics がない    基本的に mutable    shadowing 可能    排他制御が古典的    静的型付け言語は、安全方向に仕様を振っていて、 出来ることを制限する手段を提供していることが多い(例えばアクセス制限や Generics 等)。 一方 Go では、そのような制限する手段を提供していない部分が多い。  では何故、Go は言語仕様による制限をしないのか？ それは、 Go の設計者が、そんな機能に頼らなくても安全に開発を進められる、 という思いがあったからだろう。  一方近年話題になっている Rust では、 Go とは逆にエンジニアを信用していない言語で、 エンジニアはヒューマンエラーを起すことを前提にしている。 そして、ヒューマンエラーが起きたときは、コンパイラレベルで検知して エラーするようにしている。ただ、これを実現するために多くのメタ情報を コード上に宣言する必要がある。  これは言語仕様の決め方の方向性が違うだけで、 どちらが正解で、どちらが間違っているというものではない。  プロジェクトで採用する言語を決定する際に、 どのような言語がそのプロジェクトにマッチするのかを判断することが重要だ。 ","id":32,"section":"posts","summary":"Go の勉強を兼て「これ」を Go で作っていたんだが、その時感じた Go の特徴をまとめておく。 Go は気軽に書けるのに、非常に高い実行パフォーマンスを出せる","tags":null,"title":"Go 言語 (golang) について思ったこと","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-06-27-golang/","year":"2020"},{"content":" 以前 lunescript の紹介記事を書いている時に、 lunescript の日本語訳がふと気になったんで調べていたんだが、 その時の Google 翻訳の結果が衝撃的だった。  \u0026lt;https://ifritjp.github.io/documents/lunescript/tutorial1/#headline-3\u0026gt;  で、久し振りに Google 翻訳で lunescript を翻訳してみた。 その結果は次の通り。   めでたく lunescript の日本語訳が lunescript になった。  これは、 LuneScript が Google に固有名詞として認識されたということだろうか？  それとも、該当する単語が登録されていないから、 とりあえずそのまま表示しているだけなんだろうか？ ","id":33,"section":"posts","summary":"以前 lunescript の紹介記事を書いている時に、 lunescript の日本語訳がふと気になったんで調べていたんだが、 その時の Google 翻訳の結果が衝撃的だった。 \u0026lt;https://ifritjp.github.io/documents/lunescript/tutorial1/#headline-3\u0026gt; で、久し振りに Google 翻","tags":null,"title":"LuneScript の Google 翻訳","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-06-26-lunescript-trans/","year":"2020"},{"content":"  tunnel ツールのネタを書いた時、 dot を使ってグラフを作った。  dot は手軽にグラフを書ける便利なツールだが、 レイアウト制御に難があると思う。 グラフ作成ツールの利点と欠点   dot などのグラフ作成ツールの利点には次が挙げられる。  ノードのリンクを指定するだけで、後はツールが良い感じにグラフを自動で作成してくれる。  パワポ等でグラフを作成するのと比べると、これは大きな利点だ。  そして多くの場合、ツールが作成するグラフは、それなりに見易いグラフになってくれる。  ただ、少ない情報から自動でグラフを作成するため、 意図とは異なるレイアウトのグラフが出来あがることもある。  レイアウトのことは割り切って使うとか、 気に入らないなら他のパワポなどの draw 系のツールで描けば良いという話もあるが、 それは何か違うと思っている。 dot のグラフ   次の図は、 tunnel と host を繋ぐ処理をグラフ化したものだ。   このグラフの dot コードは次になる。 digraph G { rankdir = RL; tunnel [shape=doublecircle]; subgraph clusterA { packetWriter [shape=rect; margin=0.2;]; packetReader [shape=rect; margin=0.2;]; keepalive [shape=rect; margin=0.2;]; WriteQueue tunnel2Stream [shape=rect; margin=0.2;]; stream2Tunnel [shape=rect; margin=0.2;]; ReadQueue {rank = max; packetReader; packetWriter} {rank = same; WriteQueue; ReadQueue} {rank = min; tunnel2Stream; stream2Tunnel; keepalive} } host [shape=box3d]; tunnel -\u0026gt; packetReader packetReader -\u0026gt; ReadQueue ReadQueue -\u0026gt; tunnel2Stream stream2Tunnel -\u0026gt; WriteQueue WriteQueue -\u0026gt; packetWriter packetWriter -\u0026gt; tunnel keepalive -\u0026gt; WriteQueue tunnel2Stream -\u0026gt; host host -\u0026gt; stream2Tunnel {rank=min;host} }   コードの細かい部分はここでは触れないが、 次の 4 つの {rank=} を指定していることを確認して欲しい。    {rank = max; packetReader; packetWriter}    {rank = same; WriteQueue; ReadQueue}    {rank = min; tunnel2Stream; stream2Tunnel; keepalive}    {rank=min;host}    この rank 指定を外してグラフを生成すると次のようになる。 digraph G { rankdir = RL; tunnel [shape=doublecircle]; subgraph clusterA { packetWriter [shape=rect; margin=0.2;]; packetReader [shape=rect; margin=0.2;]; keepalive [shape=rect; margin=0.2;]; WriteQueue tunnel2Stream [shape=rect; margin=0.2;]; stream2Tunnel [shape=rect; margin=0.2;]; ReadQueue } host [shape=box3d]; tunnel -\u0026gt; packetReader packetReader -\u0026gt; ReadQueue ReadQueue -\u0026gt; tunnel2Stream stream2Tunnel -\u0026gt; WriteQueue WriteQueue -\u0026gt; packetWriter packetWriter -\u0026gt; tunnel keepalive -\u0026gt; WriteQueue tunnel2Stream -\u0026gt; host host -\u0026gt; stream2Tunnel }   rank 指定の有無の違い   rank 指定の有無によって生成されるグラフがどのように違いがあるのか、 分かり易いように並べて表示する。    rank 指定あり       rank 指定なし     rank 指定ありは矢印の向きが素直に円を描いる一方で、 rank 指定なしは矢印が交差していたり、矢印が長かったりで、 rank 指定ありと比べて動きが捉え辛くないだろうか？  このように、意図したレイアウトと異なる結果になった場合、 rank を指定することで、ある程度の制御が出来る。 rank 指定の意味   今回指定した 4 つの rank の内、次の 3 つは中央の四角の中の並び順を指定している。    {rank = max; packetReader; packetWriter}    {rank = same; WriteQueue; ReadQueue}    {rank = min; tunnel2Stream; stream2Tunnel; keepalive}    そもそも、 rank は何を指定するものなのかというと、 dot がリンク情報を元に どのノードをどこに配置するかを決定するアルゴリズムにおいて使用する要素の一つだ。  上記の 3 つの指定は、 packetReader, packetWriter が max のランクで、 WriteQueue, ReadQueue が同じランクで、 tunnel2Stream, stream2Tunnel, keepalive が min のランクであることを設定している。  これは、 rank 指定した時の図と見比べて、 中央の四角の中の左側から max, same, min の順で並べられていることから納得できる。  4 つの内の最後の rank 指定は、 host の場所を指定している。    {rank=min;host}    これは、 host が min のランクであることを設定している。  これも rank 指定した時の図と見比べて、 host が一番右に配置されていることから納得できる。  このように、 rank に max, same, min を指定することで、 ノードの配置を指定することが可能だ。  なお、 rank の指定は全部で 5 種類ある。    min    max    same    source    sink    これらの意味について、公式サイトに次の記載がある。 Rank constraints on the nodes in a subgraph. If rank=\u0026#34;same\u0026#34;, all nodes are placed on the same rank. If rank=\u0026#34;min\u0026#34;, all nodes are placed on the minimum rank. If rank=\u0026#34;source\u0026#34;, all nodes are placed on the minimum rank, and the only nodes on the minimum rank belong to some subgraph whose rank attribute is \u0026#34;source\u0026#34; or \u0026#34;min\u0026#34;. Analogous criteria hold for rank=\u0026#34;max\u0026#34; and rank=\u0026#34;sink\u0026#34;. (Note: the minimum rank is topmost or leftmost, and the maximum rank is bottommost or rightmost.)   min と source、 max と sink は同じように利用できる。  ただ、上記の記載にはないが、 min, max と souce, sink を混在して使用する際は、 注意が必要である。  なぜならば、min, max と souce, sink はそれぞれ異なる軸(X と Y)で 処理されるようなので、同じ軸でランク付けを行なう場合、 min, max, souce, sink を混在させてはならない。 ","id":34,"section":"posts","summary":"tunnel ツールのネタを書いた時、 dot を使ってグラフを作った。 dot は手軽にグラフを書ける便利なツールだが、 レイアウト制御に難があると思う。 グラフ作成ツー","tags":null,"title":"dot のレイアウト指定","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-06-09-graph/","year":"2020"},{"content":"  go で proxy server を建てるには、 github.com/elazarl/goproxy を使うと簡単に実現できる。  https://github.com/elazarl/goproxy  github の readme を見れば、簡単な使い方が載っているので特に問題はないだろう。  ただ、一点だけハマったポイントがあるので書いておく。 proxy 環境下で goproxy を使う場合の注意点  package main import ( \u0026#34;github.com/elazarl/goproxy\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { proxy := goproxy.NewProxyHttpServer() proxy.Verbose = true log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, proxy)) }   github の readme にサンプルとして上記コードが載っている。  基本的にこれで問題ないのだが、 proxy 環境下で動かす場合には注意が必要だ。  多くの場合、 proxy 環境下では環境変数に次のような設定をしているだろう。 export HTTP_PROXY=http://proxy.hoge.com:80/ export HTTPS_PROXY=http://proxy.hoge.com:80/   このような設定を行なっている場合、 上記サンプルコードを動かすと、 goproxy はさらに proxy.hoge.com を使って接続を行なおうとする。  つまり、 goproxy を使って localhost:80 にアクセスしようとすると、次のような形になる。 client --\u0026gt; goproxy --\u0026gt; proxy.hoge.com:80 --\u0026gt; localhost:80   ここで問題なのは、 proxy.hoge.com:80 が間に挟まることで通信が確立できなくなる可能性がある、 ということだ。  少なくとも、goproxy にとっての localhost と、 proxy.hoge.com にとっての localhost は意味が異なるし、 プライベートアドレス IP 指定を受けつけない proxy も多いだろう。 対応策   前述した proxy 環境下の問題を回避するには、次の 2 つがある。    goproxy を使用する際に上記環境変数の設定を消す    goproxy を使うコードを修正する    goproxy を使うコードを修正するには、 次のように proxy.ConnectDial = nil を追加すれば良い。 package main import ( \u0026#34;github.com/elazarl/goproxy\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { proxy := goproxy.NewProxyHttpServer() proxy.Verbose = true proxy.ConnectDial = nil // これを追加  log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, proxy)) }  ","id":35,"section":"posts","summary":"go で proxy server を建てるには、 github.com/elazarl/goproxy を使うと簡単に実現できる。 https://github.com/elazarl/goproxy github の readme を見れば、簡単な使い方が載っているので特に問題はないだろう。 ただ、一点だけハマった","tags":null,"title":"go の proxy server (github.com/elazarl/goproxy) の使い方","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-06-04-go-proxy/","year":"2020"},{"content":"  とある理由から 「Tunnel/Reverse Tunnel over websocket」 が必要になったので作ってみた。  「Tunnel/Reverse Tunnel over websocket」 が何かというと、 「websocket を tunnel にして別の TCP 通信を通すもの」だ。 「Tunnel/Reverse Tunnel over websocket」 とは   「Tunnel/Reverse Tunnel over websocket」を少し具体的にいうと、 次のような構成で通信を可能にするモノだ。 frame tunnelの例 { rectangle network_1 { node tcp_client_A node tunnel_client_1 } rectangle network_2 { node tunnel_server_1 node tcp_server_B } } tcp_client_A --\u0026gt; tunnel_client_1 tunnel_client_1 --\u0026gt; tunnel_server_1 tunnel_server_1 --\u0026gt; tcp_server_B tcp_client_A ..\u0026gt; tcp_server_B frame reverse_tunnelの例 { rectangle network_A { node tcp_server_C node tunnel_client_2 } rectangle network_B { node tunnel_server_2 node tcp_client_D } } tcp_server_C \u0026lt;-- tunnel_client_2 tunnel_client_2 --\u0026gt; tunnel_server_2 tunnel_server_2 \u0026lt;-- tcp_client_D tcp_client_D ..\u0026gt; tcp_server_C    上の図は network_1, network_2, network_A, network_B の 4 つのネットワークを表わしている。  このネットワーク間でポートが制限されていると、 tcp_client_A は tcp_server_B と直接通信が出来ない(図の点線)。  開放されているポートで接続し、そのセッション上に仮想的な Tunnel を構築する。 そして、その Tunnel 内にポートの制限を受けない通信を実現する。  左は Tunnel の構成例である。 ポート制限されている network_1, network_2 を、 tunnel server / tunnel client で接続して tunnel を構成し、 その tunnel を使って tcp client A と tcp server B を接続する。  右は Reverse Tunnel の構成例である。 ポート制限されている network_A, network_B を、 tunnel server / tunnel client で接続して tunnel を構成し、 その tunnel を使って tcp client D と tcp server C を接続する。  Tunnel と Revers Tunnel の違いは、 tcp client/server の位置関係である。  具体的には、 Tunnel server と同じネットワークに tcp server が属する構成が Tunnel で、 逆に Tunnel server と同じネットワークに tcp client が属する構成が Reverse Tunnel である。  そして、 Tunnel server と client 間の通信経路として、 websocket を利用して tunnel を構築するのが 「Tunnel/Reverse Tunnel over websocket」である。 VPN (Virtual Private Network)   このように制限されたネットワーク間で通信路を構築する方法として、 WireGuard や OpenVPN などの低レイヤー VPN がある。  低レイヤー VPN は、その名の通り仮想的なネットワークを低レイヤーで構築する。 これによって、通常のネットワークと同様に扱えて利便性が高いが、 通常のネットワークと同様であるが故、逆にリスクになる可能性がある。  今回は VPN ではなく、Tunnel を実現するのが目的である。  なお、ここでは「レイヤー 2 あるいは 3 を仮想化する技術」を VPN とし、 「ネットワーク間で TCP セッションを転送する技術」を Tunnel とする。 開発した背景   制限されたネットワーク間での通信を確立できないかどうか、 当初はフリーのツールを探して tunnel ソフトを幾つか試してみたが、 tunnel が接続できなかったり、接続できてもすぐに切れてしまったりで イマイチ希望したものとは違った。  特に自分の環境は (A)/(B) 間のネットワーク環境が悪く、 tunnel を確立しても、ある程度経過すると切断されてしまう問題があった。  tunnel が切断されても tunnel を再接続することで、 tunnel 内の tcp 通信を継続させることは論理的に可能だ。 しかし、検討していた幾つかのフリーのツールでは、 tunnel が切断されると tunnel 自体のを再接続が出来ても tunnel 内を流れる tcp 通信が継続できなかった。 そもそも tunnel を再接続すること自体、 成功したり失敗したりしているような状況だった。  そこで、今回はフリーのツールを検討することは諦め、 自分の勉強も兼てスクラッチで開発することにした。  なお、ネットワーク間を接続することが目的であれば、 WireGuard や OpenVPN などの低レイヤー VPN や、 stunnel などの Tunnel ツールを利用するのが多くの場合ベストだろう。 ネットワーク環境   今回開発した Tunnel ツールを使って、 自分のネットワーク環境の Tunnel 間通信強制切断状況を確認したところ、 次のようになった。   (a)    接続は最大でも 15 分程度で切断される   (b)    昼間は 30 秒程度で切断される   (c)    接続の 7 割強は 1 分以内で切断される    (a) について、 どうやら自分の環境では http 通信は 15 分程度でセッションが強制切断されるらしい。  (b), (c) について、 無通信が続くと 30 〜 60 秒程度で強制切断されるようなので、 無通信を回避するために 20 秒毎にトンネル間でダミーの通信を行なうよう対応した。  ただ、これでも通信負荷が高くなると数分で切断されることがある。 使用方法   このツールは Go で開発しているため、 事前に Go(1.14.2) の環境を構築してあることが前提である。 注意事項   tunnel 間の通信がインターネットを経由する場合、セキュリティには十分注意すること。    tunnel client/server 間通信の暗号化や、client 認証を実装しているが、 tunnel 内の TCP セッションは raw な tcp 接続をせずに、 ssh などで接続すること。    tunnel server は常駐させず、必要な時にだけ起動するように運用すること。    pass , encPass オプションを必ず指定し、適切な期間で変更すること。    ip オプションを指定し、接続可能な client を制限すること。   ビルド   次のコマンドを実行することで、 tunnel ディレクトリ内に tunnel コマンドがカレントディレクトリに生成される。 $ git clone --depth 1 https://github.com/ifritJP/kptunnel.git $ cd kptunnel $ make build  kptunnel コマンド   kptunnel コマンドは tunnel server と、 tunnel client の両方の役割を持ち、 オプションで切り替える。  kptunnel コマンドは、次の書式をもつ。 $ kptunnel \u0026lt;mode\u0026gt; \u0026lt;server\u0026gt; [forward [forward [...]]] [options]     mode    次のいずれかを指定する    サーバ    wsserver    r-wsserver    server    r-server      クライアント    wsclient    r-wsclient    client    r-client      \u0026#34;r-\u0026#34; が付くものは、 reverse tunnel である。    ws が付くものは、 over websocket である。    ws が付かないものは、 tcp で直接接続する。    tcp による接続は、実験的なサポートである。    tcp で接続できる環境なら、 このツールを使わずに ssh した方が良いだろう。      \u0026#34;r-\u0026#34;, \u0026#34;ws\u0026#34; は client/server で一致している必要がある。      server    server を示す。    サーバ側で指定する場合は、開放するポートを指定する。 (:1234 or localhost:1234)    この port に接続可能なネットワークを制限する場合は、 そのネットワークを指定する。 例えば localhost に制限する場合は localhost:1234 として指定する。      クライアント側で指定する場合は、ホスト名を含めて指定する (hoge.com:1234)      forward    tunnel で forward するポートの情報。    forward は複数指定できる。    reverse tunnel の場合は、 server 側で指定する。tunnel の場合は client 側で指定する。    \u0026#34;localのポート,forward先のポート\u0026#34; の書式で指定する。    localのポートに接続可能なネットワークを制限する場合は、 そのネットワークを指定する。 例えば localhost に制限する場合は localhost:1234 として指定する。    forward 先のポート情報は、相手にそのまま伝わる。    例えば reverse tunnel で localhost を指定した場合、localhost は tunnel クライアント自身になり、 通常の tunnel の場合、 localhost はサーバ自身になる。        次に代表的なコマンド例を示す。    server    server のコマンド例を示す。 $ kptunnel r-wsserver :6666 :8001,localhost:22 -pass XXXXXXX -encPass YYYYYYYY   これは次のサーバの実行を指定している。    option 意味 サンプルの意味     r-wsserver client/server の種類 reverse websocket server   :6666 tunnel サーバの情報 ポート 6666 を使用して websocket server を建てる   :8001,localost:22 tunnel で forward するポート番号 server の 8001 を client の localhost:22 に forward   -pass client の認証用パスワード XXXXXXX   -encPass client/server 間の通信路の暗号パスワード YYYYYYYY       client    client のコマンド例を示す $ kptunnel r-wsclient hoge.hoge.com:80 -proxy http://user:pass@proxy.hoge.com:8080/ -pass XXXXXXX -encPass YYYYYYYY   これは次のクライアントの実行を指定している。    option 意味 サンプルの意味     r-wsclient client/server の種類 reverse websocket client   hoge.hoge.com:80 tunnel サーバの情報 hoge.hoge.com の 80 に接続する   -proxy proxy サーバの情報 http://proxy.hoge.com::8080/ に user, pass で接続   -pass client の認証用パスワード XXXXXXX   -encPass client/server 間の通信路の暗号パスワード YYYYYYYY       tunnel への接続    上記のサンプルは localhost の 22 番ポートに接続するための reverse tunnel を構築している。 つまり、このサーバ側の 8001 ポートに繋げると、 client 側の ssh に接続されることになる。  よって、サーバ側で次のコマンドを実行することで、クライアントの ssh に接続できる。 $ ssh -p 8001 localhost  オプション一覧   kptunnel コマンドで使用可能なオプションについて説明する 基本     -proxy string    websocket server に接続するための proxy    proxy 不要なら省略する。    認証が必要な proxy の場合、 http://user:pass@proxy.hoge.com:port/ の形式で指定する。    現状は HTTP proxy のみ対応している。    client 側で指定する      -UA string    Proxy に接続する際の User Agent を指定する    websocket の client で有効     セキュリティ関連     -pass string    client 認証で使用する。    client/server で共通のものを指定する必要がある。    client 認証は challenge/respose で行なう。      -encPass string    client/server 間通信の暗号パスワード。    client/server で共通のものを指定する必要がある。      -encCount int    client/server 間の暗号処理回数を指定する。 (default -1)    -1 : infinity    0 : plain, no encrypt.    N \u0026gt; 0 : packet count      このツールは tunnel client/server 間の通信を暗号化するが、tunnel 内を通すのが ssh などの場合、 二度の暗号化が走ることになり、tunnel client/server 間の暗号は無駄になる。 そこで、tunnel client/server 間の暗号化回数を指定することで、暗号化にかかる負荷軽減を可能にする。    回数は tunnel の通信パケット単位    暗号アルゴリズムは AES256 CFB を使用している。      -ip string    server に接続可能な client の、 IP アドレス範囲を指定する。    e.g. 192.168.0.0/24      このオプションを省略した場合、 client の IP を限定しない。     動作デモ   次を実行しているデモ動画を示す。    remote と local と、それらを仲介する proxy がある。    remote で tunnel の wsserver を起動    proxy を起動    local から wsclient を使って、proxy 経由で remote と tunnel を構築する    local から tunnel 経由で remote と ssh 接続する    ssh のコンソースから X11 アプリ (ico) を起動    proxy を停止    tunnel が切断される    X11 アプリ (ico) の更新が止まるが、 ssh のセッションは継続する      proxy を起動    tunnel が再接続される    ssh のセッションが再開する    X11 アプリ (ico) の更新が再開する      以降 proxy 停止、起動を繰り返し    開発に関して   これ以降の章では、この Tunnel ツール開発に関する技術的な内容について記載する。 スレッド   この Tunnel ツールは、主に次の 6 つのスレッドで構成される。    tunnel session 制御    WriteQeue → tunnel のパケット送信制御 (packetWriter)    tunnel → ReadQueue のパケット受信制御 (packetReader)    ReadQueue → host のパケット転送制御 (tunnel2Stream)    WriteQeue → tunnel のパケット転送制御 (stream2Tunnel)    無通信が一定時間続かないようにするダミーパケット送信制御 (keepalive)    スレッド多す過ぎという気もするが、 メニーコア時代な現代であれば、 少ないスレッドで複雑なコードを書くよりも、 処理毎にスレッドを分けた方がメンテナンス性も性能も良いんじゃないだろうか？  下図は、各スレッドの役割を図示している。 digraph G { rankdir = RL; tunnel [shape=doublecircle]; subgraph clusterA { packetWriter [shape=rect; margin=0.2;]; packetReader [shape=rect; margin=0.2;]; keepalive [shape=rect; margin=0.2;]; WriteQueue tunnel2Stream [shape=rect; margin=0.2;]; stream2Tunnel [shape=rect; margin=0.2;]; ReadQueue {rank = max; packetReader; packetWriter} {rank = same; WriteQueue; ReadQueue} {rank = min; tunnel2Stream; stream2Tunnel; keepalive} } host [shape=box3d]; tunnel -\u0026gt; packetReader packetReader -\u0026gt; ReadQueue ReadQueue -\u0026gt; tunnel2Stream stream2Tunnel -\u0026gt; WriteQueue WriteQueue -\u0026gt; packetWriter packetWriter -\u0026gt; tunnel keepalive -\u0026gt; WriteQueue tunnel2Stream -\u0026gt; host host -\u0026gt; stream2Tunnel {rank=min;host} }      packetReader は tunnel からデータを読み取り ReadQueue に送る    tunnel2Stream は ReadQueue からデータを読み取り host に送る    stream2Tunnel は host からデータを読み取り WriteQueue に送る    packetWriter は WriteQueue からデータを読み取り tunnel に送る    keepalive は WriteQueue にダミーデータを送る   tunnel 内に複数の TCP セッションを通す場合   tunnel には複数の TCP セッションを通すことができる。 次の要素は、tunnel 内の TCP セッション毎に増える。    tunnel2Stream    stream2Tunnel    ReadQueue    これらをまとめて CITI (connection in tunnel information ) とすると、 2 つの TCP セッションを通す場合は次のような構成になる。 digraph G { rankdir = RL; tunnel [shape=doublecircle]; subgraph clusterA { packetWriter [shape=rect; margin=0.2;]; packetReader [shape=rect; margin=0.2;]; keepalive [shape=rect; margin=0.2;]; WriteQueue CITI1 [shape=component; margin=0.2;]; CITI2 [shape=component; margin=0.2;]; {rank = max; packetReader; packetWriter} {rank = same; WriteQueue; } {rank = min; CITI1; CITI2; keepalive} } host1 [shape=box3d]; host2 [shape=box3d]; tunnel -\u0026gt; packetReader WriteQueue -\u0026gt; packetWriter packetWriter -\u0026gt; tunnel keepalive -\u0026gt; WriteQueue packetReader -\u0026gt; CITI1 CITI1 -\u0026gt; host1 CITI1 -\u0026gt; WriteQueue host1 -\u0026gt; CITI1 packetReader -\u0026gt; CITI2 CITI2 -\u0026gt; host2 CITI2 -\u0026gt; WriteQueue host2 -\u0026gt; CITI2 {rank=min;host1;host2} }   Tunnel の再接続   tunnel が切断されても、 tunnel を再接続すれば tunnel 内に流れる tcp セッションは継続通信可能である。  ただし、tcp 通信のタイムアウト以内に再接続できることが条件である。  tunnel を再接続すれば tcp セッションは継続通信可能だ。 しかし、そう単純にはいかないケースがある。 それは『送信したつもりになっているパケットが、相手に届いていないことがある』からだ。 この場合、相手に届いていないパケットを送信しなおす必要がある。  「tcp は udp と違って再送制御などを行なって信頼性を確保しているんじゃないのか？」 と思う人もいるだろう。私も最初はそう思っていた。 しかし、実際はそうではない。 なぜなら、再送制御などはあくまでも TCP セッションが続いている場合に行なわれることで、 TCP セッションが切断された場合は再送制御なども当然破棄される。  つまり、強制的にセッションが切断された場合は、 送ったつもりのデータが相手に届いていないことが普通にありえる。  このような「送ったつもりが相手に届いていないデータ」がある場合、 TCP セッションを継続させるにはそのデータを再送してやる必要がある。 この再送処理は、 packetWriter スレッドが実行する。 フロー制御   前述の通り、再接続後は送信側と受信側とでデータの不整合を確認し、 受信されていないデータの再送信が必要になる。  これを実現するには、送信済みデータを保持しておく必要がある。 しかし、全ての送信済みのデータを保持しておく訳にもいかないので、 保持可能なパケット数を決めておく。 そして保持可能なパケット数と相手が受信していないパケット数のバランスが 崩れないようにフロー制御を行なう。  もっとも単純なのは、送信するたびに相手の受信を持ってから次の送信を行なうことだが、 これだと通信効率が悪すぎる。 そこで、保持可能なパケット数の半分づつ確認を行なっている。 participant stream2Tunnel_client participant packetReader_client participant packetWriter_client participant packetWriter_server participant packetReader_server participant tunnel2Stream_server stream2Tunnel_client -\u0026gt; stream2Tunnel_client : check the count send packets. stream2Tunnel_client -\u0026gt;\u0026gt; packetWriter_client : write the packet to client queue packetWriter_client -\u0026gt;\u0026gt; packetReader_server : write the packet packetReader_server -\u0026gt;\u0026gt; tunnel2Stream_server : read the packet to server queue tunnel2Stream_server -\u0026gt; tunnel2Stream_server : count received packets. tunnel2Stream_server -\u0026gt;\u0026gt; packetWriter_server : write the sync to server queue packetWriter_server -\u0026gt;\u0026gt; packetReader_client : write the sync      stream2Tunnel は、パケットを queue に書き込む前に送信済みパケット数を確認する。    保持可能なパケット数の半分であれば、 sync を待つ      tunnel2Stream は、受信したパケット数をカウントし、 保持可能なパケット数の半分であれば sync を queue に入れる   リングバッファ   前述の通り再送信のデータ保持のためにフロー制御を行なっている。 このデータ保持用のバッファは、 保持可能なパケット数分のバッファを通信開始時に用意しておき、 それをリングバッファにして使い回している。 digraph G { rankdir = TB; node0 [shape=rect; label = \u0026#34;buf\u0026#34;] node1 [shape=rect; label = \u0026#34;buf\u0026#34;] node2 [shape=rect; label = \u0026#34;buf\u0026#34;] node3 [shape=rect; label = \u0026#34;buf\u0026#34;] node4 [shape=rect; label = \u0026#34;buf\u0026#34;] node5 [shape=rect; label = \u0026#34;buf\u0026#34;] node0 -\u0026gt; node1 node1 -\u0026gt; node2 node2 -\u0026gt; node3 node3 -\u0026gt; node4 node4 -\u0026gt; node5 node5 -\u0026gt; node0 {rank=same; node1;node5} {rank=same; node2;node4} }   送信パケットの結合   tunnel は 2 つの Host の間のパケットを中継する。 一つのパケットは、MTU サイズに近いほど効率よく送信することができる。  そこで、細かいパケットを 1 つのパケットに結合して送信する処理を行なう。  次の図で示す通り tunnel に送信するパケットは stream2Tunnel から WriteQueue に入れられる。 そして packetWriter でパケットを取り出して tunnel に送信する。   この packetWriter でパケットを取り出す時に、 WriteQueue に複数のパケットが入っている場合、 そのパケットを結合して送信する。  packetWriter は、パケットを結合するために積極的にパケットが溜るのを待つことはない。 よって、通信のリアルタイム性が損なわれることはない。 protocol   ここでは tunnel client/server 間で通信を開始する時の protocol について説明する。  protocol は 3 つの情報をやり取りする。 participant server participant client server -\u0026gt;\u0026gt; client : AuthCallenge server \u0026lt;\u0026lt;- client : AuthResponse server -\u0026gt;\u0026gt; client : AuthResult    この protocol の後は、-port オプションで指定されたポートをリスニングし、 アクセス毎に TCP 接続セッションを開始する。 AuthCallenge   AuthCallenge は、次の情報を client に通知する。    Challenge/Response 認証の Challenge 情報    バージョン    サーバの動作モード    client は、この情報から Challenge/Response の Response 情報を生成する。 AuthResponse   AuthResponse は、次の情報を server に通知する。    Challenge/Response 認証の Response 情報    セッションID    新規接続か、切断時の再接続かを示す。    新規の場合 0。再接続の場合、再接続先を示すセッションID。      client 側パケットの WriteNo/ReadNo    再接続する時、再送信が必要かどうかを確認するためのパケット情報      制御コード    特殊な処理を行なう場合に指定する。    例えば tunnel 間のラウンドトリップタイムを計測するモードを指定できる。      server は、この情報から client 認証を行なう。 AuthResult   AuthResult は、次の情報を client に通知する。    認証結果    セッションID    どのセッション ID を使用して通信を行なうかを示す。      Server 側パケットの WriteNo/ReadNo    以上で、 tunnel の client/server 間の接続が確立する。 開発言語   この Tunnel ツールの開発には、次の技術が不可欠である。    TCP    Proxy Client    HTTP Client/Server    WebSocket Client/Server    これら技術との相性の良さという意味では、 node.js が一番始めに候補に上りそうな気がする。 しかし、今は Go の勉強中ということもあり Go で開発を行なった。 ","id":36,"section":"posts","summary":"とある理由から 「Tunnel/Reverse Tunnel over websocket」 が必要になったので作ってみた。 「Tunnel/Reverse Tunnel over webs","tags":null,"title":"Tunnel/Reverse Tunnel over websocket を作った","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-05-29-tunnel/","year":"2020"},{"content":" 技術情報を GitHub Pages で公開するにあたって、 Hugo を使うことにした。  Hugo は Markdown で静的サイトを構築するツールだが、org-mode にも対応している。 「対応」といっても、当然完全なものではない。  今回 Hugo を org-mode で使ってハマった点を紹介する。  *「TITLE は文書の先頭に書く」  hugo で使用する .org のファイルは、先頭に TITLE を書かなければならない。  .org に記載されている #+TITLE 自体は認識しているようなのだが、 それが先頭に無い限りその記事のタイトルとしては認識されない。  例えば、 emacs では次のように文書内に coding 等を指定することは良くあると思うが、 こうすると Hugo は TITLE を認識してくれない。 # -*- coding:utf-8 -*- #+TITLE: Hugo を org-mode で使う時の注意点   これが判明するまでに、1 時間以上掛ったよ。。 ","id":37,"section":"posts","summary":"技術情報を GitHub Pages で公開するにあたって、 Hugo を使うことにした。 Hugo は Markdown で静的サイトを構築するツールだが、org-mode にも対応している。 「対応」と","tags":null,"title":"Hugo を org-mode で使う時の注意点","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-03-29-hugo-org/","year":"2020"},{"content":"  raspberry pi に SSD を接続して簡易 NAS にしている。 この簡易 NAS では、 SSD を取り外ししやすいように autofs によるマウントを設定した。 しかし、SSD を接続すると PCManFM の自動マウントが動いて autofs が正常にマウントできない現象が発生した。  そこで PCManFM の自動マウントを無効化した。 PCManFM の自動マウントを無効化   ~/.config/pcmanfm/LXDE-pi/pcmanfm.conf の以下の設定を変更する。 mount_on_startup=0 mount_removable=0   これで、PCManFM の自動マウントを無効化できる。 ","id":38,"section":"posts","summary":"raspberry pi に SSD を接続して簡易 NAS にしている。 この簡易 NAS では、 SSD を取り外ししやすいように autofs によるマウントを設定した。 しかし、SSD を接続すると PCManFM の自動","tags":null,"title":"raspberry pi の USB MASS STORAGE 自動マウントを無効化する","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-02-21-raspberrypi-mount/","year":"2020"},{"content":" emacs lisp の quote でハマったのでネタに書いておく。 (defvar hoge-val nil) (defun hoge-init () (setq hoge-val \u0026#39;(:val nil)) ) (defun hoge-set () (plist-put hoge-val :val \u0026#34;1\u0026#34;))   上記のように変数 hoge-val に対して plist-put で処理する関数を定義して、 次のようにコールすると。 (let (val1 val2 val3) (hoge-init) (setq val1 (plist-get hoge-val :val)) (hoge-set) (setq val2 (plist-get hoge-val :val)) (hoge-init) (setq val3 (plist-get hoge-val :val)) (message (format \u0026#34;%s %s %s\u0026#34; val1 val2 val3)))   最後の (message (format \u0026#34;%s %s %s\u0026#34; val1 val2 val3)) で \u0026#34;nil 1 1\u0026#34; が出力される。  てっきり、 \u0026#34;nil 1 nil\u0026#34; が出力されるものだと思っていた。 なぜなら、val3 をセットする直前に hoge-init を実行しており、 この hoge-init は hoge-val を \u0026#39;(:val nil) で初期化する関数なので、 (plist-get hoge-val :val) は nil を返すと考えたからだ。  しかし実際には、最後の (plist-get hoge-val :val) は \u0026#34;1\u0026#34; になる。  なぜこのような結果になるかと言うと、 \u0026#39;() は定数として扱い、 関数 hoge-init を実行する際には新しくリストを生成せず、 defun を評価した時の値そのものが使い続けられる。  そして (plist-put) でリストの中身を操作した場合、その定数自体が書き変わり、 hoge-init 関数は変数に書き変わった定数を代入しているため初期化できない。  一方で、 hoge-init の処理に list 関数を使うと、\u0026#34;nil 1 nil\u0026#34; となる。 (defun hoge-init () (setq hoge-val (list :val nil)) )   (list) は評価されるたび新規にリストを生成しているため、変数を初期化出来る。  よく考えてみると納得できるけど、 実際の動きと見た目のギャップにどうにもこうにも意味不明だった。  これまで一度も意識せずにきたのが不思議なくらい、かなり基本的な内容だと思う。  quote した値の変更は、要注意ってことで。 ","id":39,"section":"posts","summary":"emacs lisp の quote でハマったのでネタに書いておく。 (defvar hoge-val nil) (defun hoge-init () (setq hoge-val \u0026#39;(:val nil)) ) (defun hoge-set () (plist-put hoge-val :val \u0026#34;1\u0026#34;)) 上記のように変数 hoge-val に対して plist-put で処理する関数を定義して、 次のように","tags":null,"title":"emacs lisp の quote","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-02-18-emacs-quoted-list/","year":"2020"},{"content":"  emacs の org-mode では、 .org ファイル内に C や python 等ソースコードを書いて、 export 時にそのソースコードを色付けした状態で載せることができる。  この機能を babel と言う。  babel では、ソースコードの色付けだけでなく、 dot や plantuml 等のグラフ生成言語を利用することで、 .org ファイル内に書いたグラフ生成言語からグラフを生成して、 所定位置にグラフを挿入することもできる。  今回、 org-mode 9.3.5 の babel を使って dot の画像を出力しようとしたところ、 エラーしたので原因を追ってみた。 エラー箇所   エラーは次の関数で発生していた。 (defun org-babel-chomp (string \u0026amp;optional regexp) \u0026#34;Strip a trailing space or carriage return from STRING. The default regexp used is \\\u0026#34;[ \\\\f\\\\t\\\\n\\\\r\\\\v]\\\u0026#34; but another one can be specified as the REGEXP argument.\u0026#34; (let ((regexp (or regexp \u0026#34;[ \\f\\t\\n\\r\\v]\u0026#34;))) (while (and (\u0026gt; (length string) 0) (string-match regexp (substring string -1))) (setq string (substring string 0 -1))) string))   エラーの内容は次のものだった。 Debugger entered--Lisp error: (wrong-type-argument stringp nil) string-match(nil \u0026#34;c\u0026#34;) (and (\u0026gt; (length string) 0) (string-match regexp (substring string -1))) (while (and (\u0026gt; (length string) 0) (string-match regexp (substring string -1))) (setq string (substring string 0 -1))) (let ((regexp (or regexp \u0026#34;[ \\f\\011\\n\\015\\013]\u0026#34;))) (while (and (\u0026gt; (length string) 0) (string-match regexp (substring string -1))) (setq string (substring string 0 -1))) string)   このエラーは、 上記の org-babel-chomp 関数の regexp 引数が nil だった場合に発生する。 エラーの修正   このエラーに対し、 次のように let で宣言する変数を別名(regexp-work)で定義することで回避した。 (defun org-babel-chomp (string \u0026amp;optional regexp) \u0026#34;Strip a trailing space or carriage return from STRING. The default regexp used is \\\u0026#34;[ \\\\f\\\\t\\\\n\\\\r\\\\v]\\\u0026#34; but another one can be specified as the REGEXP argument.\u0026#34; (let ((regexp-work (or regexp \u0026#34;[ \\f\\t\\n\\r\\v]\u0026#34;))) (while (and (\u0026gt; (length string) 0) (string-match regexp-work (substring string -1))) (setq string (substring string 0 -1))) string))  エラーの原因   エラーの原因を確認するため、 エラーを再現する処理を抜き出して書き換えると次になる。 ;;; -*- lexical-binding: t; -*- (defun hoge (regexp) (let ((regexp (or regexp \u0026#34;a\u0026#34;))) (string-match regexp \u0026#34;b\u0026#34;)))   上記の hoge 関数の引数 regexp に nil をセットしてコールすると同じエラーになる。 なお、この現象は lexical-binding を有効にしている時だけ発生する。  上記関数の処理を説明すると次のようになる。    let で新しく変数 regexp を宣言する    このとき、引数 regexp が nil 以外なら、引数 regexp の値を変数 regexp にセットする    引数 regexp が nil なら、 \u0026#34;a\u0026#34; を変数 regexp にセットする。      つまり、let で宣言している変数 regexp には必ず nil 以外がセットされるはずである。  しかし、実際には string-match に渡される regexp には nil がセットされている。  何故このような結果になるか原因を想像すると、  「string-match でアクセスするシンボル regexp は、 let で宣言している regexp ではなく、関数の引数 regexp が参照されるため」  と考えるのが妥当だろう。  string-match は let のスコープなので、 普通に考えれば string-match の regexp は let で宣言している変数 regexp であるはず。 しかし、実際には何故か関数の引数 regexp になっている。  これが emacs lisp の仕様なのか、はたまた仕様外の動作なのかは良く分からない。  ちなみに、これが発生している環境は emacs 26.2 だが、 他の環境で発生するかどうかは確認していない。  org-mode の履歴を追ってみたが、 この関数の処理は lexical-binding を使うようになる前から変っていないので、 lexical-binding にした事による影響だろう。  以上。 ","id":40,"section":"posts","summary":"emacs の org-mode では、 .org ファイル内に C や python 等ソースコードを書いて、 export 時にそのソースコードを色付けした状態で載せることができる。 この機能を babel と言う。 babel で","tags":null,"title":"org-mode 9.3.5 で babel(dot/plantuml) が動かなかった","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-02-13-emacs-org-9.3.5/","year":"2020"},{"content":"  この記事は、emacs 用 reviewboard モードの宣伝である。  \u0026lt;https://github.com/ifritJP/emacs-reviewboard-front\u0026gt;  reviewboard は、ソースコードレビューを Web 上で行ない記録するためのツール。  今は github の Pull-Request に代表されるように Web 上のソースレビューが普及しているが、 reviewboard の初版が 2007 年であることを考えると、 当時は先進的なツールだったと思う。  そんな reviewboard を emacs で操作するモードを今になって作ったので、 どれ程の人が使うかは不明だが、折角なので宣伝しておく。 機能   このモードでは、次の機能を提供する。    修正ファイル一覧から必要なファイルを選択して review request (以降 rrq と記す)を登録    rrq の summary/description/testing_done を編集    修正ファイルの追加、削除可能      レビューを受けて更新したファイル郡を、一発でアップロード    レビューコメントのリプライ登録    rrq の publish/close/discard    rrq に登録したファイルをコミット   設定  環境     curl, rbt, svn を事前にインストールしておく    rbt は、 diff の登録に利用する。    curl は、 reviewboard の WebAPI へのアクセスに利用する。    環境によっては、 proxy 等の環境変数設定が必要な場合がある。      上記 github から emacs-reviewboard-front を取得し適当な場所に展開する   emacs-lisp     emacs-reviewboard-front のパスに load-path に追加する。    次の設定を行なう。   (require \u0026#39;rbfront-mode) (setq rb/front-rb-api-token \u0026#34;TOKEN\u0026#34;) (setq rb/front-rb-url \u0026#34;http://reviewboard.host/path\u0026#34;) (setq rb/front-rbt \u0026#34;rbt\u0026#34;) (setq rb/front-proxy \u0026#34;http://proxy.host:8080/\u0026#34;) (setq rb/front-rb-repository \u0026#34;RESPOSITORY_NAME\u0026#34;)     rb/front-rb-api-token は、 reviewboard のアカウント管理ページで生成した API Tokens を指定する。    rb/front-rb-url は、 reviewboard のサーバの URL を指定する。    rb/front-proxy は、 reviewboard のサーバにアクセスする際に使用する proxy を指定する。    front-rb-repository は、 reviewboard に diff を登録する際の repository 名を指定する。   新規登録   emacs-reviewboard-front では、現状 svnp.el を使用することを前提としている。  ここでは、svnp.el の細かい使用方法については説明しない。 rrq の新規登録に必要な最低限の操作について説明する。    M-x svn-status で修正ファイル一覧を表示し、 commit する要領でファイルを選択する。    j キー押下で、rrq 編集バッファが表示される。   編集バッファ      title と description、 test を編集する。    編集後、 C-c C-c 押下により submit 処理で reviewboard に登録する。    新規登録の場合、 mini-buffer で reviewer を選択する。    この mini-buffer では TAB キーによる補完が可能。   修正ファイルの追加・削除       rrq に登録する修正ファイルを追加したい場合、 C-c C-a を押下する。    mini-buffer で、ファイルが存在するディレクトリを指定し、 その後表示されるファイル一覧から上記のようにファイルを選択する。    選択後、 j キー押下で、ファイルが追加される。      rrq に登録する修正ファイルを除外する場合、 除外するファイルにカーソルを移動して C-c C-SPC を押下する。    除外を reviewboard に反映するには、 C-c C-u を押下する。 review コメント       review コメントの表示はサーバアクセスが多くなるため、 デフォルトでは非表示にしている。    表示する場合、 C-c C-d する。    デフォルトで表示にする場合、 rb/front-display-comment-p に nil 以外を設定する。    review コメントに対するリプライを登録する場合、 コメントにカーソルを合わせて C-c C-r。 submit モード     submit 時の動作を、次のどちらかに変更できる。    submit と同時に publish する    submit だけする    C-c C-t でモードを切り替える。  デフォルトは publish する。  デフォルトを submit だけに切り替える場合、 rb/front-submit-and-publish-p に nil を設定する。 rrq リスト表示   M-x rb/front-list で、 自分が登録した rrq 一覧を表示する。  リスト操作    (g)    リストを更新する   (RET)    カーソル位置の rrq を編集する   (u)    カーソル位置の rrq の diff を、再アップロードする   (p)    カーソル位置の rrq を publish する。   (c)    カーソル位置の rrq を close する。   (d)    カーソル位置の rrq を discard する。   (C)    カーソル位置の rrq に登録したファイルを commit する。   diff の再アップロード   再アップロードを行なうため、ローカルの work ディレクトリを指定する必要がある。 work ディレクトリの指定は mini-buffer で行なう。 注意     rrq 編集バッファで C-c C-c を実行すると、 バッファ内容がサーバに登録され、即時 publish する。    rrq 編集バッファの C-c C-a による修正ファイル追加は、 新規 rrq の場合を除き即時 publish する。 新規 rrq の場合、submit 時に rrq 情報と一緒に更新ファイル情報が登録される。   ","id":41,"section":"posts","summary":"この記事は、emacs 用 reviewboard モードの宣伝である。 \u0026lt;https://github.com/ifritJP/emacs-reviewboard-front\u0026gt; reviewboard は、ソースコードレビューを Web 上で行ない記録するためのツール。 今は github の Pull-Request に代表されるように Web","tags":null,"title":"emacs 用 reviewboard モードの宣伝","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-02-03-emacs-reviewboard/","year":"2020"},{"content":" プログラムを組む際、ラッパー関数を作ることは良くある。  このラッパー関数のオーバーヘッドが気になったので簡単に調べてみた。  計測用サンプルは次の通り。 #include\u0026lt;stdio.h\u0026gt;typedef void (func_t)( int val1, int val2 ); void func( int val1, int val2 ) { printf( \u0026#34;%d %d\u0026#34;, val1, val2 ); } void wrapper0( int val1, int val2 ) { func( val1, val2 ); } void wrapper1( func_t * pFunc, int val1, int val2 ) { pFunc( val1, val2 ); } void wrapper2( int val1, int val2, func_t * pFunc ) { pFunc( val1, val2 ); } main() { wrapper0( 0, 1 ); wrapper1( func, 0, 1 ); wrapper2( 0, 1, func ); }   関数 func() をコールする 3 種類のラッパー関数 wrapper0, wrapper1, wrapper2 を用意した。  それぞれのラッパー関数は次の形になっている。    ラッパー 引数     wrapper0 呼び出し先と同じ引数   wrapper1 ラッパー独自引数の後に呼び出し先と同じ引数   wrapper2 呼び出し先と同じ引数の後にラッパー独自引数     これを gcc の x64 で -O の最適化した結果が次になる。 (func の処理は省略) 0000000000000021 \u0026lt;wrapper0\u0026gt;: 21:\t48 83 ec 08 sub $0x8,%rsp 25:\te8 00 00 00 00 callq 2a \u0026lt;wrapper0+0x9\u0026gt; 2a:\t48 83 c4 08 add $0x8,%rsp 2e:\tc3 retq 000000000000002f \u0026lt;wrapper1\u0026gt;: 2f:\t48 83 ec 08 sub $0x8,%rsp 33:\t48 89 f8 mov %rdi,%rax 36:\t89 f7 mov %esi,%edi 38:\t89 d6 mov %edx,%esi 3a:\tff d0 callq *%rax 3c:\t48 83 c4 08 add $0x8,%rsp 40:\tc3 retq 0000000000000041 \u0026lt;wrapper2\u0026gt;: 41:\t48 83 ec 08 sub $0x8,%rsp 45:\tff d2 callq *%rdx 47:\t48 83 c4 08 add $0x8,%rsp 4b:\tc3 retq 000000000000004c \u0026lt;main\u0026gt;: 4c:\t48 83 ec 08 sub $0x8,%rsp 50:\tbe 01 00 00 00 mov $0x1,%esi 55:\tbf 00 00 00 00 mov $0x0,%edi 5a:\te8 00 00 00 00 callq 5f \u0026lt;main+0x13\u0026gt; 5f:\tba 01 00 00 00 mov $0x1,%edx 64:\tbe 00 00 00 00 mov $0x0,%esi 69:\tbf 00 00 00 00 mov $0x0,%edi 6e:\te8 00 00 00 00 callq 73 \u0026lt;main+0x27\u0026gt; 73:\tba 00 00 00 00 mov $0x0,%edx 78:\tbe 01 00 00 00 mov $0x1,%esi 7d:\tbf 00 00 00 00 mov $0x0,%edi 82:\te8 00 00 00 00 callq 87 \u0026lt;main+0x3b\u0026gt; 87:\tb8 00 00 00 00 mov $0x0,%eax 8c:\t48 83 c4 08 add $0x8,%rsp 90:\tc3 retq   上記通り wrapper0 と wrapper2 は、ほぼ同じコードになっており、 wrapper1 は引数をずらす処理が余分に入っている。  想像通りの結果といえば想像通りだが、 ちゃんと最適化された処理になっている。  以上のことから言えることは、 ラッパー関数独自の引数は、先頭ではなく末尾にもっていった方が良いということだ。  ただし、ここまで最適化が効くケースは、 ラッパー関数内での目的の関数コールが先頭にある場合に限られるので、 目的の関数コールを先頭に持ってこれない場合は、気にしないで良いだろう。  なお、 -O2 で最適化をかけると wrapper1, wrapper2 は次の処理に最適化された。 0000000000000030 \u0026lt;wrapper1\u0026gt;: 30:\t48 89 f8 mov %rdi,%rax 33:\t89 f7 mov %esi,%edi 35:\t89 d6 mov %edx,%esi 37:\tff e0 jmpq *%rax 39:\t0f 1f 80 00 00 00 00 nopl 0x0(%rax) 0000000000000040 \u0026lt;wrapper2\u0026gt;: 40:\tff e2 jmpq *%rdx   個人的には、こっちの方が納得がいく。  また、次のようにラッパー関数に static 宣言を付加して、 外部からコールされないことを明示すると、 #include\u0026lt;stdio.h\u0026gt;typedef void (func_t)( int val1, int val2 ); void func( int val1, int val2 ) { printf( \u0026#34;%d %d\u0026#34;, val1, val2 ); } static void wrapper0( int val1, int val2 ) { func( val1, val2 ); } static void wrapper1( func_t * pFunc, int val1, int val2 ) { pFunc( val1, val2 ); } static void wrapper2( int val1, int val2, func_t * pFunc ) { pFunc( val1, val2 ); } main() { wrapper0( 0, 1 ); wrapper1( func, 0, 1 ); wrapper2( 0, 1, func ); }   出力結果は次のように、 ラッパーがインライン展開され、 ラッパーの引数の違いによる差分は無くなった。 0000000000000021 \u0026lt;main\u0026gt;: 21:\t48 83 ec 08 sub $0x8,%rsp 25:\tbe 01 00 00 00 mov $0x1,%esi 2a:\tbf 00 00 00 00 mov $0x0,%edi 2f:\te8 00 00 00 00 callq 34 \u0026lt;main+0x13\u0026gt; 34:\tbe 01 00 00 00 mov $0x1,%esi 39:\tbf 00 00 00 00 mov $0x0,%edi 3e:\te8 00 00 00 00 callq 43 \u0026lt;main+0x22\u0026gt; 43:\tbe 01 00 00 00 mov $0x1,%esi 48:\tbf 00 00 00 00 mov $0x0,%edi 4d:\te8 00 00 00 00 callq 52 \u0026lt;main+0x31\u0026gt; 52:\tb8 00 00 00 00 mov $0x0,%eax 57:\t48 83 c4 08 add $0x8,%rsp 5b:\tc3 retq   基本的に、ソースコードはメンテナンス性や可読性を優先すべきだが、 ソースコードを自動生成するような場合は、 このような細かいことも意識しておいた方が良いだろう。  以上。 ","id":42,"section":"posts","summary":"プログラムを組む際、ラッパー関数を作ることは良くある。 このラッパー関数のオーバーヘッドが気になったので簡単に調べてみた。 計測用サンプルは次の","tags":null,"title":"C 言語のラッパー関数オーバーヘッド","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-10-15-wrapper-overhead/","year":"2019"},{"content":"  以前 C 言語の関数ポインタによる関数コールのオーバーヘッドがどの程度なのか調べたが、 今回は可変長引数(va_list)処理のオーバーヘッドについて調べてみた。 結果   初めに結果から書くと、 可変長引数(va_list)処理のオーバーヘッドは、めちゃめちゃ掛る。 また、引数の数に応じて時間が増加する。  所感   今回の実験によって、 va_list 処理には当初の想定を遥かに越えたオーバーヘッドが かかることが分った。  個人的には、コンパイラがもっと賢くやってくれているものだと思っていたが、 実際には全く賢くなかった。  C 言語で可変長引数を積極的に使用することはあまりないとは思うが、 可変長引数の使用はオーバーヘッドを十分考慮に入れて慎重に検討するべきだということが判った。  この可変長引数のオーバーヘッドを調べたのは、 LuneScript のメソッド呼び出し処理を C 言語にトランスコンパイルした際に 可変長引数を利用しようと思ったからなのだが、 この結果から可変長引数は使えないことが分った。  対応する前に結果が分って良かったが、 可変長引数が使えなくなったのは当初の目論見が崩れてしまった。 実験詳細   ここでは、今回の実験方法について説明する。 コード   実験用に次の C 言語コードを作成した。 int func( int val1, int val2 ) { return val1 + val2; } int sub( int dummy, int val1, int val2 ) { return func( val1, val2 ); } int funcv2( va_list ap ) { int val1 = va_arg( ap, int ); int val2 = va_arg( ap, int ); return val1 + val2; } int subv2( int dummy, ... ) { int val; va_list ap; va_start( ap, dummy ); val = funcv2( ap ); va_end( ap ); return val; }   func, sub は、可変長引数を使用しないパターン。 funcv2, subv2 は、可変長引数を使用しするパターン。  ちなみにコードの全体は次の通りである。 #include \u0026lt;sys/time.h\u0026gt;#include \u0026lt;time.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdarg.h\u0026gt; int func( int val1, int val2 ) { return val1 + val2; } int sub( int dummy, int val1, int val2 ) { return func( val1, val2 ); } int funcv2( va_list ap ) { int val1 = va_arg( ap, int ); int val2 = va_arg( ap, int ); return val1 + val2; } int subv2( int dummy, ... ) { int val; va_list ap; va_start( ap, dummy ); val = funcv2( ap ); va_end( ap ); return val; } int funcv3( va_list ap ) { int val1 = va_arg( ap, int ); int val2 = va_arg( ap, int ); int val3 = va_arg( ap, int ); return val1 + val2 + val3; } int subv3( int dummy, ... ) { int val; va_list ap; va_start( ap, dummy ); val = funcv3( ap ); va_end( ap ); return val; } double getTime( void ) { struct timeval tm; gettimeofday( \u0026amp;tm, NULL ); return tm.tv_sec + tm.tv_usec / 1000000.0; } main( int argc, const char * argv[] ) { long long loop = strtoll( argv[ 1 ], NULL, 10 ) * 1000ll; long long count = 0; int sum = 0; double prev = getTime(); if ( strcmp( argv[ 2 ], \u0026#34;1\u0026#34; ) == 0 ) { for ( count = 0; count \u0026lt; loop; count++ ) { sum += sub( 0, 1, 2 ); } } else if ( strcmp( argv[ 2 ], \u0026#34;2\u0026#34; ) == 0 ) { for ( count = 0; count \u0026lt; loop; count++ ) { sum += subv2( 0, 1, 2 ); } } else { for ( count = 0; count \u0026lt; loop; count++ ) { sum += subv3( 0, 1, 2, 3 ); } } printf( \u0026#34;%s: %lld time = %g, %d\\n\u0026#34;, argv[ 2 ], loop, getTime() - prev, sum ); }   このプログラムは、コマンドラインの引数によって sub, subv2, subv3 を指定の回数分実行し、実行時間を表示する。 計測結果      時間(秒)     固定長引数(sub: 2 引数) 0.62   可変長引数(subv2: 2 引数) 11.95   可変長引数(subv3: 3 引数) 16.16     上記結果を見ると分かる通り、可変長引数は処理時間の桁が違う。  また、引数の数に応じて時間が増加する。  以上 ","id":43,"section":"posts","summary":"以前 C 言語の関数ポインタによる関数コールのオーバーヘッドがどの程度なのか調べたが、 今回は可変長引数(va_list)処理のオーバーヘッドにつ","tags":null,"title":"C 言語の可変長引数 (va_list) 処理のオーバーヘッド","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-08-06-va-performance/","year":"2019"},{"content":"  「日本の全てのソフトウェアプロジェクトは必ず技術的負債になる」というタイトルですが、 次の条件を満す場合に限ります。  「プロジェクトに関わるソフトウェアエンジニアの大半が技術に無関心」 動機   このネタは、次の記事を読んで個人的に思うことがあったのをきっかけに 書いています。    オブジェクト指向プログラミング – 1兆ドル規模の大失敗    \u0026lt;https://okuranagaimo.blogspot.com/2019/07/1.html\u0026gt;      大企業の技術系インターンシップに参加した    \u0026lt;https://blog.browniealice.net/post/internship2019winter/\u0026gt;      ソフト開発で世界と闘った及川卓也氏が見た、日本の弱点と可能性    \u0026lt;https://headlines.yahoo.co.jp/article?a=20190801-00010000-chuokou-bus_all\u0026gt;      上記の記事は各自に読んでもらうとして、 それぞれの記事の内容をものすごく大雑把にまとめると    「OOP はダメだから、関数型プログラミングを使え」    「日本を代表する大企業に実情に失望した」    「日本の企業はソフトウェア開発を理解していない」    になると思います。 プログラミング言語は道具にすぎない   上記ブログで「OOP はダメだから、関数型プログラミングを使え」と書かれています。 私は、OOP が万能だなんて思ってませんし、 上記ブログで指摘されている側面があることも理解しています。  ですが、オブジェクト指向プログラミングにしろ関数型プログラミングにしろ、 万能ではないという意味ではどちらも同じです。  プログラム言語は道具です。 いかなる道具であっても、 その道具を安全に運用できるかどうかは、最終的には使う人に依存することになります。  例えば、古典的なプログラミング言語の代表格に C 言語がありますが、 ご存知の通り C 言語には GC もないですし、 NULL 安全でもありません。 そのような高度な「安全」機能を持たない C 言語は、Linux Kernel の開発言語です。 C 言語によって Linux Kernel を開発しているという事実は、 高度な「安全」機能が搭載されていないプログラミング言語であっても、 使用する人次第で大規模プロジェクトでも問題なく運用できるという一つの実証と言えます。  逆に、C 言語よりも高度な「安全」機能を搭載しているプログラミング言語を使用した プロジェクトが技術的負債の塊になり運用困難になった、 という例はいくらでも身近にあると思います。 もし身近に無いとしても、ネットで検索すれば多数ヒットします。  だからと言って、 C 言語の様に使用する人への依存が高過ぎる言語と、 Rust のように先進的な安全機能搭載言語のどちらを使っても大差はない、 というつもりはありません。 私が言いたいのは、「より安全」と言われる技術を使っても、 それを使用する人への依存性が無くなることはない、ということです。  自動運転に例えると、 プログラム言語自体が提供する「安全」は高々レベル 3 のサポートにすぎません。  レベル 3 の自動運転には、ドライバーの運転技術が必須であるように、 現存するどのようなプログラム言語であっても、 ソフトウェアエンジニアの能力が欠かせません。 「ソフトウェアエンジニアの大半が技術に無関心」であることの問題   なぜ「プロジェクトに関わるソフトウェアエンジニアの大半が技術に無関心」だとダメなのか？  これは単純に、そのようなプロジェクトではどのように「安全」な環境であっても、 その「安全」がレベル 5 の自動運転のように「完全」でない限り、 「不具合をエンジニア自ら作り込んでしまう」からです。  前述している通り、プログラミング言語はあくまでも道具であって、 その道具を安全に運用できるかどうかは、最終的には使う人に依存することになります。 そしてプログラミング言語を使う人はソフトウェアエンジニアであり、 ソフトウェアエンジニアの能力は、多くの場合、技術への関心度に比例します。  特に統計を取った訳ではなく、裏付け資料がある訳でもないですが、 個人的な経験上、技術への関心度が高いソフトウェアエンジニアほど能力が高く、 技術への関心度が低いソフトウェアエンジニアほど能力が低い傾向にあります。  つまり、 「プロジェクトに関わるソフトウェアエンジニアの大半が技術に無関心」であるということは、 ソフトウェアエンジニアの大半の能力が低いということと、ほぼ同義になります。  「技術への関心度が低いソフトウェアエンジニアほど能力が低い傾向にある」という持論の 根拠となるエピソードを一つ挙げておきます。  あるソフトウェアエンジニアＡがモジュールの設計をしていました。  そのモジュールは、他モジュールとの依存が高いことが問題になっていたので、 「DI(Dependency injection)の手法を取り入れたら もっとスッキリした設計になる可能性があるので検討してみてはどうですか？」 と、そのソフトウェアエンジニアＡに話をすると、 「そういう難しいことは逆に不具合につながるのでやりたくない」と 言われて一蹴されました。 DI を検討した結果、従来通りの方法を採用する方が良いという結論になったのであれば 納得できますが、なんとなく難しそうというイメージだけで拒否していました。 そして、そのモジュールは依存が高いまま実装されました。  DI のことを理解していれば、それが難しいと考える人はほとんどいないでしょうし、 テストがしやすいことから、むしろ不具合も低減できる可能性があり、 DI を取り入れることで不具合に繋がることを心配する人はいないでしょう。  このように、技術への関心度が低いと、 自分が知らない技術を積極的に取り入れるようなことをせず、 自分が使える技術だけで解決しようとします。 これによって、よりスマートに実現できる方法が他にあるにもかかわらず、 潜在的な問題を含む古い方法によってモジュールが作られていき、 それが積み重なってプロジェクト全体の品質が下っていきます。 そしてそれは時間が経過するほど、手をつけられない技術的負債になります。  一言で表現すれば、技術への関心度が低いエンジニアは「技術的負債製造機」です。  例え TEST FIRST の開発プロセスであっても、それは防げないでしょう。 ならぜなら、 テストというのは作成した成果物が仕様通りに出来ていることを確認するものであって、 仕様そのものに不具合があった場合は、その不具合を検知することは出来ないからです。 仕様を作るのはソフトウェアエンジニアです。 能力の低いソフトウェアエンジニアほど、穴の多い仕様を作る傾向にあります。  能力の低いソフトウェアエンジニアには仕様を作らせず、 能力の高いソフトウェアエンジニアだけで仕様を作れば良い、という考えもあると思います。  確かに、能力の高い人の比率が高い場合はそういう運用が可能かもしれません。 しかし、ここでは大半が能力が低いことを前提にしているので、 そのような運用は難しいです。  また、例え仕様に問題がなくても、 実際にコード化した時に不具合が埋め込まれることは良くあります。 そして、テストで検出されることもなくリリースされ、市場で時限爆弾のように爆発する、 お決まりのパターンです。もはや伝統芸能の域です。 なぜ日本で問題なのか？   ここまでの話を納得していただけたとして、次の疑問が浮ぶかもしれません。  「プロジェクトに関わるソフトウェアエンジニアの大半が技術に無関心」が 技術的負債を生み出す原因ならば、日本でなくても同じことが言えるのではないか？  それは確かにそうです。 しかし、日本の場合、終身雇用 \u0026amp; 転職しずらい社会環境によって、 一度雇ったソフトウェアエンジニアが技術に無関心だったとしても、 そのソフトウェアエンジニアを他の優秀なソフトウェアエンジニアに入れ替える、 ということが非常に困難なため、このような状況になり易いです。  さらに、日本ではソフトウェア開発をゼネコン方式で開発するという文化があり、 一つのプロジェクトを社内の優秀なソフトウェアエンジニアだけで開発する、 というのは非常に稀なケースであり、 一部(あるいは全部)のモジュールをアウトソーシングするケースが多くあります。  これによって、プロジェクトの品質コントロールをより困難にしています。  また、日本では全ての社員の待遇に差を付けず、 等しくすることを善しとする文化があるようで、 ソフトウェアエンジニアの能力に応じた待遇にする、というようなことを滅多にしません。 一方で、マネジメント能力に関しては、 能力に応じた待遇にするキャリアパスが古くから存在するため、 自分ではコードを一切書かないで一日中パワーポイントやエクセルの資料をせっせと作成している ソフトウェアエンジニア(？)が多く存在します。 そして、マネジメント能力以外のソフトウェアエンジニアの能力が評価対象ではないため、 自然と「プロジェクトに関わるソフトウェアエンジニアの大半が技術に無関心」と いう状況になる傾向にあります。 いわゆる Japanese Traditional Big Company では、 特にこの傾向が顕著なのではないでしょうか？  最初に紹介したブログの著者が「日本を代表する大企業に実情に失望した」原因は、 このような背景があるためだと思います。  また、このような背景を作り出しているのは、 Yahoo の記事にある「日本の企業はソフトウェア開発を理解していない」ためだと思います。  以上のように、日本のソフトウェア開発プロジェクトには 技術的負債を生み出す環境が整っているため、 いかなる開発手法、プログラム言語を用いても技術的負債化を防ぐことは出来ません。  それなのに、この状況を改善する為と称して、新しいプロジェクト進捗管理手法を導入する、 という斜め上な施策が実施されることがあります。  どういう論理で考えると、「新しいプロジェクト進捗管理手法を導入すること」と、 「プロジェクトの技術的負債化を防ぐこと」が繋がるのでしょうかね？ 最後に   私は LuneScript という言語を開発しています。 「プログラム言語は単なる道具でしかない」というのは、 ある意味自己否定しているようにも思われるかもしれません。  ですが、プログラム言語自体で提供できる安全機能は まだまだ残っていると思っているので、 ソフトウェアエンジニアの助けになるような安全機能を提供できるように 今後も開発を続けていきたいと考えています。  以上。 ","id":44,"section":"posts","summary":"「日本の全てのソフトウェアプロジェクトは必ず技術的負債になる」というタイトルですが、 次の条件を満す場合に限ります。 「プロジェクトに関わるソフ","tags":null,"title":"如何なる開発手法、プログラム言語を用いても、日本の全てのソフトウェアプロジェクトは必ず技術的負債になる","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-08-02-engineering/","year":"2019"},{"content":"  emacs のバージョンを 26.2 に変えたことで、 色々と細かいところの使い勝手が変っている。  その中で、 → 等の一部のフォントが半角表示されるようになったのが 微妙にストレスだったのでちょっと追ってみた。 原因   原因、と言うよりは起因と言った方が良いかもしれないが、 → 等の一部のフォントが半角表示されるようになったのは、 フォントに \u0026#34;DejaVu Sans Mono\u0026#34; を使用していることに起因していた。  これを \u0026#34;Bitstream Vera Sans Mono\u0026#34; に変更することで、現象が治った。  全く同じ環境で、 emacs 26.2 ではなく、以前使用していたバージョンの emacs だと 現象は発生しなかった。  emacs の処理が変ったことが原因であるのはほぼ間違い無いが、 emacs の何がどう変ってこの現象が発生し、 どう設定(使用するフォントを変える以外で)すれば、 現象を修正できたのかは残念ながら分からないまま。  と、思ったが、次のブログに答えがあった。  \u0026lt;http://misohena.jp/blog/2017-09-26-symbol-font-settings-for-emacs25.html\u0026gt;  詳しくは、上記ブログを確認してもらうとして、 要点だけ説明すると use-default-font-for-symbols に nil 以外が設定されていると、 シンボル等の文字のフォントが default フォントを使用するようになるらしい。 このデフォルト値が t であるため、矢印等の一部のフォントが半角になっていた。  ということで、 以下を設定してやれば、使用するフォントを変えなくても全角で表示されるようになる。 (setq use-default-font-for-symbols nil)   じゃぁ、どうして \u0026#34;Bitstream Vera Sans Mono\u0026#34; に変えると 全角で表示されたのか？が気になったんで調べてみたが、 どうやら \u0026#34;Bitstream Vera Sans Mono\u0026#34; には矢印などのフォントが 含まれていなことが原因のようだ。  fontforge でフォントの中身を見ると、 \u0026#34;Bitstream Vera Sans Mono\u0026#34; には矢印のフォントがなく、 \u0026#34;DejaVu Sans Mono\u0026#34; には矢印のフォントがあることが判った。  つまり、\u0026#34;DejaVu Sans Mono\u0026#34; には矢印のフォントがあるので、それが表示され、 \u0026#34;Bitstream Vera Sans Mono\u0026#34; には矢印のフォントがないので、 別で設定していた全角のフォントが表示された、ということだろう。  あぁ、これでストレスが一つ減った。 ","id":45,"section":"posts","summary":"emacs のバージョンを 26.2 に変えたことで、 色々と細かいところの使い勝手が変っている。 その中で、 → 等の一部のフォントが半角表示されるようになったのが 微","tags":null,"title":"emacs26.2 で矢印(→)等の一部のフォントが半角表示されるようになった","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-07-19-font/","year":"2019"},{"content":"  これは seekable な stream と none_seekable な stream の使い分けに関する記事です。  使い分けが十分出来ている人は読まなくても大丈夫です。  皆さんは bitstream という単語をご存知でしょうか？  AV (Audio\u0026amp;Visual) が好きな人や、 それらの業界に関係のある人ならそこそこ聞く単語だと思いますが、 一般的にはあまり馴染の無い単語でしょうか。  馴染の無い人の為に身近な HDD レコーダを例に挙げて説明すると、 HDD レコーダはデジタル放送の電波に乗っているデータをそのまま記録していますが、 このデータが bitstream です。 HDD レコーダは、デジタル放送の bitstream を HDD に記録し、 記録した bitstream を再生する装置と言えます。 もちろん、実際にはそんな単純ではないですが、概ね間違ったことは言ってません。 stream   プログラムでデータを扱う時、stream という概念を使って制御します。    言語 stream (入力)     Java InputStream   Swift InputStream   Go io.Reader     上記は言語毎の入力系 stream の例です。  ちなみに入力系の stream とは何かというと、 流れてくるデータを読み出すためのものです。  例えば、先ほどの HDD レコーダの例で説明すると、    デジタル放送の電波に乗っている bitstream を読み取る部分    HDD に記録されている bitstream を読み込む部分    が入力系の stream です。  また、上記言語の stream (InputStream,io.Reader)には共通することがあります。  それは、データの流れが一方通行で遡ることが出来ない、ということです。  プログラム的に言うと、上記の stream は seek や rewind をサポートしていません。  これを、先ほどの HDD レコーダの例で説明すると、 「過去に放送された番組の録画はできない」ということです。  24 時間全ての番組を常に録画し続けて、 「1週間前に放送された任意の番組を再生する」機能を持つ HDD レコーダはありますが、 それはあくまで録画してあるものを再生しているのであって、 過去に放送された番組を録画することは出来ません。 もしそれが出来るなら、 本当の意味でのタイムマシーンを作ることが出来ることと同義になります。  なお、「過去に放送された番組の録画はできない」ですが、 「録画した番組」の逆再生などは出来ます。  先ほど説明した通り、次のどちらもの入力 stream です。    デジタル放送の電波に乗っている bitstream を読み取る部分    過去に放送された番組の録画はできない      HDD に記録されている bitstream を読み込む部分    録画した番組は逆再生など出来る      これはつまり、 stream には次の 2 つのタイプが存在することを意味します。    流れが一方通行で遡ることが出来ない stream    流れを遡ることが出来る stream    これ以降、上記をそれぞれ none_seekable と seekable とします。 none_seekable と seekable の使い分け   上記の通り、stream には none_seekable と seekable の 2 つのタイプが存在します。  では、実際のプログラムでは stream はどう使い分けるべきか？ と考えた場合、 seekable である必要がない場合は極力 none_seekable を使うべきです。  なぜならば、 seekable は none_seekable を包括する概念であり、 seekable な stream は none_seekable として使用することが出来ますが、 none_seekable な stream は seekable として使用することが出来ないからです。  次に、疑似言語を使って説明します。 fn funcA( data: seekable ) { sub( data ); } fn funcB( data: none_seekable ) { sub( data ); }   上記は、 seekable な引数を持つ関数 funcA と、 none_seekable な引数を持つ関数 funcB を定義する疑似言語コードです。 また sub() は、 none_seekable な引数を持つ関数とします。  ここで、この関数 funcA は seekable な stream でしか使用できないのに対し、 この関数 funcB は seekable, none_seekable どちらでも使用できることになり、 funcB は funcA よりも汎用性が高いと言えます。  関数の汎用性が高いことが良いプログラムである、とは一概には言えませんが、 ミドルウェアなどのライブラリでは、汎用性が高い方が良いとされます。  つまり、 stream を入力に持つ関数の処理においては、 seek や rewind の使用は極力避け、 none_seekable の stream で処理可能にすべきである、と言えます。  ただし例外として、 seek や rewind を使用しないと目標のパフォーマンスが出ないとか、 必要なワークメモリが規定を越えてしまう、等の問題がある場合は、 無理に none_seekable で処理する必要はありません。  とはいえ、あくまでも原則は、 seekable ではなく none_seekable で処理できるかどうかを検討するべきです。  言語の組込みの型として seekable と none_seekable が分かれていない言語は、 結構あると思います。  そのような言語でも、 seekable と none_seekable の考え方自体は有効なので実践してください。 none_seekable で処理することのメリット   seekable ではなく none_seekable で処理することのメリットとして、 Web ブラウザでの処理を例に挙げて説明します。  もしもブラウザの処理が全て seekable であった場合、 ブラウジングスピードが遅くなることが予想されます。  なぜなら、Web ブラウザは、サーバから HTML をダウンロードし、 HTML 内のリンクを抽出し、そのリンクをさらにダウンロードします。 そしてリンクが画像の場合、画像をデコードして表示します。  画像のデコード処理が none_seekable であるならば、 画像データのダウンロード開始と同時にデコード処理が開始でき、 画像データのダウンロード終了とほぼ同時にデコード処理を完了できます。  一方でもしも画像のデコード処理が seekable だった場合、 画像データをダウンロード終了してからデコード処理を行なわなければならず、 その分タイムロスになります。 さらに欠点はタイムロスだけでなく、 画像データの全てをダウンロードして一旦 RAM やストレージに格納しておく必要があり、 その分のリソースを消費することになります。  画像データのサイズなんてイマドキのハードウェアスペックなら無視できる、 という意見もあるかもしれませんが、例えば 8K の低圧縮画像などは軽く数 10MB を越えます。 こういった画像のデータを全てダウンロードしてからデコードするなんてしてたら、 無駄にリソースを消費することが分かると思います。  また、最近はほとんど使われていませんが、 progressive JPEG なんて画像フォーマットが使われていた時期がありましたが、 これは none_seekable で処理して始めて意味のあるものです。  progressive JPEG を簡単に説明すると、 画像データの一部をダウンロードするだけで、低解像度の画像をデコードできる技術で、 ダウンロードが進むごとにデコード結果の解像度が上がるというものです。  これは、ネットワークの通信速度が低速なころに使用されていた画像フォーマットで、 いまではほとんど使われなくなったものですが、 none_seekable で処理しなければ全く意味のないものです。  他にも none_seekable で処理することのメリットとして、 動画配信に代表されるストリーミングサービスがあります。  あれも、 none_seekable が前提にあるからこそ可能なサービスです。  「ストリーミングサービスが none_seekable だ」と書くと 「Youtube はシークできるぞ」とかツッコミがあると思うので一応補足しておきます。  たしかに Youtube などの動画配信サービスはシークできるのが当たり前です。 しかし、通常再生時は none_seekable で処理していて、 シークなどの操作が入った時だけ、 サーバからデータをダウンロードしなおして処理しています。 つまり、基本は none_seekable です。  もしも動画データが seekable 前提だった場合、 動画データを全てダウンロードしてからでないと再生できないか、 seek 処理が大量に発生してサーバ間の通信負荷が非常に高くなることが予想されます。  また、seekable(randam access) は none_seekable(sequential) と比べて 非常にパフォーマンスが悪くなるのが一般的です。  例えば HDD の randam access は sequential と比べて 2 桁以上のパフォーマンス劣化、 SSD でも 1 桁以上劣化します。 RAM であっても、randam access することでキャッシュミスが発生しやすくなり、 パフォーマンス劣化からは逃れられません。 現代ではほとんど使われませんが、 テープデバイスなんて使った日には、どれほどかかるか想像すら出来ません。 データフォーマット   stream を処理する際に、 それを none_seekable として扱うには、 stream に流れるデータのフォーマットが none_seekable として 扱い易い構造になっている必要があります。  データフォーマットが none_seekable として扱い難い構造の場合、 上記のように「目標のパフォーマンスが出ない」、「必要なワークメモリが規定を越えてしまう」 という問題が発生する可能性があります。  ある程度の大きさになるデータフォーマットを定義する時は、 必ず none_seekable で処理することを考えて定義しましょう。  なお、 stream で処理することが多い画像や音声などのデータフォーマットは、 基本的には none_seekable で処理できるように定義されています。  もしもそうでなければ、放送や動画配信でデジタルデータを扱うことは出来ません。  ちなみに、データの encode と decode の none_seekable での扱い易さは、 相反することがあります。  その場合、どちらかを優先するか、折衷案の検討が必要です。 一つ言えることは、作業バッファを 0 にすることはまず不可能なので、 どの程度の作業バッファサイズなら妥当かを判断することが重要です。 例外   none_seekable で処理することで、 ダウンロードとデコードを同時に処理できるため高速に処理できる、と説明しましたが、 一部例外があります。  それは、専用ハードウェアを使用してデコードする場合です。  HDD レコーダなどの家電製品では、 動画や音声を処理する専用ハードウェアを搭載しています。 それら専用ハードウェアは、データを渡すと高速に処理して結果を返してくれますが、 処理するデータは全て揃えてから渡さなければならない、 という制約があることがほとんどです。  その場合は、none_seekable でダウンロードとデコードを同時に処理するよりも、 専用ハードウェアを使用して処理する方が高速に処理できます。  ただし、当然専用ハードウェアであるため、処理できるデータは限られていますし、 そのような専用ハードウェアが利用できる環境は限られています。 まとめ   stream を扱う際は、次を注意する必要があります。    極力 none_seekable で扱う    データフォーマットを決める時点で、 none_seekable で扱えることを考慮する   最後に   なんでこんなことを書いたかというと、 最近とある画像コーデックのライブラリを扱うことがあったんですが、 そのライブラリへの入力が seekable であることを前提としていてムカついた、 という経験をしたためです。  データ streaming 処理を行なう場合の基本的な考えなので、 必ずこれらを考慮に入れて設計するようにお願いします。  以上。 ","id":46,"section":"posts","summary":"これは seekable な stream と none_seekable な stream の使い分けに関する記事です。 使い分けが十分出来ている人は読まなくても大丈夫です。 皆さんは bitstream という単語をご存知でしょうか？","tags":null,"title":"stream は rewind/seek できる？","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-07-10-stream/","year":"2019"},{"content":"  コレ を作るにあたって、データの serialize/deserialize の方法を調べた結果、 marshmallow_dataclass に落ち着きました。  いくつか調べた中で、パッと見、直感的に出来そうだった、というだけの理由ですが。。  実際、面倒な処理はほとんど無く、 serialize/deserialize が可能になりました。 使い型   marshmallow_dataclass は、 クラスを宣言する際に @dataclass デコレータを付けて宣言し、 メンバの型を宣言するのが基本です。  こんな感じ。 @dataclass class LogItem: # ゲームタイトル title:str # 日付 date:int # テキスト text:str # テキスト長 len:int   メンバの宣言が python っぽくないと思う方もいるかもしれませんが、 静的型付け言語になれていると、こっちの方が馴染み易い気がします。  JSON 化する場合は、 次のようにクラスメソッドに JSON 化するクラスのインスタンスを渡すだけです。 item = LogItem( \u0026#34;title\u0026#34;, time.time(), \u0026#34;text\u0026#34;, len( \u0026#34;text\u0026#34; ) ) print( marshmallow_dataclass.class_schema( LogItem )().dumps( item ) )   逆に JSON からクラスインスタンスを生成するには、 次のようにクラスメソッドに渡すだけです。 marshmallow_dataclass.class_schema( LogItem )().loads( text )   とても簡単です。  ただ、躓いた点があったので、気をつけるべき点として書いておきます。    python3.7 以降を使用する    @dataclass デコレータを付けたクラスに次を宣言してはならない    コンストラクタ init    @staticmethod load()     ","id":47,"section":"posts","summary":"コレ を作るにあたって、データの serialize/deserialize の方法を調べた結果、 marshmallow_dataclass に落ち着きました。 いくつか調べた中で、パッと見、直感的に出来そうだった、というだけの理","tags":null,"title":"python のクラスを JSON 化","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-07-04-python-json/","year":"2019"},{"content":"  4 月頃から、英語のレベルを上げるため参考書を買って勉強をしている。  その参考書を使った最低限の基礎英語の復習は終ったので、次のステップに進むことにした。  基礎が終った後の学習方法には何が良いのか色々と調べてみたが、 色々な意見があるが最終的には「持続できるものが良い」というのが結論のようだ。  まぁ、「持続すること」が英語学習で最も難しいことは、 私自身が何度も挫折した経験があるので認識している。  そもそも、先日まで復習していた参考書もかなり眠い目をこすりながらやっていて、 このまま参考書を進めていっても、間違いなくまた挫折することは明らかだった。  じゃぁ、何が一番持続できるか？と考えた時、自分にはゲームが良いだろう。 という結論になった。 海外ゲームによる英語学習   ゲームのジャンルは、いわゆるノベルゲームあるいはアドベンチャーゲーム。 有名どころで STEINS;GATE と言えば通じるだろうか？ これなら文章量がハンパないので、勉強量という意味では問題ないだろう。 「ゲームでの英語学習は効率が悪い」という意見があるが、 「持続すること」が一番重要なので、「効率の悪さ」はこの際無視することにした。  ともかく今は、英語の文章を英語のまま解釈できるようになるため、 英語の文章をひたすら入力していくのが最も重要な期間で、 その期間を挫折せずにやりすごすためにも、「持続すること」が一番重要と考えている。  「習うより慣れよ」、脊髄反射できるまでの試練だ。  そもそも、本当に効率の良い英語学習方法が存在するのであれば 文科省もバカじゃないんだからその方法を採用しているはず。 そして、その学習方法に本当に効果があれば、 日本人の大多数が英語が出来ないまま放置されているはずがない。 しかし、現実問題として私を含め日本人の大多数が英語が出来ないままである。  つまり「日本国内における英語学習方法の違いによる効率の差」は、 ほとんど誤差レベルなんだと思う。  もちろん、「英語しか話せない人の中で生活すること」と、 「日本国内で独学で英語を学習する」のとでは、英語の習得効率に明らかな違いはあるだろう。 しかし、「日本国内で独学で英語を学習する方法」は、 どのような学習方法であっても、どれも大差ないレベルなんだと思う。 海外ゲームによる英語学習における問題   ということで、先週辺りから海外のゲームをプレイしているんだが、一つ問題がある。  その問題とは「reading の経験値しか得られない」ということだ。  日本のゲームの海外移植版をやるのがとっかかり易いと考えてたが、 そのゲームの TEXT は英語だが音声は日本語のままだった。 てっきり海外移植版なら音声も英語になっているものだと思っていたが、完全に想定外だった。  それならば、海外制作のオリジナルゲームなら音声も英語だろう、と思って探したが、 そもそも海外制作のノベルゲームやアドベンチャーゲームというジャンルはほとんど無かった。 あっても、音声がないという状況だ。 もちろん、他のジャンルのゲームなら英語音声のものはある。 しかしそのようなゲームは、TEXT の量的問題や、 そもそも英語とか関係なくゲームが進んでいって、 ほとんど単にゲームをプレイしているだけになってしまう、という問題がある。  ちなみに、海外ドラマや映画を学習手段として試したことがあるが、 アレはスピードが速すぎて、 自分のレベルではとてもではないけどハードルが高過ぎるという結論になっている。  自分のペースで進められる、というのが、 ノベルゲームやアドベンチャーゲームの良いところだ。  もちろん、内容が面白く持続できるということが前提だが。  なお、今回海外のゲームを探してみて初めて気が付いたことだが、 海外でアドベンチャーゲームというと、日本のアドベンチャーゲームとは全く違って、 アクションゲームがアドベンチャーゲームに分類されていた。  まぁ「adventure」 は「冒険」なんだから、当然といえば当然だろうが。  だいぶ前置きが長くなったが、 そんな訳で、多くの時間を費やして「reading の経験値しか得られない」のは勿体無いので、 「どうにかしてゲームに音声を付けよう」と思い、今回のツール制作に至った。 ゲームに音声を付ける手段   ここで想定するゲームは、 メッセージを表示する領域があり、クリックすることでメッセージが更新されて、 ストーリーが進んでいくものだ。  このメッセージを取り出し、機械音声でしゃべらせる。  もう少し技術的にいうと次になる。    スクリーンショットでゲーム画面をキャプチャ    キャプチャしたゲーム画面からメッセージ領域を判定し    メッセージ領域内のメッセージ画像を抽出し    抽出したメッセージ画像を OCR にかけて TEXT に変換し    変換した TEXT を Text To Speech で音声化する    上記を GUI でコントロール    メッセージ画像の抽出は OpenCV、 OCR は Tesseract OCR、 Text To Speech は Windows10 標準の SAPI.SpVoice を利用する。  クラウドサービスの API を使えば、これらを全て行なってくれるものもありそうだが、 今回は上記の技術を組み合わせで自前で作成する。  まぁ、自分で作ること自体も面白そうだし。  なお、お手軽に作るため、開発言語は Python とする。  プログラミング言語として、個人的にはあまり Python は好きではないんだけど、 手軽でさまざまなライブラリが揃っていて情報量も豊富、という意味では、 今は Python に敵う言語はないんじゃないかと思う。  なんだかんだ言っても、プログラミング言語はツールにすぎないので、 目的の物を簡単に作れるのが一番良い。 特に趣味で作るケースでは。  業務で使う場合は、 「チョット待て、他の言語はちゃんと検討したのか？」と言っておく。  自分で開発している LuneScript も、 lua VM 上で動作する大規模アプリを開発するには向いているけど、 使えるライブラリは皆無(Lua 用ライブラリは使えるけど、まともに使うには module 宣言が必要) なので、残念ながらこういう用途には向いていない。  ちなみに、 cygwin 版 python で作業しようと思ったが、 pip がどうにもこうにも期待通りに動作しなかったので、 普通の windows 版 python にした。  以降では、各技術について補足する。 スクリーンショット   スクリーンショット用に次をインストールする。 $ pip install pywin32 $ pip install Pillow $ pip install pyscreenshot   pywin32 は、 win32gui で特定の Window の領域を取得するために必要。  具体的には次のような感じ。 def getImageOf( window_title ): rect = win32gui.GetWindowRect( win32gui.FindWindow(None, window_title ) ) return ImageGrab.grab().crop( rect )  OpenCV   次の処理を OpenCV で行なう。    ゲーム画面からメッセージ領域を判定    メッセージ領域内のメッセージ画像を抽出    ちなみに OpenCV のインストールは次で出来る。 $ pip install opencv-python  OCR (Tesseract OCR)   次の処理を Tesseract OCR で行なう。    抽出したメッセージ画像を OCR にかけて TEXT に変換    Tesseract OCR は、次の URL からバイナリをダウンロードしてインストールし、  https://github.com/UB-Mannheim/tesseract/wiki  さらに python から利用するためのパッケージをインストールする。 $ pip3 install pyocr  Windows10 Text To Speech (SAPI.SpVoice)   次の処理を SAPI.SpVoice で行なう。    変換した TEXT を Text To Speech で音声化する    \u0026lt;https://github.com/mhammond/pywin32/releases\u0026gt; から、 python のバージョンに合う win32com モジュールのインストーラをダウンロードし、 インストールする。  SAPI.Speech の制御方法は、次の URL を参考に。  \u0026lt;https://www.daniweb.com/programming/software-development/code/217062/text-to-speech-using-com-python\u0026gt;  この SAPI.SpVoice の音声は、 一昔前の合成音声に比べればだいぶマシに聞こえるが、やはり違和感を感じる。  英語が出来ない自分が、英語の音声に違和感の文句を云うのもどうかと思うが、 やはりイマドキの最新の Text To Speech 技術と比べると、品質が落ちる。  そこで、Text To Speech の部分はクラウドサービスを使って違和感の緩和を検討する。 これについては後日取り上げる。 GUI   GUI は tkinter を利用する。  用途は次の通り。    ゲームの Window 指定    OCR のトリガ    OCR 後のメッセージ表示 \u0026amp; 編集    音声再生制御 (再生スピード,音量)   ログ   折角なので、学習の履歴を残す。  履歴は、日付、OCR 結果、全文字数 で、JSON 形式で残す。 欠点   このシステムの一番の欠点は、読み上げられる音声に全く感情が入らないってことだろう。 ゲームのト書部分なら無感情でも問題ないが、 セリフが無感情で読み上げられるのは、いささか味気ない。 まぁ、そこは割り切るしかないが。 今は、クリアに音声が聞こえる事の方が重要だろう。 感情がどうこういうのは、 実力が付いてから海外ドラマや映画を見るようにすれば良い話だ。 最後に   専門知識がなくても、フリーの技術を組合せるだけで、 これだけのものが作れるようになったというのはスゴい時代になったものだ。  ちなみにソースは \u0026lt;https://github.com/ifritJP/game-message-tts.git\u0026gt; にある。 興味があれば。 ","id":48,"section":"posts","summary":"4 月頃から、英語のレベルを上げるため参考書を買って勉強をしている。 その参考書を使った最低限の基礎英語の復習は終ったので、次のステップに進むこ","tags":null,"title":"ゲームのメッセージ欄に表示されたメッセージの読み上げシステム","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-06-28-text-to-speech/","year":"2019"},{"content":"  だいぶ前に買って放置していた Raspberry pi zero w をセットアップしました。  Raspberry pi zero w と言えば「小型軽量」が売りなんで、 今回はポータブルな IOT デバイスとして使う事を目的として、 Bluetooth の機能(ファイル転送、 IP over Bluetooth) のセットアップをしました。  イマドキ Bluetooth なんて、 最新のイメージでセットアップすればすぐに使えるだろうと思って余裕でした。 しかし、実際には目的の機能が動作するまでに、かなりの時間が掛ってしまいました。  少なくとも、パッケージをインストールするだけでは済まず、 いくつかのファイルを編集 \u0026amp; コマンド実行が必要です。  そんな訳で、次に同じことをする時のために備忘録を残しておきます。  この記事で扱うメインは以下の通りです。    Raspberry pi zero w を USB 接続のみでセットアップ    Bluetooth によるファイル送受信機能(OBEX File Transfer)の実現    IP over Bluetooth (PAN) による、PC との SSH 接続確立    スムースにいけば、 作業時間は 10 〜 20分程度で完了します。 (OS イメージ書き込みや apt 更新などの待ち時間は除く)  なお、 Raspberry pi の設定を行なうホスト環境は Ubuntu 18.04.2 LTS とします。  Ubuntu が Native で動作する PC でも、 Windows 上の Gest OS の Ubuntu でも構いません。 ただし、 Windows 10 の subsystem の linux は対象外です。 Raspberry pi zero w を USB 接続のみでセットアップ  SD カードに OS Image を書き込む   公式サイトから OS Image を落して SD カードに書き込みます。  今回は Raspbian Stretch with desktop and recommended software の 2019-04-08 を使用しました。  以前 raspi で Bluetooth を扱った時、 Lite では意図する動作にならなかったトラウマがあるため、今回はこれを使用します。  イメージを書いたら、ssh と IP over USB (RNDIS) を有効化するため、 SD カードをマウントした直下の次のファイルを編集します。    ssh    config.txt    cmdline.txt    編集内容については、次の URL を参考に。  \u0026lt;https://qiita.com/mt08/items/ce5e3911d74d7fad4563#%E6%89%8B%E9%A0%86\u0026gt;  念の為要点だけをまとめておくと、    空の ssh ファイルを作成    config.txt に次を追加   dtoverlay=dwc2     cmdline.txt    rootwaitとquietの間に次を挿入     modules-load=dwc2,g_ether  RNDIS 設定   Ubuntu では、Raspberry pi zero w (以降 raspi) を USB (2つある USB コネクタのうち、 HDMI コネクタ側の方)で接続すれば、 運が良ければ特になにもせずに IP over USB (RNDIS) で raspi と通信可能になります。  通信可能かどうかは、次の方法で確認できます。 $ ip a   ここで enp0s20u1 的なデバイスが表示されていて、 IP アドレスが取れていることを確認します。  IP アドレスが取れている場合、次のコマンドで raspi の IP を確認します。 $ ip n   同じサブネットのアドレスがあれば、それが raspi の IP。  raspi の IP が分かったら、 ssh すれば OK。 $ ssh -Y pi@10.42.0.100   ちなみにデフォルトパスワードは raspberry.  大抵の場合、運が良くないので上記の確認では期待した結果にならない。  そのため、次のネットワーク設定が必要になる。  まず、ネットワーク設定を行なう前に、現在のネットワークの状況を確認します。 $ ip a   このコマンドで表示される「デバイス名」と「MAC アドレス」をメモっておきます。  メモった後に、次のコマンドを実行します。 $ sudo nmtui   起動すると、いくつかの Ethernet 設定がリストで表示されるので、 編集を選択します。  編集を選択すると、デバイスの欄に「デバイス名」あるいは「MAC アドレス」が 表示されているので、 USB の方の情報が表示されている Ethernet 設定を見つけます。  設定を見つけたら、一旦その設定自体を消します。 USB のデバイスに関する設定が複数ある場合は、全て削除します。  そして、新しく設定を追加します。  このときの設定内容は次の通りです。    接続タイプ Ethernet    デバイス名を enp0s20u1 (実際のデバイス名に合せる)    IP4 config を share にする    Require IPv4 addression for this connection をチェック    設定後、connection を activate する。  これで再度 ip a から確認してください。 これでも上手く動作しない場合、 deactivate と activate を何度か繰り返すと解消されることがあります。  ちなみに Windows をホストに作業する場合、野良ドライバのインストールが必要です。 個人的には、Windows への野良ドライバインストールはオススメできません。  以降は、 raspi に ssh 接続した状態で作業します。  まずは、次のコマンドで apt を更新しておきます。 $ sudo apt-get update $ sudo apt-get install bluez-tools pulseaudio-module-bluetooth   本来 pulseaudio-module-bluetooth は、 audio sink 用のものなので、 今回の目的には不要のはずなんですが、 これがないとペアリング後の接続すら出来なかったので入れておきます。  次に、 raspi のホスト名を変更します。 このホスト名が、 bluetooth のペアリングのときに使用されます。  次のコマンドを実行し、 Network Options -\u0026gt; Hostname で適当に変更します。 $ sudo raspi-config  Bluetooth によるファイル送受信機能(OBEX File Transfer)の実現   Bluetooth のファイル送受信には、 追加で obex 系の設定が必要となります。 $ sudo apt install obexpushd   obex 系の処理を動かすには、 bluetoothd に –compat オプションを必要です。  オプションの指定は次のように /etc/init.d/bluetooth に –compat を追加します。 #SSD_OPTIONS=\u0026#34;--oknodo --quiet --exec $DAEMON -- $NOPLUGIN_OPTION\u0026#34; SSD_OPTIONS=\u0026#34;--oknodo --quiet --exec $DAEMON -- --compat $NOPLUGIN_OPTION\u0026#34;   あるいは、 /etc/systemd/system/bluetooth.target.wants/bluetooth.service に追加するケースもあります。 #ExecStart=/usr/lib/bluetooth/bluetoothd ExecStart=/usr/lib/bluetooth/bluetoothd --compat   ファイル編集後 –compat オプションを反映させます。 $ sudo systemctl daemon-reload $ sudo /etc/init.d/bluetooth restart $ sudo systemctl restart bluetooth   次に Bluetooth ファイル受信用ディレクトリを作成します。 $ mkdir ~/bluetooth   そして次のコマンドを実行します。 $ sudo /usr/bin/obexpushd -B -n -o /home/pi/bluetooth   これでホスト PC からファイルを送信すると、 /home/pi/bluetooth にファイルを受信します。  なお、obexpushd は次のようにサービスとして登録します。  /etc/systemd/system/bt-obexpushd.service に次の内容をもつファイルを作成。 [Unit] Description=Bluetooth obexpushd After = bluetooth.service [Service] ExecStartPre=/bin/sleep 4 ExecStart=/usr/bin/obexpushd -B -n -o /home/pi/bluetooth Type=simple [Install] WantedBy=multi-user.target   サービスを有効化 $ sudo systemctl enable bt-obexpushd $ sudo systemctl start bt-obexpushd  IP over Bluetooth (PAN) による、PC との SSH 接続確立   PAN の設定は、次の URL の回答をそのまま設定すれば OK です。  \u0026lt;https://raspberrypi.stackexchange.com/questions/29504/how-can-i-set-up-a-bluetooth-pan-connection-with-a-raspberry-pi-and-an-ipod\u0026gt;  なお、上記 URL の内容を設定後、再度ペアリングをやり直してください。 ","id":49,"section":"posts","summary":"だいぶ前に買って放置していた Raspberry pi zero w をセットアップしました。 Raspberry pi zero w と言えば「小型軽量」が売りなんで、 今回はポータブルな IOT デバイスとして使う","tags":null,"title":"Raspberry pi zero w で Bluetooth 色々(ファイル転送:obex、 IP over BT:PAN )","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-06-15-rasp0w/","year":"2019"},{"content":"  VMWare のディスクイメージのサイズは、Gest OS 上のディスクサイズと異なる。  基本的には、Gest OS 上で実際に使用されているサイズに圧縮された形でホスト OS 上に保持される。  しかし、 Gest OS 上でファイル作成、削除を繰り返していると、 Gest OS 上での使用サイズよりも、 ホスト OS 上でのディスクイメージサイズがかなり大きくなっていることがある。  このような状態になった時に、ホスト OS 上のディスクイメージサイズを、 Gest OS 上での使用サイズ程度に削減するツール(vmware-toolbox-cmd)が vmware から提供されている。  通常は、この vmware-toolbox-cmd を使うことで圧縮されるはずなのだが、 自分の環境では全くサイズが変わらなかった。  いくつか試した結果、削減出来た方法をメモしておく。 Gest OS 上でのディスクのクローン   今回実施した方法は Gest OS 上でのディスクのクローンを作成することだ。  ある意味分かりきった方法かもしれない。  ただ、クローン作成の方法はファイル単位のコピーではなく、 dd コマンドによるクローン作成 で上手くいった、 ということは意外と言えるんじゃないだろうか？  ファイル単位のコピーだと、コピーにかなり時間がかかると思うが、 dd コマンドで済んだので、10 GB 近いコピーも比較的短時間でコピーが出来た。  dd コマンドは、特に何か特別なオプションを付けて実行したのではなく、 普通に実行しただけだ。  念の為、作業手順をまとめておく。 作業手順     クローン先の空のディスクイメージを作成する    ディスクイメージを VMWare に登録する    Gest OS を起動する    vmware-toolbox-cmd を使って圧縮   vmware-toolbox-cmd disk shrinkonly     Gest OS 上での圧縮対象ディスクと、クローン先のデバイス名をメモる    dd コマンドでクローン作成   dd if=/dev/圧縮対象 of=/dev/クローン先 bs=1M     ここで指定するドライブは、パーティションではなくドライブ全体を指定すること。      Gest OS を shutdown    ここでクローン先のディスクイメージを見て、 Gest OS 上の使用量とほぼ同じサイズに削減されていることを確認する。 もしも削減されていない場合、これ以降の作業には意味はない。      圧縮対象ディスクイメージを VMWare から除外し、 代わりにクローンしたイメージを登録する。    この時クローンイメージを割り付けるハードウェアの ID などが、 元の圧縮対象ディスクイメージと同じになるように登録する。      Gest OS を起動する。    以上の手順により、サイズが圧縮されたクローンのイメージで運用できる。 ","id":50,"section":"posts","summary":"VMWare のディスクイメージのサイズは、Gest OS 上のディスクサイズと異なる。 基本的には、Gest OS 上で実際に使用されているサイズに圧縮された形でホ","tags":null,"title":"VMWare ディスクイメージが圧縮されないときの対応方法","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-05-20-vmware/","year":"2019"},{"content":"  現在 LuneScript の C 言語へのトランスコンパイル処理を対応中だが、 トランスコンパイルする際に関数ポインタによる関数コールのオーバーヘッドが どの程度なのか気になったので調べてみた。 結果   初めに結果から書くと、 関数ポインタによる関数コールのオーバーヘッドは、 通常の関数コールに比べて約 1.267 倍となることが判った。   この数値は、あくまで今回の実験結果であって、 関数ポインタかどうかの違いだけはなく、他の要因も入ってしまっている。 また、実行環境によっても差は出てくるだろう。  しかし、それでも目安程度にはなるだろう。 所感   論理的に考えて、関数ポインタの関数コールが通常の関数コールに比べて 遅くなることは理解していたが、これまで調べたことはなかった。 それが、今回の実験で明かになった。  個人的にはもっと差が出るかと思ったが、案外少ない結果になった。 これは、実験用コードが小さ過ぎて全てキャッシュに乗ってしまっているのが一番の要因だとは思う。 とはいえ、明らかなオーバーヘッドがあることには違いない。  プログラミングをしていれば感じていることだと思うが、 プログラムは関数コールの塊だ。  つまり、関数コールのオーバーヘッドは、 そのままプログラム全体の性能低下に直結する。  「関数ポインタ」というと、あまり使わっていないイメージを持つ人も多いかもしれないが、 オブジェクト指向の「ポリモーフィズム」あるいは「多態性」というと、 良く使っているイメージがあるのではないだろうか？  関数ポインタなど動的に動作が変わる処理は、 目的の制御を実現する上で非常に重要だが、 コードの把握が難しくなったり、オーバーヘッドによる性能低下を引き起こす可能性がある。  関数ポインタと通常の関数は、その特性にあわせてどちらを使用するかの検討が必要だ。  今回の実験結果をうけて、それがより明らかになったと思う。 実験詳細   ここでは、今回の実験方法について説明する。 コード   実験用に次の C 言語コードを作成した。 void sub( void ) { } void func_direct( func_t * pFunc ) { sub(); } void func_indirect( func_t * pFunc ) { pFunc(); }   func_direct() は sub() 関数を直接コールする関数で、 func_indirect() は sub() 関数を関数ポインタでコールする関数だ。  この両者の関数を実行したときの実行時間を比較している。  ちなみにコードの全体は次の通りである。 #include \u0026lt;sys/time.h\u0026gt;#include \u0026lt;time.h\u0026gt;#include \u0026lt;stdio.h\u0026gt; typedef void (func_t)( void ); double getTime( void ) { struct timeval tm; gettimeofday( \u0026amp;tm, NULL ); return tm.tv_sec + tm.tv_usec / 1000000.0; } void sub( void ) { } void func_direct( func_t * pFunc ) { sub(); } void func_indirect( func_t * pFunc ) { pFunc(); } void func_none( func_t * pFunc ) { } int main( int argc, const char * argv[] ) { long long loop; const char * pMode; double prev = getTime(); switch ( argc ) { case 1: pMode = \u0026#34;indirect\u0026#34;; for ( loop = 0; loop \u0026lt; 1000 * 1000 * 1000 * 2; loop++ ) { func_indirect( sub ); } break; case 2: pMode = \u0026#34;direct\u0026#34;; for ( loop = 0; loop \u0026lt; 1000 * 1000 * 1000 * 2; loop++ ) { func_direct( sub ); } break; case 3: pMode = \u0026#34;none\u0026#34;; for ( loop = 0; loop \u0026lt; 1000 * 1000 * 1000 * 2; loop++ ) { func_none( sub ); } break; } printf( \u0026#34;%s: time = %g\\n\u0026#34;, pMode, getTime() - prev ); return 0; }   このプログラムは、コマンドラインの引数によって func_direct(), func_indirect(), func_none() のいずれかを 所定の回数分実行し、実行時間を表示する。  ちなみに func_none() は、関数ポインタと通常の関数コールの差を出す際に、 できるだけ他の要因を除外するために作成した関数だ。 計測結果  indirect: time = 11.4617 indirect: time = 11.2905 indirect: time = 11.2595 indirect: time = 11.3391 indirect: time = 11.3123 direct: time = 10.5253 direct: time = 10.5927 direct: time = 10.5389 direct: time = 10.6043 direct: time = 10.5259 none: time = 7.64467 none: time = 7.60627 none: time = 7.75474 none: time = 7.60123 none: time = 7.63887   これは、コマンドライン引数を変えて上記のプログラムをそれぞれ 5 回ずつ実行した結果だ。  それぞれを平均すると次のようになる。     時間(秒) 関数コールの時間(秒)     関数ポインタ 11.333 3.683   通常関数コール 10.557 2.908   関数コールなし 7.649      上記の「関数コールの時間」は、計測した時間から「関数コールなし」の時間を引いたものだ。  つまり、 for 分の制御などの関数ポインタのオーバーヘッドとは直接関係ない処理の時間を引いている。  この結果をもとに、次の計算をすると  (/ 3.683 2.908) 1.266506189821183  関数ポインタによる関数コールのオーバーヘッドは、 通常の関数コールに比べて 約 1.267 倍 となる。  以上 ","id":51,"section":"posts","summary":"現在 LuneScript の C 言語へのトランスコンパイル処理を対応中だが、 トランスコンパイルする際に関数ポインタによる関数コールのオーバーヘッドが どの程度なのか","tags":null,"title":"関数ポインタのオーバーヘッド","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-05-19-func-pointer/","year":"2019"},{"content":"  とある事情で使い続けていた emacs23.4 (2012/1) を、 先日 emacs26.2 (2019/4) にアップデートした。  このとき gdb 周りの設定を変更する必要があったので、備忘録としてまとめておく。  *2019-06-12: my-gud-stop, my-gud-mode-func を追加*  *2019-08-26: dedicate の抑制追加*  なお、M-x gud-gdb で起動すれば従来形式のインタフェースが利用できるが、 ブレークポイントが表示されない等の不具合があるので M-x gdb を利用する。  それにしても、新しい M-x gdb のインタフェースは emacs っぽくないと思うんだけど、 オレがおっさんだからそう思うんだろうか？ emacs の gdb 設定  ;; gud-overlay-arrow-position が nil だとエラーするので。。 (setq gud-tooltip-display \u0026#39;((and gud-overlay-arrow-position (eq (tooltip-event-buffer gud-tooltip-event) (marker-buffer gud-overlay-arrow-position))))) ;; gdb バッファの C-c C-c で、プログラムを停止させる。 (setq gdb-gud-control-all-threads nil) ;; input/output バッファが勝手に表示されるのはウザいので、抑制 (setq gdb-display-io-nopopup t) ;; input/output バッファが dedicate されるのはウザいので、抑制 (defadvice gdb-display-buffer (around gdb-display-buffer) (let (window) (setq window ad-do-it) (set-window-dedicated-p window nil) window )) (ad-activate \u0026#39;gdb-display-buffer) ;; gdb バッファの C-c C-c ではプログラムが停止しなかったので、修正 (defun my-gud-stop () (interactive) (comint-interrupt-subjob) (gud-stop-subjob) ) ;; 上記 my-gud-stop 関数を C-cC-c に登録する関数 (defun my-gud-mode-func () (define-key (current-local-map) \u0026#34;\\C-c\\C-c\u0026#34; \u0026#39;my-gud-stop) ) ;; フックに登録 (add-hook \u0026#39;gud-mode-hook \u0026#39;my-gud-mode-func)   以降で、上記の設定について説明する。 gud-tooltip-display   1 つ目は、単純に gud.el の不具合のような気がするが、 tooltip を表示する処理を修正している。  gud-tooltip-display は、 gud で tooltip を表示する処理のようだが、 この処理で (make-buffer gud-overlay-arrow-position) を実行している。  この処理は、 gud-overlay-arrow-position が nil の時にも実行されるケースがあるようで、 その時にエラーにならないように and を追加している。 gdb-gud-control-all-threads   gdb-gud-control-all-threads は、 gud の制御を全スレッドに対して反映させるかどうかのフラグで、 emacs 23 ではデフォルト nil だった。  新しい gdb では、 gdb-gud-control-all-threads がデフォルト t になっている。  gdb-gud-control-all-threads が t だと、 どうにもこうにも意図したデバッグ制御にならなかったので nil とした。  なお、 C-c C-c でデバッグ対象プログラムを停止できるが、正常に動作しない場合がある。  その場合 M-x gud-stop-subjob してから C-c C-c すると、停止する。 gdb-display-io-nopopup   emacs23.4 の gdb は、 デバッグ対象プログラムの stdin/out と gdb の制御コマンドを、 一つのバッファで管理していた。  しかし、 新しい gdb は stdin/out と、gdb の制御コマンドを別々のバッファで管理している。  gdb-display-io-nopopup は、 stdin/out に変化があった際のポップアップ制御を抑制するかどうかのフラグ。  デフォルトだと t だが、 これだとソース編集中やステップ実行中に、 stdin/out のバッファが突然表示されてウザいので nil とした。  なお、gdb-display-io-nopopup を t とすると、 M-x gdb 実行時にも stdin/out のバッファが表示されないため、 stdin/out にアクセスする場合は 自分で C-x b 等で切り替える必要がある。  ちなみに stdin/out バッファの名前は *input/output of ...* 。 ここで … には、デバッグ対象のファイル名が入る。 my-gud-stop   emacs23.4 だと C-cC-c でプログラムを停止して (gdb) プロンプトが表示されたのだが、 emacs26.2 だと C-cC-c でプログラムを停止できない。  そこで、プログラムを停止する関数を作成している。 my-gud-mode-func   上記関数を C-cC-c に登録するための関数。  gud-mode 時にキーバインドを登録するように gud-mode-hook に追加。 dedicate   普通に使うと、 gud の input/output バッファの window が dedicate される。  dedicate されると、 C-x b などでバッファを切り替えられなくなる。  個人的にこれは使い勝手が悪いので、 dedicate されないように gdb-display-buffer の処理をかえる。  以上。 ","id":52,"section":"posts","summary":"とある事情で使い続けていた emacs23.4 (2012/1) を、 先日 emacs26.2 (2019/4) にアップデートした。 このとき gdb 周りの設定を変更する必要があったので、備忘録としてまとめておく。 *2019-06-12: my-gud-stop,","tags":["emacs"],"title":"emacs 更新に伴なう gdb の設定","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-05-13-emacs26-gdb/","year":"2019"},{"content":"  たまたま見つけたブログの記事で気になったものがあったので、 自分の意見を書いておきます。 気になったブログの記事   「エンジニア就職志望者が情報工学科に行くのは間違いです！学べることが違います！」  \u0026lt;https://www.torikun.com/entry/engineer-jouhoukougaku\u0026gt;  この記事を要約すると、    大学の情報工学科のプログラミング単位取得だけでは 学習時間が足りないのでプログラミングスキルを上げるのは難しい。    スキルを上げるにはプログラミングスクールがオススメ    というモノです。  まぁ確かに、 大学の講義・実習だけで十分なプログラミングスキルを身に付けるのは不可能であるのは事実です。  とはいえ、『エンジニア就職志望者が情報工学科に行くのは間違い』というのは、 流石に異論があります。  ブログの著者と自分とで異なる意見になる理由を考えると、  【「エンジニア」という言葉の定義が違う】  から、だと思います。 「エンジニア」とは   上記の記事では、エンジニアには次の能力が必要だとしています。    プログラミングスキル    コミュニケーション能力    マネジメント能力    これらは確かに重要です。  というか、「コミュニケーション能力」や「マネジメント能力」は、 エンジニアでなくても社会で働くには必要な能力です。  つまりこの著者は、  【「エンジニア」に特化して必要な能力は「プログラミングスキル」だけ】  と主張しているように読めます。  これは、私の考えと完全に異なります。  まず、私が考える「エンジニア」像を説明します。  エンジニアとは、曖昧なゴールイメージを技術によってスマートな形で実現できる能力を持つ人。  例えば「家を建てる」というゴールイメージがあるとします。  家を建てることは情報系の「エンジニア」の仕事ではないと思いますが、 あくまで例として考えてください。  この場合、次のような様々なことを決定し、設計書を作成して建築する必要があります。    建てる場所    予算    広さ    デザイン    機能性    耐久性    拡張性    メンテナンス性    建材    日程    etc…    このように、 曖昧なゴールイメージを実現するために具体的な作業項目に分解し、 分解された作業の課題を洗い出し、 課題を解決し、 イメージを具現化する技術を持つのが、私が考える「エンジニア」です。  もちろん、現実には一人のエンジニアが全てを担当できる訳ではありません。  しかし、ブログの著者のような「エンジニア ＝ プログラミングスキルのある人 」では、 絶対にありません。  またブログの記事には、次の記載があります。 例えば、大学２年生の時にはフーリエ変換という数学の公式を習います。 この技術はパソコンの仕組みを突き詰めて行くと重要になってくる有名な数式です。 微分とか積分とかいろいろ難しい公式を覚えて問題を解いていきます。 エンジニアの方ならおわかりかと思いますが、 エンジニアとして仕事をする上でこのフーリエ変換を使う人はぜんぜんいません。   確かに全てのエンジニアが微分・積分を必要とする訳ではないです。 しかし、技術の背景を知っているエンジニアと、 プログラミングしか出来ないプログラマーでは、担当できる範囲が全く違ってきます。  たとえばディープラーニングなどの技術は、 プログラミングしか出来ないプログラマーでは 絶対 に作り出すことは出来ません。 様々な知識を持つエンジニアが集結してこそ可能なものです。  もちろん大学の講義レベルの知識だけで、すぐに何かが実現出来るということはありません。 しかし、大学の講義はさまざまな技術の基礎そのものであり、 その基礎を身に付けているかどうかで、その後の応用が出来るかどうかの違いに繋がってきます。  特に基礎部分は、体系的に学んだ方がより深い理解につながります。 そして大学の情報工学部の単位は、体系的に学ぶことが出来る構成になっています。  つまり大学の情報工学部は、『「エンジニア」になるためのもっとも早道である』と言えます。 認識が異なる理由   では、ブログの著者は何故「エンジニア ＝ プログラミングスキルのある人」という 認識なのでしょうか？  あくまで私の想像ですが、これは日本のソフトウェア開発業界の特色によるものだと思います。  その特色とは、いわゆる「ゼネコン方式」です。  大手が仕様を決め、実装を外部にアウトソーシングする。  ブログ著者にとって「エンジニア」とはアウトソーシング先であり、 「エンジニアは安い金額で実装さえ出来れば良い」という思考なのではないでしょうか？  日本には、このような思考が蔓延しているため、 エンジニアの待遇は良くならないし、 技術レベルも世界から離される一方なのではないでしょうか？  なお、ブログ著者のプロフィールを見ると、 IBM Tokyo Lab に務めているとあります。 いわゆる大手であるのは間違いないでしょう。 エンジニア就職志望者はどうあるべきか   私の考えは、「エンジニア就職志望者は様々な技術を学ぶべき」です。  「他人が作った仕様を元に、プログラムだけ組んでいれば幸せ」という人は、 ブログ著者が主張するようにプログラミングスクールなりに行けば良いと思います。  ただ、日本のゼネコン方式ソフトウェア開発を請け負う、 いわゆる SIer の給与は発注元の企業よりもかなり低いのが一般的です。 それこそ IBM の半分かそれ以下ではないでしょうか？ そのことは認識しておく必要があります。  なお、エンジニア志望者が行くべきなのは、情報工学科でなくても良いと思います。  というのも、私の「エンジニア」の定義は広いので、 情報工学科では収まりきらないためです。 何を極めたいかによって、何を学ぶべきかは変ってくるでしょう。  一つだけ必須技術を上げるならば、それは 「英語」 です。  今後の「エンジニア」業界で、 日本が世界をリードすることは極一部を除いて無いでしょう。  つまり、新しい技術は海外から導入することになります。 その時、その技術の解説は英語であるのが一般的です。  英語が出来れば、いち早く技術の導入が可能になります。  まぁ、これは今に始まったことではなく、 それこそコンピュータサイエンスという言葉が一般化したころから英語が標準でした。  ただ平成の時代は、    今よりは技術の進歩が激しくなく、日本語の翻訳を待っていてもまだどうにかなっていた    国内で働いているだけなら、外国人を相手にする機会がほとんどなかった    などの理由から「英語は出来た方が良い」というレベルでした。  しかし現在は、    技術の進歩が激しく、日本語の翻訳を待っていたら周回遅れどころか浦島太郎になる    ある程度新しい技術を取り入れる場合、国内の日本人だけで開発するのが難しくなった    などで、まともな「エンジニア」として働くには、英語はなくてはならない状況です。  もしもあなたがエンジニアを志す学生で、英語を苦手としているのならば、 留年してでも英語は習得しておくべきです。  世界と戦う意思のあるまともな日本の企業でエンジニアとして働くのであれば、 入社資格として英語のレベルを問われるでしょう。  逆に英語のレベルを不問とするような会社は、 世界と戦うことを諦めているか、 あなたを安く使える労働力と捉えているかのどちらかの可能性が高いです。  また、英語がまともに出来れば外資系や海外で働くことも選択肢になります。  英語習得のために大学を 1 年留年したとしても、 その後のエンジニア人生を考えれば充分おつりがくるでしょう。  英語が出来ない私だからこそ、 英語が出来ない現状がどれほどマズいことかを、 この歳になって身をもって感じています。  私はこれまで何度も英語の学習に挑戦と挫折を繰り返してきましたが、 今の状況なって本当にマズいことを実感し、 ラストチャンスとして人生で何度目かのトライをしています。  皆さんは、私のような思いをしないで済むように、英語だけは身につけてください。  もしかしたら、英語よりも中国語の方が良いかもしれませんが、 それはまだ何ともいえない状況です。 ","id":53,"section":"posts","summary":"たまたま見つけたブログの記事で気になったものがあったので、 自分の意見を書いておきます。 気になったブログの記事 「エンジニア就職志望者が情報工学","tags":null,"title":"『エンジニア就職志望者が情報工学科に行くのは間違い』は間違い","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-04-18-engineer/","year":"2019"},{"content":"  外出先の暇な時間を有効利用するため、ドキュメント書きをしたくなることがあります。  そして私は emacs ユーザ。  emacs ユーザが書きモノをするといえば、 emacs/org-mode です。  ここでは、 Android で emacs/org-mode を使って qiita に投稿するまでの環境作りを紹介します。  ノート PC を持っている人は、普通にノート PC を持っていけば良いと思います。 用意するもの     タブレット    Bluetooth キーボード    タブレット用スタンド   環境構築  Android アプリ   まずは Android に次のアプリを入れます。    termux    ハードウェアキーボード配列変更アプリ (英語 or 日本語)    Hacker\u0026#39;s Keyboard    全て Root なしに Google Play で入れられます。  配列変更アプリは US 配列と JIS 配列でアプリが分かれているので、 好きな方を入れてください。 入れた後に、 Android の設定でハードウェアキーレイアウトを 「Ctrl、Caps 交換」に切り替えます。 なお、 Caps/Ctrl の入れ替えが不要な場合は、配列変更アプリを入れなくて良いです。  Hacker\u0026#39;s Keyboard は必須ではないですが、 他の IME では、ハードウェアキーボードと想定外の干渉をすることがあります。 termux 設定     ピンチイン、アウトでフォントサイズを変更    次のパッケージを termux にインストール    emacs    curl    git     emacs 設定  ~/.emacs/init.el 設定   次の内容の ~/.emacs/init.el を作成 (package-initialize) (add-to-list \u0026#39;package-archives \u0026#39;(\u0026#34;melpa\u0026#34; . \u0026#34;https://melpa.org/packages/\u0026#34;))  パッケージインストール   M-x package-list-packages で、次のパッケージを emacs にインストール    ox-qm    ddskk    helm    session    helm/session は必須じゃないけど、入れておいて損はない。 org-qiita.el インストール  $ git clone https://github.com/ifritJP/org-qiita-el   設定等の話は次を参考に。  \u0026lt;https://qiita.com/dwarfJP/items/594a8d4b0ac6d248d1e4\u0026gt; パッケージ設定  (show-paren-mode) (add-to-list \u0026#39;load-path (expand-file-name \u0026#34;~/work/org-qiita-el\u0026#34;)) (require \u0026#39;ox-qmd) (require \u0026#39;org-qiita) (setq org-qiita-token \u0026#34;XXXXXXXXXXXXXXXXXXXXXXXXX\u0026#34;) \u0026lt;---- qiita のトークン (org-qiita.el の説明参考) (setq org-qiita-export-kill-close t) (setq my-key-map (make-keymap)) (define-key global-map (kbd \u0026#34;C-z\u0026#34;) my-key-map) (define-key my-key-map (kbd \u0026#34;SPC\u0026#34;) \u0026#39;set-mark-command) (define-key my-key-map (kbd \u0026#34;i\u0026#34;) \u0026#39;helm-imenu) (define-key global-map (kbd \u0026#34;C-x b\u0026#34;) \u0026#39;helm-mini) (require \u0026#39;helm) (require \u0026#39;session) (require \u0026#39;recentf)   Android は Ctrl-SPC が、「キーボードレイアウト切替」になっています。  このため、 Ctrl-SPC がシステムに奪われて set-mark-command が動作しません。  暫定対応として、 C-z SPC に set-mark-command を割り当てました。 使い勝手はイマイチですが、意識してやればなんとか使えるレベルです。 最後に   簡単なドキュメント書きなら、これで十分です。  ノート PC と比べても、遜色ないレベルです。  とはいえ欠点もあります。    タブレットでの Web 検索がやり難い    タブレットは org-mode 専用で、検索は別途スマホでやる方が良いと思います。    ただ、検索結果をコピペするような場合は、タブレットでやった方が良いです。      C-SPC が使えない。    これは android の制約で、しかたがない？      次回は、外出先でのソフト開発に耐えられる環境について書きたいと思います。 ","id":54,"section":"posts","summary":"外出先の暇な時間を有効利用するため、ドキュメント書きをしたくなることがあります。 そして私は emacs ユーザ。 emacs ユーザが書きモノをするといえば、 emacs/org-mode です","tags":null,"title":"Android で emacs/org-mode/qiita 投稿","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-03-23-termux-org/","year":"2019"},{"content":" forkwell の github 分析結果が面白かったので貼っておく。  ","id":55,"section":"posts","summary":"forkwell の github 分析結果が面白かったので貼っておく。","tags":["lua"],"title":"この度 Lua 神を拝命しました","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-03-16-lua/","year":"2019"},{"content":"  Outlook は当初から評判が良くないため個人的には使用していません。 もうず〜〜〜〜〜と、 PC のメール環境は Mew を使用しています。  しかし、自分のメール送信・受信環境は好きなものを選べますが、 相手のメール送信・受信環境は選べません。  そしてつい先日も、 Outlook から送信されたメールで文字化けメールを受信しました。  どうして化けたのか気になったので、調べてみました。    メールの MIME に示されているコードは \u0026#34;gb2312\u0026#34; となっている    同じメールを Outlook で受信している人に聞いてみると、文字化けしていないと言う    emacs のコード変換で化けたのか？と思い、 メールを保存してブラウザの表示言語を簡体字中国語設定で表示してみると文字化けしなかった。    この時のブラウザのテキストエンコーディングを見てみると \u0026#34;GBK\u0026#34; だった      emacs で利用可能な文字コードを見てみると \u0026#34;gb2312\u0026#34; と \u0026#34;GBK\u0026#34; は別ものとして存在している。    試しに文字化けしたメールを、 emacs の \u0026#34;GBK\u0026#34; を指定して開くと文字化けしなかった    Wikipedia を見ると \u0026#34;GBK\u0026#34; は \u0026#34;gb2312\u0026#34; を拡張したものということが分った    また、 Microsoft が GBK を Windows コードページ 936 として定義した、との記載がある。      MS も Outlook で送信すると文字コード判定が間違えることを認識している    次の URL に記載されている「方法3」が、まさにそれの対処方法    \u0026lt;https://support.microsoft.com/ja-jp/help/881816\u0026gt;      以上のことから、次の事が考えられます。    Outlook で所定の文字を含むメールを送信する際、 Outlook の自動文字コード判定によって WCP936 として認識される。    WCP936 は本来 GBK であるが、メールの MIME には charset=\u0026#34;gb2312\u0026#34; として宣言される    メールを受信した Mew は、 MIME の情報を見て gb2312 として処理するが、 実際のメールは gb2312 ではなく GBK でエンコーディングされているため、文字化けする。   Mew での対応   Outlook のダメさ加減を嘆いてもしようがないので、 ここでは Mew で受信した時に化けずに表示できる対応をします。  対応コードは以下です。 (defun my-mew-change-gb2312-for-outlook () \u0026#34;outlook 対応。 Outlook の gb2312 は gbk になっている。。。\u0026#34; (setq mew-cs-database-for-decoding (mapcar (lambda (X) (if (equal (car X) \u0026#34;gb2312\u0026#34;) (list (car X) \u0026#39;gbk) X)) mew-cs-database-for-decoding))) (eval-after-load \u0026#34;mew\u0026#34; \u0026#39;(my-mew-change-gb2312-for-outlook))   以下で上記処理の説明をします。  Mew は MIME の charset と、 emacs の coding-system の紐付けを mew-cs-database-for-decoding で管理しています。  こんな感じ。 (defvar mew-cs-database-for-decoding `((\u0026#34;us-ascii\u0026#34; nil) (\u0026#34;iso-8859-1\u0026#34; iso-8859-1) (\u0026#34;iso-8859-2\u0026#34; iso-8859-2) (\u0026#34;iso-8859-3\u0026#34; iso-8859-3) (\u0026#34;iso-8859-4\u0026#34; iso-8859-4) (\u0026#34;iso-8859-5\u0026#34; iso-8859-5) (\u0026#34;iso-8859-6\u0026#34; iso-8859-6) (\u0026#34;iso-8859-7\u0026#34; iso-8859-7) (\u0026#34;iso-8859-8\u0026#34; iso-8859-8) (\u0026#34;iso-8859-8-i\u0026#34; iso-8859-8) ;; temporary solution (\u0026#34;iso-8859-9\u0026#34; iso-8859-9) (\u0026#34;iso-8859-15\u0026#34; iso-8859-15) (\u0026#34;iso-2022-cn\u0026#34; iso-2022-cn) (\u0026#34;iso-2022-cn-ext\u0026#34; iso-2022-cn-ext) (\u0026#34;gbk\u0026#34; gbk) (\u0026#34;gb2312\u0026#34; cn-gb-2312) ;; should be before cn-gb (\u0026#34;cn-gb\u0026#34; cn-gb-2312)   この設定では、 MIME の gb2312 を cn-gb-2312 に紐付けしているので、 gb2312 を gbk の紐付けに変更しているのが先ほどのコードとなります。  中国語圏とメールのやり取りしたときに何か問題がおこるかもですが、 自分にはそんな予定はないのでとりあえずこれで十分かな、と。 ","id":56,"section":"posts","summary":"Outlook は当初から評判が良くないため個人的には使用していません。 もうず〜〜〜〜〜と、 PC のメール環境は Mew を使用しています。 しかし、自分のメール送信・","tags":["mew","outlook"],"title":"Outlook で送信された日本語メールを Mew で受信すると文字化けする問題の対応","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-02-07-outlook/","year":"2019"},{"content":" ここ十年ほどまともにゲームしてないけど、 ネット検索しているときになんとなく気になった記事を読んでみたら、 ものスゴく面白かった。  古めの記事だけど、載っけておく。    格ゲー“暗黒の10年”は、『鉄拳』を世界一売れる格闘ゲームへと鍛え上げた──世界市場に活路を拓いた戦略を訊く【バンダイナムコ原田勝弘インタビュー／西田宗千佳連載】    http://news.denfaminicogamer.jp/interview/180428    「久夛良木が面白かったからやってただけ」 プレイステーションの立役者に訊くその誕生秘話【丸山茂雄×川上量生】    http://news.denfaminicogamer.jp/interview/ps_history ","id":57,"section":"posts","summary":"ここ十年ほどまともにゲームしてないけど、 ネット検索しているときになんとなく気になった記事を読んでみたら、 ものスゴく面白かった。 古めの記事だけ","tags":["etc"],"title":"電ファミニコゲーマー","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-02-03-interview/","year":"2019"},{"content":" 先日のデフォルト引数の指定し忘れ問題の対応を行なった。  詳しくは、次の記事を参照。  \u0026lt;https://qiita.com/dwarfJP/items/922c523d27a6d77fff6d\u0026gt; ","id":58,"section":"posts","summary":"先日のデフォルト引数の指定し忘れ問題の対応を行なった。 詳しくは、次の記事を参照。 \u0026lt;https://qiita.com/dwarfJP/items/922c523d27a6d77fff6d\u0026gt;","tags":["proglang"],"title":"デフォルト引数の問題の対応","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-01-27-default-arg/","year":"2019"},{"content":" 関数をコールする際、引数を省略してコールできる機能をもつ言語が多く存在する。  ここでは、その機能を「デフォルト引数」と呼ぶ。  デフォルト引数の例として、Lua のサンプルを次に示す。 local function func( x, y ) print( x, y ) end func( \u0026#34;abc\u0026#34; ) // abc nil   Lua では関数コール時に省略された引数は、 nil として処理される。 上記の func( \u0026#34;abc\u0026#34; ) は、引数 x, y のうち y が省略され、 実行すると abc nil が表示される。  デフォルト引数は、引数が多い関数を呼び出す際に有効な機能である。 特に Lua は、引数の違いによって実行する関数を切り替える関数オーバーロードがないため、 デフォルト引数は良く使われる機能の一つである。  しかし、デフォルト引数は便利である一方、不具合を発生させるリスクにもなる。  そのリスクとは、意図してデフォルト引数を使用しているのか、 それとも、本来指定すべき引数を指定し忘れているのか、を判断出来ないということである。 タイプミス等で関数に渡す引数を間違えることが良くある。 それを判断できないというのはリスクが高い。  Lua の トランスコンパイラである LuneScript でも、同じ問題を抱えている。  次は LuneScript のデフォルト引数のサンプルである。 fn func( val: int! ): int { when! val { return val + 1; } return 0; } print( func( 1 ) ); // 2 print( func( nil ) ); // 0 print( func() ); // 0   このサンプルは、デフォルト引数を持つ func() の関数呼び出しを 3 パターン行なっている。    func( 1 )    func( nil )    func()    LuneScript は Lua と同じで、引数が省略されると nil が指定される。 よって、 func( nil ) と func() は同義である。 しかし、 func() が引数の指定忘れではないと、誰が保証できるだろうか？  また、 LuneScript では nilable は必ず省略可能なデフォルト引数になってしまう。  デフォルト引数をサポートする多くの言語では、 デフォルト引数はデフォルト値を定義する必要がある。 一方 LuneScript では、nilable は必ずデフォルト引数になってしまう。  「nil の時でも省略せずに明示すべき」としたくても、 現在の言語仕様ではそれが出来ない。  この辺りを解決する方法を検討している。  ただこれを解決するには、現状の言語仕様との互換を持たせるのは難しいかもしれない。 ","id":59,"section":"posts","summary":"関数をコールする際、引数を省略してコールできる機能をもつ言語が多く存在する。 ここでは、その機能を「デフォルト引数」と呼ぶ。 デフォルト引数の例","tags":["proglang"],"title":"デフォルト引数の問題","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-01-23-default-arg/","year":"2019"},{"content":"  blog を始めるにあたって、 emacs から出来るだけ簡単に記事を更新できる環境にするために、 次の URL の情報をもとにいくつか調査。  \u0026lt;https://orgmode.org/worg/org-blog-wiki.html\u0026gt;  とりあえず org-mode + jekyll で構築してみた。  以下は、org-mode + jekyll で環境構築から記事を投稿するまでの流れをまとめたメモ。 使用するソフト     ruby    gem    bundler    jekyll    jekyll-org      jekyll は、 markdown でサイトを構築可能なツール。 markdown は書き慣れていないので org-mode で記事を書けるように jekyll plugin の jekyll-org を使用する。 setup     install ruby    install ruby-dev    install gem   $ gem install bundler jekyll jekyll-org  jekyll setup     blog のプロジェクトディレクトリ作成   $ cd blog_top $ jekyll new blog   初回は、ここで必要な gem がインストールされる。  blog ディレクトリが生成され、blog ディレクトリ以下に幾つかのファイルが作成される。    _config.yml を編集    次の項目を編集    title:    email:    description:    twitter_username:    github_username:      plugins の項目に jekyll-org を追加     plugins:- jekyll-org  jekyll-org の設定   \u0026lt;https://github.com/eggcaker/jekyll-org\u0026gt;  Gemfile に次を追加 # jekyll-org gem \u0026#39;jekyll-org\u0026#39;, \u0026#39;\u0026gt;= 1.0.2\u0026#39;   Gemfile 編集後、次のコマンドを実行 $ bundle install  github pages 用の設定   github pages の /blog に jekyll のディレクトリを作成した場合の設定    _config.yml を編集    次の項目を設定    baseurl: \u0026#34;/blog/site\u0026#34;    url: \u0026#34;https://XXXXXXXX.github.io\u0026#34;    destination: site        jekyll の変換後の html は _site 以下に出力されるが、 github pages は _site 以下にはアクセスできないようなので、 destination: site で出力先を site に変更する。 記事作成   _posts/ 以下に、次の名前のファイルを作成する YYYY-MM-DD-title.org   例えば 2019-01-01-hoge.org とする。  title は、記事のタイトルで無くてもよい。 title は、 記事の URL に使用される。  _posts/ の下にサブディレクトリを掘って、その中にファイルを作成しても良い。 記事のフォーマット   次のメタ情報を入れれば、後は普通の org-mode 通りに記載可能。 #+LAYOUT: post #+TITLE: org-mode で blog #+TAGS: org-mode jekyll   +TAGS はオプション。 ワンポイントネタ     URL を書くだけだとリンクにならない。    リンクにする場合は URL を \u0026lt;\u0026gt; で囲む。     変換   書いた記事は jekyll を使って html に変換する。 $ cd blog $ jekyll b  確認   jekyll は httpd サーバ機能を持つ。 $ cd blog $ jekyll s   この状態でブラウザで http://localhost:4000 にアクセスすれば、 変換後の内容を確認できる。  なお、記事を修正すれば動的に変換されるので、 記事を修正後にブラウザをリロードすれば、修正後の内容を確認できる。  httpd サーバを終了する場合は、 Ctrl-C。 ネットワークアクセス  $ jekyll s   このコマンドで起動した httpd サーバは、 localhost でしかアクセスできない。  つまり PC 外部からアクセス出来ない。  セキュリティという意味では安全であるが、不便だったりする。  PC 外部からアクセスしたい場合は、次のコマンドで httpd サーバを起動する。 $ jekyll s --host 0.0.0.0  ","id":60,"section":"posts","summary":"blog を始めるにあたって、 emacs から出来るだけ簡単に記事を更新できる環境にするために、 次の URL の情報をもとにいくつか調査。 \u0026lt;https://orgmode.org/worg/org-blog-wiki.html\u0026gt; とりあえず org-mode + jekyll で構築して","tags":["org-mode","jekyll"],"title":"org-mode で blog","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-01-17-setup-jekyll/","year":"2019"}],"tags":[{"title":"emacs","uri":"https://ifritjp.github.io/blog2/public/tags/emacs/"},{"title":"etc","uri":"https://ifritjp.github.io/blog2/public/tags/etc/"},{"title":"jekyll","uri":"https://ifritjp.github.io/blog2/public/tags/jekyll/"},{"title":"lua","uri":"https://ifritjp.github.io/blog2/public/tags/lua/"},{"title":"mew","uri":"https://ifritjp.github.io/blog2/public/tags/mew/"},{"title":"org-mode","uri":"https://ifritjp.github.io/blog2/public/tags/org-mode/"},{"title":"outlook","uri":"https://ifritjp.github.io/blog2/public/tags/outlook/"},{"title":"proglang","uri":"https://ifritjp.github.io/blog2/public/tags/proglang/"}]}
{"categories":[],"posts":[{"content":" LuneScript セルフホストビルド時の go スレッドの状態について調べてみました。\nグラフの説明 次の図は、 go ランタイムのトレース機能(GODEBUG=schedtrace=5)を使って取得した go のスレッドスケジューリング情報と、 セルフホストビルドのモジュールの Meta 情報解析進捗状態を示したグラフです。\nそれぞれの値は次の通りです。\nready meta\nセルフホストビルドにおける Meta 情報解析が終了したモジュール数 threads\ngo のスレッド数 active threads\ngo のスレッドの内、待ちがなく実行中のスレッド数 runqueue\nスレッドが空くのを待つ go-routine 数 X 軸は時間を示し、それぞれの値の時間ごとの推移を表します。\nready meta(セルフホストビルドにおける Meta 情報解析が終了したモジュール数) ready meta は、Meta 情報解析が終了したセルフホストのモジュール数なので、 時間経過するごとに増加していきます。\nモジュール毎に規模が異なり、それによって処理にかかる時間も異なります。\nグラフの角度が低く横に長いところが、 Meta 情報解析処理に多くの時間が掛っているモジュールの処理であることが分かります。\nなお、Meta 情報解析終了後は .lns から .lua 等への言語変換処理を実行しますが、 今回の図には入れていません。\nready meta の処理が終了した後も threads 等の処理が続いているのは、 言語変換処理が続いているためです。\nthreads (go のスレッド数) threads を見ると、起動してからすぐにスレッド数が増加し、 一定値まで増えたところで変化しなくなります。\nLuneScript は、ビルド対象として与えられたパスの .lns ファイルを処理する 非同期処理を立ち上げます。 セルフホストの場合、全 .lns ファイルパスをビルド対象として与えるので、 起動時に一気に非同期処理が増えます。\nactive threads (go のスレッドの内、待ちがなく実行中のスレッド数) active threads はかなり増減していることが分かります。 ビルド中に出来るだけ全てのスレッドを使い切ることが理想ですが、 残念ならがそうはなっていません。\n理由は単純で、 LuneScript を構成する複数のモジュールには依存関係があり、 依存先のモジュールの Meta 情報解析が終らないと、 依存しているモジュールの解析を進められないためです。\nready meta のグラフの角度が低く横に長いところと、 active threads のグラフの値が低く落ちているところが一致していることが分かります。\nこれは、 あるモジュール A の Meta 情報解析処理に時間がかかると、 そのモジュール A に依存している他のモジュール B の処理が モジュール A の Meta 情報待ちになって処理が停止し、 モジュール A の Meta 情報解析処理が終るまではその処理だけが動くことになるためです。\nrunqueue (スレッドが空くのを待つ go-routine 数) 起動された go routine は、 実際にスレッドに割り付けられて実行される前にキューに入ります。 runqueue の値は、そのキューに入っている go routine 数を表わします。\nグラフを見ると、わずかに runqueue に変化があることが分かりますが、 active threads が低い時であれば、 次の瞬間にはキューに入っている go routine は、 空いているスレッドに割り当てられて実行されるので問題ありません。\nしかし、active threads が上限になっている場合、 どこかのスレッドが空きになるまで runqueue の go routine は待ちになるため、 そこでパフォーマンスが落ちることになります。\nグラフの後半を見ると、待ちになっていると思われる runqueue を僅かに確認できます。\nつまり、その瞬間は CPU のコア数が足りていない、と言えます。\nさらには、 コア数の多い CPU を使うことで、改善できることを示唆しています。\nただし、改善できたとしても非常に僅かだということも、グラフを見ると分かります。\nまとめ モジュールの依存関係がビルド時間に影響することは、 わざわざこのグラフを見なくても論理的に分っていたことではありました。\nでは何故今回このグラフを生成したかというと、以下を確認するためです。\n自分の想定した通りに go routine がアクティブになっているのかどうか？ アクティブになった go routine が、直ぐにスレッドに割り当てられているのかどうか？ これは、 active threads と runqueue の関係について見ると分かります。\nそしてそれらは、ほぼ想定通りだということが分かりました。\n少なくとも、 コア数が影響して実行待ちになっている go routine はほとんどない ので、 それが影響してパフォーマンスが悪くなっている、 ということはない ことが分かりました。\nただ、そもそも今の LuneScript の非同期処理数は、 現状の環境(コア数)に合せて調整してあるので、ある意味で辺り前の結果かもしれません。\n現状とは異なる環境で動かした場合、次のことが考えられます。\nいまよりもコア数の少ない環境で実行したら、 空き待ちになる go routine 数は増えるかもしれない いまよりもコア数の多い環境で非同期処理数を上げて実行したら、 もっと効率よく実行できるかもしれない ","id":0,"section":"posts","summary":"LuneScript セルフホストビルド時の go スレッドの状態について調べてみました。 グラフの説明 次の図は、 go ランタイムのトレース機能(GODEBUG=sched","tags":null,"title":"LuneScript セルフホストビルド時の go スレッド状態","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-11-03-lunescript-selfhost-thread/","year":"2023"},{"content":" LuneScript のソースコード規模まとめをやったのが、3年前の 2020/10/1。\n../../2020/2020-10-01-lunescript-codesize/\n3年経ったのでそろそろ振り返りをやっても良い頃だろう、ということで、 今回はソースコード規模とついでにビルド時間の推移についてのネタ。\nソースコード規模とビルド時間の推移 以下は、 2020/11/8 から現在までのソースコード規模とビルド時間の推移を示す図である。\nこのグラフは、以下の 4 つの値の推移を表わしている。\nセルフホストビルドの実時間\n.lns から .lua, .go へのトランスコンパイルに掛った実時間。 セルフホストビルドのユーザCPU時間\n.lns から .lua, .go へのトランスコンパイルに掛ったユーザCPU時間。 トランスコンパイルによって、CPU をどれだけ使ったかを示す。 LuneScript のビルドは並列処理をしている分、実時間よりも多くユーザ CPU 時間が掛る。 LuneScript の .lns のソースコードライン数\nコメント行も含むソースコードの行数 セルフホストビルドにおいて、1秒間に処理した行数\nソースコードライン数 / 実時間 の値 図の左の Y 軸が時間を示し、図の右の Y 軸が行数を示している。\nなお、ビルド時間に関しては、かなりの誤差を含んでいる。 複数回実行して平均を取っているが、実行時間が 1 秒前後でしかないので、 100msec の誤差が入っても 10% 違うことになる。\nもっと規模の大きいプロジェクトで計測できれば良いのだが、 残念ながら LuneScript のプロジェクトで一番大きい規模は LuneScript 自身であり、 これ以上の大きい規模のものはないため、これは割り切るしかない。\nよって、ビルド時間に関しては、だいたいの傾向を見ていく。\nまた、3年前のソースコード規模のグラフと比べると、 だいぶゴチャついていて分かり難いと思うが、 それぞれの値について以降で説明していく。\nセルフホストビルドの実時間 まず、セルフホストビルドの実時間から見ていく。 2020/11 と現在を比べると約 1/4 に短縮できているのが分かる。\n特に 2021/5 から 2021/7 にかけて短期間に短縮している。 逆に言えば、それ以降はほとんど変っていないとも言える。\n2021/7 以降も改善は続けているが、思った程の効果が出ていないのが良く分かる。\nLuneScript の .lns のソースコードライン数 ソースコードライン数の推移は特徴的な変化点(2021/5 辺りと 2022/8 辺り)が 2 つある。\nこれは何かというと、次の通り。\n2021/5\n実験的に作っていた C 言語へのトランスコンパイル用ソースを削除 2022/8\n実験的に python へのトランスコンパイル用ソースを追加 ソースコードの削除でコード量が減り、ソースコードの追加でコード量が増えている。\nそれ以外は、不具合修正や機能追加などで微増している。\n大規模な設計変更をしない限りは、今後も微増が続いていくだろう。\nセルフホストビルドのユーザCPU時間 ユーザ時間は、ほぼ LuneScript のソースコードライン数に比例して推移している。 セルフホストは、LuneScript のソースコードを全て読み込み、 解析し、別の言語への変換を行なうので、ソースコードの行数が増えれば それを処理しているユーザCPU時間が増えるのは当然の結果と言えるだろう。\nここで注目してもらいたいのは、 ユーザCPU時間が増えても実時間はほとんど変化が無い、ということ。\nそれだけ頑張って並列化して、実時間に影響が出ないようにしている。\nセルフホストビルドにおいて、1秒間に処理した行数 最後がセルフホストビルドにおいて、1秒間に処理した行数。\n実時間だけ見ていると、 2021/7 以降ほとんど全く改善されていないように見えるが、 この値の推移を見ると分かるにように、僅かではあるが改善している。\n実時間に表われ難いのは、それらが細かい改善で、 その改善のために追加したコード量と、 それによって改善された処理時間がほとんど同じになってしまっているからである。\nだた、これはセルフホストビルドの結果だからであって、 他のプロジェクトであれば、普通にビルド時間が短縮されているはずだ。\nそのための指標が、この値である。\nこの値は、単位時間でどの程度処理したか？を表わすので、 同じプロジェクトに対して、 LuneScript のバージョンを変えてビルドしたら、 どの程度処理できるか、をこのグラフから推測できる。\n2020/11 から現在までで、5倍強の量を処理できるようになっている。\nなお、この値はビルド対象の依存関係に大きく影響を受ける。 最悪なケースは、巨大な 1 ファイルで構成されて、かつ1つの関数が大きい場合で、 次に悪いのがモジュールの参照構造が片方向リストのように数珠繋ぎになっている場合である。\nまとめ 今回はソースコード規模とビルド時間について振り返りを行なった。\nビルド時間の改善については、 2021/5 から 2021/7 にかけてかなり改善したが、 それ以降は小さな改善に留まっている。\nこれは、改善するためのネタが無い、というのが一番の要因である。\nこれ以上の改善は、根本の設計からの見直しが必要になると思われる。\nここで難しいのが、 根本の設計からの見直しをするとかなり時間がかかることが予想される、ということ。 しかも、それによって確実に改善できるならまだしも、 ほとんど変らない、むしろ悪化することも考えられる。 そうすると、どうしても慎重にならざるをえない。\nそんなこんなで、速度改善に関しては厳しい状態が続いている。 まぁ、これはライフワークみたいなモノだと思って、今後も気長にやっていこうと思う。\n","id":1,"section":"posts","summary":"LuneScript のソースコード規模まとめをやったのが、3年前の 2020/10/1。 ../../2020/2020-10-01-lunescript-codesize/ 3年経ったのでそろそろ振り返りをやっても良い頃だろう、ということで、 今","tags":null,"title":"LuneScript のソースコード規模とビルド時間の推移","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-10-29-lunescript-performance-history/","year":"2023"},{"content":" そろそろ Windows12 が出ると噂されている。 自分の PC 環境は win10 が現役で、 win11 を入れる前にもう win12 なのかと、 なんとも微妙な気持ちがある。\nWindows が普及し始めた時代 ところで、今はデスクトップ PC 向け OS といえば、ほぼ windows 一択の状況である。 もちろん、 Mac 派や Linux 派の方がいるのは分っているが、 一旦ここではそれらを取り上げない。\nそんな windows がここまで勢力を強めたのは、 自分が知る限り win95 あるいは win98 辺りだ。\nそして、今思うと不思議なことだが、何故か PC の家電化が謳われ始め、 多くの家電量販店で PC が扱われ始めたのもこの頃だった。\nOS が GUI ベースの windows になったことで、 それまでの CUI ベースの MS-DOS と比べれば格段に使い易くはなったものの、 今ほどエンタメ系の使い方が出来た訳でもない。 特にこの頃のインターネットは一般的な電話回線を使った従量課金が当たり前で、 通信速度も遅い(スマホで通信制限が掛った状態よりも遅い)し、 Web コンテンツも今と比べれば全く充実していなく、 誰でもメールを送受信できる訳でもないので、 当時の PC を有効に利用できていた家庭は少なかっただろうと思う。\nそもそもこの頃は GAFA がまだない。 いや、実際には Apple は既にあったし、Amazon も創業はしている。 とはいえ、今のような様々なサービスを日本向けに提供するのはだいぶ後の話だ。\nそのような環境なので、当時購入された PC の多くは埃を被っていたのが実情だろう。\nそんな windows が勢力を強めた win95、win98 辺りに、国内の PC 業界に大きな変化が起った。 それは、 PC 規格の事実上の統一である。\nwin95、win98 登場以前は、 今考えると意外かつ様々なメーカーが独自規格の PC を発売していた。\n様々な独自規格で混沌としていた PC 市場が、 win95、win98 の登場によって、PC は「windows を動かせる規格」に統一されていった。 この「windows を動かせる規格」が、いわゆる「PC/AT 互換機」と呼ばれる規格である。\nなお、国産独自規格の NEC の PC-98 シリーズについては、 それまでの国産 PC のトップシェアだった、ということもあり、 NEC が PC-98 シリーズ向けに windows のカスタマイズ版を開発していたが、 それも windows2000 までで終わり、 これによって PC 規格は事実上 PC/AT 互換機に統一された。\nなお、 Mac は一貫して規格統一とは別に進化を続けている。\nPC9801-OS/V さて、ようやくここから本題である。\nNEC の PC-98 シリーズの最後の OS は、 windows2000 のはずである。 しかし、ChatGPT に PC-98 シリーズの OS について聞いてみると、 「最後の OS は PC9801-OS/V だ」と言ってきた。\nてっきり PC-98 シリーズの型番と勘違いしているのか？と思ったが、 OS/V という型番は PC-98 シリーズには存在しない。\nでは、本当に PC9801-OS/V なんていう OS が存在するのか？と調べてみたが、 どうにもネット検索ではヒットしない。\nOS/V に表記が似ていなくもない OS である OS/2 の最終バージョンは、 windows2000 より前に発表なので、 OS/2 と間違えたとしても説明がつかない。\n単に ChatGPT が間違っただけなのか？と思い、 Google Bard にも聞いてみたが、 やはり PC9801-OS/V は存在する OS だという。\nなんとも腑に落ちない。 LLM は学習する情報が少なければ、出力する結果の精度が落ちるのは理解できる。 ただ、学習ソースが違うはずの ChatGPT と Bard で、 こんなローカルな話題について同じ間違い方をする、というのが不思議だ。\nもしかしたら、PC9801-OS/V という OS は本当に存在するのだろうか？ NEC 内部のコードネームや愛称等である場合は調べようがないが、 仮にそうだとしたらそんなローカルな情報は LLM の学習に使えないので、 そもそも PC9801-OS/V という単語を覚えることもないだろう。\n一番可能性があるのは、以下辺りから導き出された、と考えるのが妥当な気がする。\nPC98 シリーズには様々な型番のモデルがある 型番はアルファベット 2 文字のものが多い。 型番は / が付くことがある。 PC/AT 互換機を DOS/V と呼ぶこともある。 PC98 シリーズを語る際は、DOS/V を一緒に取り上げることが多い。 以上のことから、PC98 と DOS/V が強く関連付き、 PC9801-OS/V という謎の OS が生れたのではないだろうか？\n","id":2,"section":"posts","summary":"そろそろ Windows12 が出ると噂されている。 自分の PC 環境は win10 が現役で、 win11 を入れる前にもう win12 なのかと、 なんとも微妙な気持ちがある。 Windows が普及し始めた時代 とこ","tags":null,"title":"PC9801-OS/V という PC9801 シリーズ向けの OS","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-10-23-pc9801-os-v/","year":"2023"},{"content":" 今回のネタは、これまでとちょっと違った毛色のネタである。\nネタの背景 日本人あるあるだと思うが、 これまでほとんど 「お金を運用する」 ということを やってこなかった。\n何となく「運用ってのは金持ちのすること」みたいな感覚があったし、 はっきり言って 「お金のリテラシー」 が低かった。\nなお、「ほとんど」と付けている通り、全く経験がない訳ではない。 実は 10 数年前にデビューしていたりする。 ただ、そのデビューしたタイミングがアレだったのが、運が悪かったと言えるだろう。 デビューがもうすこし遅ければ、 今頃は精神的にも金銭的にも、少しは楽になっていたかもしれない。\n10 数年前と言えばピンと来る人もいると思うが、 具体的にはいわゆる リーマンショック の起きた年だ。 リーマンショックが起きる数ヶ月前に始め、 モロに 「お金の運用の洗礼」 を受けている。\nそんな訳で、リーマンショックで精神的なダメージを受け、 「自分には運用は合わないな」と感じて今に至る。\nまぁ、何だかんだ塩漬けにしまくって、最終的にはプラスになったんだけど、 それでもデビュー時に受けたそのショックは、 運用に対するモチベーションを下げるには十分過ぎた。\nそんな訳でもう何年も運用からは手を引いていたのだが、\n近年の物価上昇による相対的な現金(日本円)の価値の下落 もうそろそろ引退後のことを考え始めないといけない年齢 の合せ技で、「お金の運用」について真面目に考えるようになった。\n最近はネット上でお金の運用に関するそれなりにまともな情報も 入手できるようになってきていて、勉強するには困らない。 もちろん、そういった情報はポジショントークが入っているのは認識している。\n「リーマンショックを経験していること」 は、 そういう意味で役立っていると思う。\n集めた情報で改めて運用の勉強を独学で進めつつ、 今回は銀行、保険屋、FP(ファイナンシャルプランナー) と相談してみた。\nなお、今回いろいろとお金の運用に関する情報を仕入れたが、 まだまだ完全に門外漢なレベルでしかないので、ここでは運用方法に関しては触れない。\nじゃぁ、なんの話をするのか？と言うと、セキュリティの話である。\n念の為に断っておくと、 自分はセキュリティを専攻していないということを前提に、以降を読んで欲しい。 セキュリティには、片足の先っちょを突っこんでいる程度だ。 あくまで単なるブログのネタである。\n何のセキュリティ？ セキュリティと言ってもさまざまだが、 今回は次について考える。\n「お金の運用を相談する相手が、悪意ある第三者でないことがどうやって担保されているか？」\nもう少し具体的に言うと、 今回の運用に関する相談は、実店舗に行って対面で行なったのではなく、 「オンライン相談」 というものを使ってみたのだが、\nその相談相手が本当に相談するべき相手なのか？ オンラインであることを悪用した悪意ある第三者ではないのか？ こちらが想定している相談相手であることをどうやって担保しているのか？ ということを考える。\n○×銀行の場合 今回相談した○×銀行では、公式 HP からオンライン相談を予約できる。\n銀行がオンラインでの振込などが出来る独自のサービスを提供するようになって久しいが、 このオンライン相談はそのサービスのアカウントとは連動せずに、 誰でも予約することが出来るようになっている。\n個人的には、そのアカウントと連動した方がセキュリティ的に良い気がするんだが、 そうすると間口を広げたいという銀行側の意図から外れるから、 あえてしていないのではないかと想像する。\n相談の予約をオンラインですると、以下の手順で担当者とリモートで相談することになる。\n銀行側からメールで予約日時の確認メールが来る 予約日時になると、担当者から電話がくる 担当者から公式 HP にあるオンライン相談の接続番号発行操作を促される 手順に従って発番する 番号を電話の相手に伝える オンラインの Web 会議が繋る オンラインで説明を受ける 次回以降は電話での対話だけで、オンラインは繋がない 電話は 0120 から始まる常に同じ番号、同じ担当から掛ってくる 手順としては以上である。\nうーん、大丈夫なんだろうか？本当にこれでしっかりと担保されているんだろうか？ ちょっと考えてみる。\nここで重要なことは、 「電話の相手が正式な銀行員に間違いないかどうか？」 だ。\n電話が掛ってくるのは 2) である。 この 2) の段階では、まだ相手が正式な銀行員だという保証はない。\n次の 3) では「公式 HP」の発番システムを使っているので、 これ自体は問題ないだろう。\n公式 HP は当然 https であり、その証明書も問題ない。\nなお、ここでは以下については スコープ外とする。\n公式 HP がクラックされて HP が書き換えられている 証明書の認証局がクラックされている うちの PC の CA 証明書、 DNS がクラックされている うちのブラウザがクラックされている これらが否定されると、オンライン自体がもう信用ならないので考えない。\n次に 4) で発番する。これもクラックされていないことが前提であれば問題ない。\n次の 5) で、発番された番号を電話の相手に伝え、 次の 6) で Web 会議が繋がる。\nここで疑問が浮ぶ。\nはたしてこの番号は何なのか？ この番号を相手に伝えて大丈夫なのか？ たとえば、これが単なる電話番号のようなものだとしたら、 それを相手に伝えてしまえば、誰でもこちらと繋ぐことが出来てしまう。 つまり、相手が正式な銀行員である保証はない。\nここが、 このオンライン相談システムの肝だ。\nということで、 5), 6) がどのように実現されているかを考えてみる。\n公式 HP サーバ内に閉じたシステムで実現されている場合 まず最も単純なのが、 このシステムが○×銀行の公式 HP サーバ内に閉じたシステムで実現されている場合だ。\nこれによって、任意の番号に繋ぐ権限を持つ人を ○×銀行内の人間に制限することが出来る。 たとえ第三者がその番号を知っても、その番号で相手に掛けられなければどうにもできない。\nもちろん、 このシステムがそういう制限をしていることが前提 だが、 ここでは当然制限していると考える。 仮に制限していないとしたら、ヤバ過ぎる。。。\n以上のように 3) 〜 6) の手順によって、 相手が○×銀行内の人間であることが担保される。\n実は、このオンライン相談では、通話に関しては Web 会議ではなく常に電話を使う。\n手順の 8) にあるように、次回以降は Web 会議つなげることすらない。\n「Web 会議があるのに電話なのか」と心の中で思ったが、 Web 会議に繋げたのは、 電話を掛けてきた担当者の身元保証に利用している のがメインのようである。\nもちろん「映像を見せながら金融商品について説明する」ことにも利用しているが、 どちらかというと前者の方が重要だろう。\nそれに、毎回 Web 会議に繋げなくても電話だけで相談できる、 というのは顧客にとってもメリットなのだろう。\nまた 9) にあるように、次回以降の電話は同じ電話番号\u0026amp;同じ担当なので、 一度身元の保証できているので、その手順を省いても大丈夫ということだろう。 0120 の番号から電話掛って来ているので、 その電話番号から掛っている限りは、 「いつの間にか担当者が銀行を止めていた」ということもない。\nなお、以上の身元保証のことに関しての説明などは、当然ながら無い。\nWeb 会議システムが公式 HP サーバ外で実現されている場合 実は、この Web 会議システムは公式 HP サーバ内に閉じたシステムではなく、 別の会社が運営しているサービスだったりする。\n具体的には、ベルフェイス株式会社が提供する「bellFace」というシステムだ。\nよって、先程考えたような単純なケースではない。\nじゃぁ、bellFace ってなんやねん。ってことになる。\n\u0026lt;https://bell-face.com/\u0026gt;\nHP を見ると、どうやら主に金融会社向けの電話面談システムを扱うシステムのようだ。\nトップページにメジャーな金融会社のロゴを多く掲げているので、 その業界では実績があるツールなのだろう。\nまぁ、それは置いておいて、問題はセキュリティが担保されるかどうか？だ。\n全般的なセキュリティに関しては、次の URL で確認できる。\n\u0026lt;https://corp.bell-face.com/security/\u0026gt;\nこういうサービスをやっているので、 セキュリティに関する情報を公開するのは当然なのだろう。\nこのページに 「接続元 IP アドレス制限」 がある。\n説明は、以下の通り。\n「bellFaceへ接続するIPアドレスを制限できます。また、制限はご契約単位で設定できます。」\n言っていることは、極普通だ。\nただ、具体的に何をどう制限するかは良く分からない。\n常識的に考えれば 任意の番号に掛けられる端末のIPアドレスを限定する 、 いうことだろう。\nさらに、それだけではなく、 ある金融機関向けに発番された番号に対し、別の金融機関から接続する 、 なんてことも出来ないように制限されているはずだ。\nここで、もう少し具体的に実現方法を想像してみる。\n○×銀行の発番システムへのアクセスは、以下のリンクにアクセスすることになる。\nhttps://user.bell-face.com/client/container/common?\u0026amp;pl=https%3A//user.bell-face.com/client/slide_entry/common\u0026amp;w=AAAA\u0026amp;h=BBB\u0026amp;logo_site_key=aaaaaaaaaa 上記にアクセスすると、Web 会議接続用の発番が出来る。\nそして、その番号を相手に伝えると、 このページを介して相手との Web 会議がつながる。\nなお、 ベルフェイス株式会社の bellFace のサービス案内 HP からも、 この発番システムへアクセスできる。\nその時の URL は以下だ。\nhttps://user.bell-face.com/client/container/common?\u0026amp;pl=https%3A//user.bell-face.com/client/slide_entry/common\u0026amp;w=BBBB\u0026amp;h=CCCCC この 2 つの URL を見ると分かる通り、以下のクエリーが異なるだけだ。\nw h logo_site_key このクエリーによって、契約を切り替えているということなんだろう。\nセキィリティにはあまり関係ないが、 このシステムで発番すると金融機関のロゴが表示される。 logo_site_key パラメータはその名前から想像するに、 表示する金融機関のロゴを指定する ID だと思われる。\n○×銀行のまとめ いくつか運用面で条件はあるが、 それらはセキュリティを考える上で実施しないとヤバいレベルの内容なので 実施しているだろう。 ということで、セキュリティは担保されている」という判断である。\nなお、 「どうして Web 会議を使わずに電話を使うのか？」に対し、 電話だけで相談できる方が顧客のメリットになる、という話をしたが、 ○×銀行側の bell-face への課金を減らす意味もあるのかなぁ？と思ったりもする。\nただし、bell-face の料金設定が分からないので、あくまで想像でしかない。\n追記\n発信者の電話番号についてだが、 発信者IDスプーフィングによって発信者の電話番号を偽装することが可能らしい。\nこの「発信者IDスプーフィング」のハードルがどの程度のものかは不明である。 ただ、少なくとも誰でも出来るレベルのものではない、ということらしいので、 ここでは一旦スコープ外とする。\nなお、発信者IDスプーフィングで発信者の電話番号偽装が出来てしまうと、 以下については全く保証が出来ない ということになる。\nまた 9) にあるように、次回以降の電話は同じ電話番号\u0026amp;同じ担当なので、 一度身元の保証できているので、その手順を省いても大丈夫ということだろう。 0120 の番号から電話掛って来ているので、 その電話番号から掛っている限りは、 「いつの間にか担当者が銀行を止めていた」ということもない。 身元を保証するには、毎度 4) からやり直す必要がある。\n△○保険の場合 次に△○保険の場合だが、これは銀行のケースと比べて単純だ。\n具体的な手順は以下。\n保険屋からメールで web 会議システムへの URL が通知される URL にアクセスして web 会議システムに接続する この web 会議システム内で担当者と話す ここで Web 会議システムの URL は、保険屋の独自ドメインである。\nこの会議システムの URL へのアクセスを次のように制限することで、 セキュリティが担保できる。\nアクセスできる IP アドレスを保険屋が管理する IP アドレスに限定する ただし、保険屋が管理する IP アドレス以外からもアクセス可能にする。 保険屋が管理する IP アドレス以外からアクセスされた場合は、 先着 1 アクセスに限定し、識別するためにトークンを発行する。 以降のアクセスで、このトークンが付加されていないアクセスは拒否する なお△○保険の場合は、○×銀行とは異なり常にこの Web 会議に繋げて相談をする。\nFP の場合 FP はオンラインではなく、家の近くでの対面だった。\n名刺をもらったが、その名刺が本人のものかどうか？を確認する手段がない。\n対面なら大丈夫か？という気がしなくもないが、 全くの別人が成りすましている可能性もある。\nある意味、セキュリティ上一番問題があるかもしれない。。。\nまとめ 実は face to face が一番危険かもしれない、という結果になった。 そう考えるのはオレだけだろうか？\nなお、個人的には金融機関の Web サービスは、 自ドメインだけで実現する方が良いと考えている。 他ドメインがあればあるだけ、リスクが大きくなる。\nOSS を使うな、と言っているのではない。 OSS を自ドメインでホストすれば良いだけだ。\nなにはともわれ、 運用がうまくいくと良いなぁ。 (これが言いたいだけ)\n","id":3,"section":"posts","summary":"今回のネタは、これまでとちょっと違った毛色のネタである。 ネタの背景 日本人あるあるだと思うが、 これまでほとんど 「お金を運用する」 ということを や","tags":null,"title":"お金にまつわる話し","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-09-30-security/","year":"2023"},{"content":" 久々にプライベートのアカウントで teams にアクセスしようとしたら、 未成年だから使えない、というような内容が表示された。\n「どういうことっちゃ？」と思い、 ブラウザでログインしてアカウント設定を見てみると、 生年月日が 2016 年になっていた。なお誕生日は本来の日付だった。\n2016 年というと、たぶん win7 から win10 へのアップグレードをしたタイミングだと思われる。\nそして、そのアップグレードをするタイミングで windows のライセンスを登録するために、 マイクロソフトアカウントを作り、 そのアカウントの生年月日を入力する際に、 ボケて自分の生れた年を入力せずにその年を入力してしまったんだろう。\nさらに、未成年として認識されたアカウントは、 自分で生年月日情報を訂正できないらしく、 別のマイクロソフトアカウントアカウントを 家族として紐付けをして、 そのアカウントの家族の情報から生年月日を更新する必要があった。\nなかなかメンドイ。\nまぁ、変更できるだけマシだが。\n","id":4,"section":"posts","summary":"久々にプライベートのアカウントで teams にアクセスしようとしたら、 未成年だから使えない、というような内容が表示された。 「どういうことっちゃ？」と思","tags":null,"title":"Microsoft アカウントの生年月日設定","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-09-02-microsoft_account_birthday/","year":"2023"},{"content":" 普段ウェブ会議には使わない作業用 PC でウェブ会議をしようと思い、 会議の少し前に外付けのマイクとカメラのセットアップを開始。\nしかし、カメラは設定できたものの、マイクは音が録れない状況に。\nそんな訳で、今回はマイクの音が小さい(というか無音)の場合の 対処方法について。\n結論 先に結論を書くと、以下の手順で問題解決できた。\n「スタートメニュー」 → 「設定」→ 「プライバシー」→ 「マイク」 「アプリがマイクにアクセスできるようにする」をオンに設定 状況 マイクは USB 接続型で、USB を指すと標準ドライバで認識される。 コンパネ → サウンド → 「録音」タブ では 「マイク」として認識されているが、 マイクに向っていくら叫んでも反応なし。 マイクのプロパティの「レベル」タブのレベルを上げても効果なし ダメもとで、マイクについて Windows のトラブルシューティングを 実行したが、やはり効果無し 別 PC に、同じマイクを接続した場合は普通に反応する 同じ PC の別アカウントでも反応する 以上のことから、マイク自体は正常で、PC のドライバ自体も正常。\nつまり、この PC のいつものアカウントの OS 設定に問題があることが判った。\nサウンド設定周り 設定を見直すために、まずはコンパネ系の設定、 コンパネ → サウンド → 「録音」タブ の設定は、 全て見直したものの効果なし。\n残り何があるか？と色々と考えた結果、 「そういえばプライバシー設定で変えられたっけ？」ということで、 プライバシー設定を見ると、プライバシー設定の「マイク」項目の 「アプリがマイクにアクセスできるようにする」がオフになっていたのを発見。\nこの設定をオンにし、 さらに再起動もするとようやくマイクが反応するようになった。\nにしても、プライバシー設定の 「アプリがマイクにアクセスできるようにする」を選択しておくと、 まさか OS のサウンド確認 UI からもボリュームの確認できないとは。。\nしかも、プライバシー設定で禁止になっていることのヒントすらない。\n","id":5,"section":"posts","summary":"普段ウェブ会議には使わない作業用 PC でウェブ会議をしようと思い、 会議の少し前に外付けのマイクとカメラのセットアップを開始。 しかし、カメラは設定","tags":null,"title":"Windows のマイクの音が小さい(というか無音)","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-09-02-mic_volume/","year":"2023"},{"content":" github に上げている個人的なツールの中で、 スターの付いている数少ないプロジェクトの1つである lctags。\nこれを久し振りに更新した。\n更新内容は以下の通り。\ndocker による環境構築対応 C++ の auto 型推論対応 libclang15 対応 暫くノーメンテだった lctags を、このタイミングで更新したのは、 イマドキの C++ に使うには色々と不備があった為。\n仕事で新しいプロジェクトに入り、そこで C++ をメインで利用していたので、 ソースを読む補助ツールとして lctags を導入しようと思ったが、 新しい環境で lctags のビルドをするのが困難だった。\n「なにが困難か」というと、 lctags は libclang 10 以降ではビルドできなくなっていた。 さらに libclang 9 以前は、 ubuntu 22.04 の apt でインストールできない。\nということで、 まずは libclang 9 を取ってこれる ubuntu 20.04 上で lctags を ビルドする docker 対応を実施。\nこれで、新プロジェクト環境で lctags を利用できるようになったが、 新プロジェクトに lctags を掛けると、解析処理がフリーズすることが判った。\nこのフリーズの原因を調べると、 C++ の auto 推論を利用している箇所を lctags で解析すると、 そこの処理でフリーズしていた。\nまぁ、 lctags はあくまでも C のプロジェクトのソース解析がメインで、 C++ はオマケ程度なので仕方がない。\n特に比較的に新しい規格は、 lctags 開発当初はまったくと言って良い程、触っていなかったので、 動作確認も全くやってなく、新しい規格で不具合が出るのはある意味当然。\nそして最後の libclang16 対応。\nこれは、折角久し振りに lctags を更新するので、 これを機会に最新バージョンに対応しておこう、ということで対応。\n特に apt で libclang9 を取ってこれる ubuntu が、20.04 と世代的に少し古めなので、 いくら docker 内とはいえ、更新しておいた方が良いだろうと判断し、 最新の libclang16 対応を行なった。\nlctags はかなりマイナーな用途のツールではあるが、 スターの数は未だに微妙に増えている \u0026amp; 自分自身の新しい仕事のプロジェクトでも C++ を使っているので、 今後もメンテはやっていく。\n","id":6,"section":"posts","summary":"github に上げている個人的なツールの中で、 スターの付いている数少ないプロジェクトの1つである lctags。 これを久し振りに更新した。 更新内容は以下","tags":null,"title":"久々のネタ更新(さらに久々の lctags 更新)","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-07-23-lctags-update/","year":"2023"},{"content":" 次の URL で提供している LuneScript playground 環境のエディタを、 シンプルな textarea からモダンな monaco editor に変更しました。\n\u0026lt;https://ifritjp.github.io/LuneScript-webFront/lnsc_web_frontend/for_wasm/\u0026gt;\n今回のネタは、monaco editor に独自言語の次の機能を追加する方法についてです。\nインデント調整 コード補完 syntax エラー表示 monaco editor monaco editor は、 vscode のエディタ・コアです。\n\u0026lt;https://microsoft.github.io/monaco-editor/\u0026gt;\nweb 上で動作する高機能エディタには、 monaco editor とは別に Ace もありますが、 今回は monaco editor の方を採用しました。\nその理由は、 近い将来的に vscode 用の LuneScript extension を作成するときに、 monaco editor を知っていた方が役立つこともあるんじゃないか？と思ったためです。\n実際に役立つかどうかは不明ですが。。\n独自言語の登録 monaco editor に独自言語の処理を登録するには、 先ず次のように言語 ID を monaco editor に登録する必要があります。\nmonaco.languages.register({ id: \u0026#34;LuneScript\u0026#34;, }); この言語 ID に紐付けて、補完処理などの機能を登録します。\n機能登録後、 editor のインスタンスを生成する際、 登録した言語 ID を指定します。\nlet monacoEditor = monaco.editor.create( element, { language: \u0026#34;LuneScript\u0026#34;, }); これによって生成した editor は、指定の言語を扱うようになります。\nインデント monaco の標準的なインデント制御機能は頭が良いので、 多くの場合 monaco 内のパラメータの設定程度で十分うまく動作すると思います。\nただ、今回は LuneScript 向けにインデント制御を別途作ってあったので、 それを利用します。\nそのため、 monaco の組込みインデント機能を無効化するため、 autoIndent に \u0026#34;none\u0026#34; を設定します。\nlet monacoEditor = monaco.editor.create( element, { language: \u0026#34;LuneScript\u0026#34;, // 組込みのインデント機能を off autoIndent: \u0026#34;none\u0026#34;, }); 次に特定のキー入力時にインデントを調整するようにバインドします。\nここでは、 次のキー入力時にインデント調整するように設定しています。\nTAB Enter C-j { } this.monacoEditor.onKeyUp( async (e) =\u0026gt; { if (e.keyCode === monaco.KeyCode.Tab) { e.preventDefault(); e.stopPropagation(); // タブキーが押されたときの処理 this.updateIndent( monacoEditor.getSelection() ); } else if ( e.keyCode === monaco.KeyCode.Enter || e.keyCode == monaco.KeyCode.KeyJ \u0026amp;\u0026amp; e.ctrlKey || e.keyCode === monaco.KeyCode.BracketLeft || e.keyCode === monaco.KeyCode.BracketRight ) { // Enter, C-j, {, } let selection = monacoEditor.getSelection(); this.updateIndent( selection ); } }); 上記コードの this.updateIndent() は、自前で作成したインデント調整処理です。\nmonaco editor の組込みインデント調整機能を利用する場合、上記処理は不要です。\nコード補完 コード補完は、次のように registerCompletionItemProvider() を使って コールバック情報を登録します。\nmonaco.languages.registerCompletionItemProvider( \u0026#34;LuneScript\u0026#34;, { // \u0026#34;.\u0026#34; で補完開始 triggerCharacters: [\u0026#34;.\u0026#34;], // 補完関数 provideCompletionItems: async function( model, position, context ) { } } このコールバック情報は provideCompletionItems を含みます。 この provideCompletionItems は、 エディタ上で英数字を入力している際に、呼び出されているようです。\nなお、 triggerCharacters で指定している文字を入力した際も、 provideCompletionItems がコールされます。\nまた、 provideCompletionItems に登録しているコールバック関数の引数 model, position, context は、それぞれ次を示します。\nmodel\n編集中の editor のデータを保持する model。 editor.getModel() が返す値と同じ。 position\n編集中の位置 context\n補完のトリガに関する情報 例えば context.triggerKind は、補完のトリガの種別を示します。 このコールバック関数は、 次のような Object を返すように作成します。\n{ incomplete: true, suggestions:[] } ここで、 incomplete は補完処理中かどうを示す値で、 この値が true の結果を受けた monaco editor は後で再度コールバック関数を呼びます。\nsuggestions は、補完候補の配列を示します。\n個々の補完候補は以下のような情報を保持します。\n{ label: \u0026#34;hoge\u0026#34;, kind: monaco.languages.CompletionItemKind.Snippet, insertText: \u0026#34;hoge\u0026#34;, range: targetRange, //command: { id: \u0026#39;editor.action.insertLineAfter\u0026#39; } } それぞれの項目は以下の通りです。\nlabel 補完候補をリスト表示する際に使われる文字列 kind\n補完候補の種別 insertText\n実際に補完文字列として展開される値 range\ninsertText を置き換える場所 command\n置き換え後に実行する command 上記のサンプルではコメントアウトしているが、 補完時にコマンド実行が必要ならここで登録できる syntax エラー syntax エラーを表示するには、monaco の Marker 機能を利用します。\n補完には補完機能を実行するトリガが登録できますが、 syntax をチェックするトリガは、特に規定されていないようです。\nただ、 onDidChangeModelContent() を使うことで、 エディタの内容が編集された場合のコールバックを登録できるので、 このコールバックをトリガに利用して syntax チェックします。\nとはいえ、 syntax チェックはそこそこ重い処理であるのと、 1 文字編集するごとにチェックしてもすぐに次の文字が入力されて、 直前の syntax チェックの多くは無駄になるため、 onDidChangeModelContent() では変更があったことだけ記録し、 周期的タイマーで変更の有無をチェックし、変更があった場合に syntax チェックを掛けるようにします。 こうすることで、リアルタイム性は少し悪くなりますが、 無駄なチェック処理に CPU パワーを取られることを避けられます。\nsyntax チェックは、 当然独自処理でそれぞれの環境に合せて実施する必要があるため、ここでは省略します。\nMarker の登録 自前の syntax チェックによってエラー箇所の情報を取得した後は、 その情報を Marker に登録します。\nそれが、 setModelMarkers() です。\nmonaco.editor.setModelMarkers( this.monacoEditor.getModel(), \u0026#34;lnsc-diag\u0026#34;, markerList ); 上記の第1引数は Marker を登録する Model。 第2引数は Marker の識別名。 第3引数は Marker の情報リストです。\n第3引数は Marker の情報リストには、次の Marker 情報を入れます。\n{ startLineNumber: range.startLineNumber, startColumn: range.startColumn, endLineNumber: range.endLineNumber, endColumn: range.endColumn, message: message, severity: monaco.MarkerSeverity.Error, } 上記を見れば各項目が何を意味するか、直感的に分かると思います。\n念の為概要を説明すると、次を指定しています。\nどこの部分にメッセージを表示するのか 実際の表示するメッセージ メッセージの種別 なお、一点注意すると、 setModelMarkers() の第2引数に指定する識別名は、 monaco.editor.removeAllMarkers() に指定します。\nこの monaco.editor.removeAllMarkers() は、 setModelMarkers() で登録した Marker を削除する際に利用します。\nMarker は、 setModelMarkers() で登録したものを、 一括して setModelMarkers() で削除します。\nさいごに monaco editor への独自言語の機能追加は、かなり簡単に実現出来ます。\n独自言語開発している人の Web エディタとして、オススメです。\n","id":7,"section":"posts","summary":"次の URL で提供している LuneScript playground 環境のエディタを、 シンプルな textarea からモダンな monaco editor に変更しました。 \u0026lt;https://ifritjp.github.io/LuneScript-webFront/lnsc_web_frontend/for_wasm/\u0026gt; 今回のネタは、monaco editor に独自言語の次の機能を追","tags":null,"title":"monaco editor に自作言語拡張(インデント、補完、syntax エラー)を登録する","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-04-23-monago/","year":"2023"},{"content":" LuneScript のセルフホストビルド時間が1秒を切れない問題。\nGOMAXPROCS を設定すれば、もしかしたら簡単に短縮できるのではないか？ と思って GOMAXPROCS を 1 〜 11 まで変えてみた。\nその結果が次の図。\nこの図を見ると、GOMAXPROCS を上げるごとに、僅かにビルド時間(real time)が下っている。 一方で、 real time の下げ幅よりも、 並列処理の合計時間(user time)の上げ幅の方が大きくなってしまっている。\n今は 6 コアの Ryzen 3600 使っていて、 次の候補として 7000 シリーズのコア数の多い CPU を検討していたけど、 この結果をみるとコア数増やしてもあまり意味がないかも？\nただ、コア数が増えた場合に、同じ傾向の結果になるとは言えないしなぁ。\nとりあえず、会社の 8 コア PC で同じように試してみよう。\n","id":8,"section":"posts","summary":"LuneScript のセルフホストビルド時間が1秒を切れない問題。 GOMAXPROCS を設定すれば、もしかしたら簡単に短縮できるのではないか？ と思って GOMAXPROCS を 1 〜 11 まで変えてみた。","tags":null,"title":"LuneScript のセルフホストビルド時間と GOMAXPROCS","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-03-19-gomaxprocs/","year":"2023"},{"content":" \u0026lt;../../2023/2023-02-11-go-generics2/\u0026gt;\n前回の記事で書いた通り、 go の generics のパフォーマンスが向上したため、 LuneScript の v1.6.0 で go の generics を利用するように対応しました。\nなお、現状は collection 型の対応に限定しています。\nLuneScript で、新しくクラスで定義した generics は、従来通りの対応です。\n詳しくは以下を参照。\n\u0026lt;https://ifritjp.github.io/documents/lunescript/generics-go/\u0026gt;\nなお、この対応前と対応後では、 LuneScript のパフォーマンスはほとんど誤差レベルの差しかありませんでした。。。 なので、現状は積極的に使っていくモノではないです。\nまぁ、でも今回の対応で既存バグがいくつか潰せたので善しとしよう。。\n","id":9,"section":"posts","summary":"\u0026lt;../../2023/2023-02-11-go-generics2/\u0026gt; 前回の記事で書いた通り、 go の generics のパフォーマンスが向上したため、 LuneScript の v1.6.0 で go の generics を利用するように対応しました。 なお、現状は collection 型の対応に限定して","tags":null,"title":"LuneScript のコレクション側を Go の generics を利用するように変更","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-02-27-go-generics3/","year":"2023"},{"content":" 以前 Golang 1.19.2 の generics のパフォーマンスを計測したところ、 generics を使ったケースと、自前で any からキャストするケースを比較すると、 なぜか自前で any からキャストする方が速くなるという謎の現象が発生していました。\n前回の結果はここ。\n../../2022/2022-10-15-go-generics/\ngo のバージョンが 1.20 に上ったので、 再度同じテストをして確認してみます。\n確認方法 テストするコードは前回と全く同じものを使います。\nこのコードを go の 1.19.2 と 1.20 でビルドし、実行結果を比較します。\n実行結果 実行結果が以下です。\ngo 1.19.2 generics\t500500000000\ttime = 2.132479 autoboxing\t500500000000\ttime = 0.9845109999999999 go 1.20 generics\t500500000000\ttime = 0.736408 autoboxing\t500500000000\ttime = 0.9796660000000001 これを見ると分かりますが、 なんと 1.20 では、 1.19.2 の時に比べて generics の処理が 約 3 倍高速化 されています。\nこれによって、自前で any からキャストするのではなく、 generics を利用した方が 2 割強速くなる ことが分かりました。\nということで、今回の実験結果を受けて、 LuneScript での golang の generics 対応を進めていきます。\n","id":10,"section":"posts","summary":"以前 Golang 1.19.2 の generics のパフォーマンスを計測したところ、 generics を使ったケースと、自前で any からキャストするケースを比較すると、 なぜか自前で any からキャストする","tags":null,"title":"Golang の generics パフォーマンスがもの凄く改善されていた","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-02-11-go-generics2/","year":"2023"},{"content":" LuneScript の v1.5.3 からタプルを対応している。\nこのタプルの go 実装についてパフォーマンスを調べた内容を載せておく。\nLuneScript のタプルの go 変換初期実装 ここでは、LuneScript のタプルを go に変換した際に、 どのような実装になっているかを説明する。\nLuneScript で次のようなタプル (int と str のペア) を定義した場合、\n(int,str) go では次の型として扱う。\n[]any つまり、タプルの各要素の型情報は一旦 any に丸め、 タプルから値を取得する際に型変換を行なう。\n例えば次の LuneScript のコードは、\nfn hoge() (int,str) { return (= 1, \u0026#34;abc\u0026#34; ); } fn sub() { let val1, val2 = hoge()...; print( val1, val2 ); } go に変換すると次のようなコードになる。\nfunc hoge() []LnsAny { return []LnsAny{1, \u0026#34;abc\u0026#34;} } func sub() { tuple := hoge() val1 := tuple[0].(int) // 型変換 val2 := tuple[1].(string) // 型変換 fmt.Print( \u0026#34;%v %v\u0026#34;, val1, val2 ) } 上記の通り、タプルから値を取得する際に型変換を行なうため、 実行時のオーバーヘッドがかかる。\nこのオーバーヘッドを削減するため、 go の generics を利用する方法を検討し、 両者のパフォーマンスを実測し、より良い方を採用する。\ngo の generics を利用した実装 上記の LuneScript を go の generics を利用した実装は以下になる。\ntype Tuple2[T1,T2 any] struct { Val1 T1 Val2 T2 } func hoge() *Tuple2[int,string] { return \u0026amp;Tuple2[int,string]{1, \u0026#34;abc\u0026#34;} } func sub() { tuple := hoge() val1 := tuple.Val1 val2 := tuple.Val2 fmt.Print( \u0026#34;%v %v\u0026#34;, val1, val2 ) } ベンチマーク用 LuneScript コード ベンチマークを測る LuneScript のコードは以下のものを利用する。\nfn sub(flag:bool) : (int,str)!,str! { if flag { return (= 1,\u0026#34;abc\u0026#34;), nil; } return nil, \u0026#34;err\u0026#34;; } fn func(flag:bool) : (int,str)!,str! { let val1, val2 = sub(flag)!...; let val3, val4 = sub(flag)!...; return (= val1 + val3, val2 .. val4 ), nil; } for _ = 1, 1000 * 1000 * 10 { func( true ); } さらに、 tuple を使わずに多値返却のみで等価な動作をする次のコードも参考に速度を測る。\nfn sub(flag:bool) : int!,str!, str! { if flag { return 1, \u0026#34;abc\u0026#34;, nil; } return nil, nil, \u0026#34;err\u0026#34;; } fn func(flag:bool) : int!,str!,str! { let val1, val2, err1 = sub(flag); if err1 { return nil, nil, err1; } let val3, val4, err2 = sub(flag); if err2 { return nil, nil, err2; } when! val1, val2, val3, val4 { return val1 + val3, val2 .. val4,nil; } error( \u0026#34;\u0026#34; ); } for _ = 1, 1000 * 1000 * 10 { func( true ); } ベンチマーク結果 tuple: []any を利用した場合 real\t0m1.925s user\t0m1.968s sys\t0m0.111s tuple: generics を利用した場合 real\t0m0.996s user\t0m1.064s sys\t0m0.033s 非tuple: 多値返却 real\t0m0.980s user\t0m1.015s sys\t0m0.021s まとめ まとめると、それぞれの実行時間は次の結果となった。\n(tuple: []any) ＞＞＞＞ (tuple: generics) ＞≒ (非tuple: 多値返却) 少し意外だったのは、 タプルを使わない多値返却と比べても、 ほとんどパフォーマンスが変わらない処理時間になることが判った。\n以上から、LuneScript のタプルの go 変換実装は、ジェネリクスを使用する。\n","id":11,"section":"posts","summary":"LuneScript の v1.5.3 からタプルを対応している。 このタプルの go 実装についてパフォーマンスを調べた内容を載せておく。 LuneScript のタプルの go 変換初期実装 ここでは、Lun","tags":null,"title":"LuneScript のタプルの go 実装","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-01-29-tuple-implementation/","year":"2023"},{"content":" Raspberry pi でサーバ運用を始めて約 2 年。\nどうにも最近 Raspberry pi に接続している USB HDD の調子がイマイチだったので、 その対応を行なった。\nただし、未解決。。。\nここでは、その対応の記録を残す。\n症状と作業内容 不調の症状は以下。\n「HDD のファイルを Read すると、不定期に iowait が増大し、最悪数秒程度止まる。」\nちなみに usb hdd は、 バスパワーではなく AC アダプタ付きの USB HDDケースを使ったもの。\nなので「電流が足らない」ということではないはず。\n念の為、 Type-A -\u0026gt; Type-C のケーブルを使っていたが、 3A 対応の Type-C -\u0026gt; Type-C のケーブルに交換してみても、現象は改善せず。\nとりあえず hdd 自体の不調と考えて、 別の hdd にコピーして繋げなおす 時間がかかりつつも、なんとか全データをコピー。\nが、まだ何か調子が悪い。\nhdd を交換してもまだ調子が悪いとなると、hdd 側の原因とは考え難い。\n試しに、交換した元の hdd を windows に接続して HD Tune でテスト すると、特に問題なく動作することを確認。\nであれば、 hdd 自体の問題ではなく raspberry 側の問題の可能性が高い。\nで、よくよく Raspberry pi の状態を観察すると、 HDD に何もアクセスしていないのに、 数秒毎に HDD のアクセス LED が点滅することが判った。\nまずは、どんなアクセスなのかを調べるために iostat -h 1 で確認 すると、 4,5 秒ごとに 2MB 程度の書き込みがあることが判った。\n次に、何のプロセスがアクセスしているのか？を調べる。\nlsof で HDD にアクセスしているプロセスを確認する しかし、なにも表示されず。\nlsof だとタイミング的に確認できていないのかも？\nそこで auditd で hdd へのアクセスを監視 が、やはり何も表示されず。\nどういうことや？と思いつつ、\n今度は fatrace でアクセスを監視 が、これでもアクセスしているログが取れない。\nさっぱり意味不明。\nfatrace はカーネルレベルのファイルアクセストレースするものなので、 「これでアクセスログが取れないってどういうことだ？」と思いつつ、ならば、と HDD を mount する際に readonly でマウントしてみた すると、流石に HDD への write アクセスは無くなった。\nとはいえ、これでは使いものにならないので、他の方法を考える。\nHDD のファイル・ディレクトリパーミッションを全て -w で書き込み権限を外してみる。 が、これでも書き込みアクセスは止まらない。\nマウントレベルで readonly にすると書き込みアクセスが止まるが、 ファイルシステムのパーミッションレベルで readonly にしても書き込みアクセスが止まらない。\nここまでの状況から、 ファイルシステムの外部からの書き込みではなく、 ファイルシステム内部のレベルで書き込みが行なわているのではないか？ と予想。\n現状 hdd は ext4 でフォーマットしてある。 この ext4 が何らかの影響しているのではないかと予想。\nそこで、HDD のフォーマットを xfs にしてみる。 しかし、定期的な書き込みは無くなったものの、読み込みで固まる症状は改善せず。。。\nどうも、細切れでファイル read すると発生しやすいように感じるが、 これ以上の追求は今はムリっぽいので、残念ながらここまでとする。。。\n","id":12,"section":"posts","summary":"Raspberry pi でサーバ運用を始めて約 2 年。 どうにも最近 Raspberry pi に接続している USB HDD の調子がイマイチだったので、 その対応を行なった。 ただし、未解決。。。 ここで","tags":null,"title":"Raspberry pi に接続していた USB HDD が調子悪いので色々と対応してみた(未解決)","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-01-09-raspi-strange-hdd/","year":"2023"},{"content":" Web サーバを作成するにあたり actix-web を使ってみたので、 初心者の目線から見た感想など。\nactix-web 世の中には言語ごとに様々な web フレームワークがありますが、 actix-web は Rust の web フレームワークです。\nなんで actix-web を選んだのかと言えば、「Rust を使いたかった」から。\nRust は数年前に話題になったときに、どんなもんなんだろう？と、 チュートリアルと簡単なツールを作っただけで、それ以降触っていなかったので、 そろそろちゃんと触っておこう、と思ったのが Rust を選択した一番の理由。\n特に当時 Rust で作ったツールはシングルスレッドのツールで、 Rust の特性であるデータの排他制御の恩恵やら、 Rust でのマルチスレッドプログラミングのやり方などがさっぱりな状況だったので、 今回改めて Rust を使うことにした。\nRust を選択した理由としては他にも、\nRust の強力なコンパイラ時のチェックはセキュリティ上も効果があるはず gc 系の言語に比べてパフォーマンスも高い などがあります。\n特に、セキュリティは結構気にしている。 というのも、web サービスは攻撃対象になりやすいので、 コンパイラ時にガッツリとチェックされる Rust であれば、 攻撃のスキを与え難いのではないか？と期待していたりします。\nまぁ、実際のところどうなのかは不明ですが。。\n少なくとも C/C++ よりはマシだとは思うが、 他のイマドキの言語と比べてどうなのか？は良く分からん。\nで、 Rust を選んだ理由は上記だが、 じゃぁなんで Rust の中で actix-web なのか、といえば、 Rust の web フレームワークの中で github のスターの数が多かったから。 というそれだけの理由です。\nactix-web のリファレンス actix-web のリファレンスは以下です。\n\u0026lt;https://actix.rs/docs/getting-started/\u0026gt;\n前述した通り、 Rust は数年前に少し触った程度ですが、 そんな知識しかない状態でも 上記のリファレンスに従うと簡単な web サービスが動かせました。\nとはいえ、 リファレンスのコードそのままなら動くが、 リファレンスのコードそのままで自分の期待する処理は実現できない訳で。\nそして、リファレンスのコードから少し外れると、 やっぱり動かなくなる(というかビルドが通らない)訳で。。。\nそんな訳で、以降では Rust 初心者、 actix-web 初心者がひっかかるであろう箇所について説明していきます。\nactix-web の構成 actix-web の構成を大まかに分けると、サーバとハンドラからなります。\nサーバの主な役割り\npath と ハンドラの紐付けの管理 サーバがクライアントからアクセスされた時に、 アクセスされた path に従って紐付けられているハンドラをコールする 各ハンドラからアクセスする共有データの管理 指定された port での Listen 処理 TLS ハンドラの主な役割り\nサーバによってハンドラが呼びだされ、 要求に対する実際の処理を行なう。 サーバとハンドラの役割を見ると、ハンドラが非常に簡素です。 そして、実際にハンドラはかなり簡単に書けます。\nなお、 リクエスト処理に必須の Query の処理や Body の Json パースなども、 ハンドラの引数に指定しておくだけで、自動で行なわれます。\nサーバ 以下のようにすると、 8080 ポートで listen するサーバが起動します。\nHttpServer::new(move || { App::new() // enable logger .wrap(middleware::Logger::default()) .service(index_test1) .route(\u0026#34;/hoge\u0026#34;, web::get().to(index_test2)) }) .bind((\u0026#34;127.0.0.1\u0026#34;, 8080))? .run() .await ここで、次の部分が path とハンドラの紐付けです。 index_test1, index_test2 はハンドラ関数で、必要な処理を自分で作成します。 ハンドラ関数の名前は任意です。\n.service(index_test1) .route(\u0026#34;/hoge\u0026#34;, web::get().to(index_test2)) この service() , route() は、 それぞれ異なるハンドラ(index_test1, index_test2)の登録処理です。 この登録関数は複数繋げて書けます。\nハンドラの登録は、 service() , route() の2種類で、 service() はハンドラ関数だけ指定し、 route() はサーバ登録時に path と http METHOD とハンドラ関数を指定します。\nこう見ると、 service() の方は path と http METHOD の指定なしにどうやって ハンドラを紐付けているのか疑問に感じると思いますが、 それはハンドラのパートで説明します。\nハンドラ ハンドラは、処理に必要なリクエストの Path や Query, JSON などを引数に宣言でき、 戻り値として Json や文字列、 Result 型などを宣言できます。 宣言したハンドラの型に応じて、サーバが良い感じに引数にデータを渡してハンドラを呼び出し、 また宣言したハンドラの戻り値の型に応じてレスポンスを返します。\nハンドラに宣言できる引数と戻り値については、以下を参照してください。\n引数\nhttps://actix.rs/docs/extractors 次の URL で説明されている web::Data\u0026lt;T\u0026gt; 型は、各ハンドラで情報を共有するため 特に重要\nhttps://actix.rs/docs/application/#shared-mutable-state web::Data\u0026lt;T\u0026gt; 型の注意点については後述します 戻り値\nhttps://docs.rs/actix-web/latest/actix_web/trait.Responder.html オススメとしては\nJSON を返す場合は Json\u0026lt;T\u0026gt; StatusCode をカスタマイズする場合 (R,StatusCode)\nここで R には、 Json\u0026lt;T\u0026gt; 等が指定可能 StatusCode 以外のヘッダを返す場合は HttpResponseBuilder 引数は、ハンドラの処理に必要なものを複数組み合わせて指定できます。\nasync fn index( info: actix_web::HttpRequest, mut body: web::Payload ) -\u0026gt; Result\u0026lt;String\u0026gt; ハンドラの service() , route() の違い 前述の通り、 ハンドラをサーバに登録するには service() , route() の 2 パターンあります。\nハンドラをサーバに登録する際に、 service() はハンドラの関数だけを指定し、 route() はハンドラの関数と path, method を指定します。\nどちらのハンドラも、 上述したようにハンドラ処理に必要な引数と戻り値を組み合わせて定義します。\n違いは、 service() の時は、 次のように関数定義の際にマクロで path と method を指定することです。\n#[get(\u0026#34;/hoge\u0026#34;)] // /hoge の GET 処理 async fn index( info: actix_web::HttpRequest ) -\u0026gt; Result\u0026lt;String\u0026gt; 関数と path と method の組み合わせがセットで定義されるので、 個人的には service() の方が分かり易いと思います。\nもちろん、 route() の方がサーバ定義に集約されていて分かり易い、 という考えもあると思います。\nweb::Data\u0026lt;T\u0026gt; 型 Web サービスの各ハンドラ処理で、なんらかの情報を共有したいことは良くあります。\nこの情報共有に利用するのが web::Data\u0026lt;T\u0026gt; 型です。\nここでは、次のサンプルを元に説明します。\n\u0026lt;https://actix.rs/docs/application/#shared-mutable-state\u0026gt;\nuse actix_web::{web, App, HttpServer}; use std::sync::Mutex; struct AppStateWithCounter { counter: Mutex\u0026lt;i32\u0026gt;, // \u0026lt;- Mutex is necessary to mutate safely across threads } async fn index(data: web::Data\u0026lt;AppStateWithCounter\u0026gt;) -\u0026gt; String { let mut counter = data.counter.lock().unwrap(); // \u0026lt;- get counter\u0026#39;s MutexGuard *counter += 1; // \u0026lt;- access counter inside MutexGuard format!(\u0026#34;Request number: {counter}\u0026#34;) // \u0026lt;- response with count } #[actix_web::main] async fn main() -\u0026gt; std::io::Result\u0026lt;()\u0026gt; { let counter = web::Data::new(AppStateWithCounter { counter: Mutex::new(0), }); HttpServer::new(move || { App::new() .app_data(counter.clone()) // \u0026lt;- register the created data .route(\u0026#34;/\u0026#34;, web::get().to(index)) }) .bind((\u0026#34;127.0.0.1\u0026#34;, 8080))? .run() .await } 共有データの持ち方 上記サンプルは、 次の AppStateWithCounter 構造体を各ハンドラで共有する情報として扱います。\nstruct AppStateWithCounter { counter: Mutex\u0026lt;i32\u0026gt;, // \u0026lt;- Mutex is necessary to mutate safely across threads } ここで counter:Mutex\u0026lt;i32\u0026gt; が、共有する情報です。 つまり、 i32 値を共有します。 もちろん、 i32 ではなく構造体など任意の情報を共有することも可能です。\n以下のように複数の情報をそれぞれ Mutex にすることも可能です。\nstruct AppStateWithCounter { counter1: Mutex\u0026lt;i32\u0026gt;, counter2: Mutex\u0026lt;i32\u0026gt;, } あるいは、一つの構造体として Mutex にすることも可能です。\nstruct CounterSet { counter1: i32, counter2: i32, } struct AppStateWithCounter { counterSet: Mutex\u0026lt;CounterSet\u0026gt;, } これは、それぞれのデータの排他をどう制御するのか？の設計の違いです。\n前者のそれぞれを Mutex にした場合、 それぞれで排他をかけるので、 それぞれ別々に異なるハンドラでアクセスできます。\n一方で後者の 1 つの Mutex にした場合、 排他をかけるのは 1 つなので、 同時アクセスできるのは 1 つのハンドラだけになります。\n前者の方は、同時アクセス可能なハンドラを増やせるというメリットはありますが、 一方でデッドロックやデータの整合性をどのように管理するか？などを考える必要があります。\n後者は、アクセス可能なハンドラが一つに限定される代りに、 デッドロックやデータの整合性を考えずに済むというメリットがあります。\nどちらにするかは、それぞれの考え方次第です。\n共有データをサーバへ登録 次の処理で共有データを生成し、\nlet counter = web::Data::new(AppStateWithCounter { counter: Mutex::new(0), }); そして次の処理 app_data(counter.clone()) で共有データをサーバに登録します。\nHttpServer::new(move || { App::new() .app_data(counter.clone()) // \u0026lt;- register the created data .route(\u0026#34;/\u0026#34;, web::get().to(index)) }) 異なる複数のサーバに、同じ共有データを登録することも出来ます。\nハンドラで共有データを処理 ハンドラで共有データを処理するには、 ハンドラの引数にそのデータの型を宣言します。\nasync fn index(data: web::Data\u0026lt;AppStateWithCounter\u0026gt;) -\u0026gt; String { これによって、サーバからそのデータが引数に渡されてハンドラがコールされます。\nそして、ハンドラから実際に共有データにアクセスするには Mutex を lock() します。\nlet mut counter = data.counter.lock().unwrap(); // \u0026lt;- get counter\u0026#39;s MutexGuard この lock() で得られたデータに対して操作すれば、共有データが操作されます。\n*counter += 1; // \u0026lt;- access counter inside MutexGuard なお、 lock() された共有データは、 その共有データの変数のスコープから出る際に unlock されます。 よって、共有データを lock() した変数のスコープを出来るだけ小さくすることで 排他期間を短くできるので、良く考えてスコープを制御する必要があります。\nただし、 排他期間を短くすることだけに注目し、 1 つのハンドラ処理で複数回 lock() する、などしてしまうと、 逆に適切な排他制御が出来なくなる可能性もあるので注意が必要です。\nまぁ、これは Rust に限った話しではなく、一般的な排他制御の話ですが。\nasync/await イマドキの言語で良く見る async/await。\nRust にも async/await があります。\nというか、 actix-web は基本となる handler の型が async なので、 async は必須。\nで、 async/await の関係については javascript とほとんど同じと考えて良いです。 async の関数は、 await で待たないと処理されずに先に進んでしまうので注意が必要です。\nなお、 await は val.await というようにメンバにアクセスするような形で指定します。\nまた、 await で待てるのは async 関数内のみになります。 この辺りも javascript と同じです。\nじゃぁ、 async 関数ではない通常の関数から async の終了を待つにはどうするのかと言うと、 次の block_on() を使う。\n\u0026lt;https://docs.rs/actix-web/4.2.1/actix_web/rt/struct.Runtime.html#method.block_on\u0026gt;\nただ、この block_on() を使うのはイマイチな気がします。\nというのも、 block_on() を使うには Runtime を作る必要があり、 Runtime を作るには OS リソースが必要です。 そして、Runtime を同時に一定数作ると OS リソースが無くなって Runtime が作れなくなります。 この OS リソースは、Linux の場合はファイルハンドル数(ulimit -n)の制限に依存します。\nまぁ、数百くらい同時に Runtime を作った場合の話なので、 実用上あまり気にしなくても良いかもしれないですが、 結構早めに上限が来てしまうことは認識しておいた方が良いでしょう。\nそんな訳で、 非 async 関数から async をコールしないように開発を進めるのが基本になります。\n","id":13,"section":"posts","summary":"Web サーバを作成するにあたり actix-web を使ってみたので、 初心者の目線から見た感想など。 actix-web 世の中には言語ごとに様々な web フレームワークがありますが、 actix-web は Rust","tags":null,"title":"actix-web (Rust の web フレームワーク)","uri":"https://ifritjp.github.io/blog2/public/posts/2023/2023-01-06-actix-web/","year":"2023"},{"content":" go の wasm と、JavaScript の非同期処理との連携についてです。\n基本的な go の wasm と JavaScript 間のインタフェースについては、 以前のネタを確認してください。\n../2022-09-19-go-wasm\ngo の wasm の非同期処理 複数の goroutine を利用したプログラムを wasm に変換すると、 GOMAXPROCS=1 を指定した時と同じ動作になります。\nつまり、複数の goroutine を起動させても、 複数の goroutine が同時に動作することはなく、 ある瞬間にアクティブになる goroutine は 1 つだけということです。\nこれは前回のネタでも書いたことです。\nそして JavaScript と連携する際に、 go にはもう一つ大きな特徴があります。\n全ての gorouine が chan 待ち等でブロックすると、go のランタイムエラーが発生する。\nこれは wasm に限らない go の特徴ですが、 JavaScript との連携する際に注意が必要な特徴です。\nJavaScript と wasm 間の関数コールは全て同期呼び出し JavaScript は、 async 宣言した関数は自動的に Promise ベースの非同期関数として処理されます。\nasync 宣言した関数の終了を待つには、 関数コールする際に await を利用して実行するか、 Promise の then 等にコールバックを登録する必要があります。\nなお、 go から JavaScript の関数をコールする場合、 通常の同期呼び出しになり、 await を利用した関数コールはできません。\nつまり、 go から JavaScript の async 関数をコールし、その async 関数の処理終了を待つには、 その async 関数の戻り値の Promise を処理する必要がある 、 ということです。\n具体的な Promise 処理については、以下のサイトの解説を確認してください。\n\u0026lt;https://stackoverflow.com/questions/68426700/how-to-wait-a-js-async-function-from-golang-wasm\u0026gt;\nここでは、上記サイトのコード部分を抜粋しておきます。\nfunc await(awaitable js.Value) ([]js.Value, []js.Value) { then := make(chan []js.Value) defer close(then) thenFunc := js.FuncOf(func(this js.Value, args []js.Value) interface{} { then \u0026lt;- args return nil }) defer thenFunc.Release() catch := make(chan []js.Value) defer close(catch) catchFunc := js.FuncOf(func(this js.Value, args []js.Value) interface{} { catch \u0026lt;- args return nil }) defer catchFunc.Release() awaitable.Call(\u0026#34;then\u0026#34;, thenFunc).Call(\u0026#34;catch\u0026#34;, catchFunc) select { case result := \u0026lt;-then: return result, nil case err := \u0026lt;-catch: return nil, err } } この Promise 処理について、一点注意が必要です。\nそれは、以下の go の特徴です。\n『全ての gorouine が chan 待ち等でブロックすると、go のランタイムエラーが発生する。』\n上記のコードの通り、Promise 処理を待つには chan を利用して待つ必要があります。 一方で、 go の特徴から全ての gorouine がブロックすると go がランタイムエラーしてしまいます。\n例えば次のようなケースです。\njs -\u0026gt; go : go.run() go -\u0026gt; go : wait chan js \u0026lt;-- go: return go\u0026#39;s Promise js -\u0026gt; go : call a go\u0026#39;s function js \u0026lt;- go: call a js\u0026#39;s async function js --\u0026gt; go : return Promise go -\u0026gt; go : wait to call a \u0026#39;then\u0026#39; callback --- deadlock このケースでは、次の動作になります。\ngo.run() で実行した go の wasm の処理内で chan 待ちを行ないます。 これにより、 wasm の処理がそこで停止し、 js 側には go の wasm の実行を待つ promise が返されます。 そして、js 側から go の関数を実行します。 この go の関数から js の async 関数を呼びます。 そして、その promise を待ちます。 こうすると、 go 内で deadlock を検知し、 go の wasm は異常終了します。\nただ、上記の図だとちょっと伝わり難いと思うので、 もう少し分かり易くした図 が以下です。\njs -\u0026gt; go_runtime: go.run() go_runtime -[#green]-\u0026gt; go_main_goroutine: \u0026lt;font color=green\u0026gt; go main() go_main_goroutine-[#red]\u0026gt; go_main_goroutine: \u0026lt;font color=red\u0026gt;wait chan js \u0026lt;-- go_runtime : return go\u0026#39;s Promise js -\u0026gt; go_runtime: call a go\u0026#39;s function js \u0026lt;- go_runtime : call a js\u0026#39;s async function js --\u0026gt; go_runtime: return Promise go_runtime-[#red]\u0026gt; go_runtime: \u0026lt;font color=red\u0026gt;wait to call a \u0026#39;then\u0026#39; callback --- deadlock go の wasm を実行する場合、 go の main 関数がコールされる前に go の runtime が実行され、 その runtime 内から同期的に main が実行されるのではなく、 main 用の goroutine が起動されて、そこで main が実行されます。 そして、 main 内で chan 待ちをすると、 go runtime が js 側に処理を戻す。 という形になります。\nそして、その後の js から go 関数の呼び出しは、 go runtime 内から直接同期実行されます。 これによって go runtime 内で chan 待ちすると全ての go routine が待ち状態になり、 deadlock する、という訳です。\ngo から js の promise 待ちをする場合 以上を踏まえ、go から js の promise 待ちをする場合に deadlock を回避するには、 以下が必要になります。\njs から実行される go の関数を同期的に実行するのではなく goroutine を利用する。\njs -\u0026gt; go_runtime: go.run() go_runtime -[#green]-\u0026gt; go_main_goroutine: \u0026lt;font color=green\u0026gt; go main() go_main_goroutine-[#red]\u0026gt; go_main_goroutine: \u0026lt;font color=red\u0026gt;wait chan js \u0026lt;-- go_runtime : return go\u0026#39;s Promise js -\u0026gt; go_runtime: call a go\u0026#39;s function go_runtime -[#green]-\u0026gt; go_sub_goroutine: \u0026lt;font color=green\u0026gt;go sub() js \u0026lt;-- go_runtime: return js \u0026lt;- go_sub_goroutine : call a js\u0026#39;s async function js --\u0026gt; go_sub_goroutine: return Promise go_sub_goroutine-[#red]\u0026gt; go_sub_goroutine: \u0026lt;font color=red\u0026gt;wait to call a \u0026#39;then\u0026#39; callback --- ok 上記のように、 go 内から js の promise 待ちをする際は、 直接 go runtime から実行するのではなく、 goroutine を起動してその goroutine 内で promise を待ちます。\nこれによって、 go が deadlock することなく js の非同期処理と連携を行なうことができます。\njs では await を使って async 関数の処理を待つことで、 await の処理内で他の非同期な js の処理を行なうことが出来ます。 一方で、 go の wasm 内の chan 待ちは完全に処理が停止します。\nなので、 js からの関数コールはブロックさせずに、速やかに処理を戻すのが鉄則です。\njs の async と go の goroutine go 内で chan 待ちをする際、 goroutine を使わずに js の async 関数から go の関数をコールし、 その go の関数内で chan 待ちをしても結果は同じになるのか気になったので、 以下のケースを確認しました。\njs -\u0026gt; go_runtime: go.run() go_runtime -[#green]-\u0026gt; go_main_goroutine: \u0026lt;font color=green\u0026gt; go main() go_main_goroutine-[#red]\u0026gt; go_main_goroutine: \u0026lt;font color=red\u0026gt;wait chan js \u0026lt;-- go_runtime : return go\u0026#39;s Promise js -[#blue]-\u0026gt; \u0026#34;js async func\u0026#34; : \u0026lt;font color=blue\u0026gt;call async func \u0026#34;js async func\u0026#34; -\u0026gt; go_runtime: call a go\u0026#39;s function js \u0026lt;- go_runtime : call a js\u0026#39;s async function js --\u0026gt; go_runtime: return Promise go_runtime-[#red]\u0026gt; go_runtime: \u0026lt;font color=red\u0026gt;wait to call a \u0026#39;then\u0026#39; callback -- deadlock 結果としては、 js の async 関数から go の関数を呼んでも deadlock しました。\nよって、 js からコールさせる go の関数は、 ブロックさせずに速やかに処理を戻しましょう。\nまとめ go の wasm 対応はちょっと面倒なイメージがありますが、 go の標準ライブラリを使ったプログラムをそのままブラウザ上で動かせるという メリットは大きいです。\nもちろん「TCP 接続をする」 などの wasm がそもそもサポートしていない処理は動きません。 しかし、それでも go のソースを変更せずにそのままビルドが通って wasm のモジュールが生成できる、 というのは大きな長所です。\nまた js で worker を使うよりは制限が少なく非同期処理を組めるのも web で go を使うメリットとも言えると思います。\n今回の JS の非同期処理との連携を活用すれば、 JS や TypeScript でプログラムを組むよりも 高度な処理を組み易くなる可能性もあると思います。\nとはいえ、go の wasm サイズは「デカ過ぎだろ」とツッコミを入れなければならないですが。。\n以上。\n","id":14,"section":"posts","summary":"go の wasm と、JavaScript の非同期処理との連携についてです。 基本的な go の wasm と JavaScript 間のインタフェースについては、 以前のネタを確認してください","tags":null,"title":"Golang の WASM (JavaScript の非同期処理 async との連携)","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-12-18-go-wasm-async/","year":"2022"},{"content":" 今回も引き続き 3D プリンタ系の話です。\n3D プリントの出来 3D プリントの出来は次の要素で決まります。\n3D プリンタの性能 フィラメントの性能 スライサーの性能、パラメータ どんなに良い 3D プリンタやフィラメントを使っても、 スライサーの性能が悪い、 スライサーのパラメータの設定が正しくない場合、 意図したプリントは出来ません。\nUltimaker cura 3D プリンタでオブジェクトをプリントするには、 3D オブジェクトを積層データ形式に変換する必要があります。\nこの変換処理を行なうのがスライサーです。 スライサーには幾つかの種類がありますが、 Ultimaker cura はオープンソースで開発されています。\n\u0026lt;https://github.com/Ultimaker/Cura\u0026gt;\nUltimaker cura は、3D モデルを基にスライスする専門ツールで、 モデリングは別のツールで行なう必要があります。\n以降は cura ver 5.2.1 について書いています。\ncura のバージョンが違う場合は、この記事の内容と異なることがあります。\ncura の設定 cura の簡易設定で Resolution を一番細かい設定にし、 Support On を選択しておけば大抵は間違いは無いですが、 それだと時間がかかり過ぎることもあります。\n逆に Resolution を一番粗い設定にすれば時間は短縮できますが、 プリントをミスする可能性が出てきます。\n自分が求めるプリント品質と時間を両立させには、 cura のカスタム設定でパラメータを適宜指定する必要があります。\n主なパラメータ cura のパラメータの内、特に重要なカテゴリは以下です。\nQuality\nフィラメントを積層する精度を指定します 細かくすれば精度は上りますが、その分時間がかかります Walls\nオブジェクトの側面の構成を指定します 側面の構成を変更することで、強度や見た目に影響します Top/Bottom\nオブジェクトの上面、底面の構成を指定します 上面、底面の構成を変更することで、強度や見た目に影響します Infill\nオブジェクト内部の構成を指定します 内部の構成を変更するとこで、強度に影響します Material\nフィラメントの特性を指定します プリント速度を上げる場合は、 フィラメントの対応温度の範囲内の上限付近に設定する方が良い傾向にあります Speed\nフィラメントのプリント速度を指定します 速度を早めればプリント時間が短縮しますが、その分精度が落ちます 速度はオブジェクトのパーツ毎に指定できます 見た目に影響の大きい表面のプリント速度を遅くし、 影響の少ないオブジェクト内部やサポートのプリント速度を上げるなどの調整が出来ます ただし、 影響の少ないパーツでも、 速度を上げ過ぎるとプリント自体が失敗する可能性があります Support\nサポートの構成を設定します サポートの剥し易さや、印刷速度に影響します support placement は、サポートの配置を指定します。\ntouching buildplate は、必ずビルドプレートからサポート材を配置するようにします Eveywhere は、プリントしたモデルからもサポート材を配置します。 現在 touching buildplate を指定すると、 本来サポートが必要な箇所にサポートが構成されずにプリントが失敗するケースがあります。 touching buildplate は、モデルに余分なサポート材が付加されないため 仕上りがキレイになるメリットがありますが、上記の通り失敗することもあるので、 touching buildplate を利用する場合はスライス結果を十分に確認してください。 Build Plate Adhesion\nオブジェクトのプリント開始時の設定をします オブジェクトとプリントベッドとの接触が悪い場合などに調整を行ないます なお、 デフォルト状態では幾つかのパラメータが非表示になっています。\nプロファイルの表示設定を変更することで、設定可能なパラメータが表示されます。\nサポートは必要悪 3D プリントにはサポート材が必要になるケースがあります。\nしかし、オブジェクトとサポートの接地面は 荒れます。 スライサーをどう設定したところで、荒れます。\nこれはシングルノズルの FDM 式の特性上 避けられません。\nサポートの矛盾 スライスは点と点を結んで線を構成し、 その線を複数結ぶことで複雑なオブジェクトを形成します。 この点と点を結んで固定するには、 下の層と接着させる 必要があります。 通常この下の層は、プリント対象のオブジェクトの層になります。 しかし、オブジェクトがない場合、サポートが形成されます。\nこのサポートと、スライスの線が接着されて複雑な図形を形成しますが、 サポートはプリント後に取り除き易くするために面が荒く作られています。 そして、面が荒く作られているということは、 スライスの線と 固定できる箇所が限られ、 当然の結果スライスで形成される図形も荒くなります。 仮にサポートの面が格子状に作られていた場合、 スライスの線が固定出来る箇所は、その格子状にしかありません。 スライスの線の固定したいポイントが格子状にない場合は、 どこか近い場所に固定されます。\n対策として、サポートの面を細かく形成してスライスの線との密着度を上げた場合を考えると、 今度は プリント後にサポートを取り除くことが困難になってしまいます。\nFDM 式には、このサポートの矛盾があり、サポート接地面が荒くなります。\nこれを解決するには、サポートの接地面を構成する特別な水溶性等のフィラメントを用意し、 オブジェクト用とサポート接地面用の二つのノズルを制御してプリントしていく方法が考えられます。 しかし、多くの家庭用 3D プリンタに搭載されているノズルは 1 つであり、 このような制御は不可能です。\n軽減策 では、どうすれば良いかと言えば、 できるだけサポートを使わないようにするしかありません。\nできるだけサポートを使わないようにする方法に、 スライス時の オブジェクトの傾き調整 があります。\nサポートが生成される条件は、 プリントするスライスの直下にオブジェクトの層がない場合です。\nつまり、この条件が出来るだけ当て嵌まらないようにすれば、 サポートの必要量を減らせます。\nなお、この条件の「直下にオブジェクトの層がない」は、 実際には少し条件が異なります。\n直下に層がなくても、近傍に層があればサポートは不要になります。\n具体的には、cura のスライス結果を下から見上げた時に、 赤だけが表示されている場合は直下に層がなくても大丈夫な面です。\nつまり、スライスの 下向きの面がなるべく赤くなるように調整する ことで、 サポートを減らせます。\nまた、サポートの数が多くても目立たない箇所であれば、 さほど気にならないので、 敢えてサポートの数を増やしてでも目立たない箇所にサポートが作られるように傾ける、 という方法も考えられます。\nオブジェクトを傾けてサポートを削減した場合 Raft が必須 上記の通り、オブジェクトを傾けることで、サポートを減らせます。 一方で、サポートの量を十分減らせた場合、次の問題が発生することがあります。\n傾けたことでプリントベッドとの接地面が少なくなる\n接地面が少なくなることで接着力が弱くなる 傾けたことでオブジェクトの重量バランスが悪くなる 接着力が弱くなり、重量バランスも悪くなることで プリント中にオブジェクトがプリントベッドから外れプリントが失敗する この問題を避けるには、 プリントベッドとの接着力強化が必要です。\nそれが Raft です。\nRaft は、プリントベッドから伸びるサポート周辺に土台を構成することで、 プリントベッドとの接着力を強化します。\nなお、 オブジェクトを傾けた場合だけでなく、 オブジェクトの上部に比べてプリントベッドとの接地面が少ないような場合は Raft が必要です。\nRaft を使用する場合、 Build Plate Adhesion Type に Raft を指定します。\nサポートの強化 Raft を使用しただけでは不十分なケース があります。\nそれは、構成されるサポートが極度に細くて貧弱な場合です。\nこの場合、Raft を作っても肝心のサポートが貧弱だと、 プリント中に折れるなど不慮の事故が発生する 可能性があります。\nサポートはプリント対象のオブジェクトとは異なり、 通常 1 ストローク分しかプリントされない、かつ、 そもそもサポートは剥し易く構成されます。\nこれによって、 サポートが極度に貧弱な場合、 Raft があってもサポート自体が途中で折れる危険があります。\nなお、そもそもこのような折れそうなサポートは不要とも言えます。 サポートが無くても大丈夫そうな場合は、 cura の Support Blocker でサポートが付いている領域を指定することで、 そのサポートを除去できます。\n除去できない貧弱なサポートがある場合、 サポート自体の強化 が必要です。\nサポート自体の強化は、次の 2 つです。\nサポートの壁の厚みを増す (Support Wall Line Count)\n通常、 1 ストローク分しかプリントされないサポートの壁を指定した数に増やします 少なくとも 3 周はしないと耐えられないです サポートの幅を増す (Support Horizontal Expansion)\n必要最低限の幅しか生成されないサポートの幅を増やすことで、安定度を増します 前述の壁の厚みを増す設定をしても、元の大きさが小さいと壁が3周しないケースがあります。 そのような場合に、これを指定して強制的にサポートを広けます また、デフォルトのサポート材のプリントスピードは、比較的早いスピードが設定されています 早いスピードは安定した土台があることが前提なので、 サポートが貧弱な場合はサポートのプリントスピードを下げた方が安定します。\n上記設定によって、貧弱なサポートが強化され、 プリント中で折れることを防ぐことができます。\nサポート用を追加する モデルによっては、Raft を設定するだけでは保持できないケースがあります。\n例えば、立方体の Z 軸を 45 度に傾けたモデルをスライスすると、 全くサポートが生成されません。\nこれはサポートが生成されなくても問題ない、ということではないです。\nどう考えても、途中でバランスを崩して倒れます。\nこのような場合は、以下のいずれかで対応します。\nsupport overhang angle を小さくする サポートとなるモデルを追加する なお、 support overhang angle を小さくすると、 全体に影響が出るので多少面倒でもサポートとなるモデルを追加する方が、 仕上りが良くなるケースがあります。\nSTL エラー対策 スライサーを使う上で一番面倒なのが、モデリングデータのエラーです。\nモデリングしたデータは、一見問題なさそうに思えても、 実際には問題があるケースがあります。\n本来は、そのデータをモデリングしたツールでモデルを修正するべきですが、 モデル公開サイトから取得したデータなどは修正が難しいことがあります。\ncura は、そのような場合にエラーを修正してプリントできるようにする機能があります。\nエラー修正は、cure のパラメータカテゴリの Mesh fixes を使います。\nMesh fixes のカテゴリ自体、 通常だと表示されていません。 プロファイルの表示設定を変更して Mesh fixes の項目を設定してください。\nMesh fixes を有効化してスライスした場合は、 スライス結果が意図しないものになっていることがあります。 オブジェクトの傾きによってもスライス結果が異なる場合があるため、 注意が必要です。\n実際にプリントする前にスライスした結果を確認しましょう。\nMesh fixes は、 修正できないモデルの印刷には効果的です。 しかし、安易に使用すると意図しないスライス結果になることもあります。\nエラーのあるモデルのプリントに Mesh fixes の設定を利用した後は、 設定を元に戻した方が良いでしょう。\nなお、MS 3D Builder を利用すると、モデリングデータのエラーを修正出来ます。 ただし、この場合もエラーが修正されただけで、 意図しない修正になっていることがあります。 実際にプリントする前に、スライスした結果を確認しましょう。\nMesh fixes 時の対策 上記の通り Mesh fixes でエラーを修正すると、 意図しないスライス結果になるケースがあります。\n多少のノイズならそのままプリントしてしまっても問題ありませんが、 致命的なノイズだとプリントしてもゴミが出来るだけなので、プリントできません。\nこのような対策として、 次を行なうと効果があります。\nモデリングソフトを使って、エラーが発生するモデルと、 エラーが発生しないモデルに分割する それぞれのモデルを cura で読み込む cura 上で組み立てる これにより、エラーが発生しないモデルにはエラー修正の影響がなくなり、 プリント可能な範囲のノイズに抑えることが出来ることが可能性があります。\n","id":15,"section":"posts","summary":"今回も引き続き 3D プリンタ系の話です。 3D プリントの出来 3D プリントの出来は次の要素で決まります。 3D プリンタの性能 フィラメントの性能 スライサーの性","tags":null,"title":"FDM 3D プリンタのスライス設定と STL エラー対策","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-12-04-3d-printer-slice/","year":"2022"},{"content":" 今回は珍しくソフト系のネタではなく、3D プリンタ系の話です。\nFDM 式は面倒が少ない 3D プリンタを購入するにあたり、事前に色々と調べた結果、 光造形式ではなく FDM 式にしました。\nFDM 式を選んだ主な理由は 「面倒が少ない」 です。\n光造形式の洗浄・二次硬化はどうしても面倒に感じました。 またそれ以外にも光造形式の以下の点が気になり、FDM 式を選択しています。\nレジンの匂い 多くのレジンが無駄になってエコ(economy,ecology)でない FDM 式に比べて強度が弱い もちろん光造形式の「精度の良さ」や、「印刷時間が平面の大きさに比例しない」という メリットは魅力的ですが、メリット・デメリットを比べた時に、 自分には FDM 式の方があっていると判断しました。\nそれに、自分の 3D プリンタが欲しい理由は、 フィギュアなどの観賞用のオブジェクトを作ることではなく、 パーツ等の実用的なモノを作ることが目的なため、 見た目よりも機能性の高い FDM 式の方がマッチしています。\nフィラメントの湿気対策 光造形式に比べて「面倒が少ない」FDM 式ですが、全く面倒がない訳でもありません。\nその代表が 「フィラメントの湿気対策」 でしょう。\nフィラメントが水分を吸収してしまうと、印刷結果に大きな悪影響があります。 そのため、「フィラメントの湿気対策」が必須になります。\nなお、プリント中でない長期保管時の湿気対策は当然ですが、 プリント中も湿気対策をした方が良いでしょう。 なぜなら、 3D プリントの印刷時間は基本的に数時間単位と長いですし、 日本は高温多湿な気候であるためです。\nネットで検索すると、皆さんそれぞれ自作の対策をされています。\nとても見栄えが良く、機能性も高そうなのですが、 個人的にちょっと 「ハードルが高い」 というか、 作るのにそれなりの準備が必要なモノが多そうでした。\n私は 直ぐに使いたい \u0026amp; お金が掛らないモノ にしたかったので、 先人の知恵をベースに自分なりの 3D プリンタ用フィラメント除湿・送出ボックス を作成しました。\n3D プリンタ用フィラメント除湿・送出ボックス 必要な材料は以下です。\n100 均で入手するモノ\nフィラメントが入る丁度良い大きさ(底が広いタイプ)の蓋付き透明な密閉プラケース 湿度計 (無くても湿度を確認できなくなるだけなので、必須ではない。が、あった方が良い) BB弾 x 2個 (家にエアガン用 BB 弾があればそれでも可) 家を探せば出てくるモノ\n除湿剤 (塩化カルシウムタイプは ダメ絶対 ) 3D プリンタに付属されているモノ\n予備のチューブ これだけです。\n上記の100均で入手するモノは、トータル 500 〜 600 円 で購入できます。\n除湿剤は、家に無ければホームセンター等で買いましょう。\nなお、除湿剤の素材は塩化カルシウムタイプは NG です。 何故なら塩化カルシウムタイプは、空気中の水分を吸収して液体に戻す効果があり、 これでは除湿どころか、フィラメントが水浸しになってしまいます。 除湿剤はシリカゲルタイプにします。\nなお極短期間であれば、 塩化カルシウムタイプの除湿剤で凌ぎ、 長期的にはシリカゲルタイプに移行するのでも問題ないでしょう。\n作成方法 作成手順は以下です。\nプラケースに予備のチューブを通す穴を開けて、チューブを通す BB弾 x 2個をプラケースにブチまける BB弾の上にフィラメントのリールを横に倒して乗せる フィラメントをチューブに通す フィラメントの上に除湿剤と湿度計を乗せる プラケースを閉じる 構成の重要パーツ この構成の重要なパーツは BB 弾 です。 (「100均に BB 弾あるかなぁ？」と気になりましたが、 オモチャコーナーに置いてありました。)\nフィラメントを BB 弾 の上に乗せることで、 フィラメント自体を 超簡易的なボールベアリング にしています。\nBB 弾 の上に乗せるためにも、 使用するプラケースはちょうど良い大きさにする必要があります。 大き過ぎると、BB 弾が 2 個では足りません。 逆に BB 弾を詰め込み過ぎると、BB 弾が転がらないので、適度なスペースを作っておきます。\nなお BB 弾を敷き詰る代りに、 以下のようなパーツを利用すると理想的な形になると思いますが、 それだと今回の前提の 直ぐに使えて \u0026amp; お金が掛らないモノ から外れてしまうので、 利用しません。\nターンテーブル 回転盤 またこの構造にするには、フィラメントは縦置きではなく、 必ず 横置き になります。\n横置きが気になる人は、この方法は利用できません。\n発展形 このボックスの発展形としては、以下があります。\n湿度計を見易くする\n湿度計をプラケースの側面に設置するマウンタを作成する リールの回転系を改善する\n簡易ターンテーブルを作成する あるいは、BB弾が散らばらないようにプラケース内にスペーサーを作成する\n簡易ターンテーブルを作成すれば BB 弾は不要 どれも、簡単に 3D プリンタで作成できると思います。\n簡易ターンテーブル 作成した簡易ターンテーブルのデータを載せておきます。\nSTL データ\n../turntable.stl イメージ\n動作\n数個の BB 弾を溝に置くだけの簡単な構造ですが、 抵抗も少なく、スムーズにフィラメントを送出できます。\nまとめ この構成のメリットは、以下です。\n直ぐにパーツを揃えられる 組み立てが楽 安価 横に倒して使うので安定する 発展させて、より使い易いモノに出来る 欠点(？)は、必ず横置きになることくらいかな？\n以上。\n","id":16,"section":"posts","summary":"今回は珍しくソフト系のネタではなく、3D プリンタ系の話です。 FDM 式は面倒が少ない 3D プリンタを購入するにあたり、事前に色々と調べた結果、 光造形式","tags":null,"title":"100 均で作る超お手軽・安価な 3D プリンタ用フィラメント除湿・送出・保管ボックス","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-11-27-3d-printer-filament-box/","year":"2022"},{"content":" go は GC で heap メモリを管理している。\nJava の場合、最大 heap サイズを指定し、 そのサイズを越えた場合は OutOfMemoryError になる。 最大 heap サイズが指定されていない場合はデフォルトのサイズが利用される。\nなお、Java でメモリフルが発生する際は、 最大 heap サイズがデフォルト設定のまま、というケースが多い。\nまぁ、ここでは Java の話は置いておいて、 go での heap 制御ってどうなの？と、いうのが今回の話。\nGOGC と GOMEMLIMIT go の heap メモリ制御は、 java のような予め決められた heap サイズ内で動作させる、 ということではなく、 GC をどのタイミングで実行するか、という制御になる。\nつまり、厳密にある heap サイズ以下で運用したい、 というようなことは 現実的には不可能 である。\nまぁ Java のように制御しても、メモリフルエラーになるだけなので、 それが嬉しいのか？と言われると、然程嬉しくないと思う。\n出来るだけ本流のユーザプログラムの処理を GC で邪魔せずに、 パフォーマンスを発揮させることが、 go の設計思想としてあると考えられる。 よって、 go は無理にユーザプログラムを邪魔してまで、 使用されていないメモリの開放を行なわない。\nとはいえ、全く開放せずに、際限なく heap を確保することは現実的に出来ないので、 あるタイミングで GC を実行する。 この GC タイミングの頻度を上げる(あるいは下げる)ことが、 環境変数 GOGC, GOMEMLIMIT の役割である。\n細かい話は次の公式ドキュメントを見てもらうのが一番だが、 それを言ったらここで話が終ってしまうので少し補足をする。\n\u0026lt;https://go.dev/doc/gc-guide\u0026gt;\n\u0026lt;https://github.com/golang/proposal/blob/master/design/48409-soft-memory-limit.md\u0026gt;\n\u0026lt;https://pkg.go.dev/runtime/debug@go1.19.2\u0026gt;\nGOGC 環境変数 GOGC は、 GC を開始するかどうかを判定する際の指標を設定する。\nSetGCPercent sets the garbage collection target percentage: a collection is triggered when the ratio of freshly allocated data to live data remaining after the previous collection reaches this percentage. SetGCPercent returns the previous setting. The initial setting is the value of the GOGC environment variable at startup, or 100 if the variable is not set. This setting may be effectively reduced in order to maintain a memory limit. A negative percentage effectively disables garbage collection, unless the memory limit is reached. See SetMemoryLimit for more details. 設定する値は 100 が基準値で、マイナスは GOMEMLIMIT(後述) だけで制御することを意味する。\nじゃぁ、 100 って具体的になんなのよ？っていうと、 前回 GC 後に残ったデータサイズに対して新しく確保されたデータの比率が 100 %に達したら GC を開始する。 という意味。\nつまり GOGC に指定した値が 100 とは、 前回 GC を実行し、利用されていて開放されなかったデータが 10MB あったら、 次に新しく 10MB 確保した時に GC を実行する。 という意味。\nこの時の動作は、以下 URL のグラフを見ると分かり易い。\n\u0026lt;https://go.dev/doc/gc-guide#GOGC\u0026gt; このグラフは、 GOGC をスライドバーで変更できる図になっていて、 デフォルトだと 100 になっている。 また、最大で 20MiB の heap を使うプログラムを動かした場合の heap サイズの変化を表わしている。\nGOGC が 100 の場合、 Live Heap がピークの 20MiB になった後、 Heap が 40MiB になった時(つまりは、新たに 20MiB 確保された時)に GC が働き、 未使用のメモリが開放されて、ピークの 20MiB に戻っている。\nGOGC のスライドを動かすと、 GOGC の値に応じてグラフが変化する。 ここで確認するべきは、 GC の働くタイミングが変るのはもちろんだが、 それとは別に、図の下部に表示されている GC CPU の値と、 Peak Mem に注目が必要である。\nGOGC を下げると、その分 Peak Mem は少なくなるが、GC 処理にかかる CPU 時間は増える。 一方で、GOGC を上げると、その分 Peak Mem は増えるが、GC 処理にかかる時間は減る。\nこのように 使用するメモリサイズと性能はトレードオフである。\nただ、メモリサイズが小さければその分キャッシュに載り易くなる。 すると、本来キャッシュに載っていた heap が、 GC 頻度を下げたことでキャッシュに載らなくなる、ことが考えられる。 この場合、キャッシュミスによるオーバーヘッドと、 GC 処理のオーバーヘッドのどちらが大きのか、を考慮する必要があるかもしれない。\nこの辺りは、 ユーザプログラムがどのような性質なのかを見極め 、 カスタマイズする必要がある。\nなお当然だが、 GOGC をどんな値にしたところで、ユーザプログラムにメモリリークがあれば、 メモリは消費される一方である。\nGOMEMLIMIT GOGC が、 GC の実行タイミングを制御する設定だったように、 環境変数 GOMEMLIMIT も GC の実行タイミングを制御する設定である。\nでは何が違うかというと、 GOGC は前回の Heap サイズに対する割合を指定する値だったが、 GOMEMLIMIT は Heap サイズそのものに対する値である。\nつまり、 Heap サイズが GOMEMLIMIT で指定した値になったら、GC を行なう。\nあくまで、GOMEMLIMIT は GC を行なうタイミングを指定するものであって、 GOMEMLIMIT で指定したサイズを越えないように保証するものではない、 ということは理解が必要である。\nGOMEMLIMIT の指定は、数値+単位で指定する。\n具体的には、 20MiB に指定したい場合は、 GOMEMLIMIT=20MiB を指定する。 単位は B, KiB, MiB, GiB, TiB が指定できるが、 go を利用するような環境は MiB か、 GiB が殆どだろう。\nなお、 GOMEMLIMIT は go 1.19 以降で利用可能。\n","id":17,"section":"posts","summary":"go は GC で heap メモリを管理している。 Java の場合、最大 heap サイズを指定し、 そのサイズを越えた場合は OutOfMemoryError になる。 最大 heap サイズが指定されていない場合はデフォ","tags":null,"title":"Golang の Heap メモリ制限","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-10-27-go-limit-heap/","year":"2022"},{"content":" LuneScript は、 Golang (1.16 以降)へのトランスコンパイルを対応しています。 また、LuneScript は Generics に対応しています。\n一方で、 Golang は version 1.18 から Generics に対応しています。\nつまり、 LuneScript は Golang が Generics 対応する前から Generics を利用できていました。\nでは、 Generics を利用していた LuneScript のコードを どうやって Generics 対応前の Golang にトランスコンパイルしていたかというと、 Generics の型パラメータの値を interface{} に変換して処理を行なっていました。\nJava でいうところの autoboxing のようなことを変換時にやっていた、 と思ってもらえば良いです。\nで、 Golang ネイティブで Generics 対応されて autoboxing する必要がなくなったので、 LuneScript の Golang へのトランスコンパイルで Golang の Generics を利用するように変更する検討作業に入りました。\n検討に利用する golang のバージョン 今回は以下の go のバージョンを利用して検討します。\n$ go version go version go1.19.2 linux/amd64 Generics のパフォーマンス確認 既存の処理を変更するので、 それなりのメリットがないと意味がないです。\nそのメリットとは、 autoboxing 相当の処理をやめて Golang ネイティブの Generics を利用することで、 多少なりとも処理が速くなるんじゃないか？ ということです。\nそのために、 次の処理を既存 autoboxing 処理と、 ネイティブの Generics 処理とで実行したパフォーマンスを比較します。\n「LuneScript の List\u0026lt;int\u0026gt; の要素の合計を計算する。」 テストコード 具体的なコードは以下です。\nこのコードの GenList[V any] が generics を利用した List\u0026lt;int\u0026gt; の構造で、 BoxingList が autoboxing を利用している従来の List\u0026lt;int\u0026gt; の構造です。\nそれぞれの構造に 1000 個の int 要素を事前に追加しておき、 リストから値を取りだしてトータルを計算する処理を 1000000 回繰替えして、 その時間を計測します。\npackage main import . \u0026#34;github.com/ifritJP/LuneScript/src/lune/base/runtime_go\u0026#34; var init_miniGo bool var miniGo__mod__ string // generics type GenList[V any] struct { items []V } func (list *GenList[V]) GetAt( index int ) V { return list.items[index] } var list GenList[int] func miniGo_generics(_env *LnsEnv) LnsInt { total := 0 for _forWork0 := 1; _forWork0 \u0026lt;= 1000000; _forWork0++ { for _forWork1 := 1; _forWork1 \u0026lt;= 1000; _forWork1++ { loop := _forWork1 total = total + list.GetAt(loop-1) // total = total + list.items[loop-1] } } return total } // autoboxing type BoxingList struct { items []any } func (list *BoxingList) GetAt( index int ) any { return list.items[index] } var boxing *BoxingList func miniGo_autoboxing(_env *LnsEnv) LnsInt { total := 0 for _forWork0 := 1; _forWork0 \u0026lt;= 1000000; _forWork0++ { for _forWork1 := 1; _forWork1 \u0026lt;= 1000; _forWork1++ { loop := _forWork1 total = total + boxing.GetAt(loop-1).(int) // total = total + boxing.items[loop-1].(int) } } return total } func Lns_miniGo_init(_env *LnsEnv) { if init_miniGo { return } init_miniGo = true miniGo__mod__ = \u0026#34;@miniGo\u0026#34; Lns_InitMod() list = GenList[int]{[]int{}} boxing = \u0026amp;BoxingList{[]any{}} { var _forFrom0 LnsInt = 1 var _forTo0 LnsInt = 1000 for _forWork0 := _forFrom0; _forWork0 \u0026lt;= _forTo0; _forWork0++ { count := _forWork0 list.items = append(list.items,count) boxing.items = append(boxing.items,count) } } miniGo_prev2 := _env.GetVM().OS_clock() Lns_print([]LnsAny{ \u0026#34;generics\u0026#34;, miniGo_generics(_env), \u0026#34;time = \u0026#34;, _env.GetVM().OS_clock() - miniGo_prev2}) miniGo_prev3 := _env.GetVM().OS_clock() Lns_print([]LnsAny{ \u0026#34;autoboxing\u0026#34;, miniGo_autoboxing(_env), \u0026#34;time = \u0026#34;, _env.GetVM().OS_clock() - miniGo_prev3}) } func MiniGo___main( _env *LnsEnv, args *LnsList ) LnsInt { Lns_miniGo_init( _env ) return 0 } func init() { init_miniGo = false } 実行結果 実行結果が以下です。\ngenerics\t500500000000\ttime = 2.1711650000000002 autoboxing\t500500000000\ttime = 0.9791500000000002 これを見ると分かりますが、 なんと ネイティブの Generics を利用した方が倍も遅くなってしまいました。\nこれは意外でした。\n効果がないどころか、逆に遅くなってしまいました。\nなお、 このサンプルプログラムでは List の要素にアクセスする際、 定義したメソッド GetAt() を介します。\nこのメソッドを通さずに直節メンバにアクセスするように変更したところ (コメントアウトしている箇所のコメントを外し、 その直前処理を代わりにコメントアウトする)、 次のように generics を利用した方が速く処理が終りました。\ngenerics\t500500000000\ttime = 0.6483559999999999 autoboxing\t500500000000\ttime = 1.000772 generics を利用したメソッドは、オーバーヘッドが異様に大きいという結果になりました。\nところで、 generics のメソッド対応方法って、これであってるよね？？\ntype GenList[V any] struct { items []V } func (list *GenList[V]) GetAt( index int ) V { return list.items[index] } まとめ 以上の結果をまとめると、次になります。\ngenerics を利用したメンバアクセスは、any との相互変換がなくなる分、速くなる。 但し generics を利用したメソッドのオーバーヘッドが大きい。 このことから、 LuneScript の autoboxing 処理をそのまま golang の generics へ 置き換えることはしません。\nですが、generics を利用した方が速くなるケースがあるのも事実なので、 今後も generics の検討を進めて、 効果的な適応方法が見つかったら対応を進めたいと思います。\n","id":18,"section":"posts","summary":"LuneScript は、 Golang (1.16 以降)へのトランスコンパイルを対応しています。 また、LuneScript は Generics に対応しています。 一方で、 Golang は version 1.18 から Generics に対応していま","tags":null,"title":"Golang の generics パフォーマンス","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-10-15-go-generics/","year":"2022"},{"content":" LuneScript Web Frontは今迄 fengari を利用していましたが、 golang の wasm で動かせるようにサポートしました。\nその際に golang の wasm の利用方法について調べたことをまとめておきます。\ngolang の wasm 基本的なことは以下の公式ドキュメントをみてください。\n\u0026lt;https://github.com/golang/go/wiki/WebAssembly\u0026gt;\n最低限のステップをまとめると、以下の手順になります。\n以下の環境変数を指定して WASM 化したいプロジェクトをビルドします。\nこれで main.wasm に WASM 化したコードが出力されます。 $ GOOS=js GOARCH=wasm go build -o main.wasm 以下の wasm_exec.js をコピーします。 $ cp \u0026#34;$(go env GOROOT)/misc/wasm/wasm_exec.js\u0026#34; . html で wasm_exec.js をロードし、JS から以下を実行すると wasm 化した go のプログラムが実行されます。\nconst go = new Go(); WebAssembly.instantiateStreaming(fetch(\u0026#34;main.wasm\u0026#34;), go.importObject).then((result) =\u0026gt; { go.run(result.instance); }); 以上のステップで、 go.run(result.instance); のタイミングで go の main が実行されます。\nos.Args の引数 golang は、コマンドライン引数を os.Args で処理します。\nJavaScript から golang のモジュールを実行する際に引数を指定するには、 以下のように go.run() する前に argv 変数にリストをセットします。\ngo.argv = [ \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34; ]; go.run(result.instance); これで、 golang 側の os.Args には [ \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34; ] が格納されて実行されます。\nただし、 この go.argv の説明が go のドキュメントに記載がないため、 将来使えなくなる可能性があります。\n注意点 ここで注意点として、以下が挙げられます。\n再度 main を実行する場合は、 JS の new Go() から実行しなおします。 goroutine は、複数同時には動作しません。\nGOMAXPROCS=1 を指定した時と同じ動作になります。 Golang から JavaScript へのアクセス golang の wasm は、 main を実行するだけです。\nこれだけでは、 折角 wasm 化した golang のモジュールを有効に使えません。\n有効に利用するには、 Golang と JavaScript を互いに連携させる必要があります。\nこの連携をするための仕組みとして、 go には \u0026#34;syscall/js\u0026#34; パッケージが提供されています。\nこのパッケージには、主に以下が提供されています。\ngolang のデータと JavaScript との相互データ変換処理 golang から JavaScript の関数コール処理 例えば、 golang から JavaScript のグローバル変数 hoge に 1 をセットするには、 以下を実行します。\njs.Global().Set(\u0026#34;hoge\u0026#34;, 1) \u0026#34;syscall/js\u0026#34; パッケージでは、 JavaScript 側のオブジェクトは 全て Value 型 でアクセスします。\n例えば、上記の js.Global() は JavaScript のグローバルスコープを返しますが、 この時の戻り値は Value 型です。\nこの Value 型は JavaScript のオブジェクトを管理し、 Value 型のメソッドを通して、 値の設定や取得、 JavaScript の関数の実行などができます。\n例えば、以下を golang で実行すると、 JavaScript の console.log( \u0026#39;hoge\u0026#39; ) が実行されます。\njs.Global().Get(\u0026#34;console\u0026#34;).Get(\u0026#34;log\u0026#34;).Invoke(\u0026#34;hoge\u0026#34;) 上記で示した通り、JavaScript の関数の実行は Invoke() です。 この関数の戻り値も Value 型です。 これは、Invoke() で実行した JavaScript の関数の戻り値を管理しています。 この Value のメソッドの Bool(), Int(), String() などを利用することで、 Value 型で管理している値を取得できます。\nJavaScript から Golang の関数の呼び出し go.run(result.instance); は、 golang の main() 関数を実行します。\nしかし、これでは Go の任意の関数を実行することができません。\nGo の任意の関数を実行するには、 JavaScript 側に golang の関数オブジェクトを渡す必要があります。\nJavaScript 側に golang の関数オブジェクトを渡す方法としては、 次の 2 つがあります。\nValue.Set() 関数を利用し、 JavaScript の任意のオブジェクトに golang の関数オブジェクトを Set する。 golang から JavaScript の関数を実行する際、 その関数の引数として golang の関数オブジェクトを渡す。 ここでは、 Value.Set() を利用する方法について例を挙げて説明します。\nJavaScript から実行する golang の関数宣言 JavaScript から実行可能な golang の関数は、次の型でなければなりません。\nfunc jsFunc(this js.Value, args []js.Value) interface{} { } ここで args は、JavaScript からこの関数を実行する際に指定した引数の情報です。 Value 型のスライスなので、実際に処理する際は String() 等のメソッドを利用し、 golang の型に変換して処理を行ないます。 なお、関数名は何でも良いです。 関数名のない関数オブジェクトでも可能です。\n戻り値は interface{} です。 int, bool, string などは、そのまま返すことが出来ます。 また、スライスや map もそのまま返せます。\nValue.Set() を使って、 golang 関数の登録 JavaScript から実行可能な関数として宣言した関数を、 Value.Set() を使って JavaScript 側に登録します。\njs.Global().Set(\u0026#34;_hoge\u0026#34;, js.FuncOf( jsFunc )) ここで js.FuncOf() は、 golang の関数オブジェクトを Value 型に変換する API です。\nこれにより、 JavaScript 側で以下を実行すると golang の関数が実行できます。\n_hoge() 注意点 ここで注意点です。\ngolang の wasm のモジュールは、 golang の main() 関数を実行している間だけ有効です。\nこれがどういうことかというと、 上記のステップで JavaScript の _hoge に、 golang の jsFunc() 関数を登録しましたが、 この _hoge を実行できるのは、 main() を実行している間だけです。\n例えば、以下のように main() で処理していると、\nfunc main() { js.Global().Set(\u0026#34;_hoge\u0026#34;, js.FuncOf( jsFunc )) } JavaScript 側で jsFunc() を実行する際には main() が終っているため、 _hoge() を実行できない、ということです。\nではどうすれば良いかというと、 次のようにチャンネルの読み込みを入れて、 main() を終了しないようにします。\nfunc jsFunc(this js.Value, args []js.Value) interface{} { } func main() { js.Global().Set(\u0026#34;_hoge\u0026#34;, js.FuncOf( jsFunc )) \u0026lt;-make( chan bool ) } これにより main() が終了しないため、 JavaScript 側から _hoge() を実行できます。\nmain() の終了検知 上記の通り、 go.run() 実行後に golang 内の関数を実行するには、 main() が終わらないようにする必要があります。\nここで、理解の早い方は、 「 main() が終らないのに go.run() が戻ってくるのか？」 と疑問に思うでしょう。\nそこは大丈夫です。\n実は go.run() API は、async 宣言された関数です。\nよって、 await を付けずに実行した場合、 go.run() は main() が終わらなくても処理が戻ってきます。\nもしも main() の実行を検出したい場合は、 await で go.run() を実行するか、 Promise の then() で処理を書きます。\nwasm のパフォーマンス これまでブラウザ上で実行可能な言語が javascript に制限されていたのが、 wasm によってその制限が無くなりました。\nしかし、現時点で wasm の実行パフォーマンスは、 ブラウザによって大きく異なるようです。\nfengari と golang の wasm とで次の lua コードの実行時間を計測したところ、\nlocal function fib( num ) if num \u0026lt; 2 then return num end return fib( num - 2 ) + fib( num - 1 ) end firefox では fengari の方が若干速く終了し、 chrome では wasm の方が爆速で終了しました。\nなお、 chrome 上で動作させた fengari は、 firefox 上で動作させた fengari よりも早いです。 つまり、 JavaScript, wasm ともに chrome の方が高速に処理できます。\nまた、 golang を wasm に変換すると、 生成した wasm のサイズが大きくなります。\n実行時のパフォーマンスがブラウザによって大きく依存する点や、 wasm のサイズをトータルで考えると、 golang の wasm を安易に利用するべきではないです。\nなお、 golang の公式ドキュメントに TinyGo が紹介されている通り、 TinyGo では standard golang と比べると、 wasm のサイズが小さく使い勝手も良いようなので、 TinyGo を検討してみると良いと思います。\nただし、TinyGo は go の幾つかの標準パッケージを対応していないため、 それらパッケージを利用したプロジェクトは、 TinyGo を利用することができません。\nLuneScript はその制限に該当したため、 TinyGo ではなく standard golang で wasm 対応しています。\n","id":19,"section":"posts","summary":"LuneScript Web Frontは今迄 fengari を利用していましたが、 golang の wasm で動かせるようにサポートしました。 その際に golang の wasm の利用方法について調べたことをまとめておき","tags":null,"title":"Golang の WASM (Golang から JavaScript の呼び出し, JavaScript から Golang の呼び出し)","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-09-19-go-wasm/","year":"2022"},{"content":" \u0026lt;http://localhost:1313/posts/2020/2020-08-01-lunescript-man-hour/\u0026gt;\n以前 LuneScript の工数を考えたが、今回は別の面から工数を考えてみる。\nソフトウェア開発分析データ集2020 \u0026lt;https://www.ipa.go.jp/ikc/reports/20200930.html\u0026gt;\n上記のリンク先の資料「ソフトウェア開発分析データ集2020」の p.84 に、 新規開発の SLOC 生産性の表「A1-2-1 SLOC 規模別 SLOC 生産性(新規開発)」がある。\nこの表には、コード規模毎に最小、最大、平均の SLOC 生産性が載っている。\nこのデータから LuneScript の工数を計算する。\nLuneScript の工数 LuneScript の現在の規模はコメント含んで約 56 Kline。 SLOC は本来コメントを除外した行数だが、 マジメにコメントを除外するのは面倒なので 仮に 20% がコメント だとする。\nすると、 LuneScript の規模は 44.8 KSLOC になる。\n先程の参照先の表 A1-2-1 から、この規模の生産性を見ると、\n平均: 0.75KSLOC/160人時 となる。\nここで、160 人時は一人あたりの 一月のフルタイムの勤務時間 。\nこれを元に LuneScript の 44.8 KSLOC の工数を計算すると、\n59.73 (/ 44.8 0.75) つまり、 フルタイム勤務の平均の生産性 で開発すると、 LuneScript は 59.73 人月 かかることになる。\nフルタイム勤務で平均 59.73 人月 (= 約5年) かかることを、 プライベートな時間で今の形までもってこれたのは、 我ながらなかなかのことだったんじゃないかと思う。\nただし、参照先の表 A1-2-1 は、開発工程(基本設計〜テスト)までの 期間の生産性である。 一方で、 LuneScript はいろいろな工程をすっ飛ばしている。 それによって早いってのはある。\nなお、参照先の表には、 最大の生産性 も載っているので、 それを使って計算すると以下になる。\n最大: 2.45 KSLOC/160人時 18.29 (/ 44.8 2.45) このように、最大の生産性でもフルタイム勤務で 18.29 人月 かかる、ということになる。\nさいごに 一般的な生産性と比べても、LuneScript は頑張った。\nもう、これで良いよね。\n","id":20,"section":"posts","summary":"\u0026lt;http://localhost:1313/posts/2020/2020-08-01-lunescript-man-hour/\u0026gt; 以前 LuneScript の工数を考えたが、今回は別の面から工数を考えてみる。 ソフトウェア開発分析データ集2020 \u0026lt;https://www.ipa.go.jp/ikc/reports/20200930.html\u0026gt; 上記のリンク先の資料「ソフトウェア開発分析","tags":null,"title":"LuneScript の工数( SLOC )","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-08-04-sloc/","year":"2022"},{"content":" wstcplink を作った。\n\u0026lt;https://github.com/ifritJP/wstcplink\u0026gt;\nこれが何かというと、 WebSocket client と TCP client の中継ツールだ。\n次のような感じ。\n⇔⇔⇔⇔⇔⇔⇔⇔ Webブラウザ → このツール ← tcp クライアント ⇔⇔⇔⇔⇔⇔⇔⇔ Web アプリケーションとの双方向通信 Web アプリケーションで双方向通信するには、 web socket を使うのが標準だと思う。 (web socket にも課題はあるが、その辺りはここでは触れない。)\nで、その場合 web socket に対応したサーバが必要になる。\n一方で、web socket に対応するのが困難な環境もある。 イマドキの環境なら web socket 対応のサーバくらい簡単に対応できる、 と思う人もいるかもだが、「イマドキの環境」じゃない環境はいくらでもある。\nそういった web socket への対応は困難な環境でも、 TCP は利用可能だったりする。\nTCP がダメなら UART でもなんでも良いが。\nともかく、そういった web socket 対応が困難な環境と、 Web アプリケーションとを双方向通信したい、というのが、 この wstcplink の開発動機だ。\nWeb アプリケーションから直接 TCP を叩く拡張機能も提案されているようだが、 少なくとも現時点では一般的に使えないし、 個人的には使えるべきではないとも思うので、今回は触れない。\nメリット このツールの特徴として、 Web アプリケーションとの接続対象が、 TCP Server ではなく TCP Client だ、ということが挙げられる。\nこれの何が特徴かというと、 TCP Client なので主体的に動ける、ということだ。 いつでも好きなタイミングで接続・切断が可能だ。\nそして、このツールの1つのポートへのセッションを 1 つに限定し、 そのセッションを維持することで、 Web アプリケーションと、 TCP クライアントとの接続がいつでも再接続できる。\n一般的な双方向通信を行なうシステムの開発は、 どちらかを再起動する時はもう片方のネットワークの再接続を行なう必要がある。 しかし、このツールがサーバとして中継してセッションを維持することで、 一方の接続が切れても、もう一方はそのまま接続を維持していることが出来る。\nもう少し具体的に言えば、 Web アプリケーション、あるいはその接続先のコードを編集して、 再実行するには通常は両方を再接続しなおさないといけないが、 このツールを挟むことで、一方だけを再接続するだけで良い。\nこれにより、Web アプリケーションと TCP Client の接続が簡単になり、 開発がスムーズに行なえる。\n使い方 このツールは、次のコマンドラインオプションを指定する。\n$ wstcplink server \u0026lt;link\u0026gt; [\u0026lt;link\u0026gt;...] こので server は、サーバモードの起動を指定するオプションだ。\nlink は、 WebScoket と TCP の listen するポートを指定する。\n指定は次のように行なう。\n:10000,:10001 ここで、最初の :10000 は websocket のポート番号を指定し、 次の :10001 は tcp のポート番号を指定する。 これによって、 10000 番ポートの websocket アクセスと、 10001 番ポートの tcp アクセスが接続される。\nなお、次のように指定することで、 内部からの通信のみを受けつけるように限定できる。\nlocalhost:10000,localhost:10001 まとめると、以下のように指定する。\nwstcplink server :10000,:10001 link は次のように複数指定できる。\nwstcplink server :10000,:10001 :20000,:20001 サンプル 動作確認用として wstcplink は、 websocket client 機能を持っている。\nこの機能と telnet コマンドを利用することで、 このツールの動きを確認できる。\nwstcplink を起動する $ wstcplink server :10000,:10001 websocket client を接続する $ wstcplink test-wsclient :10000 telnet (tcp client) を接続する $ telnet localhost 10001 これで、 websocket client と、telnet (tcp client) が接続されたので、\nwebsocket client 側で文字を入力すれば telnet 側で表示され、 telnet 側で入力すれば、websocket client 側に表示される。\nまた、どちらかを切断して再接続すれば、 一方は接続を保ったままセッションが維持されることが分かる。\n","id":21,"section":"posts","summary":"wstcplink を作った。 \u0026lt;https://github.com/ifritJP/wstcplink\u0026gt; これが何かというと、 WebSocket client と TCP client の中継ツールだ。 次のような感じ。 ⇔⇔⇔⇔⇔⇔⇔⇔ Webブラウザ → このツール ← tcp クライアント ⇔⇔⇔","tags":null,"title":"WebSocket client と TCP client の中継ツールを作った","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-06-01-wstcplink/","year":"2022"},{"content":" 家で運用している Raspberry pi サーバイメージのバックアップを shrink するのに どうするのが良いのか調べていたら、\nhttps://github.com/Drewsif/PiShrink\nを使えばいいだけだということが分かった。\n事前に raspi の sdcard イメージファイルを作って、 それを以下のように実行すれば ok.\n$ sudo pishrink.sh sdcard.img これを実行すると、次が行なわれる。\n指定のイメージファイル内の /etc/rc.local が /etc/rc.local.bak にバックアップされる 指定のイメージファイル内の /etc/rc.local に、以下を実行するスクリプトが作成される。\nshrink させたファイルシステムを expand する /etc/rc.local.bak のバックアップを /etc/rc.local に戻す 指定のイメージファイルが shrink される これでイメージファイルが shrink されるので、 このファイルを sdcard に書き戻して raspi を起動させると、 起動時に expand される。\n以上。\n","id":22,"section":"posts","summary":"家で運用している Raspberry pi サーバイメージのバックアップを shrink するのに どうするのが良いのか調べていたら、 https://github.com/Drewsif/PiShrink を使えばいいだけだということが分かった。 事前","tags":null,"title":"Raspberry pi イメージのバックアップ","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-04-30-raspi-backup/","year":"2022"},{"content":" M5stack の公式 Web サイトを見ると、 M5stack の開発環境は以下のものが挙げられています。\n\u0026lt;https://docs.m5stack.com/en/platform\u0026gt;\nUIFlow Arduino Camera Series Micropython .NET nanoFramework これらは、ソフトウェアを簡単に開発することにフォーカスされていて、 Bluetooth を制御する API の充実度は低いようです。\n上記の開発環境で提供されていない Bluetooth の機能を利用するには、 ESP32 の official SDK の esp-idf か、 汎用的な Bluetooth Library の btstack を使う必要があります。\nM5stack で Bluetooth の機能を利用するアプリを開発する場合、 その機能がどの開発環境で提供されているかを調査し、 その中から使い易い環境で開発を進める、 というようにすると、効率良く開発を進められます。\nまた、プロファイル自体はサポートされていても、 実際に動かすと思うように動かないことがあるので、 API の有無だけで判断するのではなく、サンプル等を実際に動かして確認する 必要があります。\nそして、各開発環境は日々機能が拡張されているので、 最新の環境で調査するべき です。\nここでは、 btstack を使った Bluetooth Keyboard の Device と Host の制御方法について 説明します。\nBluetooth の基本 ここでは、 Bluetooth の制御に必要な基本的な知識をまとめます。\nBluetooth classic と BLE Bluetooth は、 Version 4.0 で新しい制御方式 BLE (Bluetooth Low Energy) が 追加になりました。 この BLE は、それまでの方式 classic (BR/EDR) と互換性がないもので、 ハードウェア構成も異なります。\nBluetooth のハードウェアモジュールには、以下の構成があります。\nclassic のみサポート (Bluetooth) BLE のみサポート (Bluetooth Smart) classic/BLE 両方サポート (Bluetooth Smart Ready) なお、市販されている多くの Bluetooth キーボードは基本的に classic です。\nハードウェア構成が違えば、当然それを制御するソフトウェア側にも対応が必要です。\nソフトウェアも、ハードウェアモジュールと同様に以下の構成があります。\nclassic のみサポート BLE のみサポート classic/BLE 両方サポート ESP32 のハードウェア自体は、classic/BLE 両方サポートしていますが、 Bluetooth ライブラリがどのような対応になっているかは、ライブラリ依存です。\n対象の Bluetooth 機器が classic/BLE どちらなのかを調べるには、 スマホ用の Bluetooth 解析アプリを使うと簡単に確認できます。\ndevice と host Bluetooth には、 keyboard などの機器と、それらを接続して利用する機器があります。\n前者を device、後者を host といいます。\nこれは論理的なソフトウェア制御の違いで、Bluetooth ハードウェアモジュール自体は、 device にも host にもなれます。\nclassic/BLE と device/host Bluetooth のソフトウェア制御は、次の 4 つの組み合わせに分けられます。\nclassic の device classic の host BLE の device BLE の host これは論理的な制御の組み合わせであり、 技術的にはこれらの組み合わせを複数同時に利用することも可能です。\nしかし、Bluetooth ライブラリが複数同時利用に対応しているかどうかは別の問題です。\nbtstack \u0026lt;https://github.com/bluekitchen/btstack\u0026gt;\nbtstack は、汎用的な Bluetooth stack ライブラリで、 ESP32 に限らず複数のチップをサポートしています。\nbtstack は、esp-idf をインストールしている環境に、 btstack のライブラリを追加でインストールして利用する形態になります。\nbtstack を利用する際のセットアップ方法は、以下を参照してください。\n\u0026lt;https://github.com/bluekitchen/btstack/tree/develop/port/esp32\u0026gt;\nbtstack のソフトウェアデザイン イベントとコールバック btstack は、非同期に処理を行なうため、 各種イベントごとにコールバック関数を登録する方式を採用しています。\n例えば、「ペアリングの要求を受けた場合にその要求を許可するかどうか」や、 「接続が切断された場合にどう処理するか」をコールバックに登録した関数で処理します。\nどのようなイベントがあり、 そのコールバックではどのような情報を取得できるかは、 以下のソースで確認できます。\nbtstack/src/btstack_event.h また、そのコールバックでどのような処理が必要なのかは、 各サンプルプログラムを確認すると分かります。\n大部分のイベントは、単に状態を通知するためのものであり、 処理しなければならないイベントは極僅かです。\nなお、一つのイベントに対して複数のコールバックを登録できるものと、 一つのイベントに対して 1 つのコールバック登録に制限されるものがあります。\nペアリングデータの保存 Bluetooth は、ペアリングで取得した情報を保持しておき、 その情報をもとに再起動などの時に再接続を行ないます。\nつまり、この情報は不揮発の情報として保持しておく必要があります。\nbtstack のライブラリ内には、 これらの情報を FLASH の NVS 領域に保持する処理が書かれているので、 ユーザプログラムで直接それらの情報にアクセスする必要はありません。\n一方で、ペアリングの情報を削除したい、というようなケースがあると思います。 その場合、以下の関数を呼ぶと、これらの情報を削除できます。\ngap_drop_link_key_for_bd_addr( addr ); le_device_db_remove( index ); あるいは、少し強引な方法ですが、 NVS の namespace \u0026#34;BTstack\u0026#34; のデータを全て削除し、再起動する方法でも削除可能です。\nclassic の host M5stack に classic の keyboard 等を接続して利用する場合、 classic の host 制御が必要になります。\nbtstack の classic host のサンプルプログラムは以下にあります。\nbtstack/port/esp32/example/hid_host_demo このサンプルの中の主な処理は以下です。\nclassic HID ホストの初期化 周辺の classic デバイス有無のスキャン 指定の classic デバイスへのペアリング ペアリング済みの classic デバイスからの接続要求許可 各処理を以降で説明します。\nclassic HID ホストの初期化 hid_host_init(s_hid_descriptor_storage, sizeof(s_hid_descriptor_storage)); hid_host_register_packet_handler(packet_handler_host); gap_set_default_link_policy_settings( LM_LINK_POLICY_ENABLE_SNIFF_MODE | LM_LINK_POLICY_ENABLE_ROLE_SWITCH); hci_set_master_slave_policy(HCI_ROLE_MASTER); ここでは、classic HID ホストの初期化と、 コールバックの登録を行なっています。\n周辺の classic デバイス有無のスキャン M5stack を device と接続するには、 接続先デバイスの BD_ADDR が必要です。\nこの BD_ADDR を取得するために、周辺デバイスのスキャンを行ないます。\nなお、事前に接続先デバイスの BD_ADDR が分かっている場合、 スキャンは不要です。\nこのスキャンのサンプルは、以下にあります。\nbtstack/port/esp32/example/gap_inquiry/main/ 指定の classic デバイスへのペアリング 接続先デバイスの BD_ADDR を以下の関数に渡すことで、 そのデバイスと接続が行なわれます。\nhid_host_connect( addr, s_hid_host_report_mode, \u0026amp;s_hid_info_in.cid); なお、ペアリングが成功すると、 ペアリング情報が btstack ライブラリによって FLASH ROM の NVS 上に記録されます。\nこの情報によって、次回からキーボード側からの接続要求を受けることが可能になります。\nペアリング済みの classic デバイスからの接続要求許可 前述の通り、一度ペアリングすることで、 そのペアリング情報が NVS に記録され、 キーボード側からの接続要求を受けることが可能になります。\nこの接続要求を受けると、 HID_SUBEVENT_INCOMING_CONNECTION イベントのコールバック関数が呼び出されます。\nこのコールバック関数で以下を実行することで、 接続要求が受け入れられて接続が確立します。\nhid_host_accept_connection( cid, s_hid_host_report_mode ); classic の device M5stack を Bluetooth keyboard として動作させる場合、 classic の device 制御が必要になります。\nbtstack の classic device のサンプルプログラムは以下にあります。\nbtstack/port/esp32/example/hid_keyboard_demo このサンプルの中の主な処理は以下です。\nclassic HID Device の初期化 discoverable の設定 report の送信要求 report の送信 ペアリング後の接続 各処理を以降で説明します。 classic HID Device の初期化 ここでは、classic HID device の初期化と、 コールバックの登録を行なっています。\ngap_set_class_of_device( bt_kb_getCod() ); gap_set_local_name( s_hid_device_name ); gap_set_default_link_policy_settings( LM_LINK_POLICY_ENABLE_ROLE_SWITCH | LM_LINK_POLICY_ENABLE_SNIFF_MODE ); gap_set_allow_role_switch(true); hid_create_sdp_record(s_hid_service_buffer, 0x10001, \u0026amp;hid_params); sdp_register_service(s_hid_service_buffer); device_id_create_sdp_record( s_device_id_sdp_service_buffer, 0x10003, DEVICE_ID_VENDOR_ID_SOURCE_BLUETOOTH, BLUETOOTH_COMPANY_ID_BLUEKITCHEN_GMBH, 1, 1); sdp_register_service(s_device_id_sdp_service_buffer); hid_device_init(hid_boot_device, hidDescriptorLen, pHidDescriptor ); s_hci_event_callback_registration.callback = \u0026amp;packet_handler; hci_add_event_handler(\u0026amp;s_hci_event_callback_registration); hid_device_register_packet_handler(\u0026amp;packet_handler_device); discoverable の設定 PC 側のスキャンでリストされるように、 discoverable を有効にします。\ngap_discoverable_control( 1 ); この状態で、 PC 側からペアリング処理を行なうと、ペアリングが完了します。\nreport の送信要求 ペアリングが完了しても、 キーの押下情報を送るにはライブラリ側の準備が必要です。\nその送信準備を要求するのが、以下の関数です。\nhid_device_request_can_send_now_event( s_hid_info_out.cid ); report の送信 hid_device_request_can_send_now_event() の送信要求によって、 送信準備が行なわれ、準備が整うと HID_SUBEVENT_CAN_SEND_NOW イベントの コールバックが呼ばれます。 このコールバックで以下を実行することで、レポートが送信されます。\nhid_device_send_interrupt_message( cid, hidReport, sizeof(hidReport)); 前述の送信要求と、送信は非同期に行なわれるので、注意が必要です。\nペアリング後の接続 ペアリング後、再起動時などで devicd 側からホストに接続する場合、以下を実行します。\nkey_hid_device_connect( addr ); BLE の device M5stack を BLE keyboard として動作させる場合、 BLE の device 制御が必要になります。\nbtstack の BLE device のサンプルプログラムは以下にあります。\nbtstack/port/esp32/example/hog_keyboard_demo このサンプルの中の主な処理は以下です。\nBLE HID Device の初期化 discoverable の設定 report の送信要求 report の送信 ペアリング後の接続 各処理を以降で説明します。 BLE HID Device の初期化 ここでは、classic HID device の初期化と、 コールバックの登録を行なっています。\nsm_set_io_capabilities(IO_CAPABILITY_NO_INPUT_NO_OUTPUT); sm_set_authentication_requirements( SM_AUTHREQ_SECURE_CONNECTION | SM_AUTHREQ_BONDING); // setup ATT server att_server_init(profile_data, NULL, NULL); // setup battery service battery_service_server_init( 100 ); // setup device information service device_information_service_server_init(); // setup HID Device service hids_device_init(0, get_hidDescriptor(), get_hidDescriptorLen() ); // setup advertisements gap_advertisements_set_params( adv_int_min, adv_int_max, adv_type, 0, null_addr, 0x07, 0x00); gap_advertisements_set_data( sizeof(adv_data), (uint8_t*) adv_data); // register for SM events static btstack_packet_callback_registration_t sm_event_callback_registration; sm_event_callback_registration.callback = packet_handler; sm_add_event_handler(\u0026amp;sm_event_callback_registration); // register for HIDS hids_device_register_packet_handler(packet_handler); discoverable の設定 PC 側のスキャンでリストされるように、 discoverable を有効にします。\ngap_advertisements_enable(1); ペアリングの受け入れ PC 側からペアリング要求が来た際、 そのペアリングを受け入れるかどうかをコールバックで処理します。\n発生するイベントは、 BLE を初期化した時の以下の関数の引数によって変わります。\nsm_set_io_capabilities(); sm_set_io_capabilities の引数と動作 IO_CAPABILITY_DISPLAY_YES_NO PC 側とデバイス側にコードが表示され、同じコードであるかをユーザが確認し、 問題なければペアリングする。\nペアリング要求を受けると、 SM_EVENT_NUMERIC_COMPARISON_REQUEST イベントが通知されるので、 受け入れるかどうかを処理する。\nIO_CAPABILITY_KEYBOARD_ONLY PC 側にコードが表示される。 ユーザがそのコードを M5stack に入力し、 M5stack は、入力されたコードを PC に通知する。 一致すればペアリングする。\nPC にコードを通知する際、以下の関数を使用する。\nsm_passkey_input() これをサポートするには、 ユーザが数値を M5stack に入力できるようにする機能が必要になる。\nIO_CAPABILITY_NO_INPUT_NO_OUTPUT PC 側とデバイス側にペアリングするかどうかを確認する画面を表示し、 「ペアリングする」が選択された場合に、ペアリングする。\nSM_EVENT_JUST_WORKS_REQUEST イベントで処理される。\nイベントと処理 SM_EVENT_JUST_WORKS_REQUEST イベント ペアリングを受け入れる場合は以下を実行\nsm_just_works_confirm(sm_event_just_works_request_get_handle(packet)); ペアリングを拒否する場合は以下を実行\nsm_bonding_decline( sm_event_just_works_request_get_handle(packet) ); SM_EVENT_NUMERIC_COMPARISON_REQUEST イベント PC から通知されたキーが、 PC 側に表示されているキーと等しいかどうかを確認して、 ペアリングを受け入れます。\nこれは、 device 側にディスプレイがあるケースで利用します。\n通知されるキーは、以下で取得できます。\nsm_event_numeric_comparison_request_get_passkey(packet) ペアリングを受け入れる場合は以下を実行\nsm_numeric_comparison_confirm( sm_event_numeric_comparison_request_get_handle(packet)); ペアリングを拒否する場合は以下を実行\nsm_bonding_decline( sm_event_numeric_comparison_request_get_handle(packet) ); case SM_EVENT_PASSKEY_DISPLAY_NUMBER イベント PC 上に表示された確認用キーを、デバイス上で入力して PC 側に送ります。 これが一致することで、ペアリングを確定します。\nこれは、ディスプレイがなく、キー入力が可能なケースで利用します。\n確認用キーは以下で取得します。\nsm_event_passkey_display_number_get_passkey(packet) 送り返す場合は、以下を実行します。\nsm_passkey_input() report の送信要求 ペアリングが完了しても、 キーの押下情報を送るにはライブラリ側の準備が必要です。\nその送信準備を要求するのが、以下の関数です。\nhids_device_request_can_send_now_event( s_con_handle ); report の送信 前述の送信要求によって、 送信準備が行なわれ、準備が整うと HIDS_SUBEVENT_CAN_SEND_NOW イベントの コールバックが呼ばれます。 このコールバックで以下を実行することで、レポートが送信されます。\nhids_device_send_boot_keyboard_input_report() あるいは\nhids_device_send_input_report() 前述の送信要求と、送信は非同期に行なわれるので、注意が必要です。\nペアリング後の接続 ペアリング後、再起動時などで devicd 側からホストに接続する場合、以下を実行します。\ngap_advertisements_enable(1); 以上。\n","id":23,"section":"posts","summary":"M5stack の公式 Web サイトを見ると、 M5stack の開発環境は以下のものが挙げられています。 \u0026lt;https://docs.m5stack.com/en/platform\u0026gt; UIFlow Arduino Camera Series Micropython .NET nanoFramework これらは、ソフトウェアを簡単に開発することにフォーカス","tags":null,"title":"M5stack(ESP32) で Bluetooth(btstack) の機能を利用する際の注意点","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-02-23-m5stack-btstack/","year":"2022"},{"content":" 前回 Raspberry pi zero w 版の keyboard remapper に引き続き、 M5stack 版の keyboard remapper を作成しました。\nM5stack は、 Raspberry pi zero w と比べて以下の長所があります。\nモデルによっては小型軽量 基板が剥き出しになっていない 今は Raspberry pi より入手性が良い 消費電力が 1/5 以下 本体に汎用的に使えるボタンが付いている モデルによっては、本体にディスプレイが付いている 一方で、以下の短所があります。\nROM/RAM が圧倒的に少ない 独自 OS で、開発環境が限定的 情報が少ない 環境構築に時間がかかる 動作確認にはファーム書き換えが必要で、時間がかかる(数十秒程度だが回数が多くなると気になる) 長所で挙げた項目を魅力に感じない場合は、 Raspberry pi zero w の方が良いでしょう。\nとはいえ、 暫くは半導体不足の影響で Raspberry pi zero w が入手不可能に近いため、 必然的に M5stack を選択することになるでしょう。\nなお値段は、モデルによりますが、多くの場合 M5stack の方が高いです。 ただこれは、M5stack が高いというより Raspberry pi zero w が安いというべきでしょう。\n構成 M5stack 版の keyboard remapper は、 Bluetooth キーボードの中継器のような動きになります。\nPC 等とキーボードの間の Bluetooth 通信に M5stack を入れ、 そこで任意のキー入れ替えを行ないます。\n接続先はBluetooth keyboard に対応する端末であれば PC に限りませんが、 以降の説明では接続先を PC と記します。\nM5stack は、現状 USB Keyboad に対応していないため、 Bluetooth 接続に限定されます。\nUSB 対応が必要な場合は、 前述の Raspberry pi zero w 版 keyboard remapper を利用するか、 USB -\u0026gt; Bluetooth 変換などを利用してください。\nなお、 使用する M5stack は ATOM U を前提にしています。\nATOM シリーズであれば動くとは思いますが、 確認しているのは ATOM U だけです。\nATOM シリーズでなくても、 M5stack であれば、プログラムを少し変更するだけで動くとは思います。\nATOM U 特有の機能で利用しているものは、ボタンと LED だけです。 これらは、 M5stack シリーズでほぼ共通なので、 その部分を置き換えるだけで移植可能です。\ngit リポジトリ 以下で公開しています。\n\u0026lt;https://github.com/ifritJP/bt-keyboard-remapper\u0026gt;\n準備 M5stack に対応する開発環境には幾つか種類がありますが、 bt-keyboard-remapper は esp-idf の Ver4.4 を利用します。\nesp-idf は ESP32 のチップベンダが公式にサポートしている開発環境です。\n環境構築は面倒なので、 ここでは docker を使ってビルド、書き込み、設定まで行なう方法を説明します。\ndocker を使わずに自前で環境を構築したい人は、 以下の説明で利用する Dockerfile や docker-compose.yml の中を確認してください。\n手順 手順は以下のステップから成ります。\ngit の clone 設定 ビルド M5stack の接続 ビルドしたファームの書き込み コンソール接続 ※ docker は事前に設定していることを前提にしています。\nホストは Linux か WSL2 を使ってください。\ngit の clone 以下を実行し、 clone してください。\n$ git clone --depth 1 --recursive --shallow-submodules https://github.com/ifritJP/bt-keyboard-remapper.git 設定 以下を実行し環境を設定してください。\n$ cd bt-keyboard-remapper $ make setup ビルド 以下を実行しビルドしてください。\n$ make req-build-on-docker これにより、 docker のイメージとコンテナが作成され(名前: bt-kbd-remapper )、 そのコンテナ内で M5stack のファームがビルドされます。\n環境にもよりますが、このコマンドには 10 分程度掛ります。\nM5stack の接続 ここからは、M5stack を PC に接続して作業する必要があります。\nWSL2 の場合 WSL2 の場合、M5stack を認識させるためドライバーをインストールしてください。\nUSB ドライバー: \u0026lt;https://ftdichip.com/drivers/vcp-drivers/\u0026gt;\nまた、現時点では WSL2 から M5stack の COM に手軽にアクセスできないので (アクセスするにはカーネルのビルド等が必要)、 迂回して COM にアクセスするために hub4com を利用します。\n以下から hub4com をダウンロードし、\n\u0026lt;https://sourceforge.net/projects/com0com/files/hub4com/\u0026gt;\n展開した com2tcp-rfc2217.bat を windows 上で実行します。\ncom2tcp-rfc2217.bat COM8 5555 ここで COM8 は、 Windows が認識している M5stack の COM ポートを指定します。\nLinux の場合 カーネルがよほど古くないかぎり、 USB を接続するだけで /dev/ttyUSB? (? は数字) が認識されるはずです。\n書き込み M5stack を PC に接続した状態で、以下を実行します。\nlinux の場合 $ docker exec -it bt-kbd-remapper make -C /proj/bt-kbd-remapper burn COM=/proj/dev/ttyUSB0 ここで ttyUSB0 は、環境に合せて指定してください。\nWSL2 の場合 $ docker exec -it bt-kbd-remapper make -C /proj/bt-kbd-remapper burn HOSTPC=???.???.???.??? ここで ???.???.???.??? には、 Windows の IP を指定してください。\nコンソール接続 M5stack を PC に接続した状態で、以下を実行します。 これにより、 M5stack のコンソールが操作可能になります。\nM5stack のペアリングは、このコンソールを通して行ないます。\nここで指定する COM, HOSTPC は、前述の通りです。\nlinux の場合 $ docker exec -it bt-kbd-remapper make -C /proj/bt-kbd-remapper monitor COM=/proj/dev/ttyUSB0 WSL2 の場合 $ docker exec -it bt-kbd-remapper make -C /proj/bt-kbd-remapper monitor HOSTPC=???.???.???.??? コンソールは、 Ctrl を押下しながら ] で切断されます。\nコンソールの操作方法 前述の接続したコンソールを操作し、 M5stack をペアリングします。\nコンソールは、簡易的な対話型の UI を提供します。\n単に enter を入力すると、以下のプロンプトが表示されます。\nesp32\u0026gt; この状態でコマンドを入力することで、操作が可能です。\nhelp を入力すると、対応するコマンド一覧が表示されます。\nまた help につづいてコマンドを入力することで、 そのコマンドの説明が表示されます。\nesp32\u0026gt; help bt bt [-cDFlp] [-s dev-id] [-d host-id] [--sendkey=sendkey] [--initdev] [--inithost] [--scan=on or off or now] [--unpair=addr or \u0026#39;all\u0026#39;] [--wlist=\u0026#39;set\u0026#39; or \u0026#39;clear\u0026#39;] control bluetooth device -s dev-id connect to device -c dump channel -d host-id connect as device -D set discoverable as device -F clear discoverable as device --sendkey=sendkey send key as device --initdev init as device --inithost init as host -l list connections -p paired devices --scan=on or off or now scan devices. on or off --unpair=addr or \u0026#39;all\u0026#39; remove pair. --wlist=\u0026#39;set\u0026#39; or \u0026#39;clear\u0026#39; white list. 手順 以下を実行します。\nsetup モードに切り替え keyboard とのペアリング PC とのペアリング キーの入れ替え normal モードに切り替え 以降で、各ステップを説明します。\nsetup モードに切り替え bt-kbd-remapper は、次の 2 つのモードを持ちます。\nsetup normal setup モードは、ペアリングを行なうモードです。 normal モードは、setup モードでペアリングされた機器と自動で接続し、 キーの入れ替えを行なうモードです。 normal モードでは、新規のペアリングはできません。\nモード切り替えは、 config コマンドを利用します。\n単に config だけ入力すると、現在の設定を表示します。\nesp32\u0026gt; config mode: setup toHostAddr: 00:00:00:00:00:00 hidDeviceMode: bt demoMode: 0 以下を実行すると setup モードに切り替わります。\nesp32\u0026gt; config -m setup モード切り替えは M5stack を再起動させる必要があります。\nM5stack は以下の方法でリセットできます。\nM5stack のリセットボタンを押す コンソールで Ctrl t Ctrl r keyboard とのペアリング M5stack と接続したい keyboard を、事前にペアリングモードにセットします。\n次に以下を実行します。\nesp32\u0026gt; bt --inithost esp32\u0026gt; bt --scan=on これにより、ペアリング可能な Bluetooth 一覧をスキャンするので、 目的のキーボードの情報が出力されたら、以下を実行します。\nesp32\u0026gt; bt --scan=off これにより以下が出力されます。\n----scan result---- No.0: XX:XX:XX:XX:XX:XX, 0x2540 ==\u0026gt; ---- 次に、以下を実行しペアリングします。\nesp32\u0026gt; bt -s ? ここで ? には、 scan 結果の No.? の番号を指定します。\n数秒待つとペアリングが完了し、以下が出力されます。\nI (28798) console: console_hid_packet_handler_meta_bt: 2 I (28799) console: HID_SUBEVENT_CONNECTION_OPENED I (28811) console: CONSOLE_BT_STATE_CONNECTING HID Host connected. PC とのペアリング Bluetooth classic と BLE の切り替え bt-kbd-remapper では、 BT classic の HID keyboard と、 BLE の HID keyboard の HID モードを切り替え可能です。\n接続先の PC によって、キーボード接続や不安定や接続できない場合は、 HID モードを切り替えてください。\n切り替えは以下のコマンドで行ないます。\nesp32\u0026gt; config -h hidDevMode ここで hidDevMode は以下を指定します。\nclassic の場合 esp32\u0026gt; config -h bt BLE の場合 esp32\u0026gt; config -h le HID モード切り替えの反映はリブートが必要です。\nペアリング 以下を実行します。\nesp32\u0026gt; bt --initdev esp32\u0026gt; bt -D この状態で PC 側でペアリングします。\nペアリング終了後は、以下を実行して discoverable 状態を停止させます。\nesp32\u0026gt; bt -F キーの入れ替え キーの入れ替えは以下のコマンドを使用します。\nremap -k old,new remap -c code,mask,result,code,xor remap –b64read remap -p remap -k old,new このコマンドは、 HID キーコードを単純に置き換えます。\nold のコードを new のコードに置き換えます。\n例えば キーボードの A を B にする場合は、以下を実行します。\nesp32\u0026gt; remap -k 4,5 この HID コードの詳細は、次の USB の規格書を参照してください。\n各キーのコード情報は、以下の資料の 「10 Keyboard/Keypad Page (0x07)」 を参照\nhttps://usb.org/document-library/hid-usage-tables-122 Ctl, Alt 等の modifier キー情報は、以下の資料の「8.3 Report Format for Array Items」を参照\nhttps://www.usb.org/document-library/device-class-definition-hid-111 あるいは、ペアリングした状態でキーボードのキーを押下すると以下のようなログが出力されるので、 それも確認できます。\nI (8568910) console: console_hid_packet_handler_meta_bt: 12 [02:22:48.912] LOG -- btstack_util.c.258: 0xA1, 0x01, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x00, [02:22:48.924] LOG -- btstack_util.c.258: 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x00, 0x00, I (8568925) console: console_hid_packet_handler_meta_bt: 4 [02:22:48.936] LOG -- btstack_util.c.258: 0xA1, 0x01, 0x00, 0x00, 0x28, 0x00, 0x00, 0x00, 0x00, 0x00, I (8568978) console: console_hid_packet_handler_meta_bt: 12 [02:22:48.979] LOG -- btstack_util.c.258: 0xA1, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, [02:22:48.991] LOG -- btstack_util.c.258: 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, I (8568992) console: console_hid_packet_handler_meta_bt: 4 [02:22:49.003] LOG -- btstack_util.c.258: 0xA1, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, これは、 enter キーを押して離したときのログです。\n前半の 5 行が押下時で、後半の 5 行が離した時です。\n5行の構成は、上から順に以下になっています。\nkeyboard から report を受信したことを示すログ 受信した report の内容のダンプログ キー変換後のダンプログ PC 側への report 送信開始を示すログ 送信する report のダンプログ ここで、「受信した report の内容のダンプ」の 0x28 が enter キーの HID コードです。\nなお、normal モード時は report ダンプしません\nremap -c code,mask,result,newcode,xor このコマンドは modifier (shift や ctrl など) とのキーの組み合わせ時の、 動作を入れ替えます。\n各パラメータの意味は以下の通りです。\ncode\n押下されるキーボードの HID コードを指定します mask\nmodifier のマスク値を指定します。 result\nmodifier のマスク結果を指定します。 newcode\n条件成立時の HID コードを指定します。 xor\n条件成立時の modifier の XOR 値を指定します。 これは、以下のような処理を行ないます。\nfn conv( modifier:int, key:int ) { if (modifier \u0026amp; mask) == mask and key == code { key = newcode; modifier = modifier ^ xor; } } 例えば、 Shift を押下(modifier:2)しながら Space キー押下(HID:44) を、数字の 1 キー(HID:30)にする場合は、 以下を実行します。\nesp32\u0026gt; remap -c 44,2,2,30,2 remap –b64read このコマンドは、 後述する設定変更ツールで出力されたデータを読み込ます。 入れ替えるキーが多い場合や、設定単体を保持しておきたい場合に利用します。\n以下を実行すると、\nesp32\u0026gt; remap --b64read データ入力待ちになるので、以下を入力すると、設定が反映されます。\n16 AQAAAAAAAAAAAAAAEAAAAA== remap -p このコマンドは現在の設定を表示します。\nnormal モードに切り替え 設定終了後、以下を実行して normal モードに設定します。\nesp32\u0026gt; config -m setup モード切り替えの反映は、 M5stack の再起動が必要です。\nnomal モードの動き normal モードは、setup モードでペアリングされた PC/keyboard と自動で接続されます。\n接続は次の順番に行ないます。\nPC keyboard それぞれの接続中の状態を示すため、 LED の点滅パターンが変化します。\nPC 接続待ち中は高速点滅し、 keyboard 待ち中は点滅のパターンが変化します。 keyboard との接続終了後は常時点灯します。\n設定変更ツール JSON フォーマットで記述したキーの入れ替え情報を、 remap --b64read コマンドで読み込み可能な形式に変換するツールです。\nビルド このツールは go で作成しています。\ngo 1.16 以降をインストールした環境で以下を実行してください。\n$ cd configConv $ make all これで conv が生成されます。\nJSON キーの入れ替え情報は以下の JSON フォーマットです。\n{ \u0026#34;Comments\u0026#34;: [ \u0026#34;HID Code\u0026#34;, \u0026#34;modifier: LeftControl = 1, LeftShift = 2, LeftAlt = 4, LeftGUI = 8\u0026#34;, \u0026#34; LeftControl = 16, LeftShift = 32, LeftAlt = 64, LeftGUI = 128\u0026#34;, \u0026#34;alnum: A-Z = 4-29, 1-9,0 = 30-39\u0026#34;, \u0026#34;arrow: right,left,down,up = 79-82\u0026#34;, \u0026#34; others: execute the next command: sudo ./convkey.raspi -mode scan\u0026#34; ], \u0026#34;InputKeyboardName\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;SwitchKeys\u0026#34;: [ { \u0026#34;Src\u0026#34;: 4, \u0026#34;Dst\u0026#34;: 5 }, { \u0026#34;Src\u0026#34;: 5, \u0026#34;Dst\u0026#34;: 6 } ], \u0026#34;ConvKeyMap\u0026#34;: { \u0026#34;44\u0026#34;: [ { \u0026#34;CondModifierMask\u0026#34;: 2, \u0026#34;CondModifierResult\u0026#34;: 2, \u0026#34;Code\u0026#34;: 30, \u0026#34;ModifierXor\u0026#34;: 2 } ] } } キーの入れ替えは以下の項目で指定します。\nSwitchKeys ConvKeyMap 各項目の書式については、以下の URL を参照してください。\n\u0026lt;https://ifritjp.github.io/blog2/public/posts/2022/2022-01-10-hw-keyboard-remapper/#headline-13\u0026gt;\n変換 ビルドした conv を実行して JSON を変換します。\n$ ./conv config.json これにより、変換結果が標準出力されます。\n以上。\n","id":24,"section":"posts","summary":"前回 Raspberry pi zero w 版の keyboard remapper に引き続き、 M5stack 版の keyboard remapper を作成しました。 M5stack は、 Raspberry pi zero w と比べて以下の長所があります。 モデルによっては小型軽量 基板が剥き出し","tags":null,"title":"OS に依存しない Bluetooth キーボードのキー入れ替え (M5stack版)","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-02-22-bt-keyboard-remapper/","year":"2022"},{"content":" 普段、何気に使っている keyboard。\nこのキーボードがどのように動いているか。 そして、カスタマイズするにはどうすれば良いかを簡単に説明していく。\nキーボードと OS の役割り USB で定義される HID keyboard の各キーには、 スキャンコードという値を割り振られています。\nkeyboard は、キーが押下された時にこのスキャンコードを PC に通知します。 そして、PC はそのスキャンコードを受け、どのキーが押下されたかを検出します。 ところで、キーボードには 日本語の JIS 配列や US 配列など、 さまざまなキー配列があり、配置されているキーもさまざまです。\n前述している通り、スキャンコードはどの キー が押下されたかを示すものです。\nここで重要なのは、 「文字ではなく、キー」 ということです。\n例えば、JIS 配列のキーボードで \u0026#34; を入力するには、 Shift キーを押しながら 2 を押下します。 これは、「 Shift キーと 2 キーを押下している」、 という情報を通知するのが キーボードの仕事 で、 その結果が「 \u0026#34; になる」というのは PC 側で判断した結果 です。\nOS の設定に、「キーボードのレイアウト」がありますが、 あれが何を意味してるかといえば、 「 Shift キーと 2 キーを押下した場合に、 \u0026#34; になる」というような 「変換テーブルに何を使うのか」を指定しています。\nHID Keyboard の report USB HID デバイスは、デバイスの状態を通知するのに report という形で PC に通知します。\nHID Keyboard の report は、以下の 8 バイトで構成されます。\noffset 0 modifier offset 1 reserve offset 2 Key1 offset 3 Key2 offset 4 Key3 offset 5 Key4 offset 6 Key5 offset 7 Key6 offset 0 の modifier は、 キーボードの左右に配置されている Ctrl, Alt, Shift, GUI の 押下状態をビットで示します。 例えば Left-Ctrl と Left-Alt が押下されている場合、 0x05 (0x01 | 0x04 = 0x05) です。\noffset 2 以降は、押下されているキーのスキャンコードを示します。\na が押下されている場合の report は以下になります。\n0x00 0x00 0x04 0x00 0x00 0x00 0x00 0x00 この report は、押下されているキーを通知します。 逆に言えば、この report に含まれていないキーは押下されていないということです。\nなお、Keyboard には USB 接続と PS/2 接続がありますが、 この 2 つのスキャンコードは互換がありません。\n詳しくは、以下の資料を参照してください。\n\u0026lt;https://download.microsoft.com/download/1/6/1/161ba512-40e2-4cc9-843a-923143f3456c/translate.pdf\u0026gt;\nキーの入れ替え 前述している通り、 キーボードのキーを押下した時に、実際にどの文字として扱うかは、 OS の仕事です。\nよって、「キーボードの配置をカスタマイズしたい」という時は、 OS 側で実現すべきことです。\nしかし、全ての OS がキーボードの配置をカスタマイズ出来るとは限りません。\nそこで、 OS に依存せずにキーボードをカスタマイズするツール hw-keyboard-remapper を作成しています。\n\u0026lt;https://ifritjp.github.io/blog2/public/posts/2022/2022-01-10-hw-keyboard-remapper/\u0026gt;\nhw-keyboard-remapper ここでは、 hw-keyboard-remapper が何をやっているのかを簡単に説明します。\nまず、このツールは Raspberry pi zero w (pi0w) 上で動作します。\nそして、カスタマイズ対象の Bluetooth keyboard を pi0w と接続し、 さらに pi0w を HID keyboard として USB で PC に接続します。\nこの Bluetooth keyboard から通知されるキーイベントを処理し、 USB HID keyboard の report に変換することで、 Bluetooth keyboard の remapper として動作します。\n入れ替え hw-keyboard-remapper は、 独立した入力元の キー を別の独立した キー に入れ替える際、以下を行ないます。\nここで「独立した」とは、 modifier の修飾によって PC 側の処理が変わらないことを意味します。\n変換元\n入れ替え元のキーが押されているかどうかを判定し、 押されている場合以下を実行する。 入れ替え元のキーが modifier に属するキーかどうか判定する。\nmodifier に属するキーなら、modifier の対応するビットをクリアする 入れ替え先のキーが modifier に属するキーかどうか判定する。\nmodifier に属するキーなら、modifier に対応するビットをセットする modifier に属さないキーなら、 report の offset 2 以降に入れ替え先のスキャンコードをセットする modifier の状態と連携して動きが変るキーを入れ替える場合、 以下を行ないます。\nここでは US 配列の \u0026amp;(Shift + 7) を、 JIS 配列っぽく \u0026#39; に置き換える場合を例に挙げます。\nなお、 US 配列と JIS 配列のキーがどのように配置されているかは以下で確認してください。\nhttp://www.nagasaki-gaigo.ac.jp/toguchi/pc/multilingual/keyboard_us_jis.htm\nまず、7 が押下されているか判定する。さらに、 Left-Shift あるいは Right-Shift が押下されているか modifier から判定する。\n押下されていれば、 modifier から Shift のビットをクリアする。 report の offset 2 以降に、 \u0026#39; に対応するスキャンコードの 0x34 をセットする このように置き換えを行なうことで、 例えば US 配列のキーボードを JIS 配列に置き換えることも可能になります。\nなお、市販されているキーボードには、 切り替えボタンの付いている製品があります。\nあの切り替えボタン機能は、 ここで説明した HID keyboard の report の入れ替えを行なっています。\namazon などの Bluetooth Keyboard の商品レビューで、 「押したキーと違うキーが入力される」といった内容のレビューをよく見かけますが、 あれば意図せずに切り替えボタンを押したで発生していることがほとんどです。\n","id":25,"section":"posts","summary":"普段、何気に使っている keyboard。 このキーボードがどのように動いているか。 そして、カスタマイズするにはどうすれば良いかを簡単に説明して","tags":null,"title":"HID Keyboard の Key スキャンコード","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-01-16-keyboard-key-scan-code/","year":"2022"},{"content":" 皆さんはキーボードのキーを入れ替えてますか？ キー入れ替えのメジャーな用途は、 Ctrl キーと Cap Lock キーの入れ替えでしょう。\nそのような人は、 「OS のキー入れ替え設定」するのが新しい PC セットアップ時の手順の一つに なっている人も少なくないでしょう。\nしかし、「OS のキー入れ替え設定」が常に出来るとは限りません。 例えば、共有 PC を使うケースや、 そもそも OS がキー入れ替えをサポートしていないケースなど。\nそのような時に使うことを想定して作ったのが、Hardware Keyboard Remapper です。\nHardware Keyboard Remapper とは 今回作成した Hardware Keyboard Remapper は、 接続されているキーボードのキー入力を、 別のキー入力に変換して出力するプログラムで、 Raspberry pi zero w (以降 pi0w と略記)上で動作します。\n構成 Hardware Keyboard Remapper は、以下の構成になります。\nBluetooth keyboard ===(Bluetooth)==\u0026gt; Raspberry pi zero w ===(USB)==\u0026gt; PC pi0w と Bluetooth keyboard を予めペアリングしておき、 その pi0w を HID Keyboard として を PC に接続します。 そして、 BT keyboard のキー入力を pi0w 内で 任意の HID keyboard コードに変換して PC に通知することで、 OS に依存しないキーの置き換えを実現しています。\nなお、半導体不足の影響か、現在 pi0w の入手性が著しく悪くなっています。 そのうち raspberry pi zero 2 w が発売されるとは思いますが、 それも日本で入手できるのは暫く先になりそうです。\nしかし、ソフトウェアエンジニアなら、 使っていない pi0w の 1 台や 2 台程度、家に転がっていると思うので、 問題ないでしょう。\nちなみに、 M5stack を使って同じようなものを作ろうと取り組んでいる最中ではあります。 ただし、そちらは PC へのキー入力が USB ではなく、 BT になりそうです。\n使用方法 残念ながら「アプリを実行すれば使える」という程お手軽なモノではありません。\nここでは、raspberry pi をセットアップした経験があることを前提に、 使用方法をします。\nまず、簡単に手順をまとめると以下になります。\npi0w と BT keyboard をペアリング pi0w の USB Gadget を有効化 github から hw-keyboard-remapper を clone pi0w の USB Gadget の HID キーボードを登録 Key をカスタマイズ pi0w と BT keyboard をペアリング ペアリングは次の手順で行ないます。\nBT keyboard をペアリング開始状態にする 以下を pi0w で実行 $ sudo bluetoothctl [bluetooth]# default-agent [bluetooth]# scan on 暫くすると、キーボードが検出され以下のような出力がされる [NEW] Device XX:XX:XX:XX:XX:XX hogehogeKeyboard 目的のキーボードであることを確認し、 この XX:XX:XX:XX:XX:XX の情報をもとに以下を実行する [bluetooth]# pair XX:XX:XX:XX:XX:XX [bluetooth]# trust XX:XX:XX:XX:XX:XX [bluetooth]# connect XX:XX:XX:XX:XX:XX [bluetooth]# exit 以上の設定を行なっておけば、次回からは自動でペアリングされます。\nなお、ここで重要なのは trust しておくことです。 trust しておかないと、 再接続する時にまた操作が必要になります。\ngithub から hw-key-remapper を clone pi0w で以下を実行します。\n※ 事前に golang 1.15 以降をインストールしておきます。\ngit clone --depth 1 https://github.com/ifritJP/hw-keyboard-remapper.git cd hw-keyboard-remapper go build pi0w の USB Gadget を有効化 pi0w の /boot/config.txt に以下を追加します。\n[all] dtoverlay=dwc2 pi0w の /etc/modules に以下を追加します。\ndwc2 注意 pi0w の RNDIS 通信を有効にしている場合、 以下を /boot/cmdline.txt に追加していると思います。\nmodules-load=dwc2,g_ether この指定は外してください。 これを設定していると、 pi0w を HID キーボード化できません。\n後のステップで、別の方法で RNDIS を有効化します。\nなお、 以下の作業は RNDIS 経由の ssh ではなく、 WiFi 経由の ssh か、あるいは pi0w のコンソールで直接作業してください。\nまた、RNDIS 経由の ssh で作業していた場合は、 一旦 raspberry pi を再起動してください。\npi0w の USB Gadget で HID キーボードを登録 clone した hw-keyboard-remapper のディレクトリに移動し、 pi0w で以下を実行します。\nsudo bash usb_gadget/rndis_hid.sh これで、 pi0w が RNDIS と HID の複合デバイスとして構築されます。\n以下のコマンドで、 hid デバイスと NIC に usb が pi0w 上に認識されていることが確認できます。\nls /dev/hid* ip a なお、 sudo bash usb_gadget/rndis_hid.sh を手動で実行するのは面倒なので、 /etc/rc.local に以下を追加します。\nbash フルパスusb_gadget/rndis_hid.sh rc.local ではなく、サービスとして追加するのがカッコいいのかもしれないですが、 usb_gadget/rndis_hid.sh は一度 on すると、 動的に off が正常にできないっぽいので、今回はカッコ良さは求めません。\npi0w に接続している PC が windows OS であれば、 この状態でコントロールパネルの「デバイスとプリンター」に、 次の名前のデバイスが登録されているはずです。\nLinux USB Gadget/RNDIS+HID これが RNDIS と HID の複合デバイスになります。\nHID はドライバの設定等は不要です。 一方で、RNDIS を利用する場合は、別途ドライバの設定をしてください。\nドライバの更新 → 手動 → 一覧から選択 → ネットワークアダプタ → Microsoft → リモート NDIS 互換デバイス なお、ここまで設定しておくと、 次回の ppi0w の起動時に「不明なUSBデバイス(デバイス記述子要求の失敗)」として 認識されますが、30秒程度で正常に複合デバイスとして認識されます。\nキー変換プログラムを登録 キー変換プログラムは、次のモードを持ちます。\ninput event デバイス名のリスト出力 input event デバイスから入力されているキー情報出力 input event デバイスから入力されているキー情報を変換して HID キーボードとして出力 デバイス名の取得 まずは、以下を実行し「input event デバイス名のリスト出力」して、 デバイス名をメモっておきます。\nsudo ./hw-keyboard-remapper -mode list なお以下の場合、Keyboard のデバイス名がリストに出力されないので注意してください。\nBT Keyboard がペアリングされていない BT Keyboard が省電力モードに入って接続が切れている なお、 vc4 がリストされますが、それはキーボードではなく VideoCoreIV チップです。\ninput event デバイスから入力されているキー情報出力 以下を実行し、キー入力を取得できているか確認します。 $ sudo ./hw-keyboard-remapper -mode scan -kb \u0026#34;XXXXXXXXXXXXXXX\u0026#34; ここで、 \u0026#34;XXXXXXXXXXXXXXX\u0026#34; には先程メモしたキーボード名を指定します。\nキーボードでキーを押すと、そのキー情報が出力されます。 例えば m j と入力すると、以下のような出力がされます。\nDEBU[0002] [event] press key 50(0x32) KEY_M -\u0026gt; Keyboard m and M INFO[0002] data [0 0 16 0 0 0 0 0] DEBU[0003] [event] release key 50(0x32) KEY_M -\u0026gt; Keyboard m and M INFO[0003] data [0 0 0 0 0 0 0 0] DEBU[0003] [event] press key 36(0x24) KEY_J -\u0026gt; Keyboard j and J INFO[0003] data [0 0 13 0 0 0 0 0] DEBU[0004] [event] press key 36(0x24) KEY_J -\u0026gt; Keyboard j and J INFO[0004] data [0 0 13 0 0 0 0 0] ここで、 press key 50(0x32) KEY_M は \u0026#34;m\u0026#34; の押下イベントが発生したことを示し、 50(0x32) は linux 側の \u0026#34;m\u0026#34; のキーコードを示します。 data [0 0 16 0 0 0 0 0] は HID コードの変換結果を示し、 3 バイト目の 16 は、 HID の \u0026#34;m\u0026#34; のコードを示します。\nキーのカスタマイズは、この HID コードが重要になります。\nこの HID コードの詳細は、次の USB の規格書を参照してください。\n各キーのコード情報は、以下の資料の 「10 Keyboard/Keypad Page (0x07)」 を参照\nhttps://usb.org/document-library/hid-usage-tables-122 Ctl, Alt 等の modifier キー情報は、以下の資料の「8.3 Report Format for Array Items」を参照\nhttps://www.usb.org/document-library/device-class-definition-hid-111 なお、 linux のキーコードから HID コードへの変換がバグっている可能性は否定できません。 ローカルで修正するか、 issue で報告するか、 pull request してください。\nhw-keyboard-remapper の終了 pi0w に ssh でアクセスしている場合、 Ctrl-C すればプログラムは終了します。\nしかし、 pi0w のコンソールから実行している場合、 全てのキー入力がこのプログラムに取られて効かないため、 Ctrl-C も無効です。\nこの状態からプログラムを終了させる場合、 pi0w に接続しているキーボードから以下(qwe を4回)を入力してください。\nqweqweqweqwe これで終了します。\nなおこの文字列は、 「偶然のキータイプでは発生せずに、簡単に入力できる文字列」として使用しています。\nqweqweqweqwe が「普通に使う文字列だ」というのであれば、 適宜コードを変更してください。 (もしかしたら、 steam でゲームしてたら qwe を使うこともあるのかも？)\nKey をカスタマイズ 単純に linux のキーコードから HID コードへ変換しても意味はないので、 HID コードを別のキーのコードに置き換えるように設定します。\n置き換えは JSON ファイルで指定します。\nJSON は次のような形式です。 リポジトリに config.json.sample を同梱しているので、適宜に編集してください。\nなお、config.json を読み込ませるには、 -conf オプションで config.json のパスを指定してください。\n{ \u0026#34;InputKeyboardName\u0026#34;: \u0026#34;XXXXXXXXXXXXXXXXXXX\u0026#34;, \u0026#34;SwitchKeys\u0026#34;: [ { \u0026#34;Src\u0026#34;: 57, \u0026#34;Dst\u0026#34;: 224, \u0026#34;Comment\u0026#34;: \u0026#34;CaspLock -\u0026gt; L-Ctrl\u0026#34; }, { \u0026#34;Src\u0026#34;: 224 , \u0026#34;Dst\u0026#34;: 57, \u0026#34;Comment\u0026#34;: \u0026#34;L-Ctrl -\u0026gt; CaspLock\u0026#34; } ], \u0026#34;ConvKeyMap\u0026#34;: { \u0026#34;0x9\u0026#34;: [ { \u0026#34;modMask\u0026#34;: 1, \u0026#34;modResult\u0026#34;: 1, \u0026#34;Code\u0026#34;: 79, \u0026#34;modXor\u0026#34;: 1, \u0026#34;Comment\u0026#34;: \u0026#34;C-f -\u0026gt; right arrow\u0026#34; } ], \u0026#34;0x5\u0026#34;: [ { \u0026#34;modMask\u0026#34;: 1, \u0026#34;modResult\u0026#34;: 1, \u0026#34;Code\u0026#34;: 80, \u0026#34;modXor\u0026#34;: 1, \u0026#34;Comment\u0026#34;: \u0026#34;C-b -\u0026gt; left arrow\u0026#34; } ], \u0026#34;138\u0026#34;: [ { \u0026#34;modMask\u0026#34;: 34, \u0026#34;modResult\u0026#34;: 2, \u0026#34;Code\u0026#34;: 79, \u0026#34;modXor\u0026#34;: 2, \u0026#34;Comment\u0026#34;: \u0026#34;L-SHIFT-MUHENKAN -\u0026gt; right arrow\u0026#34; }, { \u0026#34;modMask\u0026#34;: 34, \u0026#34;modResult\u0026#34;: 32, \u0026#34;Code\u0026#34;: 80, \u0026#34;modXor\u0026#34;: 32, \u0026#34;Comment\u0026#34;: \u0026#34;L-SHIFT-MUHENKAN -\u0026gt; left arrow\u0026#34; } ] } } JSON は以下の情報を持ちます。\nInputKeyboardName SwitchKeys ConvKeyMap InputKeyboardName 接続する BT Keyboard 名を指定します。\nコマンドラインに -kb オプション指定がある場合、-kb オプションを優先します。\nSwitchKeys 置き換える HID キーコードのペアを指定します。\nSrc\n置き換え元の HID キーコード。 integer。 Dst 置き換え先の HID キーコード。 integer。 Comment コメントです。変換には関係ありません。 On\nこの置き換え情報が有効かどうかを示します。 bool。 このキーが存在しないか、 true を指定した場合、有効として扱います。 一時的に off にしたい場合に false を指定することを想定しています。 これは、単純にキーそのものを置き換えます。 例えば、 Ctrl と CapLock の置き換えのような時に利用します。\n単純にキーそのものを置き換えるので、 「Shift を押しながら A を押した場合に、他のキーに置き換えたい」と いうような用途には使えません。\nその場合は、 ConvKeyMap で指定します。\nConvKeyMap ConvKeyMap は、 Ctrl や Shift などの modifier キーを押しながら他のキーを押した時の、 キーコード変換方法を定義します。\n例えば C-f を押下したら → キーのコードを送る、なんてことも可能です。\nConvKeyMap は、次の要素からなります。\n\u0026#34;ConvKeyMap\u0026#34;: { \u0026#34;key1\u0026#34;: [ {info}, ... ], \u0026#34;key2\u0026#34;: [ {info}, ... ], ... } key\n変換元の HID キーコードを文字列で指定します。 例えば f を押下した場合の動作を定義する場合、 \u0026#34;0x9\u0026#34; を指定します。 キーコードの表現は、16進数か 10 進数です。 info 変換条件を次の配列で指定します。\nmodMask\nmodifier のマスク値を指定します。 modResult\nmodifier のマスク結果を指定します。 Code\n条件成立時の HID コードを指定します。 modXor\n条件成立時の modifier の XOR 値を指定します。 Comment\nSwitchKeys と同じです。 On\nSwitchKeys と同じです。 ConvKeyMap で指定すると、次の条件が成り立つ時に動作します。\n(modMask \u0026amp; modifier) == modResult 例えば Left-Ctrl が押下されていることを条件にするには、 modMask と modResult 両方に 1 を指定します。\n以下のサンプルは、 C-f が押下された場合、 → に変換することを示します。\n\u0026#34;0x9\u0026#34;: [ { \u0026#34;modMask\u0026#34;: 1, \u0026#34;modResult\u0026#34;: 1, \u0026#34;Code\u0026#34;: 79, \u0026#34;modXor\u0026#34;: 1, \u0026#34;Comment\u0026#34;: \u0026#34;C-f -\u0026gt; right arrow\u0026#34; } ], ここで、modXor が 1 なので modifier に 1 が xor され、 結果的に出力される modifier の Left-Ctrl ビットが 0 になっていることに注意してください。\nShift キーが押された時のキーの入れ替えも同じように行ないます。\nなお、 C-f を → に変換すると、 emacs では C-x C-f が C-x → になってしまうので、変換はオススメしません。\n変換プログラムの実行 以下を実行します。\n$ sudo ./hw-keyboard-remapper -conf config.json -v これで config.json で設定した remap が反映され、 pi0w に接続した BT キーボードの入力が、 pi0w と USB 接続している PC に HID キーボードの入力として通知されます。\n上記コマンドで動作を確認したら、/etc/rc.local に追加します。\nnice -n -5 パス/hw-keyboard-remapper -conf パス/config.json \u0026gt; /del/null \u0026amp; 他のプログラムによってキー入力処理が滞ると、 キーリピートなどの現象に繋りやすくなるため、 nice で 優先度を上げて実行しています。\n/etc/issue の編集 前述の通り、このプログラムを実行していると pi0w のコンソール上でキー入力が効かなくなる。 当然ログインも出来ない。\nssh 経由であれば作業できるが、 ssh を接続できないケースがある。 その時、 qweqweqweqwe を入力すればキーボードが使えるようになるが、 そんな事は絶対に忘れるので、 pi0w の login プロンプトに警告を表示するように設定しておく。\n/etc/issue に以下を設定しておくことで、メッセージが表示される。\n=====\u0026gt; Keyboard is invalid now. To available the keyboard, enter \u0026#34;qweqweqweqwe\u0026#34;. Raspbian GNU/Linux 11 \\n \\l なお、/etc/issue を編集する場合、 元のメッセージよりも上の行に設定せずに下の行に設定すると、 ssh 接続の鍵認証が出来なくなって、パスワード認証に切り替わってしまったので、 メッセージを編集する際は気を付けてください。\nトラブルシューティング dwc2 モジュールをロードした後、 USB Gadget に登録しないまま pi0w を PC に接続していると、 PC 側の USB 周りが不安定になることがありました。 「不明なUSBデバイス(デバイス記述子要求の失敗)」として認識されたまま、 放置するのが良くないようです。\nこの現象は環境依存かもしれませんが、dwc2 モジュールをロードした後は、 速やかに usb_gadget/rndis_hid.sh を実行してください。 rc.local に usb_gadget/rndis_hid.sh を設定しておけば、問題ありません。\nなお、 usb_gadget/rndis_hid.sh は pi0w を RNDIS + HID デバイスにするスクリプトです。\nRNDIS が不要で、 HID だけで良いという場合は usb_gadget/rndis_hid.sh の代わりに、 usb_gadget/hid.sh を実行すると HID だけを登録できます。\nただし、これも環境依存かもしれませんが、 usb_gadget/hid.sh 実行時も PC の USB 回りが不安定になりました。\nよって usb_gadget/hid.sh は、 RNDIS を使いたくない人で、 かつ PC の USB 周りが不安定になるかどうか確認する人柱になっても良い人以外は オススメしません。\n","id":26,"section":"posts","summary":"皆さんはキーボードのキーを入れ替えてますか？ キー入れ替えのメジャーな用途は、 Ctrl キーと Cap Lock キーの入れ替えでしょう。 そのような人は、 「OS のキー","tags":null,"title":"Hardware Keyboard Remapper(OS に依存しないキーボードのキー入れ替え)を作った","uri":"https://ifritjp.github.io/blog2/public/posts/2022/2022-01-10-hw-keyboard-remapper/","year":"2022"},{"content":" 4K ディスプレイが欲しくなったので調べものをしている。\n液晶ディスプレイを選ぶ際、用途によってさまざまな観点でチェックするだろう。 しかし、誰もが気になるのは 「ドット抜け」 だろう。\nそんな訳で、各メーカー毎のドット抜け保証についてまとめてみた。\nドット抜け保証まとめ 国内で購入可能なメジャーメーカーの保証状況を以下に示す。\n順位 メーカー 保証内容 リンク 1? EIZO 1点もない (例外あり) リンク 2? ACER 中央に集中して3点以内、又は全面で７点以内 リンク 3? DELL 製品によって異なる。詳細は後述。 リンク 4 IO DATA ドット抜け 0.001% 未満 リンク 5 iiyama 0.001％以下 リンク 6 LG ドット抜け 0.01% 以下 リンク 8 BENQ 修理・交換対象外 リンク - ASUS ※保証内容を見つけられず – 保証内容 1 位(？) EIZO ドット抜け(無輝点) は 1 点もない ことが保証される。 ただし、黒点や光り方のムラなどは保証されない。\n例えば、 黒点が大量にあっても保証外 ということになる。 なんだかイマイチな気がする。\n一応 1 位にはしたが、 微妙なので 「1位(？)」 としている。\n保証内容 2 位(？) ACER 次点は、 ACER の「中央に集中して3点以内、又は全面で７点以内」。 7点は多いと思うかもしれないが、 4K であれば 7 点は全体の 0.000085 % 未満なので非常に少ないと言える。\n保証内容 3 位(？) DELL 次は DELL。 DELL はモデルによって保証内容が異なる。 一番良いモデルの保証は、 ACER と同レベルあるいは DELL の方が良いが、 そうでないモデルの場合は ACER に劣る。 よって、3 位(？) とする。\n保証内容の詳細は、 上記表の ACER のリンクを参照すること。\n保証内容 4 位 IO DATA 次は IO DATA で「ドット抜け 0.001% 未満」。\nf0.001% というと、かなり少ない様に思うが、 4K だと 82 ドットとなる。 82 ドットは、これまでのメーカーと比べると桁違いに多いことが分かる。\n保証内容 5 位 iiyama 次が iiyama で「ドット抜け 0.001% 以下」。\n僅差だが、 IO DATA が 0.001% 「未満」なのに対し、 iiyama は 「0.001% 以下」となり、 iiyama は IO DATA の次となる。\n保証内容 6 位 LG 次が LG の 「ドット抜け 0.01% 以下」。 これは酷い。 0.01% ということは 4K なら 829 ドットとなる。\nいくらなんでも保証のレベルが低過ぎだろ。 大手の液晶パネルメーカーだからって、殿様商売しているんじゃなかろうか？\n保証内容 7 位 BENQ 次は BENQ の「修理・交換対象外」。 BENQ に関しては「ドット抜けは対応しない」と明言している。 とてもじゃないが、怖くて替えない。\n保証内容 ランキング保留 ASUS 最後に、 ASUS は保証内容を見つけられなかったので、判断は保留。\nただし、「保証内容を見つけ易いところに掲載していない」ということ自体、印象が悪い。\nメーカー内の品質規定 今回の調査は、ユーザクレームに対する保証だが、 メーカー内の品質規定がどうなっているのかは気になるところ。\n例えば、出荷時は OK でも、 搬送途中などの衝撃によって異常が発生することは十分に考えられる。 それ以外にも、経年劣化等でドット抜けが発生こともある。\nそのようなことを考えると、出荷時のドット欠け検査では、 ある程度のマージンを設けて品質チェックをしていることが考えられる。\nその辺りはメーカーの内部機密なので、入手は困難だろう。\nまとめ 私の経験上、ディスプレイを使ってきてドット抜けに装具した経験は滅多にない。\n『滅多にない』ということは、 逆に言えば「あった」ということでもある。 ディスプレイは常時見て作業するものなので、 そこに欠陥があると集中を妨げる要因にもなる。\n4K ディスプレイはかなりお手頃価格で購入できるようになっている。 とはいえ、気軽に買い替えるほどの値段でもない。\n最低限の保証を受けられるメーカーを選択するべきだろう。\nただし、現実問題、保証の規定があったとしても、 サポート窓口が反応しない、等の別問題がある可能性はあるので、 その辺りは個人で判断して欲しい。\n今回の調査結果を受けて、LG と BENQ, ASUS は候補から外した。\n","id":27,"section":"posts","summary":"4K ディスプレイが欲しくなったので調べものをしている。 液晶ディスプレイを選ぶ際、用途によってさまざまな観点でチェックするだろう。 しかし、誰もが","tags":null,"title":"液晶ディスプレイメーカーのドット抜け保証","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-12-05-display-dots/","year":"2021"},{"content":" 数ヶ月間 LuneScript から離れていますが、生存アピールのためにちょっと触れておきます\n今日現在、 LuneScript は言語機能としてエラーハンドリングと大域脱出をサポートしていません。\n現在でも、module 機能を利用して 裏技的にエラーハンドリングと大域脱出を使うことは出来なくもないです。 しかし、それはあくまでも裏技で正式機能ではありません。\n「何故サポートしていないか？」というと、 エラーハンドリングと大域脱出のベストプラクティスが分からないためです。\nなお、「今の LuneScript の言語仕様が全てベストプラクティスなのか？」と問われれば、 残念ながら違います。 しかし、 自分の中で納得した仕様 になっています。\n一方で、「エラーハンドリングと大域脱出」に関しては、 イマイチ決めかねています。\nエラーは例外か？ 『エラー』を、『例外として投げて、投げられた例外を掴まえて処理する』という方法は、 よく使われています。 しかし、 この方法はなにか違う気がしています。\nそもそも 『「例外」ってなんだ？』 という疑問が浮びます。\n私は、「例外 == 普通は起らないような状態を表わすべきもの」と考えています。 例えば「kill ジグナルの受信」などが例外に該当すると思います。\nしかし幾つかの言語では、 「正常系ではない異常系」を「例外」として扱かっているケースがあります。 例えば、「ファイルの書き込みに失敗した状態」が「例外」として扱われていたりします。\nこれは なにか違う 気がします。\n何が違うって、「ファイルの書き込みに失敗した状態」なんていうのは、 良くあるケースです。 良くあるケースが「例外」って何か変じゃない？ と感じるんです。\nプログラムっていうのは、エラー処理を含めて完成するものだと私は思います。 つまり、エラー処理って「例外」じゃないですよね？と考えています。\nまぁ、ユースケース記述でいうところの「メインフロー、代替フロー、例外フロー」のうち、 「例外フロー」がエラー処理になるから、やっぱり「例外」じゃないか？ というツッコミはあると思います。 ですが、 ちょっとした操作ミス等で発生するエラーと、 普通は発生しないエラーとを「例外」という一つの概念で扱うのは間違っているんじゃないか？ と感じています。\nたとえば Java では Error と RuntimeException と その他Exception とで、 これらエラーを区別して管理できるようになっていますが、 exception という 1 つの概念であることには違いありません。\n区別できるという点では、Java のエラー種別は私の考えと一致しています。 しかし、 実際に Java でプログラムしているとメンドイなぁ、と思ってしまいます。\n「メンドイ」と思ってしまうのは、「何かが違う」ということだと思います。\n例えば nil 安全を実現する unwrap 等の処理は一手間かかりますが、 nil 安全によるメリットと、unwrap 等の一手間を天秤にかければ、 メリットの方が大きいと感じることができ、面倒とはそれほど思いません。\nもちろん「それほど思わない」というのは「少しは思っている」ということであり、 nil 安全に関しても、もっと手間がかからない方法があるんじゃないか模索しています。\n「例外」の良くないところは、 「エラー」と「大域脱出」が一括りに扱われてしまっているところだと思います。\n「例外」が「 普通は発生しないエラー 」に限られるのであれば、 「大域脱出」とセットになっているのも理解できますし、合理的だと思います。 例えば、 kill シグナルを受けたら「大域脱出」するのは納得できますよね？\nしかし上述した通り、「 ちょっとした操作ミス等で発生するエラー 」も 「例外」として扱う場合は、 「大域脱出」がセットになっているのは影響が大き過ぎると考えます。\n「大域脱出」は最終手段であり、文法上も専用に扱わなければなりません。 この「専用の文法」が、「メンドイ」と感じる元になっています。\n「 ちょっとした操作ミス等で発生するエラー 」は、 普通に発生する可能性があるものであり、 普通に発生するならば、 特別に扱うことなく普通に処理を書けるべきです。\ngo のエラーハンドリング go のエラーハンドリングは error 型のデータを戻り値で返し、 それを処理することでエラーハンドリングしています。\nなお、 error 型のデータはあくまでも関数の戻り値であって、大域脱出とは別ものです。\nつまり、 go のエラーハンドリングは、特別に扱うことなく普通に処理が書けます。\nこの error 型によるエラーハンドリングは、 以下の go の特徴によって支えられています。\n関数の多値返却 defer 特に defer は go の大きな特徴と言えます。\nこの仕様をパクって「LuneScript でエラーハンドリングをサポートする」ことも考えましたが、 LuneScript はトランスコンパイラであり、 go の特徴に依存する実現方法は採用すべきでない 、 ということもあって採用を見送っています。\ndefer がなくても error 型を追加すれば それなりのエラーハンドリングは実現出来ます。 しかし、go のエラーハンドリングは defer があってこそです。\nそもそも、error 型を追加するだけなら、 LuneScript の言語仕様として組込まなくても ユーザプログラムレベルで実現できますし。。\nLuneScript でのエラーハンドリング 上で例として挙げた go だけでなく、 Rust でも関数戻り値の Option, Result 型でエラーを扱っています。\nエラー型を追加し、それを処理することでエラーハンドリングする、 というのは「 特別に扱うことなく普通に処理を書けるべき 」という 私の考えにも合致します。一方で go の defer は便利ですが、 トランスコンパイル先の言語仕様に大きく依存します。\n今後対応するかもしれないトランスコンパイル先の言語で、 defer と同等の機能が実現できない、 あるいは実現できてもコストが大きくかかる、ということが容易に想像できます。\n現状でも、Lua では簡単には defer を実現できません。\nそんな訳で、LuneScript はエラーハンドリングと大域脱出をサポートしていません。\n言語仕様に依存せず、且つ、 簡便にエラーハンドリングを記述できる方法を模索中です。\nとはいえ、 そう遠くない未来に、 必要に迫られてなんらかの方法を対応しなければならなくなる気はしています。\n","id":28,"section":"posts","summary":"数ヶ月間 LuneScript から離れていますが、生存アピールのためにちょっと触れておきます 今日現在、 LuneScript は言語機能としてエラーハンドリングと大域脱出をサポートし","tags":null,"title":"LuneScript がエラーハンドリングと大域脱出をサポートできていない理由","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-11-14-lunescript-error-handling/","year":"2021"},{"content":" VirtualBox/VMWare と WSL2 は共存可能です。 しかし、共存させると VirtualBox/VMWare 上の GuestOS にオーバーヘッドがかかります。\n今回はオーバーヘッドの概要と、共存と排他の設定切り替え方法のネタです。\nVirtualBox と WSL2 共存のオーバーヘッド 以下に VirtualBox と WSL2 の実行時の階層図を示します。\nこの図は、次の 4 つの状態を表わしています。\n(A) 従来の Windows で VirtualBox を動かす状態 (B) Windows で WSL2 を動かす状態 (C) Windows で WSL2 と VirtualBox を動かす状態(異常時) (D) Windows で WSL2 と VirtualBox を動かす状態(正常時) (A) は、 WSL サポート前の Windows で VirtualBox を動かしていた状態です。 Windows 上に VirtualBox があり、 その上に GuestOS が動作していました。\n(B) は、Windows で WSL2 を動かしている状態です。 WSL2 では、 ハードウェアの上に hypervisor があり、 その上に Windows カーネルと Linux kernel があります。\n(C) は、WSL2 と VirtualBox を共存させようとしている状態です。 この場合 VirtualBox に × を付けていますが、 これは VirtualBox が動かないことを示しています。\nWindows Kernel が hypervisor 上で動いている場合、 (A) の形態の VirtualBox は動きません。 VirtualBox を動かすには (D) のように 「Windowsハイパーバイザープラットフォーム」 が必要です。\nこれにより、 (D) の VirtualBox は (A) と比べると オーバーヘッドがあることが分かります。 アプリによってその影響度合いは異なりますが、 私の用途的に 約 100 〜 200% 程度の性能劣化 がありました。\nWSL2 に移行し、 VirtualBox はほとんど使用しないようなケースでは、 VirtualBox にオーバーヘッドがあっても問題ありません。 しかし、「VirtualBox も捨て切れない」というケースもあると思います。\nWSL2 への移行の過渡期などは特にそうなるでしょう。\nそこで、 VirtualBox の 性能を重視した (A) と、 WSL2 との共存可能な (D) を切り替えて使うための方法 を 以下で示します。\nVirtualBox/VMWare と WSL2 の共存と、 VirtualBox/VMWare 占有の切り替え方法 (D) の構成と (A) の構成を比べた場合、次の 2 つが異なります。\nhypervisor windows ハイパーバイザープラットフォーム この 2 つの無効・有効を切り替えることで、 (D) と (A) を切り替えられます。\nこの 2 つの無効・有効を切り替えるには、 PC の再起動が必要 になります。 再起動が必要なのは、使い勝手に問題があると言わざるを得ないですが、 hypervisor がカーネルよりも下にあることを考えると、 有効・無効に再起動が必要になるのは仕方がないと納得するしかないです。。\nなお、この 2 つの無効・有効の切り替え処理には、 さほど時間はかかりません。 これは、せめてもの救いです。\n(D) から (A) に切り替える (D) から (A) に切り替えるには、 管理者権限の power shell で以下を実行してから、 PC を再起動します。\n# hypervisor の無効化 C:\\Windows\\System32\\bcdedit.exe /set hypervisorlaunchtype off # windows ハイパーバイザープラットフォームの無効化 Disable-WindowsOptionalFeature -online -featurename HypervisorPlatform -NoRestart なお、 hypervisor だけ無効化し、 windows ハイパーバイザープラットフォーム が有効な状態だと、 本来は windows ハイパーバイザープラットフォーム を使わなくても VirtualBox は動くはずです。 しかし実際には、windows ハイパーバイザープラットフォームを使って 余計なオーバーヘッドがかかってしまうようです。\nよって、2 つとも無効にする必要があります。\n(A) から (D) に切り替える (A) から (D) に切り替えるには、 管理者権限の power shell で以下を実行してから、 PC を再起動します。\n# windows ハイパーバイザープラットフォームの有効化 Enable-WindowsOptionalFeature -online -featurename HypervisorPlatform -NoRestart # hypervisor の有効化 C:\\Windows\\System32\\bcdedit.exe /set hypervisorlaunchtype auto まとめ WSL や docker のような技術は軽くて便利ではありますが、 VirtualBox のようにハードウェアを仮想化する環境が 必要になるケースは今後もあるでしょう。\nそのような時に、オーバーヘッドが気にならない程度に改善されることを期待します。\nもしかしたら、 Win11 では既に改善されていたりするんだろうか？\n","id":29,"section":"posts","summary":"VirtualBox/VMWare と WSL2 は共存可能です。 しかし、共存させると VirtualBox/VMWare 上の GuestOS にオーバーヘッドがかかります。 今回はオーバーヘッドの概要と、共存と排他の設定切り替え方法の","tags":null,"title":"WSL2 共存による VirtualBox/VMWare の性能低下と、性能重視時の排他設定方法","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-11-08-wsl2-virtualbox/","year":"2021"},{"content":" 自作ツールで、MS Teams に対して投稿を read/write する方法について書きます。\nTeams の管理者権限の許可が必須 「 Teams の管理者権限の許可が必須 」です。\n大事なことなので始めに書きます。\n自作ツールで、MS Teams に任意に投稿を read/write するには、 「 Teams の管理者権限の許可が必須 」です。\nたとえ自分自身のアカウントを使って投稿したくても、 自作ツールから行なうには管理者権限の許可が必須 なんです。\nMS Graph API へのアクセス MS Graph API は、以下のサイトにリファレンスが載っています。\n\u0026lt;https://docs.microsoft.com/ja-jp/graph/\u0026gt;\nこれの Teams の API を叩けばアクセスできます。\n当然と言えば当然ですが、MS Graph API で Teams にアクセスするには、 その Teams のアカウント認証が必要です。\nそして、アカウント認証するには、Azure から発行した ClientID を使用する必要があります。\nなお、 CliendID の発行時に、クライアントの種別を指定します。 その種別には、 そのクライアントを登録したアカウントに属する組織のみにアクセスするクライアントか、 それとも組織を限定せずにアクセス可能なクライアントか、を指定します。\nより具体的な説明は以下を参照してください。\nリンク\nAzure の CliendID 発行が出来るユーザは当然限られています。\n個人で作った Azure アカウントなら、 自分が管理者でもあるので自由にクライアントを登録できますが、 誰かから発行された Azure アカウントなら、 その発行者(管理者)によって、制限されている可能性があります。\nここで、クライアント登録が出来ないのであれば、ほとんどの場合そこで終わりです。\ntoken 取得 発行された ClientID を指定して、アカウント認証するのですが、 通常はブラウザのインタフェースを通して認証するのが一般的です。\nですが、ブラウザを搭載していないアプリなどで利用する場合は、以下の手順になります。\n\u0026lt;https://learn.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-device-code\u0026gt;\nなお、 この device code を利用する方法は、 ClientID を発行したアプリの設定において、次をセットしておく必要があります。\nAzure の 「アプリ登録」 → 「認証」 で 「モバイルとデスクトップのフローを有効」を 「はい」にする。\nこれを設定しておかないと、認証手順が進みません。\n認証手順 device code 発行 まず以下を実行し、 device code 登録に必要な情報を取得します。\n$ echo \u0026#39;client_id={CLIENT_ID}\u0026amp;scope=openid%20offline_access%20https%3A%2F%2Fgraph.microsoft.com%2FChannelMessage.Send\u0026#39; | curl \u0026#39;https://login.microsoftonline.com/{TENANT_ID}/oauth2/v2.0/devicecode\u0026#39; -H \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; -d @- ここで、 {CLIENT_ID} , {TENANT_ID} には、自分の環境に合せて設定してください。\nまた、scope には必要なパーミッションのスコープを指定してください。\n上記の例は、所定のチャネルに新規登録する際に必要なパーミッション(ChannelMessage.Send)です。\nこれを実行すると、次のようなレスポンスを得られます。\n{ \u0026#34;user_code\u0026#34;:\u0026#34;??????????????????\u0026#34;, \u0026#34;device_code\u0026#34;:\u0026#34;??????????????????\u0026#34;, \u0026#34;verification_uri\u0026#34;:\u0026#34;https://microsoft.com/devicelogin\u0026#34;, \u0026#34;expires_in\u0026#34;:900, \u0026#34;interval\u0026#34;:5, \u0026#34;message\u0026#34;:\u0026#34;To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code H6YXVV74E to authenticate.\u0026#34; } ここで、 user_code と device_code をメモって起きます。\nuser_code は認証させたいユーザに表示し、 device_code は teams client を開発する側で一時的に保持しておきます。\n認可 次に teams client を認証させたいユーザが以下の URL にブラウザでアクセスします。\n\u0026lt;https://microsoft.com/devicelogin\u0026gt;\nここにアクセスすると、コード入力画面が表示されるので、 user_code を入力します。\nuser_code を入力すると、直ぐに Azure の認証画面に移るので ID/PASS を入力し、 teams client にアクセスを認可します。\ntoken 取得 つぎに、token を取得します。\necho \u0026#39;grant_type=urn:ietf:params:oauth:grant-type:device_code\u0026amp;client_id={CLIENT_ID}\u0026amp;device_code={DEVICE_CODE}\u0026#39; | curl -X POST https://login.microsoftonline.com/organizations/oauth2/v2.0/token -H \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; -d @- ここで {CLIENT_ID} , {DEVICE_CODE} に client_id と device_code を指定します。\n成功すると、次のレスポンスが返ってきます。\n{ \u0026#34;token_type\u0026#34;:\u0026#34;Bearer\u0026#34;, \u0026#34;scope\u0026#34;:\u0026#34;openid profile email https://graph.microsoft.com/ChannelMessage.Send\u0026#34;, \u0026#34;expires_in\u0026#34;:3749, \u0026#34;ext_expires_in\u0026#34;:3749, \u0026#34;access_token\u0026#34;:\u0026#34;?????????????\u0026#34;, \u0026#34;refresh_token\u0026#34;:\u0026#34;???????????\u0026#34;, \u0026#34;id_token\u0026#34;:\u0026#34;??????????????\u0026#34; } この access_token と refresh_token が Graph API を利用する際に必要になります。\nなお、 access_token は短い間隔で expire し、 refresh_token を使って expire した access_token を取り直して利用する運用方法になります。\nよって、refresh_token は非常に重要な情報です。\nrefresh_token 自体も、一定期間で expire するようです。\nここまでの作業を一定時間内で行なう必要あります。\ntoken の refresh 前述の通り access_token は短かい時間で expire するので、 refresh token で取り直す必要があります。\n以下を実行すると access_token を取り直せます。\necho \u0026#39;client_id={CLIENT_ID}\u0026amp;scope=https%3A%2F%2Fgraph.microsoft.com%2FChannelMessage.Send\u0026amp;refresh_token={REFRESH_TOKEN}\u0026amp;grant_type=refresh_token\u0026#39; | curl \u0026#39;https://login.microsoftonline.com/organizations/oauth2/v2.0/token\u0026#39; -d @- -H \u0026#39;Content-Type: application/x-www-form-urlencoded\u0026#39; 成功すると以下が返ります。\n{ \u0026#34;token_type\u0026#34;:\u0026#34;Bearer\u0026#34;, \u0026#34;scope\u0026#34;:\u0026#34;openid profile email https://graph.microsoft.com/ChannelMessage.Send\u0026#34;, \u0026#34;expires_in\u0026#34;:4745, \u0026#34;ext_expires_in\u0026#34;:4745, \u0026#34;access_token\u0026#34;:\u0026#34;????????????????\u0026#34;, \u0026#34;refresh_token\u0026#34;:\u0026#34;???????????????????\u0026#34;, \u0026#34;id_token\u0026#34;:\u0026#34;?????????????????????\u0026#34; } access token の指定 Graph API を利用するには access token が必要です。\nGraph API の URL アクセス時の HTTP header に、以下を指定してください。\nAuthorization: Bearer {ACCESS_TOKEN} permission Graph API は、そのスコープごとにアクセス制御されます。\nこのアクセス制御に permission を与えることで、 API にアクセスできるようになります。\nAPI に permission を与えるには権限が必要になります。 その権限には、個人アカウントで良いものと、管理者権限が必要なものとがあります。\nなお、任意にメッセージを投稿するには、管理者権限による permission が必要です。\nTeams への投稿 Teams へ投稿するには以下の API を利用します。\n\u0026lt;https://docs.microsoft.com/ja-jp/graph/api/resources/teams-api-overview?view=graph-rest-1.0\u0026gt;\nTeams のチームへの投稿は次の概念で管理され、 それぞれがユニークな ID を持っています。\nteam\nTeams 内の各チーム channel\n各チーム内に作られるチャネル message\nチャネル内に投稿された各メッセージ 例えば、あるチーム内の、ある channel に 新規投稿する 場合、 対象チームの ID と、対象 channel の ID を取得し、 それら ID を指定してメッセージを投稿します。\n新規投稿ではなく、 あるメッセージに対する reply には、 前述の対象チームの ID と、対象 channel の ID に加え、 対象のメッセージ ID を取得する必要があります。\nこのメッセージ ID を取得するには、 ChannelMessage.Read.All スコープの permission が必要であり、 その permission を与えるには管理者権限が必要になります。\nなお、個人間のチャットはチームのメッセージとは異なります。\n新規投稿 API あるチーム内の、あるチャネルにメッセージを新規投稿する場合は、以下を利用します。\nhttps://graph.microsoft.com/v1.0/teams/{team-id}/channels/{channel-id}/messages ここで {team-id} , {channel-id} は、チーム、チャネルの ID を指定します。\n送信するデータは以下の情報を参考にしてください。\n\u0026lt;https://learn.microsoft.com/en-us/graph/api/channel-post-messages?view=graph-rest-beta\u0026amp;tabs=http\u0026gt;\nGraph Explorer \u0026lt;https://developer.microsoft.com/en-us/graph/graph-explorer\u0026gt;\nMS Graph API をブラウザから試すことができる Web ツール(Graph Explorer)が用意されています。\nこれを利用することで、 token 取得や permission の設定を簡単に行なえます。\nなお、このツール上で token 取得はできますが、 その token は短時間で expire する access token なので、 実際にクライアントを自作する際には、 ClientID の発行が必須になります。\nMS Graph API について MS Graph API は、MS のさまざまなサービスにアクセスできる強力な API です。\nですが、強力であるために、セキュリティはかなり安全方面に振っているように思えます。 さまざまなケースで管理者権限による許可が必要になっています。\nなんでもかんでも「管理者権限による許可が必要」というのは、 セキュリティの管理手法として、安直ではないのか？と思わないでもない。\n","id":30,"section":"posts","summary":"自作ツールで、MS Teams に対して投稿を read/write する方法について書きます。 Teams の管理者権限の許可が必須 「 Teams の管理者権限の許可が必須 」です。 大事なことなので","tags":null,"title":"MS Teams client の作り方","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-08-30-teams-client/","year":"2021"},{"content":" asciidoctor-pdf を利用すると asciidoc を pdf 化できます。\nここでは、 asciidoctor-pdf のセットアップと pdf 化時のレイアウト変更方法について説明します。\nasciidoctor-pdf のセットアップ asciidoctor-pdf が既にインストールされている場合、 日本語フォントのインストール時に conflict することがあるので、 ここでは docker を利用します。\ndocker を使わなくても、ローカル環境に ruby をインストールし、 Dockerfile の RUN と同等の手順を実行してもインストールできます。 asciidoctor-pdf が conflict した場合は、 asciidoctor-pdf をアンインストールしてから asciidoctor-pdf をインストールしなおしてください。\nDockerfile asciidoctor-pdf を利用するための Dockerfile は以下になります。\nFROM alpine:3.14.0 RUN apk update; RUN apk --no-cache add \\ curl \\ bash \\ ruby # asciidoctor-pdf WORKDIR / RUN gem install asciidoctor RUN gem install --pre asciidoctor-pdf RUN gem install asciidoctor-pdf-cjk-kai_gen_gothic RUN asciidoctor-pdf-cjk-kai_gen_gothic-install RUN cp /usr/lib/ruby/gems/2.7.0/gems/asciidoctor-pdf-cjk-kai_gen_gothic-0.1.1/data/themes/KaiGenGothicJP-theme.yml / CMD [\u0026#34;/bin/bash\u0026#34;] docker-compose version: \u0026#39;3\u0026#39; services: 2pdf: build: ./ image: asciidoc2pdf container_name: asciidoc2pdf volumes: - \u0026#34;./:/proj\u0026#34; tty: true 変換 以下を実行して asciidoc から pdf を生成します。\n$ docker-compose run 2pdf asciidoctor-pdf -a scripts=cjk -a pdf-theme=KaiGenGothicJP-theme.yml -a pdf-fontsdir=$(dirname $(gem which asciidoctor-pdf-cjk-kai_gen_gothic))/../data/fonts /proj/src.adoc ここで src.adoc は変換元の asciidoc です。\n実行すると src.pdf が生成されます。\npdf のレイアウト変更 asciidoctor-pdf を使って asciidoc から pdf に変換する際、 以下のオプションを指定しています。\n-a pdf-theme=KaiGenGothicJP-theme.yml これは、 PDF 変換に使用する theme を指定しています。\nasciidoc には、最低限必要な文書情報だけで構成されているため、 「その文書情報をどのように PDF としてレイアウトするか？」は、 theme で制御します。\ntheme を変更することで、同じ asciidoc でも様々な形式の pdf に変換することができます。 これは、html と css の関係と似ています。\nこのような制御になるので、 変換元の asciidoc と、 その時に利用した theme ファイルはセットで保存しておくべきです。\n次の公式ドキュメントに、この theme の詳細があるのでそちらを見れば良いですが、 ちょっと取っ掛り難いものがあるので、ここでは簡単に変更方法を説明します。\n\u0026lt;https://github.com/asciidoctor/asciidoctor-pdf/blob/main/docs/theming-guide.adoc#alignments\u0026gt;\ntheme.yml の変更 theme.yml は、 拡張子から分かるように YAML 形式になっています。\nYAML 形式の詳細についてはここでは説明しませんが、 最低限「インデントに意味がある」ことに注意すれば、 theme.yml の変更程度であれば問題ありません。\nまず、 先ほどの docker container から KaiGenGothicJP-theme.yml をローカルにコピーします。\nsudo docker-compose run 2pdf cp /KaiGenGothicJP-theme.yml /proj これをテキストエディタで開くと以下のようになります。\nここで font: , page: は、 theme のカテゴリです。 このカテゴリの下に、さらに別のカテゴリあるいは調整項目があります。\nfont: catalog: KaiGen Gothic JP: normal: KaiGenGothicJP-Regular.ttf bold: KaiGenGothicJP-Bold.ttf italic: KaiGenGothicJP-Regular-Italic.ttf bold_italic: KaiGenGothicJP-Bold-Italic.ttf Roboto Mono: normal: RobotoMono-Regular.ttf bold: RobotoMono-Bold.ttf italic: RobotoMono-Italic.ttf bold_italic: RobotoMono-BoldItalic.ttf fallbacks: - KaiGen Gothic JP page: background_color: ffffff layout: portrait それぞれの調整項目毎に値を設定するだけなので、 既に設定されている項目を変更すること自体は簡単にできます。\nどのようなカテゴリ、調整項目があるかは、公式のドキュメントを参照してください。\n設定項目のアクセス base: font_color: 333333 font_family: KaiGen Gothic JP font_size: 10.5 line_height_length: 15 line_height: $base_line_height_length / $base_font_size 上記の line_height: $base_line_height_length / $base_font_size を見ると、 $base_line_height_length が使われています。 これは、 base カテゴリの line_height_length を参照しています。\n設定項目にアクセスするには、 以下のように YAML の階層表現を利用する方法と、\nbase: line_height_length: 15 階層名をシンボル名に含める方法があります。\nbase_line_height_length: 15 なお、区切り記号は _ と - を使えます。\nKey Prefix 設定項目名は、 Key として管理されています。\n例えば base_line_height_length が Key です。\nどのような Key があるかは、公式のドキュメントに記載があります。\n公式のドキュメントで Key を探す際、 Key Prefix: で検索すると、 目的の Key を見つけ易いです。\n現在、以下の Key Prefix (抜粋)があります。\ncover page numbering base quotes link literal heading heading-h\u0026lt;n\u0026gt; section title-page title-page-logo title-page-title title-page-subtitle title-page-authors title-page-revision prose 例えば base_line_height_length は、 Key Prefix が base になります。\nbase の説明の中に、 line-height-length の説明があります。\nなお heading-h\u0026lt;n\u0026gt; は、 heading-h1, heading-h2 などを示します。\n","id":31,"section":"posts","summary":"asciidoctor-pdf を利用すると asciidoc を pdf 化できます。 ここでは、 asciidoctor-pdf のセットアップと pdf 化時のレイアウト変更方法について説明します。 asciidoctor-pdf のセットアップ asciidoctor-pdf が既にインストー","tags":null,"title":"asciidoc の pdf 化","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-07-26-asciidoc-2-pdf/","year":"2021"},{"content":" 先日の記事に書いた org-mode ドキュメントの翻訳ツールを作成したので、 今回はそのツールの使用方法を書きます。\nセットアップ golang がインストールされている環境で、以下を実行してください。\ngo install -tags gopherlua github.com/ifritJP/trans-orgmode@latest GCP の設定 GCP アカウントを既に持っていることを前提に説明します。 アカウントが無い場合は、作成してください。\nプロジェクトの作成 以下の手順に従って作業します。\n\u0026lt;https://cloud.google.com/translate/docs/setup?hl=ja#project\u0026gt;\nこれにより、以下を行ないます。\nプロジェクトを作成 API の有効化 サービスアカウントの設定 環境変数 GOOGLE_APPLICATION_CREDENTIALS の設定 上記 URL に記載の「クライアントライブラリのインストール」は 不要 です。\ntoken ファイルの作成 この翻訳ツールは GCP の認証を行なわないため、 事前に GCP のアクセストークンを取得し、 token ファイルを作成しておく必要があります。\nアクセストークンは、以下のコマンドを実行すると stdout に出力されます。\n$ gcloud auth application-default print-access-token これで取得したトークンを、以下の JSON 形式でファイルに記録します。 ファイル名は何でも良いです。\n{ \u0026#34;token\u0026#34;: \u0026#34;GCPTOKEN\u0026#34; } 上記 JSON の GCPTOKEN をアクセストークンに置き換えてください。\nなお、アクセストークンは一定時間で expire するので、 再度取得する必要があります。\n実行 このツールのオプションは、以下の通りです。\n$ trans-orgmode [-v] [-m mode] [-c jsonpath] input.org ここで -m は、以下のモードを指定します。\norg\n指定された .org ファイルを解析し、 解析した結果の .org を stdout に出力します。 これは、 .org ファイルの解析が正常に行なえているかどうかを確認するために利用します。 mkreq\n指定された .org ファイルを解析し、翻訳が必要な日本語文字列を抽出し、 GCP REST API の request 形式に変換したものを stdout に出力します。 これは、 REST API の request 形式に正しく変換できているかどうかを確認するために、 利用します。 trans\n指定された .org ファイルを翻訳し、その結果を stdout に出力します。 このモードでは、-c オプションの指定が必須です。 github\ngithub の README で .org ファイルを使う場合、 .org の CUSTOM_ID によるドキュメント内リンクが出来ません。 その代わり、 headline のリンクが利用可能なので、 CUSTOM_ID に相当する headline のリンクに置き換えを行ない、 結果を stdout に出力します。 これは上記 GCP の翻訳とは関係なく単独で動作します。 -c は、トークンを記載した JSON ファイルのパスを指定します。 -m に trans を指定した場合に必要です。\n-v は、 .org ファイルの解析情報を出力します。 デバッグ用の情報です。\n制限 このツールは、org-mode のサブセットをサポートします。\nどの機能をサポートするかは、 -m のモード指定で org, あるいは mkreq を実行して、 正常に処理されているかどうかで確認できます。 翻訳対象の文の中で *bold* や /italic/ を利用している場合、 翻訳後の文全体を *bold* あるいは /italic/ で強調処理します。 翻訳対象の文の中で =verb= や ~exp~ を利用せずにアルファベットや () などの記号を 利用していると、翻訳結果に悪影響が出ることがあります。 #+BEGIN_SRC や : 内の日本語は、翻訳しません。 ","id":32,"section":"posts","summary":"先日の記事に書いた org-mode ドキュメントの翻訳ツールを作成したので、 今回はそのツールの使用方法を書きます。 セットアップ golang がインストールされている環境","tags":null,"title":"org-mode ドキュメントの翻訳ツールの使い方","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-07-25-org-traslation-intro/","year":"2021"},{"content":" 私は org-mode を使って LuneScript のリファレンスを作成しています。\n日本語のリファレンスを書くのも大変ですが、 それを英訳しようとすると気が遠くなります。\nそこで機械翻訳を使う予定ですが、 .org ファイルをそのまま機械翻訳で処理すると、 コードブロックや org-mode の区切り記号まで変換され、 意図した結果を得られません。\nそこで今回は、org-mode の機械翻訳をスムーズに行なえるツールを検討します。\n構成 今回検討する org-mode 翻訳ツールは、以下の構成とします。\n入力\n.org ファイル 出力\n翻訳後の .org ファイル 処理\n.org ファイルの parse\n\u0026lt;https://github.com/niklasfasching/go-org\u0026gt; 機械翻訳\nGCP の Cloud Translation API \u0026lt;https://cloud.google.com/translate/docs/basic/translating-text?hl=ja\u0026gt; 全体制御\nLuneScript で自作 go-org .org ファイルの parse には go-org を利用します。\ngo-org は、go で実装された .org ドキュメントの parser で、 hugo はこれを利用して .org ファイルを read しています。\nLuneScript のリファレンスは、 hugo で構築しているので、 hugo で利用されているものと同じ parser を使えば、 問題なく parse 出来ると考えて選択しました。\nGCP Cloud Translation API 翻訳には、GCP の Cloud Translation API を利用します。\n幾つか機械翻訳サービスがありますが、自分がアカウントを持っていて、 無料で使えるのが GCP なのでこれを選択しています。\nGCP の Cloud Translation API も一定量を越えれば有料になりますが、 今回使う程度であれば越えることはないでしょう。\nちなみに、1ヶ月間のリクエスト文字数が 500,000 文字までが無料となります。\n\u0026lt;https://cloud.google.com/translate/pricing?hl=ja\u0026gt;\nここで言う 文字数 とは、以下によると\n\u0026lt;https://cloud.google.com/translate/pricing?hl=ja#charged-characters\u0026gt;\nバイト数ではなく、 日本語なら日本語の 1 つのキャラクタを 1 文字として扱うようです。 例えば多くの日本語は utf-8 で 1 文字 3 バイトですが、 1 文字が何バイトであっても 1 としてカウントされます。\n\u0026lt;p\u0026gt;こんにちは\u0026lt;/p\u0026gt; を翻訳対象として API に渡した場合、12 文字として扱われます。 これは、 HTML の \u0026lt;p\u0026gt;\u0026lt;/p\u0026gt; の 7 文字と こんにちは の 5 文字の合計です。\nちなみに、 LuneScript のリファレンスの .org ファイルは約 380KB です。 仮に全て utf-8 の日本語として考えると、約 126,000 文字となります。\n実際には、 .org には翻訳対象外のサンプルコードが含まれ、 それを除外したデータを機械翻訳 API で処理させるため、 Cloud Translation API で翻訳する文字数は約 126,000 文字よりも 少なくなることが考えられます。\nよって、 500,000 文字の無料枠を越えずに .org 全体に翻訳をかけるテストを数回実行できる計算になります。\n開発ステップ ツールの開発ステップとしては、以下を考えています。\ngo-org を使って .org ファイルを parse する。 parse した要素から翻訳する/しないを判別する。 翻訳する要素をまとめて翻訳 API で翻訳する。 翻訳した要素と、翻訳していない要素から .org を生成する もちろん、 go-org, 翻訳 API の使い熟しが前段階にあります。\nGCP Cloud Translation API 今回は Translation API の REST の v2 basic を利用します。\nREST v2 basic を利用する場合、以下の注意が必要です。\n一度に翻訳できる文字列数は、 128 個まで API の body のサイズは 200KB まで 上記の条件を満さない場合は、エラーとなります。 なお、エラーの場合は課金対象にならないようです。\nGCP のライブラリを利用すると、 ライブラリ側がこの制限を満すように制御するため、 制限を意識する必要はありません。\n","id":33,"section":"posts","summary":"私は org-mode を使って LuneScript のリファレンスを作成しています。 日本語のリファレンスを書くのも大変ですが、 それを英訳しようとすると気が遠くなります。 そこで機","tags":null,"title":"org-mode ドキュメントの翻訳ツール検討","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-07-19-org-traslation/","year":"2021"},{"content":" 今回の記事は、 先日検討した LuneScript のクラスのオブジェクトを スタックに割り当てて高速化できるかどうか？の検討結果です。\n結果 今回の検討結果は以下の通りです。\n「スタック割り当て自体は有効ですが、 スタック割り当てから escape されないように設計しないと効果を得られません。」\nなんだか当たり前な検討結果ですが、そうなんだから仕方がない。\nでは、なぜそのような結果になったかを説明していきます。\n検討内容 LuneScript でオブジェクトをスタック割り当てするには、 そのオブジェクトのクラスは次の条件を全て満す必要があります。\n全てのメンバが immutable Super クラスがない Sub クラスがない この条件にマッチし、なおかつ生成数の多いクラスは以下になりました。\nPositon\nトークンの位置情報 Token\nParse したトークン情報 go の pprof 機能の解析によると、 この 2 つの合計は、生成している全オブジェクト数の 5% ほどになります。\nこのクラスをスタック割り当てに変更してみたところ以下の結果になりました。\nPositon をスタック割り当てに変更\nトランスコンパイル時間が 1% 程度 改善 Token をスタック割り当てに変更\nトランスコンパイル時間が 10% 程度 悪化 この通り、クラスによって結果が異なりました。\n先日の記事で書いたように、オブジェクトをスタック割り当てする場合、 そのオブジェクトを最後までスタック割り当てで扱わないと逆に効率が悪くなります。\nでは、何故スタック割り当てで扱わないケースがあるのかと言うと、 LuneScript には nilable があるからです。\nnilable を表現するために、 go の interface{} を利用しています。 そして、スタック割り当てのオブジェクトを interface{} に変換すると、 escape されます。\nこのようなケースを改善するには、異常値の表現に nilable は使わずに、 特別な値を定義する必要があります。 あるいは Rust の Option 型のような型を用意する必要があります。\nまた、 List や Map などの collection 型は interface{} として値を保持します。 そして stem 型も interface{} として保持します。 つまり、collection 型, stem 型で管理することが前提の場合、 スタック割り当て化は逆効果です。\nただ、collection 型を使えないのは流石にハードルが高いので、 スタック割り当てのまま collection 型を使えるように改善したいと考えています。\nということで結論は以下になります。\nスタック割り当て自体は有効ですが、 スタック割り当てから escape されないように設計しないと効果を得られません。\n今後の予定 今の段階(6827a64)で、 セルフホストのトランスコンパイルの内部処理時間は 0.9 秒弱まで短縮できていますが、 time コマンドの計測結果では 1.1 秒前半です。\nこの原因の一つに、 collection 型で interface{} を利用していることが挙げられるので改善したいところです。 しかし、これを改善するには go 側の slice, map の generics 対応が必要になります。\nよって、go 側の slice, map の generics 対応を持ってから、 collection 型の改善が出来るように対応を検討します。\nそれまでは、 大きな改善は見込めなさそうなので LuneScript の高速化対応を一旦中断します。\n","id":34,"section":"posts","summary":"今回の記事は、 先日検討した LuneScript のクラスのオブジェクトを スタックに割り当てて高速化できるかどうか？の検討結果です。 結果 今回の検討結果は以下の通り","tags":null,"title":"LuneScript のトランスコンパイル高速化 (スタック割り当て)","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-07-02-lunescript-value-assigned-stack/","year":"2021"},{"content":" 先月から続いて、LuneScript のトランスコンパイル高速化作業をしています。\nセルフホストのトランスコンパイル時間 今回の時間短縮は以下の通りです。\nlua VM 版 go ビルド版 lua/go 改善前 5/6 (6e5661a9) 25.69 sec 5.84 sec 440% 改善後 5/25 (364095ef) 17.42 sec 2.22 sec 785% 改善後2 6/7(52df422b) 17.57 sec 1.82 sec 965% 改善後3 6/29(8898c475) 18.07 sec 1.13 sec 1599% 改善率(改善前/改善後3) 142% 517% この表は、セルフホスティングしているソースのトランスコンパイル時間の計測結果を 示しています。 lua VM で動作させた lnsc と、go でビルドした lnsc で計測しています。\n改善前の 6e5661a9 は、2021/5/6 のバージョンです。 今回の 改善後3 の 8898c475 は、2021/6/29 のバージョンです。\nこの表の通り、 改善前の Lua と、 今回の改善後3 go のトランスコンパイル時間を比べると (/ 25.69 1.13) 22.734513274336287 == 2273% 改善しています。\nあと少しで 1 秒を切れるところまで改善しました。\nなおこの時間は、 lns コマンドの処理時間を time コマンドで計測した結果です。 一方で、トランスコンパイラ内部で計測すると、 その処理時間は 約 0.94 秒 となっていて 1 秒を切っています。 つまり、トランスコンパイラの起動・終了処理に 約 0.2 秒程度かかっているようです。\nflamegraph 次の図は、セルフホストのトランスコンパイル実行時の flamegraph です。\nこれを見ると、左端の Go runtime にかなり多くの時間がかかっていることが分かります。 ただ、この時間がパフォーマンスにどの程度影響しているかは分かっていません。\nこの Go のランタイム処理は、基本的には GC の制御だと思います。\nGC 制御にこれだけ時間がかかっているということは、 それだけオブジェクトをヒープに生成しているということでもあります。 つまり、ヒープへのオブジェクト生成を抑制できれば、 GC 制御も軽くなることが考えられます。\n現状の LuneScript は、 全てのクラスのオブジェクトをポインタで管理 します。\n以下の記事によると、 ポインタで管理するオブジェクトは、 ほとんど全てのケースでヒープに生成される ということです。\n\u0026lt;https://hnakamur.github.io/blog/2018/01/30/go-heap-allocations/\u0026gt;\nつまり、 LuneScript のクラスオブジェクトは、 ほとんど全てがヒープに生成される ことになります。\nこれでは Go のランタイム処理が重くなるのも当然 でしょう。\nならば、出来るだけポインタを使用せずにクラスオブジェクトを管理できれば、 ヒープのオブジェクト数が減り、Go のランタイム処理は軽くなるはずです。\nただしここで疑問なのは、 GC 処理が重いのは間違いないとしても、 スタック割り当てにした時に、本当に軽くなるのか？ というところ。\nまた、LuneScript のデータ構造で、 オブジェクトをスタック割り当てにすることが可能かどうか？ というところです。\nスタック割り当てなら早い？ スタック割り当てにして本当に高速化できるのかを確認するため、 簡単な検証用コードを作成しました。\nこのコードは、 sub1 〜 sub4 をそれぞれ一定回数実行し、 それぞれの実行時間を出力します。\nコメントの // escape は、 $ go build -gcflags -m コマンドで escapes to heap と出力された箇所を示します。\npackage main import \u0026#34;fmt\u0026#34; import \u0026#34;time\u0026#34; import \u0026#34;runtime\u0026#34; type Test struct { val int } var list1 = make( [] Test, 1 ) var list2 = make( [] interface{}, 1 ) func sub1( test Test ) { list1[ 0 ] = test } func sub2( test *Test ) { list2[ 0 ] = test } func sub3( test Test ) { list2[ 0 ] = test // escape } func sub4( test *Test ) { list1[ 0 ] = *test } func profile( name string, callback func() ) { runtime.GC() prev := time.Now() callback() fmt.Printf( \u0026#34;%s: time = %v\\n\u0026#34;, name, time.Now().Sub( prev ).Milliseconds() ) } func main() { maxCount := 100000 * 50000 profile( \u0026#34;sub1\u0026#34;, func() { test := Test{} for count := 0; count \u0026lt; maxCount; count++ { sub1( test ) } }) profile( \u0026#34;sub2\u0026#34;, func() { test := \u0026amp;Test{} // escape for count := 0; count \u0026lt; maxCount; count++ { sub2( test ) } }) profile( \u0026#34;sub3\u0026#34;, func() { test := Test{} for count := 0; count \u0026lt; maxCount; count++ { sub3( test ) // escape } }) profile( \u0026#34;sub4\u0026#34;, func() { test := \u0026amp;Test{} for count := 0; count \u0026lt; maxCount; count++ { sub4( test ) } }) } この処理は、 Test 構造体のオブジェクトを生成し、 スライスの list1 あるいは list2 に格納します。 オブジェクトの生成から格納するまでの間、 値渡しで処理するか、ポインタ渡しで処理するかによって、 実行時間にどのような違いが出るかを計測します。\n各関数はそれぞれ以下を実行しています。\nsub1\n値渡しのまま処理する。 sub2\nポインタ渡しのまま処理し、interface{} に変換する。 sub3\n値渡しのデータを、 interface{} に変換して処理する。 sub4\nポインタが示すアドレスから、値をコピーして処理する。 上記プログラムの実行結果は次の通りです。\nsub1: time = 1765 sub2: time = 3724 sub3: time = 11300 sub4: time = 3713 これを見ると、以下が分かります。\n値渡しをしている sub1 が一番高速に動作している。 ポインタ渡しをしている sub2 は、sub1 の倍以上の時間かかっている。 値渡しのデータを interface{} に変換している sub3 は、 最初からポインタでデータを保持している sub2 の 3 倍時間がかかっている。 ポインタ渡しのデータから値をコピーするだけなら escape されない。 しかし、コピーに時間がかかってしまい、 最初から最後までポインタで持っている sub2 と変わらない。 これにより、 値渡しがポインタ渡しよりも高速に動作する ことが確認できました。\n一方で、 sub3 のケースのように 値をスタック割り当てで処理する場合でも、 途中で interface{} に変換すると逆に遅くなる ケースがある。 ということも分かりました。\n特に、 sub1 と sub2 の比率と、 sub2 と sub3 の比率を比べると、明らかに後者の方が大きいです。\nつまり、 中途半端なスタック割り当ては逆効果になる ということです。 sub1 のつもりでスタック割り当て対応したら、結果は sub3 になってしまう。 そんなことが起きる可能性があります。\nこれを考えると、 下手にスタック割り当てすると今よりさらに遅くなる 可能性があるということで、 スタック割り当て対応は慎重に 行なわなければなりません。\nスタック割り当てを実現する場合 LuneScript でスタック割り当てを実現する場合、以下を検討する必要があります。\nlua にトランスコンパイルした時の動作の定義 スタック割り当てと、ヒープ割り当ての syntax 上の表現 lua にトランスコンパイルした時の動作の定義 lua は、ポインタという概念がありません。 というか、全てのクラスオブジェクト(table)は、ポインタで管理されるため、 go のようにヒープ割り当てされているオブジェクトを、 スタック割り当てにすれば速くなる、ということはありません。\n特に、スタック型の引数を持つ関数の動作を lua で再現するには、 ヒープ割り当てのオブジェクトを clone することになり、 ヒープ割り当てのオブジェクトが clone した分増え、 パフォーマンスが余計に劣化するだけです。\nこのパフォーマンス劣化を防ぐには、 go と lua とで出力を変更する必要があります。 具体的には、go に変換する場合はスタック割り当てオブジェクト同士のコピーにし、 lua に変換する場合はヒープオブジェクトのポインタ渡しにします。\nしかし、これではそのオブジェクトが mutable であった時に、 go と lua とで論理が異なることになります。\n逆に言えば、 オブジェクトが immutable であれば、 go と lua とで同じ論理になることになります。\nだとすれば、go でスタック割り当てオブジェクトを使う条件として、 完全 immutable オブジェクト を前提にすることで、 go と lua とで同じ論理を保ちつつ、 go を高速化できる可能性があります。\nここでいう 「完全 immutable オブジェクト」 とは、 「ある時点 T 以降で変更されることがないオブジェクトの T 以降」 を指します。\nたとえば以下のような場合、 test は 「完全 immutable オブジェクト」 ではありません。\nclass Test { let mut val:int {pub,pub}; } fn foo( test:\u0026amp;Test ) { print( test.$val ); } fn bar( test:Test ) { test.set_val( 10 ); } let mut test = new Test(1); foo( test ); // 1 bar( test ); foo( test ); // 10 上記のコードで、 foo() の中では test は immutable ですが、 完全 immutable オブジェクト ではありません。\nなぜなら、 bar() によって、 test のメンバが書き換えられるためです。\nこのように、ある範囲では immutable に見えても、 全体で見ると mutable なオブジェクトは 完全 immutable オブジェクト ではありません。\n一方で、例えば以下のようなケースでは、 test は 完全 immutable オブジェクト です。\nclass Test { let mut val:int {pub,pub}; } fn foo( test:\u0026amp;Test ) { print( test.$val ); } fn bar( test:Test ) { test.set_val( 10 ); } let test; { let mut work = new Test(1); foo( work ); bar( work ); test = work; } foo( test ); なぜなら test の型は \u0026amp;Test であり、 なおかつ test の代入元の work は、既にスコープ外になっていて、 mutable アクセス可能な変数が存在しないためです。\nただ、このようなケースを 完全 immutable オブジェクト として扱うのは困難です。\nなぜなら、 mutable 型のシンボルの有無を保証しなければならないためです。\nもしも、これを実現するのなら、 Rust のようなアクセス権制御を導入する必要があるでしょう。\nRust のようなアクセス権制御導入は最終手段にしたいので、 ここでは 完全 immutable オブジェクト として扱うために、 そのオブジェクトのクラスに次の制限を設定します。\nどのクラスからも継承されていない 全てのメンバが immutable。 あるいは、オブジェクトを生成する時点で immutable として生成する。 上記制限を満す時に限り、そのクラスのオブジェクトを 完全 immutable オブジェクト とします。\nスタック割り当てと、ヒープ割り当ての syntax 上の表現 上記検証コードで確認した通り、 スタック割り当てにしても処理が高速化させるとは限りません。\nつまり、ヒープ割り当てからスタック割り当てに時間をかけて切り替えて、 実際にパフォーマンスを計測してみたら遅くなっていた、なんていう可能性があります。\nよって、あるオブジェクトをヒープ割り当てからスタック割り当て切り替える、 そしてその逆を簡単に切り替えられるようにする必要があります。\nこのように対応することで、高速化の検討作業を効率化できます。\nこれを実現するには以下が必要です。\nスタック割り当てと、ヒープ割り当ての syntax 上の表現の違いを、 クラス宣言の表現に極力おさめる。 クラス宣言の外の syntax 表現の違いが出る場合は、 機械的な置換が出来る表現にする。 現状の syntax 候補としては、 __absImmut インタフェースを implement したクラスを、 完全 immutable オブジェクトとして扱います。\nなお、__absImmut インタフェースを implement したクラスは、以下を制限します。\nimmutable なメンバーしか持てない。 継承できない。 まずは __absImmut インタフェースの対応をすすめ、 それで効果が出るかどうかを確認する予定です。\n","id":35,"section":"posts","summary":"先月から続いて、LuneScript のトランスコンパイル高速化作業をしています。 セルフホストのトランスコンパイル時間 今回の時間短縮は以下の通","tags":null,"title":"LuneScript のトランスコンパイル高速化 (トランスコンパイル時間を 2273 パーセント改善)","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-06-28-lunescript-build-time-2000/","year":"2021"},{"content":" LuneScript の高速化のため、マルチスレッド化を行ないました。\n今回は、LuneScript のどこをマルチスレッド化したのか、 マルチスレッド化で何故高速化できるのかを説明します。\nビルド時間 今回の時間短縮は以下の通りです。\nlua VM 版 go ビルド版 lua/go 改善前 5/6 (6e5661a9) 25.69 sec 5.84 sec 440% 改善後 5/25 (364095ef) 17.42 sec 2.22 sec 785% 改善後2 6/7(52df422b) 17.57 sec 1.82 sec 965% 改善率(改善前/改善後2) 146% 329% この表は、セルフホスティングしているソースのトランスコンパイル時間の計測結果を 示しています。 lua VM で動作させた lnsc と、go でビルドした lnsc で計測しています。\n改善前の 6e5661a9 は、2021/5/6 のバージョンです。 改善後2 の 52df422b は、2021/6/7 のバージョンです。\nこの表の通り、 改善前の Lua と、改善後 go のトランスコンパイル時間を比べると (/ 25.69 1.82 ) 14.115384615384615 ≒ 1412% 改善しています。\n改善後2 の lua と go の比較では 965%、 改善前と改善後2 の go の時間を比べると、 329% 改善しています。\n前回からさらに並列度を上げています。\nLuneScript の処理フロー LuneScript は次の処理を行ないます。\n.lns ファイルの parse AST の構築 AST から .lua, .meta の生成 AST から .go の生成 図にすると、以下のようになります。\nここで、色が付いているのが処理で、色の無いのが処理の入出力データです。\n上記の処理を、各ファイルに対して行ないます。\nマルチスレッド化 マルチスレッド化した LuneScript の処理は次です。\n各処理をスレッド化しています。\nこのマルチスレッド化により、以下の効果があります。\nparse と AST 解析を並列処理できる convLua と convGo を並列処理できる 複数ファイルを処理する場合は、さらに効果を発揮します。\n複数ファイル処理時の効果 シングルスレッドで、複数ファイル(file1.lns, file2.lns, file3.lns) を処理すると、 次のようなイメージで処理されます。\nstep1 step2 step3 step4 step5 step6 step7 step8 step9 file1.lns parse create_Ast convLua convGo file2.lns parse create_Ast convLua convGo file3.lns parse 時間軸: →→→→→→→→→→→→\nこれは LuneScript の処理を示す概念図で、 左から右に処理の step が進んでいることを示します。\n一方、マルチスレッド化すると以下になります。\nstep1 step2 step3 step4 step5 file1.lns parse create_Ast convLua/Go file2.lns parse create_Ast convLua/Go file3.lns parse create_Ast convLua/Go シングルスレッドと比較して、かなり処理時間を短縮できていることが分かります。\nなお、これはあくまでもイメージなので、 実際には綺麗に step で時間が区切られている訳ではありません。\nまた、先に処理を開始したファイルが処理終了するよりも前に、 後から処理を開始したファイルの処理が終る場合もあります。\nマルチプロセスとの違い ここまでの説明を読んで、以下を疑問に思っている人もいるでしょう。\n「マルチスレッド化ではなく、make で並列ビルド(マルチプロセス処理)すれば良いじゃない？」\nそれはある意味で正しいですが、ある意味で間違いです。\nマルチプロセスと比較すると、マルチスレッド対応は以下の効果があります。\nプロセス起動にかかるオーバーヘッドを削減できる 依存関係を効率的に対応できる ここでいう依存関係とは、 『あるファイル A.lns が別のファイル B.lns をインポートしている』ことを指します。\nこの場合、 B.lns をビルドする際に、A.lns も解析する必要があります。\nそして、A.lns と B.lns を make で並列に処理しようとしても、 その依存関係から B.lns は A.lns の後にビルドされることになります。\nつまり依存関係がある場合、シングルスレッドで示した時と同じ動作になります。\nマルチスレッド化の場合 ここで、以下を疑問に思っている人もいるでしょう。\n「依存関係がある場合は、マルチスレッド化しても同じじゃないのか？」\nこれもある意味で正しいですが、ある意味で間違いです。\nここで、先ほどのマルチスレッドで A.lns と B.lns を処理するケース見てみます。\nstep1 step2 step3 step4 A.lns parse create_Ast convLua/Go B.lns parse create_Ast convLua/Go A.lns が B.lns をインポートしていても、 A.lns の処理が終る前に B.lns の解析が出来ています。\nこれが何故かというと、 step2 の A.lns の create_Ast によって A.lns の解析が終っているため、 step3 で B.lns の create_Ast が可能になります。\nもちろん、A.lns の create_Ast に時間がかかれば、 その分 B.lns の create_Ast は待たされて時間が延びます。\nしかし、 make などのマルチプロセスに比べれば、 明らかにマルチスレッド化の方が効果があります。\ngoroutine セルフホストは 44 ファイル(約44KLine)で構成しています。\n今回のマルチスレッド処理は、 golang 版のセルフホストで実現しています。\nセルフホストの 44 ファイルをトランスコンパイルする際に 動作する goroutine 数を計測したところ、最大で 160 個が同意動作することが判った。\n同時に動かす goroutine 数を制限する機能を実装し、 goroutine 数を少なくした場合どのように動作するのかを調べたところ、 以下の結果が得られた。\ngoroutine 制限数 ビルド時間 (sec) 141 1.82 130 1.83 126 1.93 121 2.02 103 2.04 52 2.02 25 2.13 同時動作させる goroutine 数を少なくすほど、 ビルド時間が劣化することが確認できる。\nただし、goroutine 数をかなり少なくしても、 2割程度のパフォーマンス劣化で済んでいる。\nセルフホストのコードは、芋蔓式の依存関係があるため、 goroutine 数を制限しても大きく代わらないのかもしれない。\n最後に LuneScript の高速化のため、マルチスレッド化を行ないました。\nこれにより、対応前と対応後とで比較すると倍以上の高速化を達成できました。\nなお、マルチスレッド化にはデータ競合との戦いがつきものですが、 LuneScript ではデータ競合を論理的に排除する仕組みを組込みました。\nこれにより、楽に安全にマルチスレッド化を実現できました。\n現状、全てのデータ競合を論理的に排除できる訳ではありませんが、 開発の楽さと安全性のバランスの取れたものになっていると思います。\n少なくとも、今回、シングルスレッドだった LuneScript のセルフホストコードを マルチスレッド化するにあたって必要だった変更は、かなり少ない修正量で済みました。\ngithub の Code frequency で変更量を見ると、かなり変更したように見えますが、 これはトランスコンパイルしたコードが変更になっているためです。\n少しの .lns の変更で、トランスコンパイル結果が変ってしまう現象については、 今後改善していきます。\nLuneScript のマルチスレッド化 syntax については、 後日整理してアップする予定です。\n","id":36,"section":"posts","summary":"LuneScript の高速化のため、マルチスレッド化を行ないました。 今回は、LuneScript のどこをマルチスレッド化したのか、 マルチスレッド化で何故高速化","tags":null,"title":"LuneScript のセルフホストのマルチスレッド化 (トランスコンパイル時間を 1412 パーセント改善)","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-06-04-lunescript-selfhost-para/","year":"2021"},{"content":" 今月上旬に TypeScriptToLua の存在を知ったことで、 「Lua のトランスコンパイラ」という LuneScript の主な 存在意義 がほとんど消えてしまいました。\nそれによって LuneScript 開発に対するモチベーションが一気に下りましたが、 よくよく考えてみれば、今迄も自分以外の誰かが使っていた訳でもないし、 独自言語開発は元々自分がやりたかったこと でもあるので、 TypeScriptToLua があろうとなかろうと 今迄と然程違いはないんじゃないか、 という結論になりました。\nそんな訳で、LuneScript は自分の検討用プログラミング言語として 今後も開発を継続 していく予定です。 特に go との連携機能に注力します。\n今迄は自分以外のユーザ環境でも使いやすくなるように 多少なりとも考えていましたが、 Lua のトランスコンパイラに TypeScriptToLua ではなく LuneScript を使おうという人はほとんどいないと思うので、 今後は自分特化になります。 ということで、先月末は LSP の対応を進めようと思っていましたが、 別のことを優先します。\n既に LSP 対応をやめて トランスコンパイル時間の高速化に着手し、 従来と比べて 1157 パーセントの改善を実現しています。\n高速化の詳細は過去記事を参照。\n安全な非同期化処理 今回の高速化の実現手段として、 go へのトランスコンパイラ時に 非同期化処理を安全に実現(コンパイラレベルでデータの競合アクセスを排除)する方法を 実験的に対応しました。\nこの 「安全な非同期化処理」 は、予想以上に効果を発揮し、 今回の非同期化対応のコード修正を完了して動かした際には、 驚くほどすんなりと何のエラーもなく並列化して動かすことができました。 46KLine (go 変換後は77KLine) のプログラムを非同期化して、 一発でまともに動くのは結構凄いことじゃないでしょうか？(自画自賛)\nなお、従来のシングルスレッド処理の非同期化には、 非同期化対応の文法エラーが発生するので、 そのエラーを逐次対応する必要があります。\nこれには、そこそこ時間が掛りましたが、 非同期処理にありがちな実行時の不具合に悩まされるよりは、 コンパイルエラーの方がよほど効率が良いです。\n特に syntax の論理的なエラーなので、コンパイラにバグがない限りは、 非同期処理における危険な箇所を抜け漏れなく解決できる、 というのはとても楽だし安全です。\nこういうことを実現できるのが、自分用の独自言語を持つ大きなメリットの一つです。\nちなみに、 LuneScript の非同期処理に関しては、 まだ検討段階であり、 syntax エラー検出にバグもあるので、リファレンスに公開するのは、 もう少し先になります。\n非同期処理を使用しないケースでは、基本的には影響のないものになっています。\n","id":37,"section":"posts","summary":"今月上旬に TypeScriptToLua の存在を知ったことで、 「Lua のトランスコンパイラ」という LuneScript の主な 存在意義 がほとんど消えてしまいました。 それによって LuneScript 開発に対す","tags":null,"title":"LuneScript のこれからの予定","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-26-lunescript-plan/","year":"2021"},{"content":" 前回から引き続き LuneScript のトランスコンパイル時間短縮を行なっています。\n今回の時間短縮は以下の通りです。\nlua go lua/go 改善前(6e5661a9) 25.69 sec 5.84 sec 440% 改善後(364095ef) 17.42 sec 2.22 sec 785% 改善率(改善前/改善後) 147% 263% この表は、セルフホスティングしているソースのトランスコンパイル時間の計測結果を 示しています。 lua VM で動作させた lnsc と、go でビルドした lnsc で計測しています。\n改善前の 6e5661a9 は、5/6 のバージョンです。 改善後の 364095ef は、5/25 のバージョンです。\nこの表の通り、 改善前の Lua と、改善後 go のトランスコンパイル時間を比べると (/ 25.69 2.22 ) 11.572072072072071 ≒ 1157% 改善しています。\n改善後の lua と go の比較では 785%、 改善前と改善後の go の時間を比べると、 263% 改善しています。\n今回は以下の高速化を行ないました。\nmeta 情報処理の高速化 ast から lua, go へ変換する処理の並列化 以降では、今回の高速化方法ついて説明します。\nmeta 情報処理の高速化 LuneScript は、モジュールをインポートする際、 そのモジュールが何のクラスや関数を公開いているか？を解析します。 この「何のクラスや関数を公開しているか」の情報が meta 情報です。\nこの meta 情報を解析するには時間がかかるため、 解析した meta 情報は .meta ファイルとして保存します。 そして、 .meta ファイルがある場合は、そのファイルから meta 情報を取得します。\n個々の .lns ファイルを一つずつトランスコンパイルする際は、 この .meta から取得するのが高速化として重要です。\n一方で、複数の .lns ファイルを一括してトランスコンパイルする際は、 この方法は多くの無駄な処理が含まれます。\nmeta 情報の処理 .meta ファイルを生成し、 生成したファイルを読み込んで meta 情報を構築するには、 以下の処理が必要です。\n.lns ファイルを解析し AST を得る。 AST に含まれる .meta 情報から .meta ファイルを出力する。 .meta ファイルを読み込み meta 情報を構築する。 ちなみに、この .meta ファイルを読み込み meta 情報を構築する処理を、 ここでは import 処理と言います。\n2 つのファイルを処理するケース 例えば、 2 つのファイル(a.lns, b.lns: b.lns から a.lns を import している)を 一括でトランスコンパイルする場合は以下になります。\na.lns ファイルを解析し AST_a を得る。 AST_a に含まれる meta_a 情報から a.meta ファイルを出力する。 b.lns ファイルを解析し AST_b を得る。\nこの解析途中に a.meta を読み込み、 meta_a 情報を構築する。 AST_b に含まれる meta_b 情報から b.meta ファイルを出力する。 ここで、 「この解析途中に a.meta を読み込み、 meta_a 情報を構築する。」 は無駄です。\nなぜならば、「meta_a 情報」は AST_a に含まれており、 AST_a はメモリ上に残っているため、 「a.meta を読み込み、 meta_a 情報を構築する」ことなく、 メモリ上の AST_a から meta_a を取得できるからです。\nimport 処理の変更 以下のように import 処理を変更します。\na.lns ファイルを解析し AST_a を得る。 AST_a に含まれる meta_a 情報から a.meta ファイルを出力する。 b.lns ファイルを解析し AST_b を得る。\nこの解析途中に AST_a に含まれる meta_a 情報を取得する。 AST_b に含まれる meta_b 情報から b.meta ファイルを出力する。 a.meta を読み込み、 meta_a 情報を構築する。 処理と、 AST_a に含まれる meta_a 情報を取得する。 処理を比較すれば、 圧倒的に後者の方が高速に処理できます。\nやっていることは非常に単純ですが、これを実現するのは結構大変でした。。\nast から lua, go へ変換する処理の並列化 トランスコンパイルは、以下の処理行ないます。\n.lns ファイルを解析して AST を取得する AST から .lua, .go を生成する これを .lns ファイル分実行します。\n例えば a.lns, b.lns, c.lns の 3 つのファイルがあった場合、 次の通り処理します。\na.lns ファイルを解析して AST_a を取得する AST_a から .lua, .go を生成する b.lns ファイルを解析して AST_b を取得する AST_b から .lua, .go を生成する c.lns ファイルを解析して AST_c を取得する AST_c から .lua, .go を生成する ここで、 「AST_a から .lua, .go を生成する」 、 「AST_b から .lua, .go を生成する」 、 「AST_c から .lua, .go を生成する」 の処理は、 基本的には独立して処理できます。\nつまり、これら処理は並列して実行可能です。\nそこで go rutine を利用して、並列化しています。\nしかし、 直感的に 並列化可能 と言っても、 実際に安全に並列化ができるかどうかは別の話です。\nシングルスレッドでは問題にならないことも、 マルチスレッドにすると問題になることが良くあります。\n今回の 並列化処理 を実現するにあたり、 マルチスレッド化を安全に論理的に実現する方法を、 LuneScript に追加しました。\n","id":38,"section":"posts","summary":"前回から引き続き LuneScript のトランスコンパイル時間短縮を行なっています。 今回の時間短縮は以下の通りです。 lua go lua/go 改善前(6e5661a9) 25.69 sec 5.84 sec 440% 改","tags":null,"title":"LuneScript のトランスコンパイル時間を 1157 パーセント改善した件","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-25-lunescript-improved-build-time/","year":"2021"},{"content":" LuneScript は golang へのトランスコンパイルをサポートしている。\ngolang 対応の付加機能として、LuneScript には限定的な非同期処理を提供している。\n今回は、この「限定」を緩和する方法を検討する。\n非同期処理を「限定」する理由 非同期処理を限定する主な理由は、非同期処理を安全に実行するためだ。\nでは、非同期処理のなにが危険なのかといえば、データアクセスの競合だ。\nRust では、データアクセスの競合が発生しないように、 言語の syntax で論理的に競合を排除する方法を採用している。\nLuneScript も、同じように言語の syntax で論理的に排除できるように目指したい。\nただ、 Rust の syntax は、 データアクセスの競合排除と、 メモリアロケーションコントロールを行なう上では非常に有用ではあるが、 プログラミングのコストが高いのも事実だ。\nLuneScript の目的は、楽をして安全に開発することなので、 安全性とのトレードオフで、もう少しコストの低い方法で実現したい。 特に LuneScript はメモリアロケーションコントロールは gc に任せているので、 Rust ほどの厳密な syntax は不要なので、その分の簡易化はすべきだ。\n非同期処理を安全に実現する方法 非同期処理を安全に実現するには、 あるデータ A に対し、 非同期に mutable なアクセスが行なわれないことが保証できれば良い。\n言い換えれば、 immutable なアクセスだけであれば安全である。\nLuneScript には、メソッドの mut 宣言による mutable 制御がある。 これは、immutable な型のオブジェクトから、 mut 宣言されたメソッドのコールを禁止するものである。 mut 宣言されたメソッドは、 オブジェクトのメンバーを変更することを宣言するものである。\nつまり、非同期処理に渡す引数を immutable 型のオブジェクトに限定し、 どこからもそのオブジェクトの mutable メソッドをコールしないようにすれば、 安全に非同期処理が実現できるように考えられる。 しかし、これを実現するのもそう簡単ではない。\nその原因は次にある。\nあるオブジェクトを、複数の mutable 型の変数に代入できる メソッドの mutable 制御だけでは対処できないケースがある 複数の mutable 型の変数に代入できる LuneScript では、 あるクラスのオブジェクトを、 複数の mutable 型の変数に代入することが出来る。 これにより、あるオブジェクトが意図していない所で mutable 型の変数に代入され、 その変数を通して mut 宣言されたメソッドがコールされ、 非同期処理に影響を及ぼす可能性がある。\nこれを防止するのがまさに Rust が採用する所有権制御である。 ただ前述しているように、 これはコストが大きいので LuneScript では採用したくない。\nこれに関しては、制限として割り切る方向で考えている。\nただ、完全に割り切ってユーザに管理を丸投げするのではなく、 なんらかの設計の手助けになる情報を提供するツールを別途検討する。\nメソッドの mutable 制御だけでは対処できないケース メソッドの mut 宣言だけでは、以下のケースにおいて危険である。\nallmut なメンバを変更するメソッドは mut 宣言が不要なため、 mut 宣言していなくても、実質的に mutable な動作をするケースがある。 モジュールの公開関数からモジュール内の大域変数の変更が可能であり、 かつ関数には mut 宣言がないため安全かどうかの区別できない form の実行において、そのフォームが mutable な処理かどうか区別できない。 LuneScript では、これらについて論理的に対応する方法を考える。\n非同期処理の実現方法 go へのトランスコンパイル時は非同期処理をサポートするが、 一方 Lua へトランスコンパイル時は非同期処理をサポートしない。\nつまり、非同期処理として書いたものを、 同期処理として動かしても矛盾のない書き方をする必要がある。\nこれに関しては、非同期処理をサポートしない場合は 「非同期処理を開始する API」実行時に、同期処理として実行することで対応する。\n非同期処理インタフェースの実装 ここの情報は検討中\n非同期処理は、クラスのメソッドを非同期で処理することで実現する。 このクラスは、__Runner インタフェースを実装する必要がある。\nまた、__Runner インタフェースを実装するクラスは、以下を制限する。\n引数は、全て immutable 型のオブジェクトでなければならない。 これにより、そのクラス内から競合する mutable アクセスがないことを保証する。\n__init() メソッド pub メソッド ただし、引数のオブジェクトのクラスのメンバが全て immutable 型の場合は、 その引数自体は immutable でなくても良い。 引数の型が型パラメータの場合、条件を満しているとして処理する。 メソッドからコールする外部モジュールの関数、メソッドは、次の条件を満さなければならない\n大域変数、あるいはクロージャの変数に影響を与えてはならない。 allmut への更新がない。 上記制限は、 __Runner インタフェースを実装するクラスの super クラス、 sub クラスも同様に制限される。\n上記制限を満すかどうかを確認するため、以下の制御を追加する。\n__async 宣言を追加する。\n__async 宣言された関数、メソッドは以下の制限に従う。\nmutable 型を格納する大域変数、あるいはクロージャの変数にアクセスしない。 allmut 型のシンボルの参照がない __noasync な関数をコールしてはならない。 _lune_control に default_async_func を追加する。\ndefault_async_func が宣言されたモジュールの関数は、 デフォルトで __async 宣言が付加される。 __async でない関数は、 __noasync 宣言する必要がある。 メソッドは対象外 _lune_control に control_default_async_all を追加する。\ndefault_async_func が宣言されたモジュールの関数は、 全ての関数、メソッドにおいて、async 宣言がデフォルトで付加される。 __noasync 宣言を追加する。\n__async 宣言とは逆の働きをする。 default_async_func が宣言されていないモジュールの関数は、 デフォルトで __noasync が付加される。 _lune_control に default_async_this_class を追加する\nクラスの body 先頭に default_async_this_class を宣言することで、 そのクラス内は control_default_async_all と同じ効果が得られる。 _lune_control に default_noasync_this_class を追加する\nクラスの body 先頭に default_async_this_class を宣言することで、 そのクラス内は control_default_async_all とは逆に、 デフォルトが __noasync 宣言になる。 ","id":39,"section":"posts","summary":"LuneScript は golang へのトランスコンパイルをサポートしている。 golang 対応の付加機能として、LuneScript には限定的な非同期処理を提供している。 今回は、こ","tags":null,"title":"LuneScript のスレッドにおける mutable 制御","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-16-lunescript-thread-mutable-control/","year":"2021"},{"content":" LuneScript は golang へのトランスコンパイルをサポートしている。\ngolang 対応の付加機能として、LuneScript には限定的なスレッド機能を提供している。\n「限定的」の大きな理由の一つとして、 golang 向け LuneScript ランタイムのマルチスレッド対応問題がある。\ngolang 向け LuneScript ランタイム golang 向け LuneScript ランタイムは、幾つか機能を持っている。 その機能の中には、次のものを含む。\nand or 演算子の処理を実現するためのスタック。 lua ランタイム制御。 LuneScript は元々 Lua 向けのトランスコンパイラであり、 Lua はシングルスレッドの言語である。 そのため、 LuneScript の上記ランタイムもシングルスレッドを 想定した構成になっているため、そのままではマルチスレッドで利用できない。\nシングルスレッド限定で良ければ、 マルチスレッドを考慮した作りに比べて簡単になるし、その分高速にもなる。\nマルチスレッド対応 LuneScript ランタイムをマルチスレッド対応する際には、 次の 2 つの方法が考えられる。\nランタイムの複数インスタンス化 ランタイムの排他制御 ランタイムの複数インスタンス化 スレッド毎にランタイムをインスタンス化して管理する場合、 どのランタイムがどのスレッドのものかを管理する必要がある。\n一方で、golang には go-routine の識別 ID がない。 つまり、 「必要な時に識別 ID からランタイムを取得する」 ということが 出来ないことになる。\ncgo を利用すれば、 go-routine が動作している pthread ID を取得することは可能だが、 golang のタスクスケジューリングでは、 ある go-routine を実行する pthread が常に固定されている訳ではない。 つまり動的に取得した pthread ID は、 go-routine の ID にはならない。\nということは、 LuneScript ランタイム情報にアクセスするためには、 全ての関数にランタイム情報を渡していく必要がある。\nランタイムの排他制御 ランタイムの複数インスタンス化には、 全ての関数パラメータにランタイム情報の追加が必要になる。 これは、全ての関数でオーバーヘッドが追加になり、 当然プログラム全体がその分遅くなる。\nそこで、ランタイムは複数インスタンス化せずに、 アクセスが必要な時だけ排他を掛けるケースを考える。\n排他には次のケースがある。\nmutex を使う channel を使う 今回は両方検証する。\nパファーマンス golang の簡単なプログラムで、 複数インスタンス化したケースと、ランタイムの排他制御を実施したケースの パフォーマンスを測ってみた。\nなお、実際に複数インスタンス化する訳ではなく、 関数に引数を追加するケースと、 排他制御を追加するケースとで、パフォーマンスを測っている。\n結果以下となった。\n引数に追加 \u0026lt;\u0026lt;\u0026lt;\u0026lt; mutex \u0026lt;\u0026lt; channel 「引数に追加」が一番負荷が少なく、「channel」が一番負荷が高かった。\nただ「mutex」や「channel」の場合は、 必要な箇所だけに制御を追加すれば良いということを考えると、 「mutex」で対応するのが一番良いのかもしれない。\nLuneScript のマルチスレッド対応は、「引数に追加」でいこうと思う。 ","id":40,"section":"posts","summary":"LuneScript は golang へのトランスコンパイルをサポートしている。 golang 対応の付加機能として、LuneScript には限定的なスレッド機能を提供している。 「限定的","tags":null,"title":"Go の関数パフォーマンス","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-15-go-func-performance/","year":"2021"},{"content":" Language Server Protocol (LSP) の調査メモ。\n後でまとめる予定だが、まずは調べた情報を列挙していく。\nLSP とは LSP は、プログラミング開発する上で役立つ様々なサポート機能を定義するプロトコル。\n従来は、エディタの開発者や、エディタの拡張機能開発者が プログラミング言語毎に様々なサポート機能の開発を行なっていた。\nこれにより、同じプログラミング言語でも、エディタごとに異る実装が必要で、 あるエディタでは使える機能が、別のエディタでは使えないなどの問題が発生していた。\nこの問題を解決するためプログラミング言語のエディタサポートに必要な機能を抽象化し、 プロトコルとして定義することで、 ある言語のサポート機能を実装すれば、 どのエディタでも同じサポート機能を利用できるように開発されているのが、 LSP である。\n\u0026lt;https://microsoft.github.io/language-server-protocol/specifications/specification-current\u0026gt;\nJSON-RPC LSP は、クライアント・サーバ型のプロトコルであり、 JSON-RCP を利用して通信を行なう。\nJSON-RCP は、その名の通り JSON を利用するプロコトルである。\nJSON-RCP では、やり取りする JSON のサイズを Context-Length で通知する。\nContent-Length: 123\\r\\n \\r\\n { \u0026#34;jsonrpc\u0026#34;: \u0026#34;2.0\u0026#34;, \u0026#34;id\u0026#34;: 1, \u0026#34;method\u0026#34;: \u0026#34;hoge\u0026#34;, \u0026#34;params\u0026#34;: { ... } } JSON-RPC は、クライアントからのリクエストをサーバが受け、 そのリクエストの処理結果をサーバが返すが、 http のような同期型の通信ではなく非同期型の通信である。 たとえば、クライアントはサーバからのレスポンスを待たずに複数の リクエストを通知できる。\nこのため、 JSON-RPC の JSON には、 リクエストを識別するための \u0026#34;id\u0026#34; が付加されていて、 リクエストの id と、それに対応するレスポンスには同じ id が付加される。\nリクエストが、どのような処理をサーバに依頼するのかを識別する情報として、 \u0026#34;method\u0026#34; がある。そして、その method の追加情報として \u0026#34;params\u0026#34; を指定する。\nこれらの内容は、 JSON-RCP を利用する実際のプロトコルで定義される。\nなお JSON-RCP は、クライアントからのリクエストとそれのレスポンスだけでなく、 サーバからの通知 (notification)と、 レスポンスを必要としないクライアントからの通知(notification)がある。\nこれらレスポンスを必要しない通知(notification)には、id が付加されない。\nこれら通信が、 1 つのセッション上で行なわれる。\nこのセッションは TCP で行なっても、 stdio で行なっても構わない。\nLSP の JSON-RPC ここでは LSP の JSON-RPC について示す。\nLSP 初期化フロー 以下に LSP 初期化フローを示す。\n\u0026lt;- はクライアントからのリクエスト -\u0026gt; はサーバからのレスポンス \u0026lt;= はクライアントからの通知 (サーバからのレスポンスが不要) \u0026lt;- initialize -\u0026gt; initialize \u0026lt;= initialized LSP の初期化は、クライアントからの initialized リクエストで始まる。 サーバは、initialized リクエストを受け初期化を行ない結果を返す。 クライアントはサーバからのレスポンスを受けて、 通信に必要な全ての準備が整ったことを示すため、 initialized を通知する。 initialize method において、 クライアント、サーバそれぞれの能力情報が付加される。\nクライアント、サーバそれぞれ、その能力に応じて処理を更新する。\nLSP の初期化は必ずこのフローで行ない、 このフローが終了するまで他の通信は行なってはならない。\ndid LSP では、編集中のファイルを did という概念で管理する。\nプログラミングは基本的にソースコードをストレージに保存し、 その保存したファイルを元にコンパイルなどを行なう。\nしかし、プログラミングのサポート機能はコーディング中に実行するのが一般的であり、 コーディング中のコードが常にストレージに保存されているとは限らない。 また、ストレージへの保存は時間がかかるため、 サポート機能の実行のたびにストレージに保存するのは効率が悪い。\nそこで、クライアント内でコーディング中のコードを、 ストレージに保存せずにサーバ側と同期管理する必要がある。\nそれを管理するのが did である。\nクライアントは、ユーザがコードを編集すると、 その編集内容をサーバに通知する。 サーバは、その編集内容をサーバ内の did に反映する。 これによって、クライアントで編集中のコードと、 サーバの did 内のコードの整合性が保たれる。\n編集内容は、部分更新情報が送られるケースと、 全体更新情報が送られるケースがある。\n部分更新情報は、開始・終了位置 (lineno,column) と、 その領域を置き換える文字列情報が送られる。 全体更新情報は、文字列情報だけが送れれ、 did 全体を新しくその文字列に置き換える。\n部分更新情報は、通信量が少なくすむため高速に処理できる。 しかし、更新処理を間違えると、クライアントとサーバ間で不整合が発生するため、 更新処理には注意が必要である。\nなお、サーバ側が部分更新をサポートするの能力情報を initialize のレスポンスとして返すことができる。\nクライアントはその能力情報を見て、 サーバが部分更新をサポートしていない場合は、全体更新で通知を行なう。\nつまり、サーバ開発の序盤や、対象のコードサイズが十分小さいケースでは、 部分更新を非サポートとして能力を返すことで、サーバ側の機能をシンプルに出来る。\nmessage サーバから通知される message には次の 2 つがある。\nlogMessage showMessage logMessage は積極的にはユーザに表示されないメッセージで、 showMessage はユーザに表示されるメッセージ。\n主な method 後で調べる。\n\u0026#34;initialize\u0026#34; \u0026#34;initialized\u0026#34; \u0026#34;exit\u0026#34; \u0026#34;shutdown\u0026#34; \u0026#34;client/registerCapability\u0026#34; \u0026#34;textDocument/completion\u0026#34; \u0026#34;textDocument/didChange\u0026#34; \u0026#34;textDocument/didClose\u0026#34; \u0026#34;textDocument/didOpen\u0026#34; \u0026#34;textDocument/didSave\u0026#34; \u0026#34;textDocument/documentHighlight\u0026#34; \u0026#34;textDocument/documentSymbol\u0026#34; \u0026#34;textDocument/hover\u0026#34; \u0026#34;textDocument/publishDiagnostics\u0026#34; \u0026#34;textDocument/signatureHelp\u0026#34; \u0026#34;textDocument/willSave\u0026#34; \u0026#34;window/logMessage\u0026#34; \u0026#34;window/showMessage\u0026#34; \u0026#34;workspace/configuration\u0026#34; \u0026#34;workspace/didChangeConfiguration\u0026#34; \u0026#34;workspace/didChangeWatchedFiles\u0026#34; \u0026#34;workspace/didChangeWatchedFiles-0\u0026#34; ","id":41,"section":"posts","summary":"Language Server Protocol (LSP) の調査メモ。 後でまとめる予定だが、まずは調べた情報を列挙していく。 LSP とは LSP は、プログラミング開発する上で役立つ様々なサポート機能を定","tags":null,"title":"Language Server Protocol (LSP) メモ","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-04-lsp/","year":"2021"},{"content":" LuneScript は、モジュールを利用する際に import 命令を使用する。\nこの import 命令は、次の処理を行う。\n指定のモジュールの .lns ファイルを解析し、何を定義しているかを調べる shebang などで起動した場合は、指定のモジュールをロードする 今回は、前者の話をする。\nmeta 情報 モジュールがどんなクラスや関数や変数を定義しているのかを示す情報を、 LuneScript では meta 情報と呼ぶ。\nこの meta 情報は、 そのモジュール内で pub (あるいは pro) 宣言されている情報からなる。\nこれには次の情報を含む。\n公開しているシンボル名 公開しているシンボルの型情報 そのモジュールが参照している外部モジュール情報 これらは、 .lns ファイルを解析することで取得できる。\nこの解析には時間がかかるため、 解析した情報を .meta ファイルとして記録しておき、 .lns ファイルが更新されない場合は .lns ファイルを解析する代わりに、 記録しておいた .meta をロードすることで解析時間を短縮している。\n.meta ファイルは lua の table 定義として記録してあり、 lua で .meta ファイルをロードすることで型を構成するために必要な table が読み込まれ、 その table 内の情報を元に LuneScript の型情報を生成する。\n一般には、 テキストフォーマットよりもバイナリフォーマットの方が高速に処理できる。\nLuneScript の .meta ファイルも、 テキストフォーマットではなくバイナリフォーマットの方が高速に処理できる可能性がある。\nしかし、次の理由から .meta ファイルを lua の table 定義として記録している。\nLuneScript は元々 Lua VM 上で動作するプログラムだったため、 VM 上でバイナリ操作する api を作成するよりも、 Lua VM のネイティブの load 命令を使用する方が高速に処理できる。 meta ファイルの syntax 変更する場合、 バイナリフォーマットよりもテキストフォーマットの方がやり易い。 不具合があった時に、テキストフォーマットの方が追い易い。 型情報 コード上に宣言した型情報は、 LuneScript トランスコンパイラ内では Ast.TypeInfo クラスで管理される。 Ast.TypeInfo インスタンスは、 1 つの型ごとに 1 つ生成される。\nそして、個々の Ast.TypeInfo インスタンスは、 Ast.ProcessInfo クラスで管理される。\nAst.TypeInfo にか、型を識別する ID が付加される。 この ID は、 Ast.ProcessInfo ごとにユニークな値が振られる。\nつまり、 1 つの Ast.ProcessInfo 内の Ast.TypeInfo は、 同じ ID を持つ Ast.TypeInfo は存在しないが、 異なる Ast.ProcessInfo においては、 同じ ID を持つ Ast.TypeInfo が存在する可能性がある。\nこの Ast.ProcessInfo から meta 情報を生成する。 そして import 時には、meta 情報から Ast.ProcessInfo を生成する。\n","id":42,"section":"posts","summary":"LuneScript は、モジュールを利用する際に import 命令を使用する。 この import 命令は、次の処理を行う。 指定のモジュールの .lns ファイルを解析し、何を定義しているかを調べ","tags":null,"title":"LuneScript の import と meta","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-05-04-lunescript-meta/","year":"2021"},{"content":" Rapberry pi 4 で簡易的な NAS を構築している。\nメイン PC の OS が Windows なので、 NAS で使っている HDD を Windows PC と直接接続してアクセスすることを考えて、 NTFS フォーマットの USB HDD を raspi にマウントしていた。\nしかし、これだとパフォーマンスが全く出ない(ntfs-3g が重すぎる)。\n次回の windows 10 アップデートで、 WSL2 の機能をつかった ext4 マウントがサポートさるようなので、 USB HDD のファイルシステムを NTFS から ext4 に変更することにした。\nこれによって、NTFS の時は smb 経由で 30MB/sec 程度だったのが、 ext4 では 80MB/sec 程度まで向上した。\nFS SMB 転送速度 (MB/sec) NTFS 約 30MB ext4 約 80MB ただ、やはりまだ windows での SATA 接続(170MB程度) と比べると、まだだいぶ遅い。\nそこで、 UASP ならもう少し速くなるのではないか？ と思ったので、UASP に対応した USB HDD ケースに入れ替えて試した結果が次の表。\nprotcol local 書き込み速度 (MB/sec) USB3.0 約 115MB UASP 約 119MB 「なんということでしょう。」\nUASP を利用することで、 書き込み速度が 4MB も向上した。。。\nUSB3.0 対応 USB-HDD ケースのアクセス速度計測 pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 12.4745 s, 84.1 MB/s pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 9.12218 s, 115 MB/s pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 9.16875 s, 114 MB/s UASP 対応 USB-HDD ケースのアクセス速度計測 pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 11.6425 s, 90.1 MB/s pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 8.80392 s, 119 MB/s pi4$ sudo dd if=/dev/zero of=/mnt/usb/share/dump bs=1M count=1000 1000+0 records in 1000+0 records out 1048576000 bytes (1.0 GB, 1000 MiB) copied, 8.82478 s, 119 MB/s UASP に入れ替えた結果は、 誤差レベル のパフォーマンス改善だった。\nもちろん、 UASP に入れ替え後の SMB 転送速度も誤差レベルだった。\nただ、そもそも SMB 転送速度に関しては、 80MB/sec で既に smbd の CPU 占有率が 100% を越えている状態 なので、 HDD の書き込み速度が改善されたとしても、 smb 経由のパフォーマンスはほとんど改善されないのかもしれない。\nraspi は、手軽に NAS を構築できる。 その NAS は、数 GB 程度のファイルのアクセスなら、ストレスなく運用できる。\nしかし、大量のファイルコピーするような場合は、 windows などの PC に HDD を SATA で接続して作業するのが得策のようだ。\n","id":43,"section":"posts","summary":"Rapberry pi 4 で簡易的な NAS を構築している。 メイン PC の OS が Windows なので、 NAS で使っている HDD を Windows PC と直接接続してアクセスすることを考えて、 NTFS フォーマットの USB HDD","tags":null,"title":"Rapberry pi 4 で構築する NAS (USB HDD UASP) の性能","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-04-03-raspi-usb-hdd/","year":"2021"},{"content":" go1.16 から embed が利用可能になりました。\n\u0026lt;https://golang.org/pkg/embed/\u0026gt;\nembed によって、 プログラムにバイナリデータを埋め込む処理が簡単に行なえるようになります。\nLuneScript のコンパイラは、 go でビルドした際に Lua 環境がなくても動作するように、 Lua 用のセルフホストコードをコンパイラ内部に埋め込み、 実行時に埋め込んであるセルフホストコードをロードしています。\n以前は、 Lua 用のセルフホストコードを []byte として定義するコードを生成するスクリプトを 自前で実行して、それをビルドしていましたが、 embed を利用することで、その作業が不要になりました。\nここでは、 embed を利用する際に引掛った embed の仕様について説明します。\nembed の概要 上記 URL からサンプルを引用します。\nimport _ \u0026#34;embed\u0026#34; //go:embed hello.txt var s string print(s) このサンプルは、 hello.txt というファイルに保持されたデータを、 s という string 型の変数で利用できるように設定し、 print(s) で出力するコードです。\n重要なのは次です。\nembed を import する。 バイナリデータを格納する変数を トップスコープ に var で宣言する 変数 var の直前に //go:embed path のコメントを記載する 変数宣言 バイナリデータを格納する変数を宣言します。 この時、次が重要です。\n変数はファイル内の トップスコープ に宣言する 変数の型は次のいずれか\nstring []byte embed.FS embed.FS は、次の用途で利用します。\n埋め込むのがファイルではなくディレクトリの場合 バイナリデータだけでなく、ファイルの更新日時などの情報も必要な場合 上記の条件を満さない場合はビルドエラーします。\n変数 var の直前に //go:embed path のコメント データを格納する変数宣言の直前に //go:embed path のコメントを記載します。\nこの時、次が重要です。\n// と go の間に スペースが入ってはならない path は go build を実行するディレクトリからの 相対パス\n. や .. を含まない。 // と go の間にスペースが入ると、単なるコメントとして扱われ、 変数は NULL 値で初期化されます。 この時なんの warning も出力されません。\npath は、 . や .. を含まない相対パスです。 つまり、go build を実行するディレクトリ以降にファイルが存在している必要があります。\nこの path の仕様は少し不便に感じましたが、 プロジェクトを go get でビルドできるようにするには必要な対応だと思うので、 仕方がないところでしょう。\n","id":44,"section":"posts","summary":"go1.16 から embed が利用可能になりました。 \u0026lt;https://golang.org/pkg/embed/\u0026gt; embed によって、 プログラムにバイナリデータを埋め込む処理が簡単に行なえるようになります。 LuneScript のコンパイラは、 go で","tags":null,"title":"go1.16 の embed によるファイル埋め込み","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-02-28-go-embed/","year":"2021"},{"content":" raspberry pi でローカルサーバを立ち上げているが、 この sdcard 寿命が気になったので調べてみた。\nsdcard はでなく、 hdd や ssd で運用する方法もあるが、 sdcard で運用できる方がランニングコストが良いので、できれば sdcard で運用したい。\nsdcard の寿命の見積り iostat -h で sdcard への書き込み量を調べると、 1日約 1GB の書き込み がある。\nこの書き込みが sdcard の 何ブロックを書き換えているのか不明 なので、 とりあえず 10 倍の 10GB 相当 のブロックを書き換えたとする。\n次に sdcard が SLC か MLC か TLC かだが、 パッケージも何も残っていないので予測でしかないが、 数年前にアキバの最安値のものを買ったはずなので TLC と予想する。\nそして 16GB の sdcard なので、TLC ならば 約 16TB の書き込みが可能だとすると、 1 日 10GB の書き換えで 約 4 年間 で寿命を越えることになる。\nほとんどが予想でしかないが、少なくとも 1 年は寿命を気にせずに使用できるだろう。\nそんな訳で、このままの構成で1年程度運用してから、 来年あたりに MLC の高耐久モデルの sdcard に入れ替えて運用しようと思う。 そうすれば、10 年程度は運用できるだろう。\nもちろん 10 年間も運用するとは思えないので、 今のサーバ構成で MLC の sdcard を使用すれば、 実質的に寿命を気にする必要はないだろう。\nもしも 1 年の運用中に sdcard の寿命を越えるようなことがあれば、 sdcard のブロック書き換え数の見積りが想定以上だったか、 ハズれの sdcard を引いたかになる。\nブロック書き換え数の見積りが想定以上なのだとしたら、 sdcard の容量を大きめのサイズにすることで対応できるだろう。\nちなみに現状の sdcard の書き込みサイズ情報は以下の通り。 約 185 GB (+ 129 56)\n$ sudo dumpe2fs -h /dev/mmcblk0p2 | grep \u0026#34;Lifetime writes\u0026#34; dumpe2fs 1.44.5 (15-Dec-2018) Lifetime writes: 129 GB $ iostat -h Linux 5.10.4-v8+ (raspberrypi4) 17/02/21 _aarch64_\t(4 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 2.9% 3.8% 1.6% 0.3% 0.0% 91.5% tps kB_read/s kB_wrtn/s kB_read kB_wrtn Device 0.41 3.4k 24.8k 7.7G 56.3G mmcblk0 パフォーマンス計測 寿命を予測する方法として、 定期的(月に一度程度)に SD card への書き込みパフォーマンスを記録することにした。\nパフォーマンスは dd コマンドによる 200MB 書き込みの時間とする。\nただし、書き込み時間はかなりばらつく。 特に初回の dd コマンドの書き込みはバッファリングが効くためか異様に早いので、 3回目、4回目を記録する。\n2021/04/17 $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 42.9515 s, 4.9 MB/s $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 30.8832 s, 6.8 MB/s この時点で既にめちゃくちゃ遅い。\n今後どれほど変っていくのか興味深い。\n2021/05/30 $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 28.4992 s, 7.4 MB/s 4$ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 60.2642 s, 3.5 MB/s $ iostat -h tps kB_read/s kB_wrtn/s kB_read kB_wrtn Device 0.41 3.1k 36.6k 15.9G 187.0G mmcblk0 $ sudo dumpe2fs -h /dev/mmcblk0p2 | grep \u0026#34;Lifetime writes\u0026#34; Lifetime writes: 261 GB 予想よりもだいぶ多い書き込みが発生している。\n次回も書き込み速度がさらに下るようなら、 実験を停止して新しい SD カードに移行した方が良いかもしれない。\n2021/07/04 $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 47.6562 s, 4.4 MB/s $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 38.4939 s, 5.4 MB/s $ iostat -h Linux 5.10.4-v8+ (raspberrypi4) 04/07/21 _aarch64_\t(4 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 2.9% 3.6% 1.5% 0.2% 0.0% 91.7% tps kB_read/s kB_wrtn/s kB_read kB_wrtn Device 0.16 2.5k 2.5k 6.9G 6.7G mmcblk0 0.24 0.1k 32.6k 147.1M 88.2G sdb $ sudo dumpe2fs -h /dev/mmcblk0p2 | grep \u0026#34;Lifetime writes\u0026#34; Lifetime writes: 454 GB 2021/08/01 $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 32.3397 s, 6.5 MB/s $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 34.3965 s, 6.1 MB/s $ iostat -h Linux 5.10.4-v8+ (raspberrypi4) 01/08/21 _aarch64_\t(4 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 3.0% 3.5% 1.5% 0.2% 0.0% 91.8% tps kB_read/s kB_wrtn/s kB_read kB_wrtn Device 0.16 2.5k 2.3k 12.3G 11.7G mmcblk0 0.24 0.0k 33.3k 236.0M 166.7G sdb 2022/01/02 $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 39.4435 s, 5.3 MB/s $ sudo dd if=/dev/zero of=/tmp/dump bs=1M count=200 200+0 records in 200+0 records out 209715200 bytes (210 MB, 200 MiB) copied, 46.9338 s, 4.5 MB/s $ iostat -h Linux 5.10.4-v8+ (raspberrypi4) 02/01/22 _aarch64_\t(4 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 3.0% 0.3% 1.2% 0.1% 0.0% 95.3% tps kB_read/s kB_wrtn/s kB_read kB_wrtn Device 0.15 3.0k 2.4k 12.4G 10.2G mmcblk0 0.24 0.0k 32.7k 148.3M 136.2G sdb ","id":45,"section":"posts","summary":"raspberry pi でローカルサーバを立ち上げているが、 この sdcard 寿命が気になったので調べてみた。 sdcard はでなく、 hdd や ssd で運用する方法もあるが、 sdcard で運用できる方がラ","tags":null,"title":"raspberry pi の sdcard 書き換え回数寿命を考える","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-02-17-rasp-sdcard/","year":"2021"},{"content":" LuneScript の解説サイトは、 hugo を使用して構築している。 その解説サイトに掲載しているソースコードは、 hugo によって解析されて、色付けに必要な \u0026lt;span class=\u0026#34;\u0026#34;\u0026gt; が付加され、 css で色付けを行なっている。 なお、 ソースコードの解析自体は hugo というよりも、 hugo が chroma の API を呼び出して利用している。\nしかし LuneScript は超マイナー言語なので、 chroma の対応言語には当然 LuneScript が入っていない。\nこれだと LuneScript のサンプルコードのハイライトが付かないため、コードを読み難い。 そこで、LuneScript のハイライト表示に対応するために highlight.js を導入したので、 今回は highlight.js を利用して独自言語の色付けを行なうための方法を簡単に説明する。\nハイライト表示の対応手段として chroma の方を変更するという方法もあるが、 highlight.js の方が hugo を使用していないどの Web サイトでも使えるので汎用的だろう。\nちなみに chroma は、 hugo で静的サイトを構築する際に コンテンツ内のソースコードを解析して、解析結果を反映した html を出力する。 一方で highlight.js は、 Web ブラウザでソースを表示する際に動的にソースコードを解析する。\nつまり、 chroma 側で対応した方がブラウザの負担を減らし UX を向上できる。 しかし、サンプル程度の短いソースコード解析であれば、 さほど解析に時間がかかることもないので、気にする必要はないだろう。\nhighlight.js への独自言語追加 まずは以下を追加する。\n\u0026lt;script src=\u0026#34;//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; なお、 highlight.js の公式サイトには default.min.css のロードの記載もあるが、 独自言語追加には不要である。\nhighlight.js によるソースコード解析 次の関数を実行して、ソースコードを保持する element を highlight.js で解析する。\nhljs.highlightBlock( element ); このとき element の class は、 language-言語識別 として定義しておく。 例えば LuneScript は language-lns としている。\nなお、 highlight.js の使用方法として次の関数を実行する方法が紹介されているが、\nhljs.initHighlightingOnLoad(); この関数は全ての \u0026lt;pre\u0026gt;\u0026lt;code\u0026gt; element を解析対象としてしまう。\n今回は、 LuneScript 以外の言語を hugo で解析済みなので、 全ての \u0026lt;pre\u0026gt;\u0026lt;code\u0026gt; を解析対象にしてしまうと 2 重解析になってしまうため、 hljs.highlightBlock( element ); で解析する element を明示的に指定する。\nhljs.highlightBlock( element ); によって highlight.js による解析が行なわれるが、 まだこの状態では highlight.js は独自言語に対応していない。 そこで、highlight.js に独自言語の情報を事前に登録しておく。\nhighlight.js への独自言語の登録 highlight.js へ独自言語を登録するには次の関数を利用する。\nhljs.registerLanguage( langName, langDef ) ここで、 langName は前述の language-言語識別 の 言語識別 部分を指す。 つまり language-lns の場合 \u0026#34;lns\u0026#34; を langName に使用する。 langDef は、次のような関数オブジェクトを指定する。\nfunction( obj ) { return { keywords: \u0026#34;hoge foo bar\u0026#34; }; } つまり、まとめると以下のようになる。\nhljs.registerLanguage( \u0026#34;lns\u0026#34;, function( obj ) { return { keywords: \u0026#34;hoge foo bar\u0026#34; }; }); 上記の langDef で定義する関数オブジェクトは、 言語情報を定義するオブジェクトを返す。\nこのオブジェクトの詳細は次の URL に記載がある。\n\u0026lt;https://highlightjs.readthedocs.io/en/latest/mode-reference.html\u0026gt;\n以降では、良く使う属性について説明する。\n言語情報定義オブジェクト まず、言語情報定義オブジェクトが何を定義するものかを説明する。\nhighlight.js は、ソースコード内の文字列を解析し、 「どの文字列」が「何の種別」かを判別する。\nこのオブジェクトは、「どの文字列」「何の種別」を定義するのが役割である。\nたとえば、 C 言語では for, while, if などの文字列の種別は予約語(keyword) であり、 /* */ で括られている文字列の種別はコメント(comment) である。\n次のオブジェクトを返すことで、for, while, if を keyword として定義できる。\nreturn { contains: [ { className: \u0026#34;keyword\u0026#34;, keyword: \u0026#34;for while if\u0026#34; } ] }; ここで className は、 for while if が keyword であることを示す。\nこの定義のよって、 highlight.js は解析対象のソースコード内の for を、次のように変換する。\n\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;for\u0026lt;span/\u0026gt; highlight.js は、上記オブジェクトの className で指定した名前を span element のクラス名として使用する。\nこの例の場合 className: \u0026#34;keyword\u0026#34; で定義したクラス名は、 \u0026#34;hljs-keyword\u0026#34; となる。 仮に className が \u0026#34;hoge\u0026#34; ならば、 \u0026#34;hljs-hoge\u0026#34; となる。\nこのように 言語情報オブジェクトで定義した各文字列にクラスが指定されるので、 CSS によって hljs-keyword に色を指定することでソースコードの色付けが可能になる。\nなお、 className は任意の文字列を定義可能だが、 もし将来独自言語の対応を highlight.js に pull request したい、 という思いがあるならば、 highlight が既に対応している言語に合せて className を利用するべきだろう。\ncontains { contains: [ { className: \u0026#34;keyword\u0026#34;, begin: /hoge|foo|bar/ } ] } contains は、 sub-mode を配列で指定するためのものである。 sub-mode は JavaScript の object で、 上記の例では { className: \u0026#34;keyword\u0026#34;, begin: /hoge|foo|bar/ } が sub-mode である。 複数の種別を定義する際に利用する。\nbegin, end begin は、定義する種別の文字列の開始パターンを定義する。 なお、 end を明示的に指定しない場合、 begin でマッチした文字列だけが、所定の種別になる。\nつまり、 { className: \u0026#34;keyword\u0026#34;, begin: /hoge|foo|bar/ } は、 種別 keyword は、文字列 hoge , foo, bar から成ることを定義している。\nもしも end に end: /$/ を指定した場合、 hoge, foo, bar のいずれから始まり、その行末までが指定した種別 keyword になる。\nネスト sub-mode はネストできる。\n{ contains: [ { className: \u0026#34;keyword\u0026#34;, begin: /abc/, end: /ij/, contains: [ { className: \u0026#34;meta\u0026#34;, begin: /ef/ } ] } ] } 上記は keyword の種別の中に meta を含む定義である。\nこれは、次のような文字列があった場合、\nabc defgh ijk abc 〜 ij までを \u0026#34;keyword\u0026#34; として扱い、 その中の ef を \u0026#34;meta\u0026#34; として扱う。\nこの時の HTML 出力は次になる。\n\u0026lt;span class=\u0026#34;hljs-keyword\u0026#34;\u0026gt;abc d\u0026lt;span class=\u0026#34;hljs-meta\u0026#34;\u0026gt;ef\u0026lt;/span\u0026gt;gh ij\u0026lt;/span\u0026gt;k ネストすることで、ある種別の中に別の種別を定義することが可能になる。\nLuneScript の highlight.js 設定 参考までに、 highlight.js に LuneScript を追加登録するスクリプトを載せておく。\n\u0026lt;script src=\u0026#34;https://ifritjp.github.io/documents/js/highlight_lns.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://ifritjp.github.io/documents/css/highlight_lns.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; LuneScript のソースを保持する element の class は、 language-lns として指定する必要がある。\n","id":46,"section":"posts","summary":"LuneScript の解説サイトは、 hugo を使用して構築している。 その解説サイトに掲載しているソースコードは、 hugo によって解析されて、色付けに必要な \u0026lt;span class=\u0026#34;\u0026#34;\u0026gt; が付加され、","tags":null,"title":"highlight.js で独自言語の色付けを追加","uri":"https://ifritjp.github.io/blog2/public/posts/2021/2021-02-01-hilightjs/","year":"2021"},{"content":" WSL2 と virtual BOX が共存できるようになったらしいので、 家の環境に WSL2 を入れてみました。\nセットアップ自体は上手くいきましたが、 結果として virtual BOX のパフォーマンス(DISK IO？)は 1,2 割程度落ちたようです。\nWSL2 のパフォーマンスが WSL2 無効時の virtual BOX と同等程度なので、 virtual BOX から WSL2 に完全移行できるなら問題ないと思いますが、 WSL2 に完全移行できず、かつ、1,2 割程度のパフォーマンスダウンが許容出来ない場合は、 従来通り WSL2 無効で運用することになると思います。\n個人的には、試しに暫く WSL2 で運用し、 問題なければそのまま WSL2 に移行する予定です。\n今回の作業でいくつかハマったポイントがあるので、 備忘録として残します。\n基本的な WSL2 セットアップに関しては、 ネットにいくつも手順が載っているのでそれを参考にしてもらうとして、 ここでは個人的にハマった点に絞って書きます。\nVirtualBox での Guest OS 起動が失敗する 以下の 2 つのポイントがあります。\nVirtualBox の プロセッサー設定で、ネステッド VT-x/AMD-V を有効化をチェックしている WSL2 を有効にすると、 VirtualBox などの既存の仮想化アプリに制限がかかり、 一部機能を利用できなくなります。\nその一つに「ネステッド VT-x/AMD-V」があるようです。\n「Windows ハイパーバイザー プラットフォーム」を有効化していない WSL2 を有効にしている環境で VirtualBox などの既存の仮想化アプリを実行するには、 上記機能を有効化する必要があります。\nWSL2 が有効な環境では、VirtualBox などの既存の仮想化アプリは、 「Windows ハイパーバイザー プラットフォーム」という機能を経由して、 仮想化制御を行なうようです。\nなお、VirtualBox などの既存の仮想化アプリはこの機能を経由するため、 WSL2 無効環境と比べるとパフォーマンスが落ちているような気がします。\nwsl コマンドを実行する際の Shell は管理者権限で起動してはならない WSL2 のセットアップで、ディストリビューションのイメージの一覧を確認する際、 次のコマンドを入力します。\nwsl -l この wsl コマンドを実行する際、Shell を管理者権限で実行していると、 ubuntu をインストールしているのにも関わらず次のように出力されました。\n\u0026gt; wsl -l Linux 用 Windows サブシステムには、ディストリビューションがインストールされていません。 ディストリビューションは Microsoft Store にアクセスしてインストールすることができます: 何故このようなことになったかというと、 私は普段 Windows を使用する際、 管理者権限のないアカウントで作業してます。 そして、管理者権限が必要な作業をする時に、 管理者権限で実行したり、管理者アカウントで入って作業しています。\n今回も、一般ユーザのアカウントで WSL2 をセットアップしていました。\nそして、 Web の作業手順に管理者権限で実行するように書いてあったため、 PowerShell を管理者権限で実行していました。\nしかし管理者権限の PowerShell で \u0026#34;wsl -l\u0026#34; を実行すると、 管理者権限のユーザ環境にインストールされている ディストリビューション情報がリストされるため、 一般ユーザのアカウントにインストールしていた ubuntu の情報は出力されない、 ということです。\nwsl コマンドの操作に管理者権限は不要です。 というか、管理者権限で実行するとこのような現象が発生するため、 管理者権限は付けずにそのまま実行してください。\nWSL2 を使うようなユーザは管理者権限を持つアカウントで作業すると思うので、 こんなことにハマらないでしょうが、 一応気をつけてください。\ncygwin xorg で GUI 表示できない virtual Box で作業する際、 ssh で入ってX11トンネリングした xwindow で作業しています。\nWSL2 の場合は、 ssh ではなく直接 DISPLAY を指定して作業する例が紹介されています。\nその例に沿って作業すると、xwindow の接続が出来なかったので、 それの対応方法を説明します。\nError: Can\u0026#39;t open display: 最初は次のようなエラーになりました。\n$ DISPLAY=xxx.xxx.xxx.xxx:0 xeyes Error: Can\u0026#39;t open display: xxx.xxx.xxx.xxx:0 これは、指定の DISPLAY に接続できないことを示します。\nこれを解決するには、 cygwin の xserver 起動のショートカットに次のオプションを追加します。\n-- -listen tcp ssh のX11トンネリングの場合、 xserver のサービスを listen しなくても接続できるのですが、 ssh のX11トンネリングではなく直接通信を行なう場合は、 xserver のサービスを listen しておく必要があります。\nAuthorization required, but no authorization protocol specified xserver のサービスを listen しても、次のようなエラーになりました。\n$ DISPLAY=xxx.xxx.xxx.xxx:0 xeyes Authorization required, but no authorization protocol specified Error: Can\u0026#39;t open display: xxx.xxx.xxx.xxx:0 これは、 xserver に接続するには認証が必要なことを示しています。\nこれを解決するには、次の手順を行ないます。\nwindows 側で次を実行 $ xauth list :0 NAME:0 MIT-MAGIC-COOKIE-1 ?????????????????????? ここで出力された MIT-MAGIC-COOKIE-1 ?????????????????????? をコピーしておきます。\nクライアント側 (ubuntu)で次を実行 $ xauth add xxx.xxx.xxx.xxx:0 MIT-MAGIC-COOKIE-1 ?????????????????????? これで、 ubuntu から windows の xwindow に表示されます。\nなお、 server の auth control を無効化する方法 (startxwin の -auth を与えないように修正する方法)でも対応できますが、 xauth を使っておいた方が無難でしょう。\nWSL2 のイメージデータの置き場所 WSL2 のイメージデータは、次の場所で管理されています。\nC:\\Users\\?????\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu20.04onWindows_????????\\LocalState このイメージデータを直接操作することはありませんが、 実体が何処にあるかは意識しておいた方が良いでしょう。\n自分の PC 環境は、 C ドライブは m.2 NVMe で、 D ドライブを HDD にしていて、 開発作業は D の HDD で行なっています。\n開発作業は docker イメージの作成などによって、 そこそこ書き込み量が多いので、 イメージデータが C ドライブにあるのはあまり望ましくないです。\nなので、しばらくこのまま使ってみて、 C への書き込み量が急激に増えるようならイメージデータを D に移すか、 virtual box に戻すかしようと思います。\nちなみ現在 (2020/12/09) の書き込み総サイズは、\n1522 GB スペック上、 200TB までは大丈夫なはず。\nなお、既に 1 年ちょっと使っている状態なので、 今のペースだと単純計算で 100 年くらいは大丈夫なはずだったｗｗ\nWSL2 の RAM WSL2 は、RAM の使用状況を確認せずに固定サイズを上限としてメモリを使用するようです。\nこれにより、メモリを多く使用する他のアプリと一緒に WSL2 コンテナを実行すると、 メモリ枯渇が発生します。\nこれを防ぐには、 %USERPROFILE%\\.wslconfig ファイルを生成し、 以下の内容を設定して WSL2 のメモリ上限を設定します。\n[wsl2] memory=6GB swap=0 \u0026lt;https://qiita.com/yoichiwo7/items/e3e13b6fe2f32c4c6120\u0026gt;\n以上。\n","id":47,"section":"posts","summary":"WSL2 と virtual BOX が共存できるようになったらしいので、 家の環境に WSL2 を入れてみました。 セットアップ自体は上手くいきましたが、 結果として virtual BOX のパフォーマン","tags":null,"title":"WSL2 と cygwin xorg を使って GUI 表示するまでのハマりどころ","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-12-09-wsl2-xwin/","year":"2020"},{"content":" LuneScript の CI 環境として github actions を使用している。 この CI のテスト時にビルドした go 版 LuneScript のシングルバイナリを、 google drive にアップロードして公開するように対応した。\n\u0026lt;https://drive.google.com/drive/folders/1S5NgeM6qIOIUC0rkBHqnWZcuhmsTqB2w\u0026gt;\n今回は、この手順について説明する。\n公開方法 基本的には次の手順に従えば出来るが、 Google の UI の一部が変っているので、そこを主に補足していく。\n\u0026lt;https://qiita.com/satackey/items/56729c8551aabb2ae7cc\u0026gt;\nskicka google drive へのアップロードは skicka を利用する。\nskicka は OSS だ。\nこの skicka を利用するためには、 OAuth2 認証 ClientID と Client Secret が必要になる。\nOAuth2 認証は、ウェブサービス間のアクセス権を管理するもので、 今回は skicka が google drive へアクセスするための権利を取得するために OAuth2 が必要になる。\nOAuth2 ClientID と Client Secret 前述の通り OAuth2 は、ウェブサービス間のアクセス権を管理する。 ここでは google drive と skicka の間のアクセスが対象となる。 では OAuth2 ClientID が何故必要になるかというと、 アクセス権を求めて来ているのが何者で、どのようなサービスなのか？ということを google とユーザ自身が認識するのに利用するためだ。\n世の中には google drive にアクセスするサービスが大量にあるが、 それらは全て個々の ID が割り振られている。\nそして Client Secret は、 ClientID を使用しているサービスが、 本当にその ClientID の所有者かどうかを判断するために利用する鍵のようなものだ。\nClientID と Client Secret によって、 なりすましによる サービスへの不正アクセスを防止している。 (なりすましの防止というか、 誰がアクセスしようとしているのか？を確認する手段を提供している)\nskicka に ClientID と Client Secret が必要な理由 ClientID は、そのサービスが何者なのかを識別するためのものなので、 サービス提供者と ClientID の保有者は同じなのが普通である。\nしかし、 skicka はオープンソースのツールであり、 もちろん作者は私ではない。 それなのに skicka を利用するために私が ClientID, Secret を用意する必要がある。\nそれは何故か？\n少し話が逸れるが、 twitter クライアントアプリには公式アプリ意外にも様々なアプリがある。 あれらのアプリを利用する際にアカウントの認証は行なうが、 ユーザは ClientID, Secret を用意しなくて良い。\nこの違いは何かというと、 skicka はツールそのものを提供しているのに対し、 twitter クライアントアプリはサービスを提供している。\n別の言い方をすると、 skicka は使用者自らがサービス提供者 になり、 twitter クライアントアプリは、 アプリ開発者がサービス提供者 になる。\nこの違いを認識していないと、 これ以降の作業に問題が生じた時に対処が難しくなるのと、 セキュリティの考え方にも影響してくるので、注意が必要だ。\nClientID / Client Secret 取得方法 取得方法は次の URL の手順に従う。\n\u0026lt;https://qiita.com/satackey/items/34c7fc5bf77bd2f5c633\u0026gt;\nただし次の点に注意する。\nアプリケーションのタイプを選択する箇所があるが、 この時「テレビと入力機能が限られているデバイス」を選択する。 この選択を間違えると、 OAuth2 認証が失敗する。\nトークン取得方法 上記 URL の手順に従うとトークン取得まで行なえる。\nしかし、次の点に注意が必要である。\n認証を通す前に、次の画面で設定が必要になる。\n2箇所をマークしてあるが、それぞれ次の意味である。\nアプリを公開\nデフォルトでは、サービスがテスト状態になっている。 テスト状態では、事前に登録したアカウントだけが認証が通るようになっている。 つまり、事前にアカウントを登録しておかないと、 上記 URL の手順の OAuth2 認証が通らない。 逆に言えば、事前にアカウントを登録すれば、サービス設定を公開に変更する必要はない。 skicka は個人で使うので、サービスを公開してもリスクしかない。 よって、ここはテスト状態のままにする。 ADD USERS 前述した通り、テスト状態では事前にアカウントを登録しておかないと OAuth2 認証が通らない。 ここでは、そのアカウントの登録を行なう。 アカウント情報は、許可するアカウントのメールアドレスをセットする。 なお、 Client ID を発行したアカウントと、 OAuth2 認証を許可するアカウントが別でも良い。 上記の通り事前にアカウントを登録しておくことで、 OAuth2 認証が通る。\nなおこの設定で OAuth2 を通すと警告ページが表示されるが、 これはサービスがテスト設定の状態なための警告なので、 そのまま進めて問題ない。\n以上\n","id":48,"section":"posts","summary":"LuneScript の CI 環境として github actions を使用している。 この CI のテスト時にビルドした go 版 LuneScript のシングルバイナリを、 google drive にアップロードして公開するように対応した。 \u0026lt;https://drive.google.com/drive/folders/1S5NgeM6qIOIUC0rkBHqnWZcuhmsTqB2w\u0026gt;","tags":null,"title":"github actions でビルドしたモジュールを google drive にアップロード","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-12-05-lns-release/","year":"2020"},{"content":" LuneScript 向けの別ツールを作ろうと思い、 LuneScript の go 向けランタイムを単独モジュールとして分割して管理すべく 奮闘した際の備忘録。\ngo のモジュール go は、 github に公開されているモジュールを取得して使用できる。\nでは、自作モジュールを github に公開して使用するにはどうすれば良いか？\nここでは、その方法について順を追って説明する。\ngo のモジュール管理のおさらい go にはモジュール管理機能が内包されており、 基本的には次の手順でコマンドを実行するだけで、 使用している依存モジュールを管理できる。\n$ go mod init $ go mod tidy 依存モジュール情報は go.mod に記録される。\n自作モジュールを github へ公開する モジュールを github へ公開しないと始まらないので、 まずは github に公開する。\nこの時ディレクトリ構成は何でも良い。\n最も重要な点は、次の 1 点。\nタグを付ける\nこのタグは v0.0.0 (数値はモジュールのバージョン)で付ける。\nこれがないと、 意図したリビジョンのモジュールを go が取ってきてくれない。\nタグは必須ではない。\nタグはバージョン管理する際に必要だが、 タグがなくても go でモジュールを利用できる。\ngo mod init した際に、 プログラムで import しているモジュール情報を収集し、 そのモジュールの最新のタグを拾ってきて go.mod に記録している。\nこのときに依存モジュールの git に一つもタグがないと、 依存モジュールの初回コミットが利用される。 一つでもタグがある場合は、そのタグが利用される。\ngo のバージョンアップで go mod init , go mod tidy の動きが変っている。\ngo 1.16 では、以下の動作になる。\ngo mod init\ngo のコードは解析せず、 module 名と go のバージョンだけ記載した go.mod を作成する。 go mod tidy\ngo のコードを解析し、 import しているモジュール情報を取得し go.mod に反映する。 このとき、 import しているモジュールにタグが付いていれば、 最新タグのモジュールを取得する。\nタグ付けした後に更新があったとしても、 それにタグが無ければその更新は無視される。 import しているモジュールにタグが付いていなければ、最新のコミットを取得する go.mod に、既にモジュール情報、バージョン情報が記載されていれば、 その情報は更新しない。 バージョン情報にブランチ名を書いていると、そのブランチの最新コミットを取得する\nこれは、モジュールにタグが付いている場合でも、最新コミットを取得する。 自作モジュールの更新 自作モジュールを更新した場合、 git への push はもちろんのこと、 タグを付けなければならない。\n前述した通り、go の依存モジュール管理は、あくまでもタグで制御しているため、 その修正を有効にするにはタグ付けが必須である。\n自作モジュールを更新した場合、git への push するだけで良い。\nなお、ローカルで試す際は git への push せずに確認できる。\ngo.mod の更新 モジュールを使用している側の go.mod は、 import しているモジュールと、そのバージョン(タグ)を紐付けて管理している。\n一度 go.mod にバージョン情報が記録されると、 go mod tidy を実行しても依存モジュールのバージョンが自動で更新されることはない。\n使用する依存モジュールのバージョンを更新するには、 go.mod で指定されているバージョンを書き換える必要がある。\n最新に変更するだけなら、バージョン情報にブランチ名を書けば良い。 たいていは master を指定するだけでよい。\n環境変数の GOPATH 以下にソースを置いていれば、基本的にはこれだけで良い。\n環境変数の GOPATH 以下にソースを置いていない場合は、 幾つかの対応が必要となる。\nなお、 go module を利用するのであれば、 GOPATH 以下にソースを置くのが結局は間違いのない方法になる。\nただし、GOPATH 以下にソースを置くとディレクトリが深くなってしまうので、 それを嫌うのであれば、ソースを管理するディレクトリは別に作成し、 GOPATH 以下にはシンボリックリンクを作成することで回避できる。 但し、シンボリックリンクでは正常に動作しない可能性も考えられるので、 その辺りは自己責任で。\nreplace 以上のように、 依存モジュールはバージョン情報で管理されている。\nこれは、依存モジュールの再現性を担保するには必要な機能である。 一方でバージョン毎に管理するのが面倒なこともある。\nreplace 機能は、 require しているモジュールを他の場所から取得できるように置き換える機能である。\nたとえば、 github.com/ifritJP/lnssqlite3 のモジュールを ../ のローカルディレクトリから取得したい場合は、 次のように書く。\nrequire github.com/ifritJP/lnssqlite3 v0.0.0 replace github.com/ifritJP/lnssqlite3 =\u0026gt; ../ これにより github.com/ifritJP/lnssqlite3 は、 どのバージョンに限らずに ../ ディレクトリのものを利用する。\nブランチ名 前述の通り go.mod は依存モジュールをバージョンと紐付けて管理している。\nmodule hoge go 1.14 require github.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e require github.com/ifritJP/LuneScript v1.1.12-0.20201216131727-df4ec0979d4d ここで、次のようにバージョンの代わりにブランチ名を指定し、 go mod tidy することで、そのブランチの最新を取得できる。\nmodule hoge go 1.14 require github.com/golang/groupcache v0.0.0-20200121045136-8c9f03a8e57e require github.com/ifritJP/LuneScript master ただし、go mod tidy すると、 上記の master の部分が v1.1.12-0.20201216131727-df4ec0979d4d のように 最新のバージョンに置き変わるので、 依存ライブラリを再度更新した場合、 go.mod を master に書き直す必要がある。\n外部ライブラリを利用している場合 LuneScript は、外部ラリブラリとして lua を利用している。\ngo は cgo を使うことで C 言語のライブラリを利用できるが、 cgo では外部ライブラリの include パスやリンクオプションを .go のソースファイル内にコメントとして指定する必要がある。\n外部ライブラリのパスは環境によって異なるため、 全ての環境に合せて include パスやリンクオプションを指定しておくことは出来ない。\nそこで pkg-config を利用する。\ncgo で pkg-config を利用するには、次のように指定する。\n// #cgo pkg-config: package1 package2 package3 LuneScript では、次のように指定している。\n// #include \u0026lt;string.h\u0026gt; // #include \u0026lt;stdlib.h\u0026gt; // #cgo pkg-config: lua-5.3 // #include \u0026lt;lauxlib.h\u0026gt; // #include \u0026lt;lualib.h\u0026gt; import \u0026#34;C\u0026#34; ","id":49,"section":"posts","summary":"LuneScript 向けの別ツールを作ろうと思い、 LuneScript の go 向けランタイムを単独モジュールとして分割して管理すべく 奮闘した際の備忘録。 go のモジュール go は、 github に公開","tags":null,"title":"go の自作モジュールを github で公開して import するまで","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-11-28-golang-module/","year":"2020"},{"content":" 前回から引き続き LuneScript のトランスコンパイル時間短縮を行なっています。\n今回の時間短縮は以下の通りです。\n改善前(lua) 改善後(go) 参考 (lua batch) 参考 (luajit) 20.65 sec 4.32 sec 21.90 sec 21.56 sec この表の通り、 (/ 20.65 4.32) 4.780092592592592 ≒ 478% 改善しています。\n以降では、今回の LuneScript 性能向上の実現方法について説明します。\n一括処理 従来は、複数ある .lns ファイルを一つずつ処理するために、 LuneScript をファイル数分実行していました。\n今回は、複数ある .lns ファイル全てを 一回の LuneScript の起動で処理するように対応しました。\nこれによって、次の効果が得られていると思います。\nデータがメモリ上にキャッシュされ、一部の解析が不要になった 複数回の起動終了処理に掛る時間が、 1 度だけになった ある意味で当たり前といえば当たり前の結果ですが、 これを実現するには、最低限リエントラントにする必要があり、 意外なところに落とし穴があったりするものです。\nまぁ今回は事前に準備をしておいたので、 解析処理の繰り返し制御部分を追加しただけで動いたのですが。\n上の表を見ると分かりますが、 同じ一括処理を Lua 版 LuneScript で実行すると 逆に遅くなるという結果になりました。\nなお、今回の対応後の goprof の結果を見ると、 import 処理が思った以上に短縮されていないことが分かりました。\nこの原因は、 トランスコンパイルするファイルが異なる場合、 以前別のファイルで import した型も再度登録処理しているため、 想像以上に時間がかかっているようです。\nこれは、型の ID がファイル毎にシーケンシャルになっていることを前提に処理しているため、 必要な処理です。 この import 処理を高速化するには、 「型の ID がファイル毎にシーケンシャルになっている」ことを期待しないで 処理できるように対応する必要があります。\nこれはちょっと面倒そうです。\nただこれを改善すると、更に 1 秒近く改善できそうなので対応する価値はあります。\n気が向いたら対応しようと思います。\nなお今回の一括処理対応では、指定されたファイルをシーケンシャルに処理します。 個々のファイルのトランスコンパイル処理を並列化していません。\nLuneScript のセルフホスティングのソースでは、 ほとんどのファイルが片方向リストの様に import しているため、 並列に処理することが出来ません。 前のファイルを処理しないと、次のファイルが処理できない状態です。\nよって、並列化されないことはほとんどパフォーマンスに影響しません。 しかし、プロジェクトによっては並列化の影響が大きいこともあります。\nその場合は、今回の一括処理すると遅くなる可能性があります。\n使用方法 LuneScript のトランスコンパイル対象ファイル指定のオプションに @- を指定し、 トランスコンパイル対象のファイルパスを一行毎 stdin に入力するだけです。\nなお、一点注意があります。\n一括処理している際の –depends オプションは、 ディレクトリ指定として扱います。\nつまり従来のファイル毎の LuneScript では、 –depends オプションは、 Make 用依存ファイルの出力先ファイルパスでしたが、 一括処理時の –depends オプションは依存ファイルの出力先ディレクトリパスになります。 そして、実際に出力さられるファイルは、その出力先ディレクトリパスに トランスコンパイル対象のファイルパスの .lns を .d に変換したファイルとなります。\n","id":50,"section":"posts","summary":"前回から引き続き LuneScript のトランスコンパイル時間短縮を行なっています。 今回の時間短縮は以下の通りです。 改善前(lua) 改善後(go) 参考 (lua batch) 参考 (luajit)","tags":null,"title":"LuneScript のトランスコンパイル時間を 478 パーセント改善した件","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-11-08-lunescript-speed-up-batch/","year":"2020"},{"content":" LuneScript は Lua 向けのトランスコンパイラで、 LuneScript 自体も Lua 上で動作しています。\nまた、LuneScript は LuneScript 自体の処理を、 LuneScript で開発する所謂セルフホスティングを採用しています。\nそのセルフホスティングしているコード規模は、右肩上がりで増大しています。\n上記グラフは少し以前のもので、現在は 50Kline を突破しています。\nコード規模が増えて一番気になるのは、やはりコンパイル時間です。\n特に LuneScript は Lua で動作するため、 一般的なネイティブのコンパイラよりも遅くなります。\n一年以上前から速度向上のための取り組みは行なっていましたが、 今回ようやく速度向上版を安定して運用できるレベルまで到達しました。\nそして速度向上の結果、従来と比較して 425% 改善しました。\n(2020/11/8) 更新\nそして速度向上の結果、従来と比較して 387% 改善しました。\n以下は、セルフホストしている LuneScript コードをトランスコンパイルする際に掛る時間を、 改善前と後とで測定した結果です。\n改善前(lua) 改善後(go) 参考 (luajit) 20.67 sec 4.86 sec 21.56 sec この表の通り、 (/ 20.67 4.86) 4.253086419753086 ≒ 425% 改善しています。\n以降では、今回の LuneScript 性能向上の実現方法について説明します。\nセルフホスティング 前述の通り LuneScript は次の特徴があります。\nLuneScript 自体 Lua で動作する 一般的に Lua はネイティブと比べて遅い この特徴から、 Lua ではなく、ネイティブで動く LuneScript コンパイラを作成するのが、 性能向上のための最も確実性の高い手段だと考えられます。\nネイティブで動くプログラムを組むには、 当然ネイティブに対応したコンパイラが必要になります。\n当然ながら、 LuneScript のコードに対応したコンパイラは LuneScript 以外にありません。\nまた、 Lua のコードに対応したコンパイラもありません。 Lua には、JIT コンパイラに対応した LuaJIT がありますが、 上記の表の通り LuaJIT では LuneScript の速度向上は実現できませんでした。\nではどうすれば LuneScript をネイティブで動かせるか？\n次の方法が考えられます。\nネイティブのコンパイルに対応した別の言語で LuneScript を開発する セルフホストしている LuneScript コードを、ネイティブコードにコンパイルできるように LuneScript を拡張する 上記の 1) は、 LuneScript の特徴であるセルフホスティングを止めるということです。 しかし、セルフホスティングは LuneScript にとって非常に重要な特徴です。 セルフホスティングが重要な理由はいくつかありますが、 品質を担保するという意味での重要性については、以下を参照してください。\n\u0026lt;https://ifritjp.github.io/documents/lunescript/test/\u0026gt;\nよって、 1) は却下し 2) で対応しています。\nネイティブコードにコンパイルする方法 「ネイティブコードにコンパイル」するには、次の方法があります。\nLuneScript から、直接ネイティブコードへのコンパイル機能を LuneScript に拡張する LuneScript から、別のコンパイラの言語に変換する機能を LuneScript に追加し、 別の言語に変換したソースをそのコンパイラでビルドする 上記 (a) は、独自にコンパイラを作ることになるので、 非常に柔軟に開発することが出来るメリットがあります。 その一方で、多くのことを自分でやらなければならないというデメリットがあります。\n上記 (b) は、変換する言語仕様に制限されるというデメリットがありますが、 多くのことを変換先のコンパイラに任せられるというメリットがあります。\n(b) はトランスコンパイラそのものであり、 LuneScript との相性が良いと判断し、 (b) を採用しました。\nなお、変換先は go を選択しています。\nこれは、ちょうど go を勉強したいと思っていたタイミングとマッチしていたのと、 静的型付け言語の割には比較的緩く書けるので、 変換先の言語にちょうど良いと考えたためです。\n「比較的緩く書ける」のが何故良いのかと言えば、 例えば Rust のように非常に厳格な言語だと、 その言語仕様に併せこむのが困難で、 LuneScript からの変換ができなくなる可能性が高いためです。\nLuneScript と Go の言語仕様の差異 LuneScript は、イマドキの言語の多くの仕様を取り込んでいるため、 何気に言語仕様が大きくなっています。\nそれら言語仕様を、変換先の言語で実現できるかどうかが課題です。 変換先の言語の制約によって、 LuneScript の言語仕様が実現できないことも考えられます。\n今回の go への変換については、実現不可能な言語仕様はありませんでした。\nただし、現時点では LuneScript の言語仕様の全てを、 Go 版の LuneScript で実現できているか？ というと、実はそうではなく、 LuneScript をセルフホスティングするために必要な言語仕様に限定しています。\nセルフホスティングに必要ない言語仕様については、今後対応していきます。\nなお、以下の LuneScript の言語仕様については、 Go 言語の文法には直接ないものなので、 変換処理時にいろいろと制御を入れて実現している仕様の一部です。\nクラス継承 多値返却 (go にも多値返却があるが、 LuneScript とは大きく仕様が異なる) generics ファイル内スコープ nil 安全 and or 演算子 Lua 言語との連携 別の言い方をすれば、 go 言語では直接的にはサポートされていないこれらの機能も、 コードの書き方次第で go 言語上で実現できるということ です。\nLuneScript の言語仕様への影響 今回の go 言語へのトランスコンパイル対応で、 LuneScript の言語仕様を一部修正しています。\nできるだけ従来の仕様に影響がないように対応しましたが、 どうしても吸収できない部分があったため修正しています。\n具体的な差分ついては、 LuneScript のサイトの方で後日解説します。\n\u0026lt;https://ifritjp.github.io/documents/lunescript/\u0026gt;\ngo 版 LuneScript の利用方法 go 版 LuneScript の利用方法についても、後日 LuneScript のサイトで解説します。\n以上。\n","id":51,"section":"posts","summary":"LuneScript は Lua 向けのトランスコンパイラで、 LuneScript 自体も Lua 上で動作しています。 また、LuneScript は LuneScript 自体の処理を、 LuneScript で開発する所謂セルフホスティン","tags":null,"title":"LuneScript のトランスコンパイル時間を 425 パーセント改善した件","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-11-01-lunescript-speed-up/","year":"2020"},{"content":" これまでの LuneScript のコード規模の推移を調べてみた。\nこれは単純に LuneScript をセルフホストしている .lns ファイルの行数をトータルした結果。 よって、コメントや空行等も入っている。\n2020年前半はさぼってたけど、それ以外はコンスタントに成長している感じ。\n参考までに、このグラフを作った gnuplot スクリプト。 1列目に YYYY-MM-DD の日付データ、2列目に行数データの dump.csv からデータをロードして、 codesize.svg を出力する。\nfile=\u0026#39;dump\u0026#39; se g se xdata time se timefmt \u0026#34;%Y-%m-%d\u0026#34; se datafile separator \u0026#34;,\u0026#34; se format x \u0026#34;%Y/%m\u0026#34; se title \u0026#39;Code Size of LuneScript\u0026#39; set xtics rotate by -45 se terminal svg se output \u0026#39;codesize.svg\u0026#39; p file u 1:2 w l title \u0026#34;lineNo\u0026#34; #pause -1 ","id":52,"section":"posts","summary":"これまでの LuneScript のコード規模の推移を調べてみた。 これは単純に LuneScript をセルフホストしている .lns ファイルの行数をトータルした結果。 よって、コメントや空行等","tags":null,"title":"LuneScript のコード規模の推移を調べた","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-10-01-lunescript-codesize/","year":"2020"},{"content":" emacs で snippet を管理するパッケージに yasnippet がある。\nyasnippet はメジャーモード毎に snippet を登録しておき、 編集中のメジャーモードに合せて snippet を呼び出すことができる。\nyasnippet に snippet を登録するには、 変数 yas-snippet-dirs で指定しているディレクトリ内に メジャーモード名のディレクトリを作成し、 そのメジャーモード名のディレクトリ内に snippet 情報を記述したファイルを置く。\nこれにより、 yasnippet のロード時、あるいは M-x yas-reload-all 実行時に、 snippet が yasnippet に登録される。\nここで問題がある。\n説明した通り、yasnippet に snippet を登録するには、 メジャーモード名のディレクトリを作成する必要があるが、 emacs のメジャーモード名は / 等を含むことが出来る。 つまり、そのようなメジャーモードのディレクトリを作成することが出来ないので、 snippet を登録することが出来ない。\n今回は、/ 等のファイル名に使用できない文字を含むメジャーモードの snippet を 登録する方法について示す。\n登録方法 登録方法を説明する前に、 yasnippet の snippet 呼び出し処理について簡単に説明する。\nyasnippet は snippet を展開する際、現在のメジャーモードを確認し、 各メジャーモードに登録されている snippet を取得する。 この時、現在のメジャーモードだけでなく、 変数 yas–extra-modes に指定されている モードに登録されている snippet についても取得する。 上記の通り yas–extra-modes に指定されているモードも snippet の検索対象になるので、 今回は yas–extra-modes を利用して対応する。\nsnippet を登録したいモードを mode_A とする。\n次のように処理することで、この mode_A で利用する snippet を登録できる。\nmode_A の代替となるモードを作成する。\nこのモードを mode_B とする。 通常の手順で mode_B に snippet を登録する。 mode_A の hook に、次の処理を行なう関数を登録する。\nyas–extra-modes をバッファローカル変数に設定し、その値に \u0026#39;(mode_B) をセットする。 以上により、 メジャーモード mode_A が有効になったバッファの バッファローカル変数 yas–extra-modes に mode_B が登録される。 これで、mode_A 内で yasnippet の snippet を呼び出すと mode_B の snippet が検索対象になる。\n上記の方法は、mode_A の snippet を直接登録する方法ではなく、 mode_A と mode_B を紐付けて mode_A の snippet に mode_B の snippet を含めることで、 目的を実現している。\nmode_A の snippet を直接登録するには、 yasnippet のコードを修正する以外には方法が無さそうなので、 今回はこのような対応にしている。\n","id":53,"section":"posts","summary":"emacs で snippet を管理するパッケージに yasnippet がある。 yasnippet はメジャーモード毎に snippet を登録しておき、 編集中のメジャーモードに合せて snippet を呼び出すことができる。 yasnippet に snippet","tags":null,"title":"emacs yasnippet の snippet を対応させるモード名に / 等のファイル名に使用できない文字がある場合","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-08-19-emacs-yasnippet/","year":"2020"},{"content":" LuneScript の開発を続けて約 2 年経過。\n2年間ずっと開発し続けているわけではないけど、 かなりの時間を LuneScript の開発にあてている。\nそんな訳で、今回は LuneScript の開発工数を概算してみる。\nもちろん、作業時間の記録なんて面倒なことはしていないので、 あくまで概算である。\n開発作業 LuneScript に限ったことではないが、 github で個人開発する際は、 だいたい次のように開発を進めている。\n作業項目(TODOリスト)を doc/todo.org にリストアップする TODOリストを順次潰していく 作業した日は、出来るだけ commit, push する。\ncommit する条件は、テストをパスすること。 作業項目の対応の途中でも、キリの良いところで commit, push する。 そんな訳で、「commit した日 + C == 作業した日」が成りたつ。\nここで C は、「作業したが commit していない日」である。 これの多くは、修正内容の規模が大きくて、 1 日ではテストをパスできずに commit できない日である。\nこのようなケースは、頻度が少ないので概算から除外する。\n概算 LuneScript の commit ログは 397 個.\n$ git log --oneline | wc -l 397 commit の日付けから、同じ日に commit したものは除外し、 異なる日が何個あるかを計算すると、 286 個。\n$ git log --pretty=%aI | sed \u0026#39;s/T.*//g\u0026#39; | uniq | wc -l 286 つまり、286 日以上は LuneScript の作業を行なっている。\n1 日の作業時間は、日によってバラバラだが、 平均すれば 2 時間以上は間違いなく作業している。 これを計算すれば、\n(* 2 286) 572 よって、 572 時間 は最低限 LuneScript にかけている計算になる。\n8 時間労働で考えると、 (/ 572 8.0) 71.5 日。4 ヶ月弱の工数。\n会社で働けば 100 万円は稼げる。\nこれは、1 日の平均作業時間を 2 時間として計算した結果であって、 実際にはもっと作業している感覚がある。 あくまで最低限の概算だ。\n個人的には、LuneScript は少なくとも 100 万以上の価値がある。\n","id":54,"section":"posts","summary":"LuneScript の開発を続けて約 2 年経過。 2年間ずっと開発し続けているわけではないけど、 かなりの時間を LuneScript の開発にあてている。 そんな訳で、今回は LuneScript の開発工数","tags":null,"title":"LuneScript の開発工数","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-08-01-lunescript-man-hour/","year":"2020"},{"content":" GCP から「Go 1.11 は使えなくなるから Go 1.13 にして」という通知があったので、 忘れないうちに Go 1.13 にして deploy をしたら、次のエラーが出た。\nERROR: (gcloud.functions.deploy) OperationError: code=13, message=Build failed: go mod: -require=xxxxxx/hoge/foo@v0.0.0: invalid path: malformed module path \u0026#34;xxxxxx/hoge/foo\u0026#34;: missing dot in first path element; Error ID: 3182a79f どうやら、モジュールの先頭ディレクトリは FQDN の形式しないと NG になったようだ。 いままでは . を含まない適当な名前にしてたんだが、 「xxxxxx/hoge/foo の xxxxxx に . が含まれてない == FQDN ではない」、 ということで NG っぽい。 xxxxxx を github pages の自分の FQDN にして deploy したら上手くいった。\nちなみに、ローカルの Go build では FQDN ではなくても問題なかった。 deploy の時だけ問題になるようだ。\nどうせなら、ローカルの Go build でもエラーになれば良いのに。\n","id":55,"section":"posts","summary":"GCP から「Go 1.11 は使えなくなるから Go 1.13 にして」という通知があったので、 忘れないうちに Go 1.13 にして deploy をしたら、次のエラーが出た。 ERROR: (gcloud.functions.deploy) OperationError: code=13, message=Build failed: go mod: -require=xxxxxx/hoge/foo@v0.0.0:","tags":null,"title":"Google Cloud Functions の deploy で 'missing dot in first path element; Error ID: 3182a79f' エラー","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-07-18-gcp-function-deploy/","year":"2020"},{"content":" 先日、 Google 翻訳で lunescript が固有名詞として認識された可能性について ネタにしたが、 どうやら本当に lunescript が固有名詞として認識されたのではないかと思われる。\nというのも、 google の検索バーに lunesc まで入力すると、\n上のように lunescript が候補に挙げられる。\ngoogle の単語として登録されたからといって、 LuneScript の認知度が上った訳でもないが、何となく嬉しい。\nなお、 lunescript を検索した際の関連ワードは次の通り。\nちゃんと lua を認識している。\n念のため、次の状態で確認しているんで、 Google 検索が自分の環境にカスタマイズされているのではないと思われる。\nCookie をクリア 海外 proxy を使ってアクセスする IP を変更 Google には login していない ","id":56,"section":"posts","summary":"先日、 Google 翻訳で lunescript が固有名詞として認識された可能性について ネタにしたが、 どうやら本当に lunescript が固有名詞として認識されたのではないかと思われる。 とい","tags":null,"title":"LuneScript の Google 検索ワード","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-07-15-lunescript-search/","year":"2020"},{"content":" イマドキは少数派だと思うが、 PC に ubuntu と windows のデュアルブートを設定している。\nさらに面倒なことに、 windows は BitLocker で暗号化 \u0026amp; PIN 認証を設定している。\nそして、この状態で ubuntu を apt upgrade したら、 何故か windows ブート時の BitLocker の PIN 認証が失敗するようになった。\nPIN を間違えているはずはないのだが、何度やっても PIN 認証が通らない。\nしかたがないので、 BitLocker の回復キーを入力したところ問題なく起動した。\nそういえば ubuntu の apt upgrade 実行時、grub の更新が掛った。 その際、設定をどうするか聞いてきたので、 設定を変更しないように選択したのだが何か問題があったようだ。\nなお、回復キーを使って起動した後、 再度 PIN を設定することで、問題なく PIN 認証が通るようになった。\nPIN を忘れてなくても、回復キーが必要になることがあるんだな。\n","id":57,"section":"posts","summary":"イマドキは少数派だと思うが、 PC に ubuntu と windows のデュアルブートを設定している。 さらに面倒なことに、 windows は BitLocker で暗号化 \u0026amp; PIN 認証を設定している。 そして、この","tags":null,"title":"デュアルブートの ubuntu を upgrade したら windows の BitLocker が PIN の認証失敗するようになった","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-07-10-bitlocker/","year":"2020"},{"content":" Go の勉強を兼て「これ」を Go で作っていたんだが、その時感じた Go の特徴をまとめておく。\nGo は気軽に書けるのに、非常に高い実行パフォーマンスを出せる使い勝手の良い言語だと思う。\nまた、パッケージマネージャを言語自身に内蔵しているため、 拡張パッケージが揃っていて、今後さらにパッケージが充実して使える言語になるだろう。\nこんな様なことは、もう誰もが書いていることだと思うので、 以降では、もう少し違った角度で Go について考えたことをまとめておく。\nGo はエンジニアを信用している言語 「エンジニアを信用している」 とはどういう事かというと、 Go を使うエンジニアはつまらない間違いをしない高レベルな技術を持っていることを 前提にしている、ということだ。\nこの根拠は、Go の次の言語仕様から来ている。\nnil 安全がない 構造体のコンストラクタがない アクセス制限が公開と package 内限定しかない Generics がない 基本的に mutable shadowing 可能 排他制御が古典的 静的型付け言語は、安全方向に仕様を振っていて、 出来ることを制限する手段を提供していることが多い(例えばアクセス制限や Generics 等)。 一方 Go では、そのような制限する手段を提供していない部分が多い。\nでは何故、Go は言語仕様による制限をしないのか？ それは、 Go の設計者が、そんな機能に頼らなくても安全に開発を進められる、 という思いがあったからだろう。\n一方近年話題になっている Rust では、 Go とは逆にエンジニアを信用していない言語で、 エンジニアはヒューマンエラーを起すことを前提にしている。 そして、ヒューマンエラーが起きたときは、コンパイラレベルで検知して エラーするようにしている。ただ、これを実現するために多くのメタ情報を コード上に宣言する必要がある。\nこれは言語仕様の決め方の方向性が違うだけで、 どちらが正解で、どちらが間違っているというものではない。\nプロジェクトで採用する言語を決定する際に、 どのような言語がそのプロジェクトにマッチするのかを判断することが重要だ。\n","id":58,"section":"posts","summary":"Go の勉強を兼て「これ」を Go で作っていたんだが、その時感じた Go の特徴をまとめておく。 Go は気軽に書けるのに、非常に高い実行パフォーマンスを出せる","tags":null,"title":"Go 言語 (golang) について思ったこと","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-06-27-golang/","year":"2020"},{"content":" 以前 lunescript の紹介記事を書いている時に、 lunescript の日本語訳がふと気になったんで調べていたんだが、 その時の Google 翻訳の結果が衝撃的だった。\n\u0026lt;https://ifritjp.github.io/documents/lunescript/tutorial1/#headline-3\u0026gt;\nで、久し振りに Google 翻訳で lunescript を翻訳してみた。 その結果は次の通り。\nめでたく lunescript の日本語訳が lunescript になった。\nこれは、 LuneScript が Google に固有名詞として認識されたということだろうか？\nそれとも、該当する単語が登録されていないから、 とりあえずそのまま表示しているだけなんだろうか？\n","id":59,"section":"posts","summary":"以前 lunescript の紹介記事を書いている時に、 lunescript の日本語訳がふと気になったんで調べていたんだが、 その時の Google 翻訳の結果が衝撃的だった。 \u0026lt;https://ifritjp.github.io/documents/lunescript/tutorial1/#headline-3\u0026gt; で、久し振りに Google 翻","tags":null,"title":"LuneScript の Google 翻訳","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-06-26-lunescript-trans/","year":"2020"},{"content":" tunnel ツールのネタを書いた時、 dot を使ってグラフを作った。\ndot は手軽にグラフを書ける便利なツールだが、 レイアウト制御に難があると思う。\nグラフ作成ツールの利点と欠点 dot などのグラフ作成ツールの利点には次が挙げられる。\nノードのリンクを指定するだけで、後はツールが良い感じにグラフを自動で作成してくれる。\nパワポ等でグラフを作成するのと比べると、これは大きな利点だ。\nそして多くの場合、ツールが作成するグラフは、それなりに見易いグラフになってくれる。\nただ、少ない情報から自動でグラフを作成するため、 意図とは異なるレイアウトのグラフが出来あがることもある。\nレイアウトのことは割り切って使うとか、 気に入らないなら他のパワポなどの draw 系のツールで描けば良いという話もあるが、 それは何か違うと思っている。\ndot のグラフ 次の図は、 tunnel と host を繋ぐ処理をグラフ化したものだ。\nこのグラフの dot コードは次になる。\ndigraph G { rankdir = RL; tunnel [shape=doublecircle]; subgraph clusterA { packetWriter [shape=rect; margin=0.2;]; packetReader [shape=rect; margin=0.2;]; keepalive [shape=rect; margin=0.2;]; WriteQueue tunnel2Stream [shape=rect; margin=0.2;]; stream2Tunnel [shape=rect; margin=0.2;]; ReadQueue {rank = max; packetReader; packetWriter} {rank = same; WriteQueue; ReadQueue} {rank = min; tunnel2Stream; stream2Tunnel; keepalive} } host [shape=box3d]; tunnel -\u0026gt; packetReader packetReader -\u0026gt; ReadQueue ReadQueue -\u0026gt; tunnel2Stream stream2Tunnel -\u0026gt; WriteQueue WriteQueue -\u0026gt; packetWriter packetWriter -\u0026gt; tunnel keepalive -\u0026gt; WriteQueue tunnel2Stream -\u0026gt; host host -\u0026gt; stream2Tunnel {rank=min;host} } コードの細かい部分はここでは触れないが、 次の 4 つの {rank=} を指定していることを確認して欲しい。\n{rank = max; packetReader; packetWriter} {rank = same; WriteQueue; ReadQueue} {rank = min; tunnel2Stream; stream2Tunnel; keepalive} {rank=min;host} この rank 指定を外してグラフを生成すると次のようになる。\ndigraph G { rankdir = RL; tunnel [shape=doublecircle]; subgraph clusterA { packetWriter [shape=rect; margin=0.2;]; packetReader [shape=rect; margin=0.2;]; keepalive [shape=rect; margin=0.2;]; WriteQueue tunnel2Stream [shape=rect; margin=0.2;]; stream2Tunnel [shape=rect; margin=0.2;]; ReadQueue } host [shape=box3d]; tunnel -\u0026gt; packetReader packetReader -\u0026gt; ReadQueue ReadQueue -\u0026gt; tunnel2Stream stream2Tunnel -\u0026gt; WriteQueue WriteQueue -\u0026gt; packetWriter packetWriter -\u0026gt; tunnel keepalive -\u0026gt; WriteQueue tunnel2Stream -\u0026gt; host host -\u0026gt; stream2Tunnel } rank 指定の有無の違い rank 指定の有無によって生成されるグラフがどのように違いがあるのか、 分かり易いように並べて表示する。\nrank 指定あり rank 指定なし rank 指定ありは矢印の向きが素直に円を描いる一方で、 rank 指定なしは矢印が交差していたり、矢印が長かったりで、 rank 指定ありと比べて動きが捉え辛くないだろうか？\nこのように、意図したレイアウトと異なる結果になった場合、 rank を指定することで、ある程度の制御が出来る。\nrank 指定の意味 今回指定した 4 つの rank の内、次の 3 つは中央の四角の中の並び順を指定している。\n{rank = max; packetReader; packetWriter} {rank = same; WriteQueue; ReadQueue} {rank = min; tunnel2Stream; stream2Tunnel; keepalive} そもそも、 rank は何を指定するものなのかというと、 dot がリンク情報を元に どのノードをどこに配置するかを決定するアルゴリズムにおいて使用する要素の一つだ。\n上記の 3 つの指定は、 packetReader, packetWriter が max のランクで、 WriteQueue, ReadQueue が同じランクで、 tunnel2Stream, stream2Tunnel, keepalive が min のランクであることを設定している。\nこれは、 rank 指定した時の図と見比べて、 中央の四角の中の左側から max, same, min の順で並べられていることから納得できる。\n4 つの内の最後の rank 指定は、 host の場所を指定している。\n{rank=min;host} これは、 host が min のランクであることを設定している。\nこれも rank 指定した時の図と見比べて、 host が一番右に配置されていることから納得できる。\nこのように、 rank に max, same, min を指定することで、 ノードの配置を指定することが可能だ。\nなお、 rank の指定は全部で 5 種類ある。\nmin max same source sink これらの意味について、公式サイトに次の記載がある。\nRank constraints on the nodes in a subgraph. If rank=\u0026#34;same\u0026#34;, all nodes are placed on the same rank. If rank=\u0026#34;min\u0026#34;, all nodes are placed on the minimum rank. If rank=\u0026#34;source\u0026#34;, all nodes are placed on the minimum rank, and the only nodes on the minimum rank belong to some subgraph whose rank attribute is \u0026#34;source\u0026#34; or \u0026#34;min\u0026#34;. Analogous criteria hold for rank=\u0026#34;max\u0026#34; and rank=\u0026#34;sink\u0026#34;. (Note: the minimum rank is topmost or leftmost, and the maximum rank is bottommost or rightmost.) min と source、 max と sink は同じように利用できる。\nただ、上記の記載にはないが、 min, max と souce, sink を混在して使用する際は、 注意が必要である。\nなぜならば、min, max と souce, sink はそれぞれ異なる軸(X と Y)で 処理されるようなので、同じ軸でランク付けを行なう場合、 min, max, souce, sink を混在させてはならない。\n","id":60,"section":"posts","summary":"tunnel ツールのネタを書いた時、 dot を使ってグラフを作った。 dot は手軽にグラフを書ける便利なツールだが、 レイアウト制御に難があると思う。 グラフ作成ツー","tags":null,"title":"dot のレイアウト指定","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-06-09-graph/","year":"2020"},{"content":" go で proxy server を建てるには、 github.com/elazarl/goproxy を使うと簡単に実現できる。\nhttps://github.com/elazarl/goproxy\ngithub の readme を見れば、簡単な使い方が載っているので特に問題はないだろう。\nただ、一点だけハマったポイントがあるので書いておく。\nproxy 環境下で goproxy を使う場合の注意点 package main import ( \u0026#34;github.com/elazarl/goproxy\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { proxy := goproxy.NewProxyHttpServer() proxy.Verbose = true log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, proxy)) } github の readme にサンプルとして上記コードが載っている。\n基本的にこれで問題ないのだが、 proxy 環境下で動かす場合には注意が必要だ。\n多くの場合、 proxy 環境下では環境変数に次のような設定をしているだろう。\nexport HTTP_PROXY=http://proxy.hoge.com:80/ export HTTPS_PROXY=http://proxy.hoge.com:80/ このような設定を行なっている場合、 上記サンプルコードを動かすと、 goproxy はさらに proxy.hoge.com を使って接続を行なおうとする。\nつまり、 goproxy を使って localhost:80 にアクセスしようとすると、次のような形になる。\nclient --\u0026gt; goproxy --\u0026gt; proxy.hoge.com:80 --\u0026gt; localhost:80 ここで問題なのは、 proxy.hoge.com:80 が間に挟まることで通信が確立できなくなる可能性がある、 ということだ。\n少なくとも、goproxy にとっての localhost と、 proxy.hoge.com にとっての localhost は意味が異なるし、 プライベートアドレス IP 指定を受けつけない proxy も多いだろう。\n対応策 前述した proxy 環境下の問題を回避するには、次の 2 つがある。\ngoproxy を使用する際に上記環境変数の設定を消す goproxy を使うコードを修正する goproxy を使うコードを修正するには、 次のように proxy.ConnectDial = nil を追加すれば良い。\npackage main import ( \u0026#34;github.com/elazarl/goproxy\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { proxy := goproxy.NewProxyHttpServer() proxy.Verbose = true proxy.ConnectDial = nil // これを追加 log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, proxy)) } ","id":61,"section":"posts","summary":"go で proxy server を建てるには、 github.com/elazarl/goproxy を使うと簡単に実現できる。 https://github.com/elazarl/goproxy github の readme を見れば、簡単な使い方が載っているので特に問題はないだろう。 ただ、一点だけハマった","tags":null,"title":"go の proxy server (github.com/elazarl/goproxy) の使い方","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-06-04-go-proxy/","year":"2020"},{"content":" とある理由から 「Tunnel/Reverse Tunnel over websocket」 が必要になったので作ってみた。\n「Tunnel/Reverse Tunnel over websocket」 が何かというと、 「websocket を tunnel にして別の TCP 通信を通すもの」だ。\n「Tunnel/Reverse Tunnel over websocket」 とは 「Tunnel/Reverse Tunnel over websocket」を少し具体的にいうと、 次のような構成で通信を可能にするモノだ。\nframe tunnelの例 { rectangle network_1 { node tcp_client_A node tunnel_client_1 } rectangle network_2 { node tunnel_server_1 node tcp_server_B } } tcp_client_A --\u0026gt; tunnel_client_1 tunnel_client_1 --\u0026gt; tunnel_server_1 tunnel_server_1 --\u0026gt; tcp_server_B tcp_client_A ..\u0026gt; tcp_server_B frame reverse_tunnelの例 { rectangle network_A { node tcp_server_C node tunnel_client_2 } rectangle network_B { node tunnel_server_2 node tcp_client_D } } tcp_server_C \u0026lt;-- tunnel_client_2 tunnel_client_2 --\u0026gt; tunnel_server_2 tunnel_server_2 \u0026lt;-- tcp_client_D tcp_client_D ..\u0026gt; tcp_server_C 上の図は network_1, network_2, network_A, network_B の 4 つのネットワークを表わしている。\nこのネットワーク間でポートが制限されていると、 tcp_client_A は tcp_server_B と直接通信が出来ない(図の点線)。\n開放されているポートで接続し、そのセッション上に仮想的な Tunnel を構築する。 そして、その Tunnel 内にポートの制限を受けない通信を実現する。\n左は Tunnel の構成例である。 ポート制限されている network_1, network_2 を、 tunnel server / tunnel client で接続して tunnel を構成し、 その tunnel を使って tcp client A と tcp server B を接続する。\n右は Reverse Tunnel の構成例である。 ポート制限されている network_A, network_B を、 tunnel server / tunnel client で接続して tunnel を構成し、 その tunnel を使って tcp client D と tcp server C を接続する。\nTunnel と Revers Tunnel の違いは、 tcp client/server の位置関係である。\n具体的には、 Tunnel server と同じネットワークに tcp server が属する構成が Tunnel で、 逆に Tunnel server と同じネットワークに tcp client が属する構成が Reverse Tunnel である。\nそして、 Tunnel server と client 間の通信経路として、 websocket を利用して tunnel を構築するのが 「Tunnel/Reverse Tunnel over websocket」である。\nVPN (Virtual Private Network) このように制限されたネットワーク間で通信路を構築する方法として、 WireGuard や OpenVPN などの低レイヤー VPN がある。\n低レイヤー VPN は、その名の通り仮想的なネットワークを低レイヤーで構築する。 これによって、通常のネットワークと同様に扱えて利便性が高いが、 通常のネットワークと同様であるが故、逆にリスクになる可能性がある。\n今回は VPN ではなく、Tunnel を実現するのが目的である。\nなお、ここでは「レイヤー 2 あるいは 3 を仮想化する技術」を VPN とし、 「ネットワーク間で TCP セッションを転送する技術」を Tunnel とする。\n開発した背景 制限されたネットワーク間での通信を確立できないかどうか、 当初はフリーのツールを探して tunnel ソフトを幾つか試してみたが、 tunnel が接続できなかったり、接続できてもすぐに切れてしまったりで イマイチ希望したものとは違った。\n特に自分の環境は (A)/(B) 間のネットワーク環境が悪く、 tunnel を確立しても、ある程度経過すると切断されてしまう問題があった。\ntunnel が切断されても tunnel を再接続することで、 tunnel 内の tcp 通信を継続させることは論理的に可能だ。 しかし、検討していた幾つかのフリーのツールでは、 tunnel が切断されると tunnel 自体のを再接続が出来ても tunnel 内を流れる tcp 通信が継続できなかった。 そもそも tunnel を再接続すること自体、 成功したり失敗したりしているような状況だった。\nそこで、今回はフリーのツールを検討することは諦め、 自分の勉強も兼てスクラッチで開発することにした。\nなお、ネットワーク間を接続することが目的であれば、 WireGuard や OpenVPN などの低レイヤー VPN や、 stunnel などの Tunnel ツールを利用するのが多くの場合ベストだろう。\nネットワーク環境 今回開発した Tunnel ツールを使って、 自分のネットワーク環境の Tunnel 間通信強制切断状況を確認したところ、 次のようになった。\n(a) 接続は最大でも 15 分程度で切断される (b) 昼間は 30 秒程度で切断される (c) 接続の 7 割強は 1 分以内で切断される (a) について、 どうやら自分の環境では http 通信は 15 分程度でセッションが強制切断されるらしい。\n(b), (c) について、 無通信が続くと 30 〜 60 秒程度で強制切断されるようなので、 無通信を回避するために 20 秒毎にトンネル間でダミーの通信を行なうよう対応した。\nただ、これでも通信負荷が高くなると数分で切断されることがある。\n使用方法 このツールは Go で開発しているため、 事前に Go(1.14.2) の環境を構築してあることが前提である。\n注意事項 tunnel 間の通信がインターネットを経由する場合、セキュリティには十分注意すること。\ntunnel client/server 間通信の暗号化や、client 認証を実装しているが、 tunnel 内の TCP セッションは raw な tcp 接続をせずに、 ssh などで接続すること。 tunnel server は常駐させず、必要な時にだけ起動するように運用すること。 pass , encPass オプションを必ず指定し、適切な期間で変更すること。 ip オプションを指定し、接続可能な client を制限すること。 ビルド 次のコマンドを実行することで、 tunnel ディレクトリ内に tunnel コマンドがカレントディレクトリに生成される。\n$ git clone --depth 1 https://github.com/ifritJP/kptunnel.git $ cd kptunnel $ make build kptunnel コマンド kptunnel コマンドは tunnel server と、 tunnel client の両方の役割を持ち、 オプションで切り替える。\nkptunnel コマンドは、次の書式をもつ。\n$ kptunnel \u0026lt;mode\u0026gt; \u0026lt;server\u0026gt; [forward [forward [...]]] [options] mode\n次のいずれかを指定する サーバ\nwsserver r-wsserver server r-server クライアント\nwsclient r-wsclient client r-client \u0026#34;r-\u0026#34; が付くものは、 reverse tunnel である。 ws が付くものは、 over websocket である。 ws が付かないものは、 tcp で直接接続する。\ntcp による接続は、実験的なサポートである。 tcp で接続できる環境なら、 このツールを使わずに ssh した方が良いだろう。 \u0026#34;r-\u0026#34;, \u0026#34;ws\u0026#34; は client/server で一致している必要がある。 server\nserver を示す。 サーバ側で指定する場合は、開放するポートを指定する。 (:1234 or localhost:1234)\nこの port に接続可能なネットワークを制限する場合は、 そのネットワークを指定する。 例えば localhost に制限する場合は localhost:1234 として指定する。 クライアント側で指定する場合は、ホスト名を含めて指定する (hoge.com:1234) forward\ntunnel で転送するポートの情報。 forward は複数指定できる。 server 側に forward が指定されている場合、 client 側の設定は server 側の設定で上書きされる。 \u0026#34;localのポート,forward先のポート\u0026#34; の書式で指定する。 localのポートに接続可能なネットワークを制限する場合は、 そのネットワークを指定する。 例えば localhost に制限する場合は localhost:1234 として指定する。 forward 先のポート情報は、相手にそのまま伝わる。\n例えば reverse tunnel で localhost を指定した場合、localhost は tunnel クライアント自身になり、 通常の tunnel の場合、 localhost はサーバ自身になる。 forward の書式は old_forward と new_forward の 2 つの書式がある。\nold_forward は、 local-port,remote-port の書式で指定する。\nここで reverse-tunnel の場合、 local-port はサーバ側の host:port を指定し、 remote-port はクライアントからアクセスする host:port を指定する。 tunnel の場合、 reverse-tunnel と逆になる。 new_forward は、 \u0026lt;r|t\u0026gt;,old_forward の書式で指定する。\nここで r は、 old_forward を reverse-tunnel として指定する。 ここで t は、 old_forward を tunnel として指定する。 つまり、old_forward は転送設定を mode 指定に従うのに対し、 new_forward は forward 設定毎に tunnel, reverse 設定を行なうかの違いである。 さらに言えば、 new_forward 書式を利用すると、 mode の tunnel, reverse の違いは意味がない。\nmode の reverse (r-client, r-server 等)は、互換性のために残しているが、 将来は削除する可能性がある。 次に代表的なコマンド例を示す。\nserver server のコマンド例を示す。\n$ kptunnel r-wsserver :6666 :8001,localhost:22 -pass XXXXXXX -encPass YYYYYYYY これは次のサーバの実行を指定している。\noption 意味 サンプルの意味 r-wsserver client/server の種類 reverse websocket server :6666 tunnel サーバの情報 ポート 6666 を使用して websocket server を建てる :8001,localost:22 tunnel で forward するポート番号 server の 8001 を client の localhost:22 に forward -pass client の認証用パスワード XXXXXXX -encPass client/server 間の通信路の暗号パスワード YYYYYYYY client client のコマンド例を示す\n$ kptunnel r-wsclient hoge.hoge.com:80 -proxy http://user:pass@proxy.hoge.com:8080/ -pass XXXXXXX -encPass YYYYYYYY これは次のクライアントの実行を指定している。\noption 意味 サンプルの意味 r-wsclient client/server の種類 reverse websocket client hoge.hoge.com:80 tunnel サーバの情報 hoge.hoge.com の 80 に接続する -proxy proxy サーバの情報 http://proxy.hoge.com::8080/ に user, pass で接続 -pass client の認証用パスワード XXXXXXX -encPass client/server 間の通信路の暗号パスワード YYYYYYYY tunnel への接続 上記のサンプルは localhost の 22 番ポートに接続するための reverse tunnel を構築している。 つまり、このサーバ側の 8001 ポートに繋げると、 client 側の ssh に接続されることになる。\nよって、サーバ側で次のコマンドを実行することで、クライアントの ssh に接続できる。\n$ ssh -p 8001 localhost オプション一覧 kptunnel コマンドで使用可能なオプションについて説明する\n基本 -proxy string\nwebsocket server に接続するための proxy proxy 不要なら省略する。 認証が必要な proxy の場合、 http://user:pass@proxy.hoge.com:port/ の形式で指定する。 現状は HTTP proxy のみ対応している。 client 側で指定する -UA string\nProxy に接続する際の User Agent を指定する websocket の client で有効 セキュリティ関連 -pass string\nclient 認証で使用する。 client/server で共通のものを指定する必要がある。 client 認証は challenge/respose で行なう。 -encPass string\nclient/server 間通信の暗号パスワード。 client/server で共通のものを指定する必要がある。 -encCount int\nclient/server 間の暗号処理回数を指定する。 (default -1)\n-1 : infinity 0 : plain, no encrypt. N \u0026gt; 0 : packet count このツールは tunnel client/server 間の通信を暗号化するが、tunnel 内を通すのが ssh などの場合、 二度の暗号化が走ることになり、tunnel client/server 間の暗号は無駄になる。 そこで、tunnel client/server 間の暗号化回数を指定することで、暗号化にかかる負荷軽減を可能にする。 回数は tunnel の通信パケット単位 暗号アルゴリズムは AES256 CFB を使用している。 -ip string\nserver に接続可能な client の、 IP アドレス範囲を指定する。\ne.g. 192.168.0.0/24 このオプションを省略した場合、 client の IP を限定しない。 動作デモ 次を実行しているデモ動画を示す。\nremote と local と、それらを仲介する proxy がある。 remote で tunnel の wsserver を起動 proxy を起動 local から wsclient を使って、proxy 経由で remote と tunnel を構築する local から tunnel 経由で remote と ssh 接続する ssh のコンソースから X11 アプリ (ico) を起動 proxy を停止\ntunnel が切断される X11 アプリ (ico) の更新が止まるが、 ssh のセッションは継続する proxy を起動\ntunnel が再接続される ssh のセッションが再開する X11 アプリ (ico) の更新が再開する 以降 proxy 停止、起動を繰り返し dispatcher この Tunnel ツールは、 一つの tunnel server で複数の tunnel client と接続できる。\nしかしその場合、次の問題がある。\ntunnel server が落ちると、接続していた全ての tunnel client に影響する client 毎にパラメータを設定できない\nパスワード forward 設定 等々 これを解決するには、 tunnel server を複数起動する必要がある。\nこの場合、tunnel server ごとに tcp port を割り当てる必要が出てくる。\nしかし、複数のポートを開けるのは一般的にセキュリティ上好ましくない。\nそこで、 kptunnel では dispatcher サーバを用意している。\ndispatcher サーバは、 個々の tunnel client からの要求をまとめて受け、 reverse proxy のように各 tunnel server に振り分ける。\nclient -----\u0026gt;| |---\u0026gt; server client ------|--\u0026gt; dispatcher ---|---\u0026gt; server client -----\u0026gt;| |---\u0026gt; server dispatcher の処理 dispatcher は、 client から接続要求を受けると次の処理を行なう。\n接続要求の uri, http header をもとに、 その接続要求を受け付けるかどうかを判定する (canAccept) 接続要求を受け付ける場合、 その client に対応する server の起動パラメータを決定する (getTunnelInfo) server を起動する 起動した server に、 client からの接続要求を転送する これにより、 dispatcher を介して client と server が接続される。\ndispatcher の処理のカスタマイズ dispatcher は、 tunnel client の要求毎に起動する tunnel server の構成を変更する。\nこの tunnel server の具体的な制御は、ユーザによって異なる。\nこの制御のカスタマイズは、 LuneScript のコードによって行なう。\nLuneScript のコードは、次の 2 つからなる。\nCanAccept.lns\n非 排他処理 接続要求の uri, http header をもとに、 client からの接続要求を受け付けるかどうかを判定する この処理は 非 排他処理で、 client のリクエスト毎に複数同時に動作する 1リクエスト毎に、 独立 した VM 上で動作するため、 オブジェクトが毎回初期化される UserHandler.lns\n排他処理 次を処理する\nclient からの接続要求を受け付けた後の、サーバ構成を決定する 切断後の処理 この処理は、排他処理で、client のリクエスト毎にシーケンシャルに動作する 全てのリクエストで 共通 した VM 上で動作するため、 全てのリクエストでオブジェクトが保持される sample コード CanAccept.lns, UserHandler.lns の処理サンプルは、以下にある。\ndispatcher/lns/user/sample/ dispatcher 起動コマンドオプション dispatcher の起動コマンドオプションを示す。\n$ ./dispatcher wsserver Usage: ./dispatcher wsserver \u0026lt;server\u0026gt; [option] server: e.g. localhost:1234/path or :1234 options: -console string console port. (:1234) -ip string allow ip range (192.168.0.1/24) -u string userHandler path. (ex: handler.lns,canAccess.lns) -verbose verbose. (true or false) 次は、 localhost の 10000 ポートの /path に dispatcher を立ち上げ、 カスタマイズ処理として lns/user/UserHandler.lns lns/user/canAccess.lns を指定している。\n./dispatcher wsserver localhost:10000/path -u lns/user/UserHandler.lns,lns/user/canAccess.lns 開発に関して これ以降の章では、この Tunnel ツール開発に関する技術的な内容について記載する。\nスレッド この Tunnel ツールは、主に次の 6 つのスレッドで構成される。\ntunnel session 制御 WriteQeue → tunnel のパケット送信制御 (packetWriter) tunnel → ReadQueue のパケット受信制御 (packetReader) ReadQueue → host のパケット転送制御 (tunnel2Stream) WriteQeue → tunnel のパケット転送制御 (stream2Tunnel) 無通信が一定時間続かないようにするダミーパケット送信制御 (keepalive) スレッド多す過ぎという気もするが、 メニーコア時代な現代であれば、 少ないスレッドで複雑なコードを書くよりも、 処理毎にスレッドを分けた方がメンテナンス性も性能も良いんじゃないだろうか？\n下図は、各スレッドの役割を図示している。\ndigraph G { rankdir = RL; tunnel [shape=doublecircle]; subgraph clusterA { packetWriter [shape=rect; margin=0.2;]; packetReader [shape=rect; margin=0.2;]; keepalive [shape=rect; margin=0.2;]; WriteQueue tunnel2Stream [shape=rect; margin=0.2;]; stream2Tunnel [shape=rect; margin=0.2;]; ReadQueue {rank = max; packetReader; packetWriter} {rank = same; WriteQueue; ReadQueue} {rank = min; tunnel2Stream; stream2Tunnel; keepalive} } host [shape=box3d]; tunnel -\u0026gt; packetReader packetReader -\u0026gt; ReadQueue ReadQueue -\u0026gt; tunnel2Stream stream2Tunnel -\u0026gt; WriteQueue WriteQueue -\u0026gt; packetWriter packetWriter -\u0026gt; tunnel keepalive -\u0026gt; WriteQueue tunnel2Stream -\u0026gt; host host -\u0026gt; stream2Tunnel {rank=min;host} } packetReader は tunnel からデータを読み取り ReadQueue に送る tunnel2Stream は ReadQueue からデータを読み取り host に送る stream2Tunnel は host からデータを読み取り WriteQueue に送る packetWriter は WriteQueue からデータを読み取り tunnel に送る keepalive は WriteQueue にダミーデータを送る tunnel 内に複数の TCP セッションを通す場合 tunnel には複数の TCP セッションを通すことができる。 次の要素は、tunnel 内の TCP セッション毎に増える。\ntunnel2Stream stream2Tunnel ReadQueue これらをまとめて CITI (connection in tunnel information ) とすると、 2 つの TCP セッションを通す場合は次のような構成になる。\ndigraph G { rankdir = RL; tunnel [shape=doublecircle]; subgraph clusterA { packetWriter [shape=rect; margin=0.2;]; packetReader [shape=rect; margin=0.2;]; keepalive [shape=rect; margin=0.2;]; WriteQueue CITI1 [shape=component; margin=0.2;]; CITI2 [shape=component; margin=0.2;]; {rank = max; packetReader; packetWriter} {rank = same; WriteQueue; } {rank = min; CITI1; CITI2; keepalive} } host1 [shape=box3d]; host2 [shape=box3d]; tunnel -\u0026gt; packetReader WriteQueue -\u0026gt; packetWriter packetWriter -\u0026gt; tunnel keepalive -\u0026gt; WriteQueue packetReader -\u0026gt; CITI1 CITI1 -\u0026gt; host1 CITI1 -\u0026gt; WriteQueue host1 -\u0026gt; CITI1 packetReader -\u0026gt; CITI2 CITI2 -\u0026gt; host2 CITI2 -\u0026gt; WriteQueue host2 -\u0026gt; CITI2 {rank=min;host1;host2} } Tunnel の再接続 tunnel が切断されても、 tunnel を再接続すれば tunnel 内に流れる tcp セッションは継続通信可能である。\nただし、tcp 通信のタイムアウト以内に再接続できることが条件である。\ntunnel を再接続すれば tcp セッションは継続通信可能だ。 しかし、そう単純にはいかないケースがある。 それは『送信したつもりになっているパケットが、相手に届いていないことがある』からだ。 この場合、相手に届いていないパケットを送信しなおす必要がある。\n「tcp は udp と違って再送制御などを行なって信頼性を確保しているんじゃないのか？」 と思う人もいるだろう。私も最初はそう思っていた。 しかし、実際はそうではない。 なぜなら、再送制御などはあくまでも TCP セッションが続いている場合に行なわれることで、 TCP セッションが切断された場合は再送制御なども当然破棄される。\nつまり、強制的にセッションが切断された場合は、 送ったつもりのデータが相手に届いていないことが普通にありえる。\nこのような「送ったつもりが相手に届いていないデータ」がある場合、 TCP セッションを継続させるにはそのデータを再送してやる必要がある。 この再送処理は、 packetWriter スレッドが実行する。\nフロー制御 前述の通り、再接続後は送信側と受信側とでデータの不整合を確認し、 受信されていないデータの再送信が必要になる。\nこれを実現するには、送信済みデータを保持しておく必要がある。 しかし、全ての送信済みのデータを保持しておく訳にもいかないので、 保持可能なパケット数を決めておく。 そして保持可能なパケット数と相手が受信していないパケット数のバランスが 崩れないようにフロー制御を行なう。\nもっとも単純なのは、送信するたびに相手の受信を持ってから次の送信を行なうことだが、 これだと通信効率が悪すぎる。 そこで、保持可能なパケット数の半分づつ確認を行なっている。\nparticipant stream2Tunnel_client participant packetReader_client participant packetWriter_client participant packetWriter_server participant packetReader_server participant tunnel2Stream_server stream2Tunnel_client -\u0026gt; stream2Tunnel_client : check the count send packets. stream2Tunnel_client -\u0026gt;\u0026gt; packetWriter_client : write the packet to client queue packetWriter_client -\u0026gt;\u0026gt; packetReader_server : write the packet packetReader_server -\u0026gt;\u0026gt; tunnel2Stream_server : read the packet to server queue tunnel2Stream_server -\u0026gt; tunnel2Stream_server : count received packets. tunnel2Stream_server -\u0026gt;\u0026gt; packetWriter_server : write the sync to server queue packetWriter_server -\u0026gt;\u0026gt; packetReader_client : write the sync stream2Tunnel は、パケットを queue に書き込む前に送信済みパケット数を確認する。\n保持可能なパケット数の半分であれば、 sync を待つ tunnel2Stream は、受信したパケット数をカウントし、 保持可能なパケット数の半分であれば sync を queue に入れる リングバッファ 前述の通り再送信のデータ保持のためにフロー制御を行なっている。 このデータ保持用のバッファは、 保持可能なパケット数分のバッファを通信開始時に用意しておき、 それをリングバッファにして使い回している。\ndigraph G { rankdir = TB; node0 [shape=rect; label = \u0026#34;buf\u0026#34;] node1 [shape=rect; label = \u0026#34;buf\u0026#34;] node2 [shape=rect; label = \u0026#34;buf\u0026#34;] node3 [shape=rect; label = \u0026#34;buf\u0026#34;] node4 [shape=rect; label = \u0026#34;buf\u0026#34;] node5 [shape=rect; label = \u0026#34;buf\u0026#34;] node0 -\u0026gt; node1 node1 -\u0026gt; node2 node2 -\u0026gt; node3 node3 -\u0026gt; node4 node4 -\u0026gt; node5 node5 -\u0026gt; node0 {rank=same; node1;node5} {rank=same; node2;node4} } 送信パケットの結合 tunnel は 2 つの Host の間のパケットを中継する。 一つのパケットは、MTU サイズに近いほど効率よく送信することができる。\nそこで、細かいパケットを 1 つのパケットに結合して送信する処理を行なう。\n次の図で示す通り tunnel に送信するパケットは stream2Tunnel から WriteQueue に入れられる。 そして packetWriter でパケットを取り出して tunnel に送信する。\nこの packetWriter でパケットを取り出す時に、 WriteQueue に複数のパケットが入っている場合、 そのパケットを結合して送信する。\npacketWriter は、パケットを結合するために積極的にパケットが溜るのを待つことはない。 よって、通信のリアルタイム性が損なわれることはない。\nprotocol ここでは tunnel client/server 間で通信を開始する時の protocol について説明する。\nprotocol は 3 つの情報をやり取りする。\nparticipant server participant client server -\u0026gt;\u0026gt; client : AuthCallenge server \u0026lt;\u0026lt;- client : AuthResponse server -\u0026gt;\u0026gt; client : AuthResult この protocol の後は、-port オプションで指定されたポートをリスニングし、 アクセス毎に TCP 接続セッションを開始する。\nAuthCallenge AuthCallenge は、次の情報を client に通知する。\nChallenge/Response 認証の Challenge 情報 バージョン サーバの動作モード client は、この情報から Challenge/Response の Response 情報を生成する。\nAuthResponse AuthResponse は、次の情報を server に通知する。\nChallenge/Response 認証の Response 情報 セッションID\n新規接続か、切断時の再接続かを示す。 新規の場合 0。再接続の場合、再接続先を示すセッションID。 client 側パケットの WriteNo/ReadNo\n再接続する時、再送信が必要かどうかを確認するためのパケット情報 制御コード\n特殊な処理を行なう場合に指定する。 例えば tunnel 間のラウンドトリップタイムを計測するモードを指定できる。 server は、この情報から client 認証を行なう。\nAuthResult AuthResult は、次の情報を client に通知する。\n認証結果 セッションID\nどのセッション ID を使用して通信を行なうかを示す。 Server 側パケットの WriteNo/ReadNo 以上で、 tunnel の client/server 間の接続が確立する。\n開発言語 この Tunnel ツールの開発には、次の技術が不可欠である。\nTCP Proxy Client HTTP Client/Server WebSocket Client/Server これら技術との相性の良さという意味では、 node.js が一番始めに候補に上りそうな気がする。 しかし、今は Go の勉強中ということもあり Go で開発を行なった。\n","id":62,"section":"posts","summary":"とある理由から 「Tunnel/Reverse Tunnel over websocket」 が必要になったので作ってみた。 「Tunnel/Reverse Tunnel over webs","tags":null,"title":"Tunnel/Reverse Tunnel over websocket を作った","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-05-29-tunnel/","year":"2020"},{"content":" 技術情報を GitHub Pages で公開するにあたって、 Hugo を使うことにした。\nHugo は Markdown で静的サイトを構築するツールだが、org-mode にも対応している。 「対応」といっても、当然完全なものではない。\n今回 Hugo を org-mode で使ってハマった点を紹介する。\n*「TITLE は文書の先頭に書く」\nhugo で使用する .org のファイルは、先頭に TITLE を書かなければならない。\n.org に記載されている #+TITLE 自体は認識しているようなのだが、 それが先頭に無い限りその記事のタイトルとしては認識されない。\n例えば、 emacs では次のように文書内に coding 等を指定することは良くあると思うが、 こうすると Hugo は TITLE を認識してくれない。\n# -*- coding:utf-8 -*- #+TITLE: Hugo を org-mode で使う時の注意点 これが判明するまでに、1 時間以上掛ったよ。。\n","id":63,"section":"posts","summary":"技術情報を GitHub Pages で公開するにあたって、 Hugo を使うことにした。 Hugo は Markdown で静的サイトを構築するツールだが、org-mode にも対応している。 「対応」と","tags":null,"title":"Hugo を org-mode で使う時の注意点","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-03-29-hugo-org/","year":"2020"},{"content":" raspberry pi に SSD を接続して簡易 NAS にしている。 この簡易 NAS では、 SSD を取り外ししやすいように autofs によるマウントを設定した。 しかし、SSD を接続すると PCManFM の自動マウントが動いて autofs が正常にマウントできない現象が発生した。\nそこで PCManFM の自動マウントを無効化した。\nPCManFM の自動マウントを無効化 ~/.config/pcmanfm/LXDE-pi/pcmanfm.conf の以下の設定を変更する。\nmount_on_startup=0 mount_removable=0 これで、PCManFM の自動マウントを無効化できる。\n","id":64,"section":"posts","summary":"raspberry pi に SSD を接続して簡易 NAS にしている。 この簡易 NAS では、 SSD を取り外ししやすいように autofs によるマウントを設定した。 しかし、SSD を接続すると PCManFM の自動","tags":null,"title":"raspberry pi の USB MASS STORAGE 自動マウントを無効化する","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-02-21-raspberrypi-mount/","year":"2020"},{"content":" emacs lisp の quote でハマったのでネタに書いておく。\n(defvar hoge-val nil) (defun hoge-init () (setq hoge-val \u0026#39;(:val nil)) ) (defun hoge-set () (plist-put hoge-val :val \u0026#34;1\u0026#34;)) 上記のように変数 hoge-val に対して plist-put で処理する関数を定義して、 次のようにコールすると。\n(let (val1 val2 val3) (hoge-init) (setq val1 (plist-get hoge-val :val)) (hoge-set) (setq val2 (plist-get hoge-val :val)) (hoge-init) (setq val3 (plist-get hoge-val :val)) (message (format \u0026#34;%s %s %s\u0026#34; val1 val2 val3))) 最後の (message (format \u0026#34;%s %s %s\u0026#34; val1 val2 val3)) で \u0026#34;nil 1 1\u0026#34; が出力される。\nてっきり、 \u0026#34;nil 1 nil\u0026#34; が出力されるものだと思っていた。 なぜなら、val3 をセットする直前に hoge-init を実行しており、 この hoge-init は hoge-val を \u0026#39;(:val nil) で初期化する関数なので、 (plist-get hoge-val :val) は nil を返すと考えたからだ。\nしかし実際には、最後の (plist-get hoge-val :val) は \u0026#34;1\u0026#34; になる。\nなぜこのような結果になるかと言うと、 \u0026#39;() は定数として扱い、 関数 hoge-init を実行する際には新しくリストを生成せず、 defun を評価した時の値そのものが使い続けられる。\nそして (plist-put) でリストの中身を操作した場合、その定数自体が書き変わり、 hoge-init 関数は変数に書き変わった定数を代入しているため初期化できない。\n一方で、 hoge-init の処理に list 関数を使うと、\u0026#34;nil 1 nil\u0026#34; となる。\n(defun hoge-init () (setq hoge-val (list :val nil)) ) (list) は評価されるたび新規にリストを生成しているため、変数を初期化出来る。\nよく考えてみると納得できるけど、 実際の動きと見た目のギャップにどうにもこうにも意味不明だった。\nこれまで一度も意識せずにきたのが不思議なくらい、かなり基本的な内容だと思う。\nquote した値の変更は、要注意ってことで。\n","id":65,"section":"posts","summary":"emacs lisp の quote でハマったのでネタに書いておく。 (defvar hoge-val nil) (defun hoge-init () (setq hoge-val \u0026#39;(:val nil)) ) (defun hoge-set () (plist-put hoge-val :val \u0026#34;1\u0026#34;)) 上記のように変数 hoge-val に対して plist-put で処理する関数を定義して、 次のように","tags":null,"title":"emacs lisp の quote","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-02-18-emacs-quoted-list/","year":"2020"},{"content":" emacs の org-mode では、 .org ファイル内に C や python 等ソースコードを書いて、 export 時にそのソースコードを色付けした状態で載せることができる。\nこの機能を babel と言う。\nbabel では、ソースコードの色付けだけでなく、 dot や plantuml 等のグラフ生成言語を利用することで、 .org ファイル内に書いたグラフ生成言語からグラフを生成して、 所定位置にグラフを挿入することもできる。\n今回、 org-mode 9.3.5 の babel を使って dot の画像を出力しようとしたところ、 エラーしたので原因を追ってみた。\nエラー箇所 エラーは次の関数で発生していた。\n(defun org-babel-chomp (string \u0026amp;optional regexp) \u0026#34;Strip a trailing space or carriage return from STRING. The default regexp used is \\\u0026#34;[ \\\\f\\\\t\\\\n\\\\r\\\\v]\\\u0026#34; but another one can be specified as the REGEXP argument.\u0026#34; (let ((regexp (or regexp \u0026#34;[ \\f\\t\\n\\r\\v]\u0026#34;))) (while (and (\u0026gt; (length string) 0) (string-match regexp (substring string -1))) (setq string (substring string 0 -1))) string)) エラーの内容は次のものだった。\nDebugger entered--Lisp error: (wrong-type-argument stringp nil) string-match(nil \u0026#34;c\u0026#34;) (and (\u0026gt; (length string) 0) (string-match regexp (substring string -1))) (while (and (\u0026gt; (length string) 0) (string-match regexp (substring string -1))) (setq string (substring string 0 -1))) (let ((regexp (or regexp \u0026#34;[ \\f\\011\\n\\015\\013]\u0026#34;))) (while (and (\u0026gt; (length string) 0) (string-match regexp (substring string -1))) (setq string (substring string 0 -1))) string) このエラーは、 上記の org-babel-chomp 関数の regexp 引数が nil だった場合に発生する。\nエラーの修正 このエラーに対し、 次のように let で宣言する変数を別名(regexp-work)で定義することで回避した。\n(defun org-babel-chomp (string \u0026amp;optional regexp) \u0026#34;Strip a trailing space or carriage return from STRING. The default regexp used is \\\u0026#34;[ \\\\f\\\\t\\\\n\\\\r\\\\v]\\\u0026#34; but another one can be specified as the REGEXP argument.\u0026#34; (let ((regexp-work (or regexp \u0026#34;[ \\f\\t\\n\\r\\v]\u0026#34;))) (while (and (\u0026gt; (length string) 0) (string-match regexp-work (substring string -1))) (setq string (substring string 0 -1))) string)) エラーの原因 エラーの原因を確認するため、 エラーを再現する処理を抜き出して書き換えると次になる。\n;;; -*- lexical-binding: t; -*- (defun hoge (regexp) (let ((regexp (or regexp \u0026#34;a\u0026#34;))) (string-match regexp \u0026#34;b\u0026#34;))) 上記の hoge 関数の引数 regexp に nil をセットしてコールすると同じエラーになる。 なお、この現象は lexical-binding を有効にしている時だけ発生する。\n上記関数の処理を説明すると次のようになる。\nlet で新しく変数 regexp を宣言する\nこのとき、引数 regexp が nil 以外なら、引数 regexp の値を変数 regexp にセットする 引数 regexp が nil なら、 \u0026#34;a\u0026#34; を変数 regexp にセットする。 つまり、let で宣言している変数 regexp には必ず nil 以外がセットされるはずである。\nしかし、実際には string-match に渡される regexp には nil がセットされている。\n何故このような結果になるか原因を想像すると、\n「string-match でアクセスするシンボル regexp は、 let で宣言している regexp ではなく、関数の引数 regexp が参照されるため」\nと考えるのが妥当だろう。\nstring-match は let のスコープなので、 普通に考えれば string-match の regexp は let で宣言している変数 regexp であるはず。 しかし、実際には何故か関数の引数 regexp になっている。\nこれが emacs lisp の仕様なのか、はたまた仕様外の動作なのかは良く分からない。\nちなみに、これが発生している環境は emacs 26.2 だが、 他の環境で発生するかどうかは確認していない。\norg-mode の履歴を追ってみたが、 この関数の処理は lexical-binding を使うようになる前から変っていないので、 lexical-binding にした事による影響だろう。\n以上。\n","id":66,"section":"posts","summary":"emacs の org-mode では、 .org ファイル内に C や python 等ソースコードを書いて、 export 時にそのソースコードを色付けした状態で載せることができる。 この機能を babel と言う。 babel で","tags":null,"title":"org-mode 9.3.5 で babel(dot/plantuml) が動かなかった","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-02-13-emacs-org-9.3.5/","year":"2020"},{"content":" この記事は、emacs 用 reviewboard モードの宣伝である。\n\u0026lt;https://github.com/ifritJP/emacs-reviewboard-front\u0026gt;\nreviewboard は、ソースコードレビューを Web 上で行ない記録するためのツール。\n今は github の Pull-Request に代表されるように Web 上のソースレビューが普及しているが、 reviewboard の初版が 2007 年であることを考えると、 当時は先進的なツールだったと思う。\nそんな reviewboard を emacs で操作するモードを今になって作ったので、 どれ程の人が使うかは不明だが、折角なので宣伝しておく。\n機能 このモードでは、次の機能を提供する。\n修正ファイル一覧から必要なファイルを選択して review request (以降 rrq と記す)を登録\nrrq の summary/description/testing_done を編集 修正ファイルの追加、削除可能 レビューを受けて更新したファイル郡を、一発でアップロード レビューコメントのリプライ登録 rrq の publish/close/discard rrq に登録したファイルをコミット 設定 環境 curl, rbt, svn を事前にインストールしておく\nrbt は、 diff の登録に利用する。 curl は、 reviewboard の WebAPI へのアクセスに利用する。 環境によっては、 proxy 等の環境変数設定が必要な場合がある。 上記 github から emacs-reviewboard-front を取得し適当な場所に展開する emacs-lisp emacs-reviewboard-front のパスに load-path に追加する。 次の設定を行なう。 (require \u0026#39;rbfront-mode) (setq rb/front-rb-api-token \u0026#34;TOKEN\u0026#34;) (setq rb/front-rb-url \u0026#34;http://reviewboard.host/path\u0026#34;) (setq rb/front-rbt \u0026#34;rbt\u0026#34;) (setq rb/front-proxy \u0026#34;http://proxy.host:8080/\u0026#34;) (setq rb/front-rb-repository \u0026#34;RESPOSITORY_NAME\u0026#34;) rb/front-rb-api-token は、 reviewboard のアカウント管理ページで生成した API Tokens を指定する。 rb/front-rb-url は、 reviewboard のサーバの URL を指定する。 rb/front-proxy は、 reviewboard のサーバにアクセスする際に使用する proxy を指定する。 front-rb-repository は、 reviewboard に diff を登録する際の repository 名を指定する。 新規登録 emacs-reviewboard-front では、現状 svnp.el を使用することを前提としている。\nここでは、svnp.el の細かい使用方法については説明しない。 rrq の新規登録に必要な最低限の操作について説明する。\nM-x svn-status で修正ファイル一覧を表示し、 commit する要領でファイルを選択する。 j キー押下で、rrq 編集バッファが表示される。 編集バッファ title と description、 test を編集する。 編集後、 C-c C-c 押下により submit 処理で reviewboard に登録する。\n新規登録の場合、 mini-buffer で reviewer を選択する。\nこの mini-buffer では TAB キーによる補完が可能。 修正ファイルの追加・削除 rrq に登録する修正ファイルを追加したい場合、 C-c C-a を押下する。\nmini-buffer で、ファイルが存在するディレクトリを指定し、 その後表示されるファイル一覧から上記のようにファイルを選択する。 選択後、 j キー押下で、ファイルが追加される。 rrq に登録する修正ファイルを除外する場合、 除外するファイルにカーソルを移動して C-c C-SPC を押下する。\n除外を reviewboard に反映するには、 C-c C-u を押下する。 review コメント review コメントの表示はサーバアクセスが多くなるため、 デフォルトでは非表示にしている。 表示する場合、 C-c C-d する。 デフォルトで表示にする場合、 rb/front-display-comment-p に nil 以外を設定する。 review コメントに対するリプライを登録する場合、 コメントにカーソルを合わせて C-c C-r。 submit モード submit 時の動作を、次のどちらかに変更できる。\nsubmit と同時に publish する submit だけする C-c C-t でモードを切り替える。\nデフォルトは publish する。\nデフォルトを submit だけに切り替える場合、 rb/front-submit-and-publish-p に nil を設定する。\nrrq リスト表示 M-x rb/front-list で、 自分が登録した rrq 一覧を表示する。\nリスト操作 (g) リストを更新する (RET) カーソル位置の rrq を編集する (u) カーソル位置の rrq の diff を、再アップロードする (p) カーソル位置の rrq を publish する。 (c) カーソル位置の rrq を close する。 (d) カーソル位置の rrq を discard する。 (C) カーソル位置の rrq に登録したファイルを commit する。 diff の再アップロード 再アップロードを行なうため、ローカルの work ディレクトリを指定する必要がある。 work ディレクトリの指定は mini-buffer で行なう。\n注意 rrq 編集バッファで C-c C-c を実行すると、 バッファ内容がサーバに登録され、即時 publish する。 rrq 編集バッファの C-c C-a による修正ファイル追加は、 新規 rrq の場合を除き即時 publish する。 新規 rrq の場合、submit 時に rrq 情報と一緒に更新ファイル情報が登録される。 ","id":67,"section":"posts","summary":"この記事は、emacs 用 reviewboard モードの宣伝である。 \u0026lt;https://github.com/ifritJP/emacs-reviewboard-front\u0026gt; reviewboard は、ソースコードレビューを Web 上で行ない記録するためのツール。 今は github の Pull-Request に代表されるように Web","tags":null,"title":"emacs 用 reviewboard モードの宣伝","uri":"https://ifritjp.github.io/blog2/public/posts/2020/2020-02-03-emacs-reviewboard/","year":"2020"},{"content":" プログラムを組む際、ラッパー関数を作ることは良くある。\nこのラッパー関数のオーバーヘッドが気になったので簡単に調べてみた。\n計測用サンプルは次の通り。\n#include\u0026lt;stdio.h\u0026gt; typedef void (func_t)( int val1, int val2 ); void func( int val1, int val2 ) { printf( \u0026#34;%d %d\u0026#34;, val1, val2 ); } void wrapper0( int val1, int val2 ) { func( val1, val2 ); } void wrapper1( func_t * pFunc, int val1, int val2 ) { pFunc( val1, val2 ); } void wrapper2( int val1, int val2, func_t * pFunc ) { pFunc( val1, val2 ); } main() { wrapper0( 0, 1 ); wrapper1( func, 0, 1 ); wrapper2( 0, 1, func ); } 関数 func() をコールする 3 種類のラッパー関数 wrapper0, wrapper1, wrapper2 を用意した。\nそれぞれのラッパー関数は次の形になっている。\nラッパー 引数 wrapper0 呼び出し先と同じ引数 wrapper1 ラッパー独自引数の後に呼び出し先と同じ引数 wrapper2 呼び出し先と同じ引数の後にラッパー独自引数 これを gcc の x64 で -O の最適化した結果が次になる。 (func の処理は省略)\n0000000000000021 \u0026lt;wrapper0\u0026gt;: 21:\t48 83 ec 08 sub $0x8,%rsp 25:\te8 00 00 00 00 callq 2a \u0026lt;wrapper0+0x9\u0026gt; 2a:\t48 83 c4 08 add $0x8,%rsp 2e:\tc3 retq 000000000000002f \u0026lt;wrapper1\u0026gt;: 2f:\t48 83 ec 08 sub $0x8,%rsp 33:\t48 89 f8 mov %rdi,%rax 36:\t89 f7 mov %esi,%edi 38:\t89 d6 mov %edx,%esi 3a:\tff d0 callq *%rax 3c:\t48 83 c4 08 add $0x8,%rsp 40:\tc3 retq 0000000000000041 \u0026lt;wrapper2\u0026gt;: 41:\t48 83 ec 08 sub $0x8,%rsp 45:\tff d2 callq *%rdx 47:\t48 83 c4 08 add $0x8,%rsp 4b:\tc3 retq 000000000000004c \u0026lt;main\u0026gt;: 4c:\t48 83 ec 08 sub $0x8,%rsp 50:\tbe 01 00 00 00 mov $0x1,%esi 55:\tbf 00 00 00 00 mov $0x0,%edi 5a:\te8 00 00 00 00 callq 5f \u0026lt;main+0x13\u0026gt; 5f:\tba 01 00 00 00 mov $0x1,%edx 64:\tbe 00 00 00 00 mov $0x0,%esi 69:\tbf 00 00 00 00 mov $0x0,%edi 6e:\te8 00 00 00 00 callq 73 \u0026lt;main+0x27\u0026gt; 73:\tba 00 00 00 00 mov $0x0,%edx 78:\tbe 01 00 00 00 mov $0x1,%esi 7d:\tbf 00 00 00 00 mov $0x0,%edi 82:\te8 00 00 00 00 callq 87 \u0026lt;main+0x3b\u0026gt; 87:\tb8 00 00 00 00 mov $0x0,%eax 8c:\t48 83 c4 08 add $0x8,%rsp 90:\tc3 retq 上記通り wrapper0 と wrapper2 は、ほぼ同じコードになっており、 wrapper1 は引数をずらす処理が余分に入っている。\n想像通りの結果といえば想像通りだが、 ちゃんと最適化された処理になっている。\n以上のことから言えることは、 ラッパー関数独自の引数は、先頭ではなく末尾にもっていった方が良いということだ。\nただし、ここまで最適化が効くケースは、 ラッパー関数内での目的の関数コールが先頭にある場合に限られるので、 目的の関数コールを先頭に持ってこれない場合は、気にしないで良いだろう。\nなお、 -O2 で最適化をかけると wrapper1, wrapper2 は次の処理に最適化された。 0000000000000030 \u0026lt;wrapper1\u0026gt;: 30:\t48 89 f8 mov %rdi,%rax 33:\t89 f7 mov %esi,%edi 35:\t89 d6 mov %edx,%esi 37:\tff e0 jmpq *%rax 39:\t0f 1f 80 00 00 00 00 nopl 0x0(%rax) 0000000000000040 \u0026lt;wrapper2\u0026gt;: 40:\tff e2 jmpq *%rdx 個人的には、こっちの方が納得がいく。\nまた、次のようにラッパー関数に static 宣言を付加して、 外部からコールされないことを明示すると、\n#include\u0026lt;stdio.h\u0026gt; typedef void (func_t)( int val1, int val2 ); void func( int val1, int val2 ) { printf( \u0026#34;%d %d\u0026#34;, val1, val2 ); } static void wrapper0( int val1, int val2 ) { func( val1, val2 ); } static void wrapper1( func_t * pFunc, int val1, int val2 ) { pFunc( val1, val2 ); } static void wrapper2( int val1, int val2, func_t * pFunc ) { pFunc( val1, val2 ); } main() { wrapper0( 0, 1 ); wrapper1( func, 0, 1 ); wrapper2( 0, 1, func ); } 出力結果は次のように、 ラッパーがインライン展開され、 ラッパーの引数の違いによる差分は無くなった。\n0000000000000021 \u0026lt;main\u0026gt;: 21:\t48 83 ec 08 sub $0x8,%rsp 25:\tbe 01 00 00 00 mov $0x1,%esi 2a:\tbf 00 00 00 00 mov $0x0,%edi 2f:\te8 00 00 00 00 callq 34 \u0026lt;main+0x13\u0026gt; 34:\tbe 01 00 00 00 mov $0x1,%esi 39:\tbf 00 00 00 00 mov $0x0,%edi 3e:\te8 00 00 00 00 callq 43 \u0026lt;main+0x22\u0026gt; 43:\tbe 01 00 00 00 mov $0x1,%esi 48:\tbf 00 00 00 00 mov $0x0,%edi 4d:\te8 00 00 00 00 callq 52 \u0026lt;main+0x31\u0026gt; 52:\tb8 00 00 00 00 mov $0x0,%eax 57:\t48 83 c4 08 add $0x8,%rsp 5b:\tc3 retq 基本的に、ソースコードはメンテナンス性や可読性を優先すべきだが、 ソースコードを自動生成するような場合は、 このような細かいことも意識しておいた方が良いだろう。\n以上。\n","id":68,"section":"posts","summary":"プログラムを組む際、ラッパー関数を作ることは良くある。 このラッパー関数のオーバーヘッドが気になったので簡単に調べてみた。 計測用サンプルは次の","tags":null,"title":"C 言語のラッパー関数オーバーヘッド","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-10-15-wrapper-overhead/","year":"2019"},{"content":" 以前 C 言語の関数ポインタによる関数コールのオーバーヘッドがどの程度なのか調べたが、 今回は可変長引数(va_list)処理のオーバーヘッドについて調べてみた。\n結果 初めに結果から書くと、\n可変長引数(va_list)処理のオーバーヘッドは、めちゃめちゃ掛る。 また、引数の数に応じて時間が増加する。 所感 今回の実験によって、 va_list 処理には当初の想定を遥かに越えたオーバーヘッドが かかることが分った。\n個人的には、コンパイラがもっと賢くやってくれているものだと思っていたが、 実際には全く賢くなかった。\nC 言語で可変長引数を積極的に使用することはあまりないとは思うが、 可変長引数の使用はオーバーヘッドを十分考慮に入れて慎重に検討するべきだということが判った。\nこの可変長引数のオーバーヘッドを調べたのは、 LuneScript のメソッド呼び出し処理を C 言語にトランスコンパイルした際に 可変長引数を利用しようと思ったからなのだが、 この結果から可変長引数は使えないことが分った。\n対応する前に結果が分って良かったが、 可変長引数が使えなくなったのは当初の目論見が崩れてしまった。\n実験詳細 ここでは、今回の実験方法について説明する。\nコード 実験用に次の C 言語コードを作成した。\nint func( int val1, int val2 ) { return val1 + val2; } int sub( int dummy, int val1, int val2 ) { return func( val1, val2 ); } int funcv2( va_list ap ) { int val1 = va_arg( ap, int ); int val2 = va_arg( ap, int ); return val1 + val2; } int subv2( int dummy, ... ) { int val; va_list ap; va_start( ap, dummy ); val = funcv2( ap ); va_end( ap ); return val; } func, sub は、可変長引数を使用しないパターン。 funcv2, subv2 は、可変長引数を使用しするパターン。\nちなみにコードの全体は次の通りである。\n#include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; int func( int val1, int val2 ) { return val1 + val2; } int sub( int dummy, int val1, int val2 ) { return func( val1, val2 ); } int funcv2( va_list ap ) { int val1 = va_arg( ap, int ); int val2 = va_arg( ap, int ); return val1 + val2; } int subv2( int dummy, ... ) { int val; va_list ap; va_start( ap, dummy ); val = funcv2( ap ); va_end( ap ); return val; } int funcv3( va_list ap ) { int val1 = va_arg( ap, int ); int val2 = va_arg( ap, int ); int val3 = va_arg( ap, int ); return val1 + val2 + val3; } int subv3( int dummy, ... ) { int val; va_list ap; va_start( ap, dummy ); val = funcv3( ap ); va_end( ap ); return val; } double getTime( void ) { struct timeval tm; gettimeofday( \u0026amp;tm, NULL ); return tm.tv_sec + tm.tv_usec / 1000000.0; } main( int argc, const char * argv[] ) { long long loop = strtoll( argv[ 1 ], NULL, 10 ) * 1000ll; long long count = 0; int sum = 0; double prev = getTime(); if ( strcmp( argv[ 2 ], \u0026#34;1\u0026#34; ) == 0 ) { for ( count = 0; count \u0026lt; loop; count++ ) { sum += sub( 0, 1, 2 ); } } else if ( strcmp( argv[ 2 ], \u0026#34;2\u0026#34; ) == 0 ) { for ( count = 0; count \u0026lt; loop; count++ ) { sum += subv2( 0, 1, 2 ); } } else { for ( count = 0; count \u0026lt; loop; count++ ) { sum += subv3( 0, 1, 2, 3 ); } } printf( \u0026#34;%s: %lld time = %g, %d\\n\u0026#34;, argv[ 2 ], loop, getTime() - prev, sum ); } このプログラムは、コマンドラインの引数によって sub, subv2, subv3 を指定の回数分実行し、実行時間を表示する。\n計測結果 時間(秒) 固定長引数(sub: 2 引数) 0.62 可変長引数(subv2: 2 引数) 11.95 可変長引数(subv3: 3 引数) 16.16 上記結果を見ると分かる通り、可変長引数は処理時間の桁が違う。\nまた、引数の数に応じて時間が増加する。\n以上\n","id":69,"section":"posts","summary":"以前 C 言語の関数ポインタによる関数コールのオーバーヘッドがどの程度なのか調べたが、 今回は可変長引数(va_list)処理のオーバーヘッドにつ","tags":null,"title":"C 言語の可変長引数 (va_list) 処理のオーバーヘッド","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-08-06-va-performance/","year":"2019"},{"content":" 「日本の全てのソフトウェアプロジェクトは必ず技術的負債になる」というタイトルですが、 次の条件を満す場合に限ります。\n「プロジェクトに関わるソフトウェアエンジニアの大半が技術に無関心」\n動機 このネタは、次の記事を読んで個人的に思うことがあったのをきっかけに 書いています。\nオブジェクト指向プログラミング – 1兆ドル規模の大失敗\n\u0026lt;https://okuranagaimo.blogspot.com/2019/07/1.html\u0026gt; 大企業の技術系インターンシップに参加した\n\u0026lt;https://blog.browniealice.net/post/internship2019winter/\u0026gt; ソフト開発で世界と闘った及川卓也氏が見た、日本の弱点と可能性\n\u0026lt;https://headlines.yahoo.co.jp/article?a=20190801-00010000-chuokou-bus_all\u0026gt; 上記の記事は各自に読んでもらうとして、 それぞれの記事の内容をものすごく大雑把にまとめると\n「OOP はダメだから、関数型プログラミングを使え」 「日本を代表する大企業に実情に失望した」 「日本の企業はソフトウェア開発を理解していない」 になると思います。\nプログラミング言語は道具にすぎない 上記ブログで「OOP はダメだから、関数型プログラミングを使え」と書かれています。 私は、OOP が万能だなんて思ってませんし、 上記ブログで指摘されている側面があることも理解しています。\nですが、オブジェクト指向プログラミングにしろ関数型プログラミングにしろ、 万能ではないという意味ではどちらも同じです。\nプログラム言語は道具です。 いかなる道具であっても、 その道具を安全に運用できるかどうかは、最終的には使う人に依存することになります。\n例えば、古典的なプログラミング言語の代表格に C 言語がありますが、 ご存知の通り C 言語には GC もないですし、 NULL 安全でもありません。 そのような高度な「安全」機能を持たない C 言語は、Linux Kernel の開発言語です。 C 言語によって Linux Kernel を開発しているという事実は、 高度な「安全」機能が搭載されていないプログラミング言語であっても、 使用する人次第で大規模プロジェクトでも問題なく運用できるという一つの実証と言えます。\n逆に、C 言語よりも高度な「安全」機能を搭載しているプログラミング言語を使用した プロジェクトが技術的負債の塊になり運用困難になった、 という例はいくらでも身近にあると思います。 もし身近に無いとしても、ネットで検索すれば多数ヒットします。\nだからと言って、 C 言語の様に使用する人への依存が高過ぎる言語と、 Rust のように先進的な安全機能搭載言語のどちらを使っても大差はない、 というつもりはありません。 私が言いたいのは、「より安全」と言われる技術を使っても、 それを使用する人への依存性が無くなることはない、ということです。\n自動運転に例えると、 プログラム言語自体が提供する「安全」は高々レベル 3 のサポートにすぎません。\nレベル 3 の自動運転には、ドライバーの運転技術が必須であるように、 現存するどのようなプログラム言語であっても、 ソフトウェアエンジニアの能力が欠かせません。\n「ソフトウェアエンジニアの大半が技術に無関心」であることの問題 なぜ「プロジェクトに関わるソフトウェアエンジニアの大半が技術に無関心」だとダメなのか？\nこれは単純に、そのようなプロジェクトではどのように「安全」な環境であっても、 その「安全」がレベル 5 の自動運転のように「完全」でない限り、 「不具合をエンジニア自ら作り込んでしまう」からです。\n前述している通り、プログラミング言語はあくまでも道具であって、 その道具を安全に運用できるかどうかは、最終的には使う人に依存することになります。 そしてプログラミング言語を使う人はソフトウェアエンジニアであり、 ソフトウェアエンジニアの能力は、多くの場合、技術への関心度に比例します。\n特に統計を取った訳ではなく、裏付け資料がある訳でもないですが、 個人的な経験上、技術への関心度が高いソフトウェアエンジニアほど能力が高く、 技術への関心度が低いソフトウェアエンジニアほど能力が低い傾向にあります。\nつまり、 「プロジェクトに関わるソフトウェアエンジニアの大半が技術に無関心」であるということは、 ソフトウェアエンジニアの大半の能力が低いということと、ほぼ同義になります。\n「技術への関心度が低いソフトウェアエンジニアほど能力が低い傾向にある」という持論の 根拠となるエピソードを一つ挙げておきます。\nあるソフトウェアエンジニアＡがモジュールの設計をしていました。\nそのモジュールは、他モジュールとの依存が高いことが問題になっていたので、 「DI(Dependency injection)の手法を取り入れたら もっとスッキリした設計になる可能性があるので検討してみてはどうですか？」 と、そのソフトウェアエンジニアＡに話をすると、 「そういう難しいことは逆に不具合につながるのでやりたくない」と 言われて一蹴されました。 DI を検討した結果、従来通りの方法を採用する方が良いという結論になったのであれば 納得できますが、なんとなく難しそうというイメージだけで拒否していました。 そして、そのモジュールは依存が高いまま実装されました。\nDI のことを理解していれば、それが難しいと考える人はほとんどいないでしょうし、 テストがしやすいことから、むしろ不具合も低減できる可能性があり、 DI を取り入れることで不具合に繋がることを心配する人はいないでしょう。\nこのように、技術への関心度が低いと、 自分が知らない技術を積極的に取り入れるようなことをせず、 自分が使える技術だけで解決しようとします。 これによって、よりスマートに実現できる方法が他にあるにもかかわらず、 潜在的な問題を含む古い方法によってモジュールが作られていき、 それが積み重なってプロジェクト全体の品質が下っていきます。 そしてそれは時間が経過するほど、手をつけられない技術的負債になります。\n一言で表現すれば、技術への関心度が低いエンジニアは「技術的負債製造機」です。\n例え TEST FIRST の開発プロセスであっても、それは防げないでしょう。 ならぜなら、 テストというのは作成した成果物が仕様通りに出来ていることを確認するものであって、 仕様そのものに不具合があった場合は、その不具合を検知することは出来ないからです。 仕様を作るのはソフトウェアエンジニアです。 能力の低いソフトウェアエンジニアほど、穴の多い仕様を作る傾向にあります。\n能力の低いソフトウェアエンジニアには仕様を作らせず、 能力の高いソフトウェアエンジニアだけで仕様を作れば良い、という考えもあると思います。\n確かに、能力の高い人の比率が高い場合はそういう運用が可能かもしれません。 しかし、ここでは大半が能力が低いことを前提にしているので、 そのような運用は難しいです。\nまた、例え仕様に問題がなくても、 実際にコード化した時に不具合が埋め込まれることは良くあります。 そして、テストで検出されることもなくリリースされ、市場で時限爆弾のように爆発する、 お決まりのパターンです。もはや伝統芸能の域です。\nなぜ日本で問題なのか？ ここまでの話を納得していただけたとして、次の疑問が浮ぶかもしれません。\n「プロジェクトに関わるソフトウェアエンジニアの大半が技術に無関心」が 技術的負債を生み出す原因ならば、日本でなくても同じことが言えるのではないか？\nそれは確かにそうです。 しかし、日本の場合、終身雇用 \u0026amp; 転職しずらい社会環境によって、 一度雇ったソフトウェアエンジニアが技術に無関心だったとしても、 そのソフトウェアエンジニアを他の優秀なソフトウェアエンジニアに入れ替える、 ということが非常に困難なため、このような状況になり易いです。\nさらに、日本ではソフトウェア開発をゼネコン方式で開発するという文化があり、 一つのプロジェクトを社内の優秀なソフトウェアエンジニアだけで開発する、 というのは非常に稀なケースであり、 一部(あるいは全部)のモジュールをアウトソーシングするケースが多くあります。\nこれによって、プロジェクトの品質コントロールをより困難にしています。\nまた、日本では全ての社員の待遇に差を付けず、 等しくすることを善しとする文化があるようで、 ソフトウェアエンジニアの能力に応じた待遇にする、というようなことを滅多にしません。 一方で、マネジメント能力に関しては、 能力に応じた待遇にするキャリアパスが古くから存在するため、 自分ではコードを一切書かないで一日中パワーポイントやエクセルの資料をせっせと作成している ソフトウェアエンジニア(？)が多く存在します。 そして、マネジメント能力以外のソフトウェアエンジニアの能力が評価対象ではないため、 自然と「プロジェクトに関わるソフトウェアエンジニアの大半が技術に無関心」と いう状況になる傾向にあります。 いわゆる Japanese Traditional Big Company では、 特にこの傾向が顕著なのではないでしょうか？\n最初に紹介したブログの著者が「日本を代表する大企業に実情に失望した」原因は、 このような背景があるためだと思います。\nまた、このような背景を作り出しているのは、 Yahoo の記事にある「日本の企業はソフトウェア開発を理解していない」ためだと思います。\n以上のように、日本のソフトウェア開発プロジェクトには 技術的負債を生み出す環境が整っているため、 いかなる開発手法、プログラム言語を用いても技術的負債化を防ぐことは出来ません。\nそれなのに、この状況を改善する為と称して、新しいプロジェクト進捗管理手法を導入する、 という斜め上な施策が実施されることがあります。\nどういう論理で考えると、「新しいプロジェクト進捗管理手法を導入すること」と、 「プロジェクトの技術的負債化を防ぐこと」が繋がるのでしょうかね？\n最後に 私は LuneScript という言語を開発しています。 「プログラム言語は単なる道具でしかない」というのは、 ある意味自己否定しているようにも思われるかもしれません。\nですが、プログラム言語自体で提供できる安全機能は まだまだ残っていると思っているので、 ソフトウェアエンジニアの助けになるような安全機能を提供できるように 今後も開発を続けていきたいと考えています。\n以上。\n","id":70,"section":"posts","summary":"「日本の全てのソフトウェアプロジェクトは必ず技術的負債になる」というタイトルですが、 次の条件を満す場合に限ります。 「プロジェクトに関わるソフ","tags":null,"title":"如何なる開発手法、プログラム言語を用いても、日本の全てのソフトウェアプロジェクトは必ず技術的負債になる","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-08-02-engineering/","year":"2019"},{"content":" emacs のバージョンを 26.2 に変えたことで、 色々と細かいところの使い勝手が変っている。\nその中で、 → 等の一部のフォントが半角表示されるようになったのが 微妙にストレスだったのでちょっと追ってみた。\n原因 原因、と言うよりは起因と言った方が良いかもしれないが、 → 等の一部のフォントが半角表示されるようになったのは、 フォントに \u0026#34;DejaVu Sans Mono\u0026#34; を使用していることに起因していた。\nこれを \u0026#34;Bitstream Vera Sans Mono\u0026#34; に変更することで、現象が治った。\n全く同じ環境で、 emacs 26.2 ではなく、以前使用していたバージョンの emacs だと 現象は発生しなかった。\nemacs の処理が変ったことが原因であるのはほぼ間違い無いが、 emacs の何がどう変ってこの現象が発生し、 どう設定(使用するフォントを変える以外で)すれば、 現象を修正できたのかは残念ながら分からないまま。\nと、思ったが、次のブログに答えがあった。\n\u0026lt;http://misohena.jp/blog/2017-09-26-symbol-font-settings-for-emacs25.html\u0026gt;\n詳しくは、上記ブログを確認してもらうとして、 要点だけ説明すると use-default-font-for-symbols に nil 以外が設定されていると、 シンボル等の文字のフォントが default フォントを使用するようになるらしい。 このデフォルト値が t であるため、矢印等の一部のフォントが半角になっていた。\nということで、 以下を設定してやれば、使用するフォントを変えなくても全角で表示されるようになる。\n(setq use-default-font-for-symbols nil) じゃぁ、どうして \u0026#34;Bitstream Vera Sans Mono\u0026#34; に変えると 全角で表示されたのか？が気になったんで調べてみたが、 どうやら \u0026#34;Bitstream Vera Sans Mono\u0026#34; には矢印などのフォントが 含まれていなことが原因のようだ。\nfontforge でフォントの中身を見ると、 \u0026#34;Bitstream Vera Sans Mono\u0026#34; には矢印のフォントがなく、 \u0026#34;DejaVu Sans Mono\u0026#34; には矢印のフォントがあることが判った。\nつまり、\u0026#34;DejaVu Sans Mono\u0026#34; には矢印のフォントがあるので、それが表示され、 \u0026#34;Bitstream Vera Sans Mono\u0026#34; には矢印のフォントがないので、 別で設定していた全角のフォントが表示された、ということだろう。\nあぁ、これでストレスが一つ減った。\n","id":71,"section":"posts","summary":"emacs のバージョンを 26.2 に変えたことで、 色々と細かいところの使い勝手が変っている。 その中で、 → 等の一部のフォントが半角表示されるようになったのが 微","tags":null,"title":"emacs26.2 で矢印(→)等の一部のフォントが半角表示されるようになった","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-07-19-font/","year":"2019"},{"content":" これは seekable な stream と none_seekable な stream の使い分けに関する記事です。\n使い分けが十分出来ている人は読まなくても大丈夫です。\n皆さんは bitstream という単語をご存知でしょうか？\nAV (Audio\u0026amp;Visual) が好きな人や、 それらの業界に関係のある人ならそこそこ聞く単語だと思いますが、 一般的にはあまり馴染の無い単語でしょうか。\n馴染の無い人の為に身近な HDD レコーダを例に挙げて説明すると、 HDD レコーダはデジタル放送の電波に乗っているデータをそのまま記録していますが、 このデータが bitstream です。 HDD レコーダは、デジタル放送の bitstream を HDD に記録し、 記録した bitstream を再生する装置と言えます。 もちろん、実際にはそんな単純ではないですが、概ね間違ったことは言ってません。\nstream プログラムでデータを扱う時、stream という概念を使って制御します。\n言語 stream (入力) Java InputStream Swift InputStream Go io.Reader 上記は言語毎の入力系 stream の例です。\nちなみに入力系の stream とは何かというと、 流れてくるデータを読み出すためのものです。\n例えば、先ほどの HDD レコーダの例で説明すると、\nデジタル放送の電波に乗っている bitstream を読み取る部分 HDD に記録されている bitstream を読み込む部分 が入力系の stream です。\nまた、上記言語の stream (InputStream,io.Reader)には共通することがあります。\nそれは、データの流れが一方通行で遡ることが出来ない、ということです。\nプログラム的に言うと、上記の stream は seek や rewind をサポートしていません。\nこれを、先ほどの HDD レコーダの例で説明すると、 「過去に放送された番組の録画はできない」ということです。\n24 時間全ての番組を常に録画し続けて、 「1週間前に放送された任意の番組を再生する」機能を持つ HDD レコーダはありますが、 それはあくまで録画してあるものを再生しているのであって、 過去に放送された番組を録画することは出来ません。 もしそれが出来るなら、 本当の意味でのタイムマシーンを作ることが出来ることと同義になります。\nなお、「過去に放送された番組の録画はできない」ですが、 「録画した番組」の逆再生などは出来ます。\n先ほど説明した通り、次のどちらもの入力 stream です。\nデジタル放送の電波に乗っている bitstream を読み取る部分\n過去に放送された番組の録画はできない HDD に記録されている bitstream を読み込む部分\n録画した番組は逆再生など出来る これはつまり、 stream には次の 2 つのタイプが存在することを意味します。\n流れが一方通行で遡ることが出来ない stream 流れを遡ることが出来る stream これ以降、上記をそれぞれ none_seekable と seekable とします。\nnone_seekable と seekable の使い分け 上記の通り、stream には none_seekable と seekable の 2 つのタイプが存在します。\nでは、実際のプログラムでは stream はどう使い分けるべきか？ と考えた場合、 seekable である必要がない場合は極力 none_seekable を使うべきです。\nなぜならば、 seekable は none_seekable を包括する概念であり、 seekable な stream は none_seekable として使用することが出来ますが、 none_seekable な stream は seekable として使用することが出来ないからです。\n次に、疑似言語を使って説明します。\nfn funcA( data: seekable ) { sub( data ); } fn funcB( data: none_seekable ) { sub( data ); } 上記は、 seekable な引数を持つ関数 funcA と、 none_seekable な引数を持つ関数 funcB を定義する疑似言語コードです。 また sub() は、 none_seekable な引数を持つ関数とします。\nここで、この関数 funcA は seekable な stream でしか使用できないのに対し、 この関数 funcB は seekable, none_seekable どちらでも使用できることになり、 funcB は funcA よりも汎用性が高いと言えます。\n関数の汎用性が高いことが良いプログラムである、とは一概には言えませんが、 ミドルウェアなどのライブラリでは、汎用性が高い方が良いとされます。\nつまり、 stream を入力に持つ関数の処理においては、 seek や rewind の使用は極力避け、 none_seekable の stream で処理可能にすべきである、と言えます。\nただし例外として、 seek や rewind を使用しないと目標のパフォーマンスが出ないとか、 必要なワークメモリが規定を越えてしまう、等の問題がある場合は、 無理に none_seekable で処理する必要はありません。\nとはいえ、あくまでも原則は、 seekable ではなく none_seekable で処理できるかどうかを検討するべきです。\n言語の組込みの型として seekable と none_seekable が分かれていない言語は、 結構あると思います。\nそのような言語でも、 seekable と none_seekable の考え方自体は有効なので実践してください。\nnone_seekable で処理することのメリット seekable ではなく none_seekable で処理することのメリットとして、 Web ブラウザでの処理を例に挙げて説明します。\nもしもブラウザの処理が全て seekable であった場合、 ブラウジングスピードが遅くなることが予想されます。\nなぜなら、Web ブラウザは、サーバから HTML をダウンロードし、 HTML 内のリンクを抽出し、そのリンクをさらにダウンロードします。 そしてリンクが画像の場合、画像をデコードして表示します。\n画像のデコード処理が none_seekable であるならば、 画像データのダウンロード開始と同時にデコード処理が開始でき、 画像データのダウンロード終了とほぼ同時にデコード処理を完了できます。\n一方でもしも画像のデコード処理が seekable だった場合、 画像データをダウンロード終了してからデコード処理を行なわなければならず、 その分タイムロスになります。 さらに欠点はタイムロスだけでなく、 画像データの全てをダウンロードして一旦 RAM やストレージに格納しておく必要があり、 その分のリソースを消費することになります。\n画像データのサイズなんてイマドキのハードウェアスペックなら無視できる、 という意見もあるかもしれませんが、例えば 8K の低圧縮画像などは軽く数 10MB を越えます。 こういった画像のデータを全てダウンロードしてからデコードするなんてしてたら、 無駄にリソースを消費することが分かると思います。\nまた、最近はほとんど使われていませんが、 progressive JPEG なんて画像フォーマットが使われていた時期がありましたが、 これは none_seekable で処理して始めて意味のあるものです。\nprogressive JPEG を簡単に説明すると、 画像データの一部をダウンロードするだけで、低解像度の画像をデコードできる技術で、 ダウンロードが進むごとにデコード結果の解像度が上がるというものです。\nこれは、ネットワークの通信速度が低速なころに使用されていた画像フォーマットで、 いまではほとんど使われなくなったものですが、 none_seekable で処理しなければ全く意味のないものです。\n他にも none_seekable で処理することのメリットとして、 動画配信に代表されるストリーミングサービスがあります。\nあれも、 none_seekable が前提にあるからこそ可能なサービスです。\n「ストリーミングサービスが none_seekable だ」と書くと 「Youtube はシークできるぞ」とかツッコミがあると思うので一応補足しておきます。\nたしかに Youtube などの動画配信サービスはシークできるのが当たり前です。 しかし、通常再生時は none_seekable で処理していて、 シークなどの操作が入った時だけ、 サーバからデータをダウンロードしなおして処理しています。 つまり、基本は none_seekable です。\nもしも動画データが seekable 前提だった場合、 動画データを全てダウンロードしてからでないと再生できないか、 seek 処理が大量に発生してサーバ間の通信負荷が非常に高くなることが予想されます。\nまた、seekable(randam access) は none_seekable(sequential) と比べて 非常にパフォーマンスが悪くなるのが一般的です。\n例えば HDD の randam access は sequential と比べて 2 桁以上のパフォーマンス劣化、 SSD でも 1 桁以上劣化します。 RAM であっても、randam access することでキャッシュミスが発生しやすくなり、 パフォーマンス劣化からは逃れられません。 現代ではほとんど使われませんが、 テープデバイスなんて使った日には、どれほどかかるか想像すら出来ません。\nデータフォーマット stream を処理する際に、 それを none_seekable として扱うには、 stream に流れるデータのフォーマットが none_seekable として 扱い易い構造になっている必要があります。\nデータフォーマットが none_seekable として扱い難い構造の場合、 上記のように「目標のパフォーマンスが出ない」、「必要なワークメモリが規定を越えてしまう」 という問題が発生する可能性があります。\nある程度の大きさになるデータフォーマットを定義する時は、 必ず none_seekable で処理することを考えて定義しましょう。\nなお、 stream で処理することが多い画像や音声などのデータフォーマットは、 基本的には none_seekable で処理できるように定義されています。\nもしもそうでなければ、放送や動画配信でデジタルデータを扱うことは出来ません。\nちなみに、データの encode と decode の none_seekable での扱い易さは、 相反することがあります。\nその場合、どちらかを優先するか、折衷案の検討が必要です。 一つ言えることは、作業バッファを 0 にすることはまず不可能なので、 どの程度の作業バッファサイズなら妥当かを判断することが重要です。\n例外 none_seekable で処理することで、 ダウンロードとデコードを同時に処理できるため高速に処理できる、と説明しましたが、 一部例外があります。\nそれは、専用ハードウェアを使用してデコードする場合です。\nHDD レコーダなどの家電製品では、 動画や音声を処理する専用ハードウェアを搭載しています。 それら専用ハードウェアは、データを渡すと高速に処理して結果を返してくれますが、 処理するデータは全て揃えてから渡さなければならない、 という制約があることがほとんどです。\nその場合は、none_seekable でダウンロードとデコードを同時に処理するよりも、 専用ハードウェアを使用して処理する方が高速に処理できます。\nただし、当然専用ハードウェアであるため、処理できるデータは限られていますし、 そのような専用ハードウェアが利用できる環境は限られています。\nまとめ stream を扱う際は、次を注意する必要があります。\n極力 none_seekable で扱う データフォーマットを決める時点で、 none_seekable で扱えることを考慮する 最後に なんでこんなことを書いたかというと、 最近とある画像コーデックのライブラリを扱うことがあったんですが、 そのライブラリへの入力が seekable であることを前提としていてムカついた、 という経験をしたためです。\nデータ streaming 処理を行なう場合の基本的な考えなので、 必ずこれらを考慮に入れて設計するようにお願いします。\n以上。\n","id":72,"section":"posts","summary":"これは seekable な stream と none_seekable な stream の使い分けに関する記事です。 使い分けが十分出来ている人は読まなくても大丈夫です。 皆さんは bitstream という単語をご存知でしょうか？","tags":null,"title":"stream は rewind/seek できる？","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-07-10-stream/","year":"2019"},{"content":" コレ を作るにあたって、データの serialize/deserialize の方法を調べた結果、 marshmallow_dataclass に落ち着きました。\nいくつか調べた中で、パッと見、直感的に出来そうだった、というだけの理由ですが。。\n実際、面倒な処理はほとんど無く、 serialize/deserialize が可能になりました。\n使い型 marshmallow_dataclass は、 クラスを宣言する際に @dataclass デコレータを付けて宣言し、 メンバの型を宣言するのが基本です。\nこんな感じ。\n@dataclass class LogItem: # ゲームタイトル title:str # 日付 date:int # テキスト text:str # テキスト長 len:int メンバの宣言が python っぽくないと思う方もいるかもしれませんが、 静的型付け言語になれていると、こっちの方が馴染み易い気がします。\nJSON 化する場合は、 次のようにクラスメソッドに JSON 化するクラスのインスタンスを渡すだけです。\nitem = LogItem( \u0026#34;title\u0026#34;, time.time(), \u0026#34;text\u0026#34;, len( \u0026#34;text\u0026#34; ) ) print( marshmallow_dataclass.class_schema( LogItem )().dumps( item ) ) 逆に JSON からクラスインスタンスを生成するには、 次のようにクラスメソッドに渡すだけです。\nmarshmallow_dataclass.class_schema( LogItem )().loads( text ) とても簡単です。\nただ、躓いた点があったので、気をつけるべき点として書いておきます。\npython3.7 以降を使用する @dataclass デコレータを付けたクラスに次を宣言してはならない\nコンストラクタ init @staticmethod load() ","id":73,"section":"posts","summary":"コレ を作るにあたって、データの serialize/deserialize の方法を調べた結果、 marshmallow_dataclass に落ち着きました。 いくつか調べた中で、パッと見、直感的に出来そうだった、というだけの理","tags":null,"title":"python のクラスを JSON 化","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-07-04-python-json/","year":"2019"},{"content":" 4 月頃から、英語のレベルを上げるため参考書を買って勉強をしている。\nその参考書を使った最低限の基礎英語の復習は終ったので、次のステップに進むことにした。\n基礎が終った後の学習方法には何が良いのか色々と調べてみたが、 色々な意見があるが最終的には「持続できるものが良い」というのが結論のようだ。\nまぁ、「持続すること」が英語学習で最も難しいことは、 私自身が何度も挫折した経験があるので認識している。\nそもそも、先日まで復習していた参考書もかなり眠い目をこすりながらやっていて、 このまま参考書を進めていっても、間違いなくまた挫折することは明らかだった。\nじゃぁ、何が一番持続できるか？と考えた時、自分にはゲームが良いだろう。 という結論になった。\n海外ゲームによる英語学習 ゲームのジャンルは、いわゆるノベルゲームあるいはアドベンチャーゲーム。 有名どころで STEINS;GATE と言えば通じるだろうか？ これなら文章量がハンパないので、勉強量という意味では問題ないだろう。 「ゲームでの英語学習は効率が悪い」という意見があるが、 「持続すること」が一番重要なので、「効率の悪さ」はこの際無視することにした。\nともかく今は、英語の文章を英語のまま解釈できるようになるため、 英語の文章をひたすら入力していくのが最も重要な期間で、 その期間を挫折せずにやりすごすためにも、「持続すること」が一番重要と考えている。\n「習うより慣れよ」、脊髄反射できるまでの試練だ。\nそもそも、本当に効率の良い英語学習方法が存在するのであれば 文科省もバカじゃないんだからその方法を採用しているはず。 そして、その学習方法に本当に効果があれば、 日本人の大多数が英語が出来ないまま放置されているはずがない。 しかし、現実問題として私を含め日本人の大多数が英語が出来ないままである。\nつまり「日本国内における英語学習方法の違いによる効率の差」は、 ほとんど誤差レベルなんだと思う。\nもちろん、「英語しか話せない人の中で生活すること」と、 「日本国内で独学で英語を学習する」のとでは、英語の習得効率に明らかな違いはあるだろう。 しかし、「日本国内で独学で英語を学習する方法」は、 どのような学習方法であっても、どれも大差ないレベルなんだと思う。\n海外ゲームによる英語学習における問題 ということで、先週辺りから海外のゲームをプレイしているんだが、一つ問題がある。\nその問題とは「reading の経験値しか得られない」ということだ。\n日本のゲームの海外移植版をやるのがとっかかり易いと考えてたが、 そのゲームの TEXT は英語だが音声は日本語のままだった。 てっきり海外移植版なら音声も英語になっているものだと思っていたが、完全に想定外だった。\nそれならば、海外制作のオリジナルゲームなら音声も英語だろう、と思って探したが、 そもそも海外制作のノベルゲームやアドベンチャーゲームというジャンルはほとんど無かった。 あっても、音声がないという状況だ。 もちろん、他のジャンルのゲームなら英語音声のものはある。 しかしそのようなゲームは、TEXT の量的問題や、 そもそも英語とか関係なくゲームが進んでいって、 ほとんど単にゲームをプレイしているだけになってしまう、という問題がある。\nちなみに、海外ドラマや映画を学習手段として試したことがあるが、 アレはスピードが速すぎて、 自分のレベルではとてもではないけどハードルが高過ぎるという結論になっている。\n自分のペースで進められる、というのが、 ノベルゲームやアドベンチャーゲームの良いところだ。\nもちろん、内容が面白く持続できるということが前提だが。\nなお、今回海外のゲームを探してみて初めて気が付いたことだが、 海外でアドベンチャーゲームというと、日本のアドベンチャーゲームとは全く違って、 アクションゲームがアドベンチャーゲームに分類されていた。\nまぁ「adventure」 は「冒険」なんだから、当然といえば当然だろうが。\nだいぶ前置きが長くなったが、 そんな訳で、多くの時間を費やして「reading の経験値しか得られない」のは勿体無いので、 「どうにかしてゲームに音声を付けよう」と思い、今回のツール制作に至った。\nゲームに音声を付ける手段 ここで想定するゲームは、 メッセージを表示する領域があり、クリックすることでメッセージが更新されて、 ストーリーが進んでいくものだ。\nこのメッセージを取り出し、機械音声でしゃべらせる。\nもう少し技術的にいうと次になる。\nスクリーンショットでゲーム画面をキャプチャ キャプチャしたゲーム画面からメッセージ領域を判定し メッセージ領域内のメッセージ画像を抽出し 抽出したメッセージ画像を OCR にかけて TEXT に変換し 変換した TEXT を Text To Speech で音声化する 上記を GUI でコントロール メッセージ画像の抽出は OpenCV、 OCR は Tesseract OCR、 Text To Speech は Windows10 標準の SAPI.SpVoice を利用する。\nクラウドサービスの API を使えば、これらを全て行なってくれるものもありそうだが、 今回は上記の技術を組み合わせで自前で作成する。\nまぁ、自分で作ること自体も面白そうだし。\nなお、お手軽に作るため、開発言語は Python とする。\nプログラミング言語として、個人的にはあまり Python は好きではないんだけど、 手軽でさまざまなライブラリが揃っていて情報量も豊富、という意味では、 今は Python に敵う言語はないんじゃないかと思う。\nなんだかんだ言っても、プログラミング言語はツールにすぎないので、 目的の物を簡単に作れるのが一番良い。 特に趣味で作るケースでは。\n業務で使う場合は、 「チョット待て、他の言語はちゃんと検討したのか？」と言っておく。\n自分で開発している LuneScript も、 lua VM 上で動作する大規模アプリを開発するには向いているけど、 使えるライブラリは皆無(Lua 用ライブラリは使えるけど、まともに使うには module 宣言が必要) なので、残念ながらこういう用途には向いていない。\nちなみに、 cygwin 版 python で作業しようと思ったが、 pip がどうにもこうにも期待通りに動作しなかったので、 普通の windows 版 python にした。\n以降では、各技術について補足する。\nスクリーンショット スクリーンショット用に次をインストールする。\n$ pip install pywin32 $ pip install Pillow $ pip install pyscreenshot pywin32 は、 win32gui で特定の Window の領域を取得するために必要。\n具体的には次のような感じ。\ndef getImageOf( window_title ): rect = win32gui.GetWindowRect( win32gui.FindWindow(None, window_title ) ) return ImageGrab.grab().crop( rect ) OpenCV 次の処理を OpenCV で行なう。\nゲーム画面からメッセージ領域を判定 メッセージ領域内のメッセージ画像を抽出 ちなみに OpenCV のインストールは次で出来る。\n$ pip install opencv-python OCR (Tesseract OCR) 次の処理を Tesseract OCR で行なう。\n抽出したメッセージ画像を OCR にかけて TEXT に変換 Tesseract OCR は、次の URL からバイナリをダウンロードしてインストールし、\nhttps://github.com/UB-Mannheim/tesseract/wiki\nさらに python から利用するためのパッケージをインストールする。\n$ pip3 install pyocr Windows10 Text To Speech (SAPI.SpVoice) 次の処理を SAPI.SpVoice で行なう。\n変換した TEXT を Text To Speech で音声化する \u0026lt;https://github.com/mhammond/pywin32/releases\u0026gt; から、 python のバージョンに合う win32com モジュールのインストーラをダウンロードし、 インストールする。\nSAPI.Speech の制御方法は、次の URL を参考に。\n\u0026lt;https://www.daniweb.com/programming/software-development/code/217062/text-to-speech-using-com-python\u0026gt;\nこの SAPI.SpVoice の音声は、 一昔前の合成音声に比べればだいぶマシに聞こえるが、やはり違和感を感じる。\n英語が出来ない自分が、英語の音声に違和感の文句を云うのもどうかと思うが、 やはりイマドキの最新の Text To Speech 技術と比べると、品質が落ちる。\nそこで、Text To Speech の部分はクラウドサービスを使って違和感の緩和を検討する。 これについては後日取り上げる。\nGUI GUI は tkinter を利用する。\n用途は次の通り。\nゲームの Window 指定 OCR のトリガ OCR 後のメッセージ表示 \u0026amp; 編集 音声再生制御 (再生スピード,音量) ログ 折角なので、学習の履歴を残す。\n履歴は、日付、OCR 結果、全文字数 で、JSON 形式で残す。\n欠点 このシステムの一番の欠点は、読み上げられる音声に全く感情が入らないってことだろう。 ゲームのト書部分なら無感情でも問題ないが、 セリフが無感情で読み上げられるのは、いささか味気ない。 まぁ、そこは割り切るしかないが。 今は、クリアに音声が聞こえる事の方が重要だろう。 感情がどうこういうのは、 実力が付いてから海外ドラマや映画を見るようにすれば良い話だ。\n最後に 専門知識がなくても、フリーの技術を組合せるだけで、 これだけのものが作れるようになったというのはスゴい時代になったものだ。\nちなみにソースは \u0026lt;https://github.com/ifritJP/game-message-tts.git\u0026gt; にある。 興味があれば。\n","id":74,"section":"posts","summary":"4 月頃から、英語のレベルを上げるため参考書を買って勉強をしている。 その参考書を使った最低限の基礎英語の復習は終ったので、次のステップに進むこ","tags":null,"title":"ゲームのメッセージ欄に表示されたメッセージの読み上げシステム","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-06-28-text-to-speech/","year":"2019"},{"content":" だいぶ前に買って放置していた Raspberry pi zero w をセットアップしました。\nRaspberry pi zero w と言えば「小型軽量」が売りなんで、 今回はポータブルな IOT デバイスとして使う事を目的として、 Bluetooth の機能(ファイル転送、 IP over Bluetooth) のセットアップをしました。\nイマドキ Bluetooth なんて、 最新のイメージでセットアップすればすぐに使えるだろうと思って余裕でした。 しかし、実際には目的の機能が動作するまでに、かなりの時間が掛ってしまいました。\n少なくとも、パッケージをインストールするだけでは済まず、 いくつかのファイルを編集 \u0026amp; コマンド実行が必要です。\nそんな訳で、次に同じことをする時のために備忘録を残しておきます。\nこの記事で扱うメインは以下の通りです。\nRaspberry pi zero w を USB 接続のみでセットアップ Bluetooth によるファイル送受信機能(OBEX File Transfer)の実現 IP over Bluetooth (PAN) による、PC との SSH 接続確立 スムースにいけば、 作業時間は 10 〜 20分程度で完了します。 (OS イメージ書き込みや apt 更新などの待ち時間は除く)\nなお、 Raspberry pi の設定を行なうホスト環境は Ubuntu 18.04.2 LTS とします。\nUbuntu が Native で動作する PC でも、 Windows 上の Gest OS の Ubuntu でも構いません。 ただし、 Windows 10 の subsystem の linux は対象外です。\nRaspberry pi zero w を USB 接続のみでセットアップ SD カードに OS Image を書き込む 公式サイトから OS Image を落して SD カードに書き込みます。\n今回は Raspbian Stretch with desktop and recommended software の 2019-04-08 を使用しました。\n以前 raspi で Bluetooth を扱った時、 Lite では意図する動作にならなかったトラウマがあるため、今回はこれを使用します。\nイメージを書いたら、ssh と IP over USB (RNDIS) を有効化するため、 SD カードをマウントした直下の次のファイルを編集します。\nssh config.txt cmdline.txt 編集内容については、次の URL を参考に。\n\u0026lt;https://qiita.com/mt08/items/ce5e3911d74d7fad4563#%E6%89%8B%E9%A0%86\u0026gt;\n念の為要点だけをまとめておくと、\n空の ssh ファイルを作成 config.txt に次を追加 dtoverlay=dwc2 cmdline.txt rootwaitとquietの間に次を挿入 modules-load=dwc2,g_ether RNDIS 設定 Ubuntu では、Raspberry pi zero w (以降 raspi) を USB (2つある USB コネクタのうち、 HDMI コネクタ側の方)で接続すれば、 運が良ければ特になにもせずに IP over USB (RNDIS) で raspi と通信可能になります。\n通信可能かどうかは、次の方法で確認できます。\n$ ip a ここで enp0s20u1 的なデバイスが表示されていて、 IP アドレスが取れていることを確認します。\nIP アドレスが取れている場合、次のコマンドで raspi の IP を確認します。\n$ ip n 同じサブネットのアドレスがあれば、それが raspi の IP。\nraspi の IP が分かったら、 ssh すれば OK。\n$ ssh -Y pi@10.42.0.100 ちなみにデフォルトパスワードは raspberry.\n大抵の場合、運が良くないので上記の確認では期待した結果にならない。\nそのため、次のネットワーク設定が必要になる。\nまず、ネットワーク設定を行なう前に、現在のネットワークの状況を確認します。\n$ ip a このコマンドで表示される「デバイス名」と「MAC アドレス」をメモっておきます。\nメモった後に、次のコマンドを実行します。\n$ sudo nmtui 起動すると、いくつかの Ethernet 設定がリストで表示されるので、 編集を選択します。\n編集を選択すると、デバイスの欄に「デバイス名」あるいは「MAC アドレス」が 表示されているので、 USB の方の情報が表示されている Ethernet 設定を見つけます。\n設定を見つけたら、一旦その設定自体を消します。 USB のデバイスに関する設定が複数ある場合は、全て削除します。\nそして、新しく設定を追加します。\nこのときの設定内容は次の通りです。\n接続タイプ Ethernet デバイス名を enp0s20u1 (実際のデバイス名に合せる) IP4 config を share にする Require IPv4 addression for this connection をチェック 設定後、connection を activate する。\nこれで再度 ip a から確認してください。 これでも上手く動作しない場合、 deactivate と activate を何度か繰り返すと解消されることがあります。\nちなみに Windows をホストに作業する場合、野良ドライバのインストールが必要です。 個人的には、Windows への野良ドライバインストールはオススメできません。\n以降は、 raspi に ssh 接続した状態で作業します。\nまずは、次のコマンドで apt を更新しておきます。\n$ sudo apt-get update $ sudo apt-get install bluez-tools pulseaudio-module-bluetooth 本来 pulseaudio-module-bluetooth は、 audio sink 用のものなので、 今回の目的には不要のはずなんですが、 これがないとペアリング後の接続すら出来なかったので入れておきます。\n次に、 raspi のホスト名を変更します。 このホスト名が、 bluetooth のペアリングのときに使用されます。\n次のコマンドを実行し、 Network Options -\u0026gt; Hostname で適当に変更します。\n$ sudo raspi-config Bluetooth によるファイル送受信機能(OBEX File Transfer)の実現 Bluetooth のファイル送受信には、 追加で obex 系の設定が必要となります。\n$ sudo apt install obexpushd obex 系の処理を動かすには、 bluetoothd に –compat オプションを必要です。\nオプションの指定は次のように /etc/init.d/bluetooth に –compat を追加します。\n#SSD_OPTIONS=\u0026#34;--oknodo --quiet --exec $DAEMON -- $NOPLUGIN_OPTION\u0026#34; SSD_OPTIONS=\u0026#34;--oknodo --quiet --exec $DAEMON -- --compat $NOPLUGIN_OPTION\u0026#34; あるいは、 /etc/systemd/system/bluetooth.target.wants/bluetooth.service に追加するケースもあります。\n#ExecStart=/usr/lib/bluetooth/bluetoothd ExecStart=/usr/lib/bluetooth/bluetoothd --compat ファイル編集後 –compat オプションを反映させます。\n$ sudo systemctl daemon-reload $ sudo /etc/init.d/bluetooth restart $ sudo systemctl restart bluetooth 次に Bluetooth ファイル受信用ディレクトリを作成します。\n$ mkdir ~/bluetooth そして次のコマンドを実行します。\n$ sudo /usr/bin/obexpushd -B -n -o /home/pi/bluetooth これでホスト PC からファイルを送信すると、 /home/pi/bluetooth にファイルを受信します。\nなお、obexpushd は次のようにサービスとして登録します。\n/etc/systemd/system/bt-obexpushd.service に次の内容をもつファイルを作成。\n[Unit] Description=Bluetooth obexpushd After = bluetooth.service [Service] ExecStartPre=/bin/sleep 4 ExecStart=/usr/bin/obexpushd -B -n -o /home/pi/bluetooth Type=simple [Install] WantedBy=multi-user.target サービスを有効化\n$ sudo systemctl enable bt-obexpushd $ sudo systemctl start bt-obexpushd IP over Bluetooth (PAN) による、PC との SSH 接続確立 PAN の設定は、次の URL の回答をそのまま設定すれば OK です。\n\u0026lt;https://raspberrypi.stackexchange.com/questions/29504/how-can-i-set-up-a-bluetooth-pan-connection-with-a-raspberry-pi-and-an-ipod\u0026gt;\nなお、上記 URL の内容を設定後、再度ペアリングをやり直してください。\n","id":75,"section":"posts","summary":"だいぶ前に買って放置していた Raspberry pi zero w をセットアップしました。 Raspberry pi zero w と言えば「小型軽量」が売りなんで、 今回はポータブルな IOT デバイスとして使う","tags":null,"title":"Raspberry pi zero w で Bluetooth 色々(ファイル転送:obex、 IP over BT:PAN )","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-06-15-rasp0w/","year":"2019"},{"content":" VMWare のディスクイメージのサイズは、Gest OS 上のディスクサイズと異なる。\n基本的には、Gest OS 上で実際に使用されているサイズに圧縮された形でホスト OS 上に保持される。\nしかし、 Gest OS 上でファイル作成、削除を繰り返していると、 Gest OS 上での使用サイズよりも、 ホスト OS 上でのディスクイメージサイズがかなり大きくなっていることがある。\nこのような状態になった時に、ホスト OS 上のディスクイメージサイズを、 Gest OS 上での使用サイズ程度に削減するツール(vmware-toolbox-cmd)が vmware から提供されている。\n通常は、この vmware-toolbox-cmd を使うことで圧縮されるはずなのだが、 自分の環境では全くサイズが変わらなかった。\nいくつか試した結果、削減出来た方法をメモしておく。\nGest OS 上でのディスクのクローン 今回実施した方法は Gest OS 上でのディスクのクローンを作成することだ。\nある意味分かりきった方法かもしれない。\nただ、クローン作成の方法はファイル単位のコピーではなく、 dd コマンドによるクローン作成 で上手くいった、 ということは意外と言えるんじゃないだろうか？\nファイル単位のコピーだと、コピーにかなり時間がかかると思うが、 dd コマンドで済んだので、10 GB 近いコピーも比較的短時間でコピーが出来た。\ndd コマンドは、特に何か特別なオプションを付けて実行したのではなく、 普通に実行しただけだ。\n念の為、作業手順をまとめておく。\n作業手順 クローン先の空のディスクイメージを作成する ディスクイメージを VMWare に登録する Gest OS を起動する vmware-toolbox-cmd を使って圧縮 vmware-toolbox-cmd disk shrinkonly Gest OS 上での圧縮対象ディスクと、クローン先のデバイス名をメモる dd コマンドでクローン作成 dd if=/dev/圧縮対象 of=/dev/クローン先 bs=1M ここで指定するドライブは、パーティションではなくドライブ全体を指定すること。 Gest OS を shutdown ここでクローン先のディスクイメージを見て、 Gest OS 上の使用量とほぼ同じサイズに削減されていることを確認する。 もしも削減されていない場合、これ以降の作業には意味はない。 圧縮対象ディスクイメージを VMWare から除外し、 代わりにクローンしたイメージを登録する。\nこの時クローンイメージを割り付けるハードウェアの ID などが、 元の圧縮対象ディスクイメージと同じになるように登録する。 Gest OS を起動する。 以上の手順により、サイズが圧縮されたクローンのイメージで運用できる。\n","id":76,"section":"posts","summary":"VMWare のディスクイメージのサイズは、Gest OS 上のディスクサイズと異なる。 基本的には、Gest OS 上で実際に使用されているサイズに圧縮された形でホ","tags":null,"title":"VMWare ディスクイメージが圧縮されないときの対応方法","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-05-20-vmware/","year":"2019"},{"content":" 現在 LuneScript の C 言語へのトランスコンパイル処理を対応中だが、 トランスコンパイルする際に関数ポインタによる関数コールのオーバーヘッドが どの程度なのか気になったので調べてみた。\n結果 初めに結果から書くと、\n関数ポインタによる関数コールのオーバーヘッドは、 通常の関数コールに比べて約 1.267 倍となることが判った。 この数値は、あくまで今回の実験結果であって、 関数ポインタかどうかの違いだけはなく、他の要因も入ってしまっている。 また、実行環境によっても差は出てくるだろう。\nしかし、それでも目安程度にはなるだろう。\n所感 論理的に考えて、関数ポインタの関数コールが通常の関数コールに比べて 遅くなることは理解していたが、これまで調べたことはなかった。 それが、今回の実験で明かになった。\n個人的にはもっと差が出るかと思ったが、案外少ない結果になった。 これは、実験用コードが小さ過ぎて全てキャッシュに乗ってしまっているのが一番の要因だとは思う。 とはいえ、明らかなオーバーヘッドがあることには違いない。\nプログラミングをしていれば感じていることだと思うが、 プログラムは関数コールの塊だ。\nつまり、関数コールのオーバーヘッドは、 そのままプログラム全体の性能低下に直結する。\n「関数ポインタ」というと、あまり使わっていないイメージを持つ人も多いかもしれないが、 オブジェクト指向の「ポリモーフィズム」あるいは「多態性」というと、 良く使っているイメージがあるのではないだろうか？\n関数ポインタなど動的に動作が変わる処理は、 目的の制御を実現する上で非常に重要だが、 コードの把握が難しくなったり、オーバーヘッドによる性能低下を引き起こす可能性がある。\n関数ポインタと通常の関数は、その特性にあわせてどちらを使用するかの検討が必要だ。\n今回の実験結果をうけて、それがより明らかになったと思う。\n実験詳細 ここでは、今回の実験方法について説明する。\nコード 実験用に次の C 言語コードを作成した。\nvoid sub( void ) { } void func_direct( func_t * pFunc ) { sub(); } void func_indirect( func_t * pFunc ) { pFunc(); } func_direct() は sub() 関数を直接コールする関数で、 func_indirect() は sub() 関数を関数ポインタでコールする関数だ。\nこの両者の関数を実行したときの実行時間を比較している。\nちなみにコードの全体は次の通りである。\n#include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; typedef void (func_t)( void ); double getTime( void ) { struct timeval tm; gettimeofday( \u0026amp;tm, NULL ); return tm.tv_sec + tm.tv_usec / 1000000.0; } void sub( void ) { } void func_direct( func_t * pFunc ) { sub(); } void func_indirect( func_t * pFunc ) { pFunc(); } void func_none( func_t * pFunc ) { } int main( int argc, const char * argv[] ) { long long loop; const char * pMode; double prev = getTime(); switch ( argc ) { case 1: pMode = \u0026#34;indirect\u0026#34;; for ( loop = 0; loop \u0026lt; 1000 * 1000 * 1000 * 2; loop++ ) { func_indirect( sub ); } break; case 2: pMode = \u0026#34;direct\u0026#34;; for ( loop = 0; loop \u0026lt; 1000 * 1000 * 1000 * 2; loop++ ) { func_direct( sub ); } break; case 3: pMode = \u0026#34;none\u0026#34;; for ( loop = 0; loop \u0026lt; 1000 * 1000 * 1000 * 2; loop++ ) { func_none( sub ); } break; } printf( \u0026#34;%s: time = %g\\n\u0026#34;, pMode, getTime() - prev ); return 0; } このプログラムは、コマンドラインの引数によって func_direct(), func_indirect(), func_none() のいずれかを 所定の回数分実行し、実行時間を表示する。\nちなみに func_none() は、関数ポインタと通常の関数コールの差を出す際に、 できるだけ他の要因を除外するために作成した関数だ。\n計測結果 indirect: time = 11.4617 indirect: time = 11.2905 indirect: time = 11.2595 indirect: time = 11.3391 indirect: time = 11.3123 direct: time = 10.5253 direct: time = 10.5927 direct: time = 10.5389 direct: time = 10.6043 direct: time = 10.5259 none: time = 7.64467 none: time = 7.60627 none: time = 7.75474 none: time = 7.60123 none: time = 7.63887 これは、コマンドライン引数を変えて上記のプログラムをそれぞれ 5 回ずつ実行した結果だ。\nそれぞれを平均すると次のようになる。\n時間(秒) 関数コールの時間(秒) 関数ポインタ 11.333 3.683 通常関数コール 10.557 2.908 関数コールなし 7.649 上記の「関数コールの時間」は、計測した時間から「関数コールなし」の時間を引いたものだ。\nつまり、 for 分の制御などの関数ポインタのオーバーヘッドとは直接関係ない処理の時間を引いている。\nこの結果をもとに、次の計算をすると\n(/ 3.683 2.908) 1.266506189821183\n関数ポインタによる関数コールのオーバーヘッドは、 通常の関数コールに比べて 約 1.267 倍 となる。\n以上\n","id":77,"section":"posts","summary":"現在 LuneScript の C 言語へのトランスコンパイル処理を対応中だが、 トランスコンパイルする際に関数ポインタによる関数コールのオーバーヘッドが どの程度なのか","tags":null,"title":"関数ポインタのオーバーヘッド","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-05-19-func-pointer/","year":"2019"},{"content":" とある事情で使い続けていた emacs23.4 (2012/1) を、 先日 emacs26.2 (2019/4) にアップデートした。\nこのとき gdb 周りの設定を変更する必要があったので、備忘録としてまとめておく。\n2019-06-12: my-gud-stop, my-gud-mode-func を追加\n2019-08-26: dedicate の抑制追加\nなお、M-x gud-gdb で起動すれば従来形式のインタフェースが利用できるが、 ブレークポイントが表示されない等の不具合があるので M-x gdb を利用する。\nそれにしても、新しい M-x gdb のインタフェースは emacs っぽくないと思うんだけど、 オレがおっさんだからそう思うんだろうか？\nemacs の gdb 設定 ;; gud-overlay-arrow-position が nil だとエラーするので。。 (setq gud-tooltip-display \u0026#39;((and gud-overlay-arrow-position (eq (tooltip-event-buffer gud-tooltip-event) (marker-buffer gud-overlay-arrow-position))))) ;; gdb バッファの C-c C-c で、プログラムを停止させる。 (setq gdb-gud-control-all-threads nil) ;; input/output バッファが勝手に表示されるのはウザいので、抑制 (setq gdb-display-io-nopopup t) ;; input/output バッファが dedicate されるのはウザいので、抑制 (defadvice gdb-display-buffer (around gdb-display-buffer) (let (window) (setq window ad-do-it) (set-window-dedicated-p window nil) window )) (ad-activate \u0026#39;gdb-display-buffer) ;; gdb バッファの C-c C-c ではプログラムが停止しなかったので、修正 (defun my-gud-stop () (interactive) (comint-interrupt-subjob) (gud-stop-subjob) ) ;; 上記 my-gud-stop 関数を C-cC-c に登録する関数 (defun my-gud-mode-func () (define-key (current-local-map) \u0026#34;\\C-c\\C-c\u0026#34; \u0026#39;my-gud-stop) ) ;; フックに登録 (add-hook \u0026#39;gud-mode-hook \u0026#39;my-gud-mode-func) 以降で、上記の設定について説明する。\ngud-tooltip-display 1 つ目は、単純に gud.el の不具合のような気がするが、 tooltip を表示する処理を修正している。\ngud-tooltip-display は、 gud で tooltip を表示する処理のようだが、 この処理で (make-buffer gud-overlay-arrow-position) を実行している。\nこの処理は、 gud-overlay-arrow-position が nil の時にも実行されるケースがあるようで、 その時にエラーにならないように and を追加している。\ngdb-gud-control-all-threads gdb-gud-control-all-threads は、 gud の制御を全スレッドに対して反映させるかどうかのフラグで、 emacs 23 ではデフォルト nil だった。\n新しい gdb では、 gdb-gud-control-all-threads がデフォルト t になっている。\ngdb-gud-control-all-threads が t だと、 どうにもこうにも意図したデバッグ制御にならなかったので nil とした。\nなお、 C-c C-c でデバッグ対象プログラムを停止できるが、正常に動作しない場合がある。\nその場合 M-x gud-stop-subjob してから C-c C-c すると、停止する。\ngdb-display-io-nopopup emacs23.4 の gdb は、 デバッグ対象プログラムの stdin/out と gdb の制御コマンドを、 一つのバッファで管理していた。\nしかし、 新しい gdb は stdin/out と、gdb の制御コマンドを別々のバッファで管理している。\ngdb-display-io-nopopup は、 stdin/out に変化があった際のポップアップ制御を抑制するかどうかのフラグ。\nデフォルトだと t だが、 これだとソース編集中やステップ実行中に、 stdin/out のバッファが突然表示されてウザいので nil とした。\nなお、gdb-display-io-nopopup を t とすると、 M-x gdb 実行時にも stdin/out のバッファが表示されないため、 stdin/out にアクセスする場合は 自分で C-x b 等で切り替える必要がある。\nちなみに stdin/out バッファの名前は *input/output of ...* 。 ここで … には、デバッグ対象のファイル名が入る。\nmy-gud-stop emacs23.4 だと C-cC-c でプログラムを停止して (gdb) プロンプトが表示されたのだが、 emacs26.2 だと C-cC-c でプログラムを停止できない。\nそこで、プログラムを停止する関数を作成している。\nmy-gud-mode-func 上記関数を C-cC-c に登録するための関数。\ngud-mode 時にキーバインドを登録するように gud-mode-hook に追加。\ndedicate 普通に使うと、 gud の input/output バッファの window が dedicate される。\ndedicate されると、 C-x b などでバッファを切り替えられなくなる。\n個人的にこれは使い勝手が悪いので、 dedicate されないように gdb-display-buffer の処理をかえる。\n以上。\n","id":78,"section":"posts","summary":"とある事情で使い続けていた emacs23.4 (2012/1) を、 先日 emacs26.2 (2019/4) にアップデートした。 このとき gdb 周りの設定を変更する必要があったので、備忘録としてまとめておく。 2019-06-12: my-gud-stop,","tags":["emacs"],"title":"emacs 更新に伴なう gdb の設定","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-05-13-emacs26-gdb/","year":"2019"},{"content":" たまたま見つけたブログの記事で気になったものがあったので、 自分の意見を書いておきます。\n気になったブログの記事 「エンジニア就職志望者が情報工学科に行くのは間違いです！学べることが違います！」\n\u0026lt;https://www.torikun.com/entry/engineer-jouhoukougaku\u0026gt;\nこの記事を要約すると、\n大学の情報工学科のプログラミング単位取得だけでは 学習時間が足りないのでプログラミングスキルを上げるのは難しい。 スキルを上げるにはプログラミングスクールがオススメ というモノです。\nまぁ確かに、 大学の講義・実習だけで十分なプログラミングスキルを身に付けるのは不可能であるのは事実です。\nとはいえ、『エンジニア就職志望者が情報工学科に行くのは間違い』というのは、 流石に異論があります。\nブログの著者と自分とで異なる意見になる理由を考えると、\n【「エンジニア」という言葉の定義が違う】\nから、だと思います。\n「エンジニア」とは 上記の記事では、エンジニアには次の能力が必要だとしています。\nプログラミングスキル コミュニケーション能力 マネジメント能力 これらは確かに重要です。\nというか、「コミュニケーション能力」や「マネジメント能力」は、 エンジニアでなくても社会で働くには必要な能力です。\nつまりこの著者は、\n【「エンジニア」に特化して必要な能力は「プログラミングスキル」だけ】\nと主張しているように読めます。\nこれは、私の考えと完全に異なります。\nまず、私が考える「エンジニア」像を説明します。\nエンジニアとは、曖昧なゴールイメージを技術によってスマートな形で実現できる能力を持つ人。\n例えば「家を建てる」というゴールイメージがあるとします。\n家を建てることは情報系の「エンジニア」の仕事ではないと思いますが、 あくまで例として考えてください。\nこの場合、次のような様々なことを決定し、設計書を作成して建築する必要があります。\n建てる場所 予算 広さ デザイン 機能性 耐久性 拡張性 メンテナンス性 建材 日程 etc… このように、 曖昧なゴールイメージを実現するために具体的な作業項目に分解し、 分解された作業の課題を洗い出し、 課題を解決し、 イメージを具現化する技術を持つのが、私が考える「エンジニア」です。\nもちろん、現実には一人のエンジニアが全てを担当できる訳ではありません。\nしかし、ブログの著者のような「エンジニア ＝ プログラミングスキルのある人 」では、 絶対にありません。\nまたブログの記事には、次の記載があります。\n例えば、大学２年生の時にはフーリエ変換という数学の公式を習います。 この技術はパソコンの仕組みを突き詰めて行くと重要になってくる有名な数式です。 微分とか積分とかいろいろ難しい公式を覚えて問題を解いていきます。 エンジニアの方ならおわかりかと思いますが、 エンジニアとして仕事をする上でこのフーリエ変換を使う人はぜんぜんいません。 確かに全てのエンジニアが微分・積分を必要とする訳ではないです。 しかし、技術の背景を知っているエンジニアと、 プログラミングしか出来ないプログラマーでは、担当できる範囲が全く違ってきます。\nたとえばディープラーニングなどの技術は、 プログラミングしか出来ないプログラマーでは 絶対 に作り出すことは出来ません。 様々な知識を持つエンジニアが集結してこそ可能なものです。\nもちろん大学の講義レベルの知識だけで、すぐに何かが実現出来るということはありません。 しかし、大学の講義はさまざまな技術の基礎そのものであり、 その基礎を身に付けているかどうかで、その後の応用が出来るかどうかの違いに繋がってきます。\n特に基礎部分は、体系的に学んだ方がより深い理解につながります。 そして大学の情報工学部の単位は、体系的に学ぶことが出来る構成になっています。\nつまり大学の情報工学部は、『「エンジニア」になるためのもっとも早道である』と言えます。\n認識が異なる理由 では、ブログの著者は何故「エンジニア ＝ プログラミングスキルのある人」という 認識なのでしょうか？\nあくまで私の想像ですが、これは日本のソフトウェア開発業界の特色によるものだと思います。\nその特色とは、いわゆる「ゼネコン方式」です。\n大手が仕様を決め、実装を外部にアウトソーシングする。\nブログ著者にとって「エンジニア」とはアウトソーシング先であり、 「エンジニアは安い金額で実装さえ出来れば良い」という思考なのではないでしょうか？\n日本には、このような思考が蔓延しているため、 エンジニアの待遇は良くならないし、 技術レベルも世界から離される一方なのではないでしょうか？\nなお、ブログ著者のプロフィールを見ると、 IBM Tokyo Lab に務めているとあります。 いわゆる大手であるのは間違いないでしょう。\nエンジニア就職志望者はどうあるべきか 私の考えは、「エンジニア就職志望者は様々な技術を学ぶべき」です。\n「他人が作った仕様を元に、プログラムだけ組んでいれば幸せ」という人は、 ブログ著者が主張するようにプログラミングスクールなりに行けば良いと思います。\nただ、日本のゼネコン方式ソフトウェア開発を請け負う、 いわゆる SIer の給与は発注元の企業よりもかなり低いのが一般的です。 それこそ IBM の半分かそれ以下ではないでしょうか？ そのことは認識しておく必要があります。\nなお、エンジニア志望者が行くべきなのは、情報工学科でなくても良いと思います。\nというのも、私の「エンジニア」の定義は広いので、 情報工学科では収まりきらないためです。 何を極めたいかによって、何を学ぶべきかは変ってくるでしょう。\n一つだけ必須技術を上げるならば、それは 「英語」 です。\n今後の「エンジニア」業界で、 日本が世界をリードすることは極一部を除いて無いでしょう。\nつまり、新しい技術は海外から導入することになります。 その時、その技術の解説は英語であるのが一般的です。\n英語が出来れば、いち早く技術の導入が可能になります。\nまぁ、これは今に始まったことではなく、 それこそコンピュータサイエンスという言葉が一般化したころから英語が標準でした。\nただ平成の時代は、\n今よりは技術の進歩が激しくなく、日本語の翻訳を待っていてもまだどうにかなっていた 国内で働いているだけなら、外国人を相手にする機会がほとんどなかった などの理由から「英語は出来た方が良い」というレベルでした。\nしかし現在は、\n技術の進歩が激しく、日本語の翻訳を待っていたら周回遅れどころか浦島太郎になる ある程度新しい技術を取り入れる場合、国内の日本人だけで開発するのが難しくなった などで、まともな「エンジニア」として働くには、英語はなくてはならない状況です。\nもしもあなたがエンジニアを志す学生で、英語を苦手としているのならば、 留年してでも英語は習得しておくべきです。\n世界と戦う意思のあるまともな日本の企業でエンジニアとして働くのであれば、 入社資格として英語のレベルを問われるでしょう。\n逆に英語のレベルを不問とするような会社は、 世界と戦うことを諦めているか、 あなたを安く使える労働力と捉えているかのどちらかの可能性が高いです。\nまた、英語がまともに出来れば外資系や海外で働くことも選択肢になります。\n英語習得のために大学を 1 年留年したとしても、 その後のエンジニア人生を考えれば充分おつりがくるでしょう。\n英語が出来ない私だからこそ、 英語が出来ない現状がどれほどマズいことかを、 この歳になって身をもって感じています。\n私はこれまで何度も英語の学習に挑戦と挫折を繰り返してきましたが、 今の状況なって本当にマズいことを実感し、 ラストチャンスとして人生で何度目かのトライをしています。\n皆さんは、私のような思いをしないで済むように、英語だけは身につけてください。\nもしかしたら、英語よりも中国語の方が良いかもしれませんが、 それはまだ何ともいえない状況です。\n","id":79,"section":"posts","summary":"たまたま見つけたブログの記事で気になったものがあったので、 自分の意見を書いておきます。 気になったブログの記事 「エンジニア就職志望者が情報工学","tags":null,"title":"『エンジニア就職志望者が情報工学科に行くのは間違い』は間違い","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-04-18-engineer/","year":"2019"},{"content":" 外出先の暇な時間を有効利用するため、ドキュメント書きをしたくなることがあります。\nそして私は emacs ユーザ。\nemacs ユーザが書きモノをするといえば、 emacs/org-mode です。\nここでは、 Android で emacs/org-mode を使って qiita に投稿するまでの環境作りを紹介します。\nノート PC を持っている人は、普通にノート PC を持っていけば良いと思います。\n用意するもの タブレット Bluetooth キーボード タブレット用スタンド 環境構築 Android アプリ まずは Android に次のアプリを入れます。\ntermux ハードウェアキーボード配列変更アプリ (英語 or 日本語) Hacker\u0026#39;s Keyboard 全て Root なしに Google Play で入れられます。\n配列変更アプリは US 配列と JIS 配列でアプリが分かれているので、 好きな方を入れてください。 入れた後に、 Android の設定でハードウェアキーレイアウトを 「Ctrl、Caps 交換」に切り替えます。 なお、 Caps/Ctrl の入れ替えが不要な場合は、配列変更アプリを入れなくて良いです。\nHacker\u0026#39;s Keyboard は必須ではないですが、 他の IME では、ハードウェアキーボードと想定外の干渉をすることがあります。\ntermux 設定 ピンチイン、アウトでフォントサイズを変更 次のパッケージを termux にインストール\nemacs curl git emacs 設定 ~/.emacs/init.el 設定 次の内容の ~/.emacs/init.el を作成\n(package-initialize) (add-to-list \u0026#39;package-archives \u0026#39;(\u0026#34;melpa\u0026#34; . \u0026#34;https://melpa.org/packages/\u0026#34;)) パッケージインストール M-x package-list-packages で、次のパッケージを emacs にインストール\nox-qm ddskk helm session helm/session は必須じゃないけど、入れておいて損はない。\norg-qiita.el インストール $ git clone https://github.com/ifritJP/org-qiita-el 設定等の話は次を参考に。\n\u0026lt;https://qiita.com/dwarfJP/items/594a8d4b0ac6d248d1e4\u0026gt;\nパッケージ設定 (show-paren-mode) (add-to-list \u0026#39;load-path (expand-file-name \u0026#34;~/work/org-qiita-el\u0026#34;)) (require \u0026#39;ox-qmd) (require \u0026#39;org-qiita) (setq org-qiita-token \u0026#34;XXXXXXXXXXXXXXXXXXXXXXXXX\u0026#34;) \u0026lt;---- qiita のトークン (org-qiita.el の説明参考) (setq org-qiita-export-kill-close t) (setq my-key-map (make-keymap)) (define-key global-map (kbd \u0026#34;C-z\u0026#34;) my-key-map) (define-key my-key-map (kbd \u0026#34;SPC\u0026#34;) \u0026#39;set-mark-command) (define-key my-key-map (kbd \u0026#34;i\u0026#34;) \u0026#39;helm-imenu) (define-key global-map (kbd \u0026#34;C-x b\u0026#34;) \u0026#39;helm-mini) (require \u0026#39;helm) (require \u0026#39;session) (require \u0026#39;recentf) Android は Ctrl-SPC が、「キーボードレイアウト切替」になっています。\nこのため、 Ctrl-SPC がシステムに奪われて set-mark-command が動作しません。\n暫定対応として、 C-z SPC に set-mark-command を割り当てました。 使い勝手はイマイチですが、意識してやればなんとか使えるレベルです。\n最後に 簡単なドキュメント書きなら、これで十分です。\nノート PC と比べても、遜色ないレベルです。\nとはいえ欠点もあります。\nタブレットでの Web 検索がやり難い\nタブレットは org-mode 専用で、検索は別途スマホでやる方が良いと思います。 ただ、検索結果をコピペするような場合は、タブレットでやった方が良いです。 C-SPC が使えない。\nこれは android の制約で、しかたがない？ 次回は、外出先でのソフト開発に耐えられる環境について書きたいと思います。\n","id":80,"section":"posts","summary":"外出先の暇な時間を有効利用するため、ドキュメント書きをしたくなることがあります。 そして私は emacs ユーザ。 emacs ユーザが書きモノをするといえば、 emacs/org-mode です","tags":null,"title":"Android で emacs/org-mode/qiita 投稿","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-03-23-termux-org/","year":"2019"},{"content":" forkwell の github 分析結果が面白かったので貼っておく。\n","id":81,"section":"posts","summary":"forkwell の github 分析結果が面白かったので貼っておく。","tags":["lua"],"title":"この度 Lua 神を拝命しました","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-03-16-lua/","year":"2019"},{"content":" Outlook は当初から評判が良くないため個人的には使用していません。 もうず〜〜〜〜〜と、 PC のメール環境は Mew を使用しています。\nしかし、自分のメール送信・受信環境は好きなものを選べますが、 相手のメール送信・受信環境は選べません。\nそしてつい先日も、 Outlook から送信されたメールで文字化けメールを受信しました。\nどうして化けたのか気になったので、調べてみました。\nメールの MIME に示されているコードは \u0026#34;gb2312\u0026#34; となっている 同じメールを Outlook で受信している人に聞いてみると、文字化けしていないと言う emacs のコード変換で化けたのか？と思い、 メールを保存してブラウザの表示言語を簡体字中国語設定で表示してみると文字化けしなかった。\nこの時のブラウザのテキストエンコーディングを見てみると \u0026#34;GBK\u0026#34; だった emacs で利用可能な文字コードを見てみると \u0026#34;gb2312\u0026#34; と \u0026#34;GBK\u0026#34; は別ものとして存在している。 試しに文字化けしたメールを、 emacs の \u0026#34;GBK\u0026#34; を指定して開くと文字化けしなかった Wikipedia を見ると \u0026#34;GBK\u0026#34; は \u0026#34;gb2312\u0026#34; を拡張したものということが分った\nまた、 Microsoft が GBK を Windows コードページ 936 として定義した、との記載がある。 MS も Outlook で送信すると文字コード判定が間違えることを認識している\n次の URL に記載されている「方法3」が、まさにそれの対処方法 \u0026lt;https://support.microsoft.com/ja-jp/help/881816\u0026gt; 以上のことから、次の事が考えられます。\nOutlook で所定の文字を含むメールを送信する際、 Outlook の自動文字コード判定によって WCP936 として認識される。 WCP936 は本来 GBK であるが、メールの MIME には charset=\u0026#34;gb2312\u0026#34; として宣言される メールを受信した Mew は、 MIME の情報を見て gb2312 として処理するが、 実際のメールは gb2312 ではなく GBK でエンコーディングされているため、文字化けする。 Mew での対応 Outlook のダメさ加減を嘆いてもしようがないので、 ここでは Mew で受信した時に化けずに表示できる対応をします。\n対応コードは以下です。\n(defun my-mew-change-gb2312-for-outlook () \u0026#34;outlook 対応。 Outlook の gb2312 は gbk になっている。。。\u0026#34; (setq mew-cs-database-for-decoding (mapcar (lambda (X) (if (equal (car X) \u0026#34;gb2312\u0026#34;) (list (car X) \u0026#39;gbk) X)) mew-cs-database-for-decoding))) (eval-after-load \u0026#34;mew\u0026#34; \u0026#39;(my-mew-change-gb2312-for-outlook)) 以下で上記処理の説明をします。\nMew は MIME の charset と、 emacs の coding-system の紐付けを mew-cs-database-for-decoding で管理しています。\nこんな感じ。\n(defvar mew-cs-database-for-decoding `((\u0026#34;us-ascii\u0026#34; nil) (\u0026#34;iso-8859-1\u0026#34; iso-8859-1) (\u0026#34;iso-8859-2\u0026#34; iso-8859-2) (\u0026#34;iso-8859-3\u0026#34; iso-8859-3) (\u0026#34;iso-8859-4\u0026#34; iso-8859-4) (\u0026#34;iso-8859-5\u0026#34; iso-8859-5) (\u0026#34;iso-8859-6\u0026#34; iso-8859-6) (\u0026#34;iso-8859-7\u0026#34; iso-8859-7) (\u0026#34;iso-8859-8\u0026#34; iso-8859-8) (\u0026#34;iso-8859-8-i\u0026#34; iso-8859-8) ;; temporary solution (\u0026#34;iso-8859-9\u0026#34; iso-8859-9) (\u0026#34;iso-8859-15\u0026#34; iso-8859-15) (\u0026#34;iso-2022-cn\u0026#34; iso-2022-cn) (\u0026#34;iso-2022-cn-ext\u0026#34; iso-2022-cn-ext) (\u0026#34;gbk\u0026#34; gbk) (\u0026#34;gb2312\u0026#34; cn-gb-2312) ;; should be before cn-gb (\u0026#34;cn-gb\u0026#34; cn-gb-2312) この設定では、 MIME の gb2312 を cn-gb-2312 に紐付けしているので、 gb2312 を gbk の紐付けに変更しているのが先ほどのコードとなります。\n中国語圏とメールのやり取りしたときに何か問題がおこるかもですが、 自分にはそんな予定はないのでとりあえずこれで十分かな、と。\n","id":82,"section":"posts","summary":"Outlook は当初から評判が良くないため個人的には使用していません。 もうず〜〜〜〜〜と、 PC のメール環境は Mew を使用しています。 しかし、自分のメール送信・","tags":["mew","outlook"],"title":"Outlook で送信された日本語メールを Mew で受信すると文字化けする問題の対応","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-02-07-outlook/","year":"2019"},{"content":" ここ十年ほどまともにゲームしてないけど、 ネット検索しているときになんとなく気になった記事を読んでみたら、 ものスゴく面白かった。\n古めの記事だけど、載っけておく。\n格ゲー“暗黒の10年”は、『鉄拳』を世界一売れる格闘ゲームへと鍛え上げた──世界市場に活路を拓いた戦略を訊く【バンダイナムコ原田勝弘インタビュー／西田宗千佳連載】 http://news.denfaminicogamer.jp/interview/180428\n「久夛良木が面白かったからやってただけ」 プレイステーションの立役者に訊くその誕生秘話【丸山茂雄×川上量生】 http://news.denfaminicogamer.jp/interview/ps_history\n","id":83,"section":"posts","summary":"ここ十年ほどまともにゲームしてないけど、 ネット検索しているときになんとなく気になった記事を読んでみたら、 ものスゴく面白かった。 古めの記事だけ","tags":["etc"],"title":"電ファミニコゲーマー","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-02-03-interview/","year":"2019"},{"content":" 先日のデフォルト引数の指定し忘れ問題の対応を行なった。\n詳しくは、次の記事を参照。\n\u0026lt;https://qiita.com/dwarfJP/items/922c523d27a6d77fff6d\u0026gt;\n","id":84,"section":"posts","summary":"先日のデフォルト引数の指定し忘れ問題の対応を行なった。 詳しくは、次の記事を参照。 \u0026lt;https://qiita.com/dwarfJP/items/922c523d27a6d77fff6d\u0026gt;","tags":["proglang"],"title":"デフォルト引数の問題の対応","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-01-27-default-arg/","year":"2019"},{"content":" 関数をコールする際、引数を省略してコールできる機能をもつ言語が多く存在する。\nここでは、その機能を「デフォルト引数」と呼ぶ。\nデフォルト引数の例として、Lua のサンプルを次に示す。\nlocal function func( x, y ) print( x, y ) end func( \u0026#34;abc\u0026#34; ) // abc nil Lua では関数コール時に省略された引数は、 nil として処理される。 上記の func( \u0026#34;abc\u0026#34; ) は、引数 x, y のうち y が省略され、 実行すると abc nil が表示される。\nデフォルト引数は、引数が多い関数を呼び出す際に有効な機能である。 特に Lua は、引数の違いによって実行する関数を切り替える関数オーバーロードがないため、 デフォルト引数は良く使われる機能の一つである。\nしかし、デフォルト引数は便利である一方、不具合を発生させるリスクにもなる。\nそのリスクとは、意図してデフォルト引数を使用しているのか、 それとも、本来指定すべき引数を指定し忘れているのか、を判断出来ないということである。 タイプミス等で関数に渡す引数を間違えることが良くある。 それを判断できないというのはリスクが高い。\nLua の トランスコンパイラである LuneScript でも、同じ問題を抱えている。\n次は LuneScript のデフォルト引数のサンプルである。\nfn func( val: int! ): int { when! val { return val + 1; } return 0; } print( func( 1 ) ); // 2 print( func( nil ) ); // 0 print( func() ); // 0 このサンプルは、デフォルト引数を持つ func() の関数呼び出しを 3 パターン行なっている。\nfunc( 1 ) func( nil ) func() LuneScript は Lua と同じで、引数が省略されると nil が指定される。 よって、 func( nil ) と func() は同義である。 しかし、 func() が引数の指定忘れではないと、誰が保証できるだろうか？\nまた、 LuneScript では nilable は必ず省略可能なデフォルト引数になってしまう。\nデフォルト引数をサポートする多くの言語では、 デフォルト引数はデフォルト値を定義する必要がある。 一方 LuneScript では、nilable は必ずデフォルト引数になってしまう。\n「nil の時でも省略せずに明示すべき」としたくても、 現在の言語仕様ではそれが出来ない。\nこの辺りを解決する方法を検討している。\nただこれを解決するには、現状の言語仕様との互換を持たせるのは難しいかもしれない。\n","id":85,"section":"posts","summary":"関数をコールする際、引数を省略してコールできる機能をもつ言語が多く存在する。 ここでは、その機能を「デフォルト引数」と呼ぶ。 デフォルト引数の例","tags":["proglang"],"title":"デフォルト引数の問題","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-01-23-default-arg/","year":"2019"},{"content":" blog を始めるにあたって、 emacs から出来るだけ簡単に記事を更新できる環境にするために、 次の URL の情報をもとにいくつか調査。\n\u0026lt;https://orgmode.org/worg/org-blog-wiki.html\u0026gt;\nとりあえず org-mode + jekyll で構築してみた。\n以下は、org-mode + jekyll で環境構築から記事を投稿するまでの流れをまとめたメモ。\n使用するソフト ruby gem\nbundler jekyll jekyll-org jekyll は、 markdown でサイトを構築可能なツール。 markdown は書き慣れていないので org-mode で記事を書けるように jekyll plugin の jekyll-org を使用する。\nsetup install ruby install ruby-dev install gem $ gem install bundler jekyll jekyll-org jekyll setup blog のプロジェクトディレクトリ作成 $ cd blog_top $ jekyll new blog 初回は、ここで必要な gem がインストールされる。\nblog ディレクトリが生成され、blog ディレクトリ以下に幾つかのファイルが作成される。\n_config.yml を編集\n次の項目を編集\ntitle: email: description: twitter_username: github_username: plugins の項目に jekyll-org を追加 plugins: - jekyll-org jekyll-org の設定 \u0026lt;https://github.com/eggcaker/jekyll-org\u0026gt;\nGemfile に次を追加\n# jekyll-org gem \u0026#39;jekyll-org\u0026#39;, \u0026#39;\u0026gt;= 1.0.2\u0026#39; Gemfile 編集後、次のコマンドを実行\n$ bundle install github pages 用の設定 github pages の /blog に jekyll のディレクトリを作成した場合の設定\n_config.yml を編集\n次の項目を設定\nbaseurl: \u0026#34;/blog/site\u0026#34; url: \u0026#34;https://XXXXXXXX.github.io\u0026#34; destination: site jekyll の変換後の html は _site 以下に出力されるが、 github pages は _site 以下にはアクセスできないようなので、 destination: site で出力先を site に変更する。\n記事作成 _posts/ 以下に、次の名前のファイルを作成する\nYYYY-MM-DD-title.org 例えば 2019-01-01-hoge.org とする。\ntitle は、記事のタイトルで無くてもよい。 title は、 記事の URL に使用される。\n_posts/ の下にサブディレクトリを掘って、その中にファイルを作成しても良い。\n記事のフォーマット 次のメタ情報を入れれば、後は普通の org-mode 通りに記載可能。\n#+LAYOUT: post #+TITLE: org-mode で blog #+TAGS: org-mode jekyll +TAGS はオプション。\nワンポイントネタ URL を書くだけだとリンクにならない。\nリンクにする場合は URL を \u0026lt;\u0026gt; で囲む。 変換 書いた記事は jekyll を使って html に変換する。\n$ cd blog $ jekyll b 確認 jekyll は httpd サーバ機能を持つ。\n$ cd blog $ jekyll s この状態でブラウザで http://localhost:4000 にアクセスすれば、 変換後の内容を確認できる。\nなお、記事を修正すれば動的に変換されるので、 記事を修正後にブラウザをリロードすれば、修正後の内容を確認できる。\nhttpd サーバを終了する場合は、 Ctrl-C。\nネットワークアクセス $ jekyll s このコマンドで起動した httpd サーバは、 localhost でしかアクセスできない。\nつまり PC 外部からアクセス出来ない。\nセキュリティという意味では安全であるが、不便だったりする。\nPC 外部からアクセスしたい場合は、次のコマンドで httpd サーバを起動する。\n$ jekyll s --host 0.0.0.0 ","id":86,"section":"posts","summary":"blog を始めるにあたって、 emacs から出来るだけ簡単に記事を更新できる環境にするために、 次の URL の情報をもとにいくつか調査。 \u0026lt;https://orgmode.org/worg/org-blog-wiki.html\u0026gt; とりあえず org-mode + jekyll で構築して","tags":["org-mode","jekyll"],"title":"org-mode で blog","uri":"https://ifritjp.github.io/blog2/public/posts/2019/2019-01-17-setup-jekyll/","year":"2019"}],"tags":[{"title":"emacs","uri":"https://ifritjp.github.io/blog2/public/tags/emacs/"},{"title":"etc","uri":"https://ifritjp.github.io/blog2/public/tags/etc/"},{"title":"jekyll","uri":"https://ifritjp.github.io/blog2/public/tags/jekyll/"},{"title":"lua","uri":"https://ifritjp.github.io/blog2/public/tags/lua/"},{"title":"mew","uri":"https://ifritjp.github.io/blog2/public/tags/mew/"},{"title":"org-mode","uri":"https://ifritjp.github.io/blog2/public/tags/org-mode/"},{"title":"outlook","uri":"https://ifritjp.github.io/blog2/public/tags/outlook/"},{"title":"proglang","uri":"https://ifritjp.github.io/blog2/public/tags/proglang/"}]}